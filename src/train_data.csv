Вопрос;Эталонный ответ преподавателя;Ответ студента;Оценка
Примеры использования гистограммы;Гистограммы применяются для анализа распределения яркости в обработке изображений, контроля качества в производстве через анализ распределения параметров продукции;Использование гистограмм для визуального анализа данных в разных областях;2
Как специалисты анализируют данные в рамках big data?;Технологии big data позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Big data используется для обработки информации и улучшения решений.;3
Какие риски связаны с использованием нейронные сети в критически важных системах?;Нейронные сети помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Нейронные сети применяется в бизнесе и иногда в науке для анализа данных.;3
В чем преимущества применения NLP по сравнению с традиционными методами?;Nlp применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Nlp применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;4
Что такое Apache Spark SQL?;Модуль Spark для работы со структурированными данными с использованием SQL-подобного синтаксиса.;Возможность использовать SQL в Spark для работы с данными.;3
Какие способы визуализации корреляции были изучены в курсе Big Data?;Основные способы: корреляционная матрица, тепловая карта (heatmap), диаграмма рассеяния (scatter plot), графики зависимости и парные диаграммы (pairplot).;Используются scatter plot и матрица корреляции для визуализации.;3
Какие компании активно используют большие данные и зачем?;Большие данные применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;5
Как работает технология In-Memory Computing в современных СУБД?;Хранение и обработка данных в оперативной памяти вместо диска. Обеспечивает sub-millisecond latency для transactional и analytical workloads.;Работа с данными непосредственно в памяти. Дает экстремально низкую задержку для OLTP и OLAP систем, ускоряя выполнение запросов на порядки.;4
Свойства эластичности и надёжности сложных сетей;Эластичность - устойчивость к нагрузкам, надежность - отказоустойчивость. Зависит от структуры сети;Эластичность - как сеть держит нагрузку, надежность - как работает при отказах. Зависит от связей;3
Какие типы машинного обучения существуют?;Существует три типа машинного обучения: с учителем, без учителя и с подкреплением. Первый использует размеченные данные, второй — неразмеченные, третий — обучение через взаимодействие с средой.;Есть обучение с учителем и без учителя.;4
Каковы условия остановки ветвления дерева?;Условия остановки включают достижение максимальной глубины, минимального числа образцов в узле, отсутствие улучшения качества разбиения или достижение чистого узла.;Условия остановки включают максимальную глубину и минимальное число образцов в узле;5
Свойства описательных статистик;Меры центральной тенденции, меры изменчивости и показатели формы распределения данных;Меры центра, меры разброса и параметры формы распределения;4
Структуры и типы данных в R;Основные структуры данных в R включают векторы, матрицы, списки, data frames и factors, каждая с определенными свойствами и методами обработки;Векторы для атомарных данных, матрицы для таблиц чисел, списки для разнотипных данных, data frames для табличных данных;3
Какие риски связаны с применением data lakes?;Технологии data lakes позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Data lakes применяется в финансах, медицине, рекламе и IT, помогает анализировать данные и строить модели.;4
Какие методы использовать для обнаружения concept drift в ML моделей?;Statistical tests (KS test, PSI), monitoring performance metrics, drift detection algorithms (ADWIN, DDM), анализ распределения предсказаний и фактических значений.;Методы обнаружения когда модель устаревает из-за изменений в данных.;2
Архитектура хранилищ данных;Архитектура включает уровни сбора, обработки, хранения и анализа данных с использованием ETL-процессов, data lakes и витрин данных;Архитектура включает ETL-процессы и data lakes;5
Что такое Data Mining и какие задачи он решает?;Data Mining — интеллектуальный анализ данных, направленный на выявление скрытых закономерностей. Основные задачи: классификация, кластеризация, ассоциативные правила, прогнозирование.;Data Mining — анализ данных для поиска зависимостей.;4
Векторы, матрицы, фреймы и факторы в R. Сходство и различия, способы обработки.;Векторы и матрицы содержат данные одного типа, data.frame — разных типов, factor используется для категориальных данных. Обработка осуществляется функциями length(), dim(), apply(), summary().;Все объекты R одинаковые, нет разницы между вектором и матрицей.;2
Какие реальные примеры использования data lakes существуют?;Технологии data lakes позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Data lakes используется бизнесом для оптимизации процессов, анализа клиентов и прогнозирования.;4
В чем различия между R и Python для анализа данных?;R - специализирован для статистики и визуализации, богатые статистические пакеты. Python - универсальный, лучше для ML и production систем. R удобнее для исследований, Python - для промышленной разработки.;Два языка для работы с данными с разными возможностями.;2
Что такое 'регрессия' в машинном обучении?;Регрессия — это метод моделирования зависимости между зависимой переменной и одной или несколькими независимыми переменными.;Регрессия — это способ определить зависимость между двумя параметрами.;4
Какие риски связаны с использованием data mining в критически важных системах?;Data mining применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Data mining — это что-то про компьютеры. Применяется редко.;2
Что такое ETL-процессы и какие задачи оно решает?;Etl-процессы помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Etl-процессы применяется в бизнесе и иногда в науке для анализа данных.;3
Где применяется компьютерное зрение в промышленности и бизнесе?;Компьютерное зрение помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;4
Какие основные инструменты и технологии используются для работы с модели прогнозирования?;Модели прогнозирования применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Модели прогнозирования — это что-то про компьютеры. Применяется редко.;2
Какие реальные примеры использования обработка потоковых данных существуют?;Обработка потоковых данных используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Обработка потоковых данных применяется в финансах, медицине, рекламе и IT, помогает анализировать данные и строить модели.;4
Что такое reinforcement learning и где применяется?;Reinforcement learning - обучение с подкреплением, где агент учится через взаимодействие со средой, применяется в робототехнике, играх и рекомендательных системах;Обучение через взаимодействие;2
Виды связи между переменными при корреляции;Связи бывают положительные, отрицательные и нулевые.;Есть прямая и обратная зависимость, иногда её нет.;4
«Меры изменчивости»: что к ним относится?;К мерам изменчивости относятся дисперсия, стандартное отклонение, размах, межквартильный размах и среднее абсолютное отклонение;Основные меры изменчивости статистических данных;4
Разница описательных и предсказательных задач;Описательные анализируют текущие данные, предсказательные строят прогнозы на будущее;Описательные задачи анализируют историю, предсказательные строят модели;4
Почему технологии хранилища данных стали критически важны?;Хранилища данных используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Хранилища данных обеспечивает анализ потоковых данных, улучшает прогнозирование, помогает автоматизировать процессы и повышает точность аналитических моделей.;5
Нормальное распределение;Нормальное распределение характеризуется симметричной колоколообразной формой и определенными параметрами центра и dispersion;Симметричное распределение вероятностей;3
Что такое Apache Kafka;Apache Kafka — это распределенная потоковая платформа для обработки потоков данных в реальном времени. Состоит из производителей, потребителей, брокеров и тем.;Apache Kafka — это распределенная, горизонтально масштабируемая платформа потоковой обработки, которая функционирует как отказоустойчивый publish-subscribe messaging system, обеспечивающий обработку миллионов сообщений в секунду с гарантированной доставкой и сохранением порядка сообщений.;5
Что такое F1-score?;Гармоническое среднее между precision и recall.;Комбинированная метрика качества для задач классификации, учитывающая и точность, и полноту.;3
Метрики качества для компьютерного зрения;"Accuracy, Precision, Recall, F1-score для классификации; mAP, IoU для детекции; Dice coefficient для сегментации";Метрики для CV задач;2
С какими проблемами сталкиваются при применении рекомендательные системы, и как их решают?;Рекомендательные системы применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Рекомендательные системы нужно только программистам.;2
Что понимается под признаковым пространством (feature space)?;Признаковое пространство — это многомерное пространство, где каждая ось соответствует отдельному признаку, а каждая точка — объекту с набором характеристик.;Feature space — это многомерное пространство признаков, в котором описываются объекты.;4
Как обеспечить воспроизводимость экспериментов в ML и data science?;Version control для кода и данных, фиксация seed значений, контейнеризация (Docker), detailed logging, MLflow для отслеживания экспериментов.;Сохранять код, данные и параметры экспериментов, использовать одинаковое окружение и фиксировать случайные seed'ы.;3
Понятия репликации и шардинга для хранилищ данных.;Репликация — копирование данных между узлами для повышения отказоустойчивости. Шардинг — горизонтальное разделение данных на сегменты (shards) для масштабирования. Используются в NoSQL и распределённых СУБД.;Репликация и шардинг — это методы резервного копирования.;3
Какие реальные примеры использования in-memory обработка существуют?;In-memory обработка используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;In-memory обработка применяется в финансах, медицине, рекламе и IT, помогает анализировать данные и строить модели.;4
Мотивация происхождения NoSQL;Необходимость работы с неструктурированными данными и горизонтального масштабирования систем;Потребность в масштабируемости и гибкости схем данных;3
Что такое регуляризация в машинном обучении?;Регуляризация — это метод предотвращения переобучения за счёт добавления штрафа за сложность модели в функцию потерь (например, L1, L2).;Регуляризация помогает уменьшить переобучение, добавляя штраф за большие коэффициенты в модели.;5
Каковы факторы, влияющие на коэффициент корреляции?;Коэффициент корреляции зависит от линейности данных, наличия выбросов, дисперсии, размера выборки и точности измерений.;Коэффициент корреляции может меняться из-за выбросов, объема данных и нелинейной зависимости.;3
Какие риски связаны с применением масштабируемые системы?;Масштабируемые системы используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Масштабируемые системы почти нигде не применяется. Это просто большие таблицы.;2
Какие методы использовать для обнаружения concept drift в ML моделей?;Statistical tests (KS test, PSI), monitoring performance metrics, drift detection algorithms (ADWIN, DDM), анализ распределения предсказаний и фактических значений.;Статистические тесты распределений, мониторинг accuracy/precision/recall, алгоритмы детектирования дрейфа, анализ изменений в данных и предсказаниях модели.;4
Сравнительный анализ алгоритмов кластеризации;Алгоритмы кластеризации сравниваются по масштабируемости, чувствительности к шуму, способности находить кластеры сложной формы и вычислительной сложности;Сравнение разных методов кластеризации по их характеристикам и производительности;2
Как внедрение компьютерное зрение влияет на процессы в организациях?;Компьютерное зрение применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Помогает работать с данными и строить модели.;3
Что такое data versioning?;Контроль версий для наборов данных и их метаданных;Версионирование данных;2
Как организовать versioning для ML моделей в production?;Model registry, version metadata, A/B testing инфраструктура, rollback capabilities, dependency tracking, reproducibility guarantees.;Система управления версиями ML моделей с возможностью тестирования и отката.;3
Какие алгоритмы лежат в основе методов выделения сообществ? Дайте общее описание шагов выполнения этих алгоритмов.;Алгоритмы выделения сообществ включают методы модульности (Лувен, Ньюман-Гирван), спектральные методы и итерационные подходы. Основные шаги: построение графа, вычисление меры модульности Q, итеративное объединение или разбиение узлов до оптимума Q.;Методы выделения сообществ просто группируют узлы по количеству связей.;3
Какие проблемы возникают при использовании data lakes?;Data lakes используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Data lakes используется бизнесом для оптимизации процессов, анализа клиентов и прогнозирования.;4
Что такое Edge AI и какие вызовы оно решает по сравнению с cloud AI?;Выполнение AI моделей на edge устройствах вместо облака. Решает проблемы latency, bandwidth, privacy, offline работы в IoT, мобильных и embedded системах.;Работа AI моделей непосредственно на устройствах. Решает проблемы скорости, приватности и зависимости от интернета в сравнении с облачными решениями.;3
Что такое dropout в нейросетях?;Метод регуляризации, при котором случайно выбранные нейроны игнорируются во время обучения для предотвращения переобучения.;Регуляризация через случайное отключение нейронов при обучении. Улучшает обобщающую способность сети.;4
Основные вызовы больших данных;Volume, Velocity, Variety, Veracity - основные характеристики и challenges больших данных;Volume, Velocity, Variety, Veracity представляют основные вызовы больших данных;5
Что такое XGBoost?;Библиотека для градиентного бустинга с оптимизацией производительности и регуляризацией.;Алгоритм градиентного бустинга с оптимизациями для скорости и качества. Использует деревья решений с регуляризацией и эффективной обработкой пропусков.;5
Что такое Apache Kafka и для каких задач он используется?;Распределенная потоковая платформа для обработки данных в реальном времени. Используется для построения data pipelines, event-driven архитектур, streaming приложений.;Технология для обработки данных в реальном времени.;2
Что такое data locality в Hadoop?;Принцип обработки данных на том же узле где они хранятся для уменьшения сетевого трафика;Принцип оптимизации в Hadoop;2
Как выбрать между колоночным и строчным хранением данных для аналитических нагрузок?;Колоночное хранилище лучше для аналитических запросов с агрегациями по немногим колонкам, строчное - для OLTP с операциями над целыми строками. Использовать колоночные форматы (Parquet, ORC) для data warehousing.;Колоночные форматы эффективны когда запросы затрагивают несколько колонок, так как читаются только нужные данные. Строчные лучше для операций со всеми полями записи. Для аналитики обычно выбирают колоночное хранение.;5
Основные вызовы больших данных;Основные вызовы больших данных включают объем (Volume), скорость (Velocity), разнообразие (Variety) и достоверность (Veracity) данных;Вызовы: Volume, Velocity, Variety, Veracity;4
Какие риски связаны с применением data warehouses?;Технологии data warehouses позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Data warehouses используется для обработки информации и улучшения решений.;3
Охарактеризовать конструкции языка R;R похож на Python, но со своими особенностями.;R нужен для работы с числами.;3
Основные вызовы больших данных;Ключевые вызовы включают объем (Volume), скорость (Velocity), разнообразие (Variety) и достоверность (Veracity) данных, требующие специальных подходов к обработке;Volume - терабайты данных, Velocity - потоковая обработка, Variety - структурированные и неструктурированные данные, Veracity - надежность и качество данных;4
Какие основные инструменты и технологии используются для работы с классификация данных?;Классификация данных используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Классификация данных применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;4
Что такое процесс ETL и каковы его этапы?;ETL (Extract, Transform, Load) — это процесс извлечения данных из источников, их преобразования в нужный формат и загрузки в целевое хранилище. Он является ключевым в интеграции данных.;ETL — это метод обработки данных: взять, поменять и загрузить в хранилище.;5
Какие метрики используются для оценки моделей в задачах мультиклассовой классификации?;Для мультиклассовой классификации используются accuracy, macro/micro averaged precision/recall, F1-score и confusion matrix для детального анализа ошибок;Accuracy, precision, recall и F1-score для многоклассовых задач;4
Принципы и инструменты аналитики. Задачи и компетенции аналитиков Big Data;Принципы включают data-driven подход, итеративность, автоматизацию. Инструменты: Hadoop, Spark, NoSQL. Задачи: анализ паттернов, прогнозирование. Компетенции: статистика, программирование, доменные знания;Принципы, инструменты и навыки аналитиков;3
Зачем нужно уменьшение размерностей?;Уменьшение размерностей позволяет снизить вычислительную сложность, устранить мультиколлинеарность и улучшить интерпретируемость моделей;Уменьшение размерностей нужно для снижения вычислительной сложности;5
Векторы, матрицы, фреймы в R;Вектор - одномерный массив, матрица - двумерный, фрейм - таблица с разными типами данных;Векторы для одного типа, матрицы для чисел, фреймы для таблиц;3
Что такое Data Governance;Data Governance — это система управления доступностью, usability, integrity и безопасностью данных в организации через политики, стандарты и процессы.;Комплексная система управления корпоративными данными с политиками и стандартами;5
Что такое Data Lineage;Data Lineage — это отслеживание происхождения, перемещения и трансформации данных от источника до конечного использования, включая все промежуточные этапы.;Полное отслеживание жизненного цикла данных с трансформациями;5
Перечислите основные метрики больших графов.;Основные метрики: степень вершины (degree), средняя длина пути (L), кластерный коэффициент (C), центральность по посредничеству (betweenness), собственная центральность (eigenvector), плотность графа и диаметр.;Метрики графов включают степень вершины, центральности и диаметр, измеряющие структуру сети.;5
Достоинства и недостатки деревьев решений;"Достоинства: интерпретируемость, не требуют нормализации; недостатки: склонность к переобучению, нестабильность";Преимущества и ограничения деревьев решений;4
Метрики качества для компьютерного зрения;"Accuracy, Precision, Recall для классификации; mAP, IoU для детекции объектов; Dice coefficient для сегментации изображений";"Классификация: Accuracy, Precision, Recall; детекция: mAP, IoU; сегментация: Dice coefficient для оценки качества";5
Что такое Apache Arrow?;Формат in-memory для колоночного хранения данных с нулевой сериализацией для ускорения анализа.;Способ хранения данных в памяти для ускорения обработки. Используется в Big Data инструментах.;3
Как развитие компьютерное зрение влияет на будущее цифровых технологий?;Компьютерное зрение используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;4
Что такое recall и precision?;Precision - точность предсказаний, recall - полнота охвата реальных позитивных случаев.;Precision измеряет качество позитивных предсказаний, а recall - насколько хорошо модель находит все позитивные случаи.;4
Параметрическая модель статистического обучения;Модель с фиксированным числом параметров, заданная функциональной формой и распределением ошибок;Модель с параметрами для обучения;2
Что такое Apache Spark и в чем его преимущество перед Hadoop MapReduce?;Это фреймворк для распределенной обработки больших данных. Ключевое преимущество — выполнение операций в оперативной памяти (in-memory), что значительно ускоряет итерационные алгоритмы и интерактивную аналитику по сравнению с дисковыми операциями MapReduce.;Apache Spark — это распределенная вычислительная система, которая обрабатывает данные в оперативной памяти, что делает ее намного быстрее Hadoop MapReduce для итерационных задач и интерактивных запросов, так как избегает многократных обращений к диску.;5
Какие реальные примеры использования масштабируемые системы существуют?;Масштабируемые системы используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Технологии масштабируемые системы позволяют компаниям обрабатывать большие объёмы разнородных данных, выявлять сложные закономерности и принимать обоснованные решения.;5
Разновидности сложных сетей;Сети можно классифицировать на однородные, масштабно-инвариантные, малого мира и иерархические в зависимости от их структурных свойств;Однородные сети с равномерным распределением связей, масштабно-инвариантные со степенным распределением, сети малого мира с высокой кластеризацией и короткими путями, иерархические с модульной структурой;5
Алгоритмы выделения сообществ;Алгоритмы Louvain, Girvan-Newman, Label Propagation используются для обнаружения сообществ в сложных сетях на основе модульности и связности;Louvain использует жадную оптимизацию модульности, Girvan-Newman последовательно удаляет ребра с максимальной betweenness;4
Где применяется классификация данных в промышленности и бизнесе?;Классификация данных используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;5
Обучение с подкреплением и ансамбли;Обучение с подкреплением основано на взаимодействии со средой, ансамбли комбинируют несколько моделей;Два подхода в машинном обучении;2
Что такое Data Lineage;Data Lineage — это отслеживание происхождения, перемещения и трансформации данных от источника до конечного использования, включая все промежуточные этапы.;Отслеживание пути данных;3
Свойства эластичности и надёжности сложных сетей;"Эластичность - устойчивость к нагрузкам, надежность - отказоустойчивость; зависят от структуры и связности сети";Эластичность это устойчивость к нагрузкам, надежность к отказам;5
Алгоритмы классификации;Основные алгоритмы включают логистическую регрессию, деревья решений, случайный лес, метод опорных векторов и наивный байесовский классификатор;Линейные модели (Logistic Regression), tree-based (Decision Trees, Random Forest), instance-based (k-NN), probabilistic (Naive Bayes), kernel methods (SVM);4
Как работает механизм Attention в трансформерах и почему он революционен для NLP?;Взвешенная агрегация информации из всех позиций последовательности. Революционен благодаря ability улавливать long-range зависимости и параллелизации в отличие от RNN.;Механизм взвешивания важности разных частей входных данных. Революционен для NLP потому что позволяет обрабатывать длинные последовательности и учитывать глобальный контекст эффективнее RNN.;4
Принцип массивных вычислений в R;Векторизованные операции в R позволяют эффективно обрабатывать большие объемы данных без использования циклов через применение оптимизированных встроенных функций и операций;Быстрые вычисления с большими массивами данных в языке программирования R;2
"Понятие корреляции; коэффициенты Пирсона, Спирмена, Кендалла";"Корреляция - мера линейной связи; Пирсон для нормальных данных, Спирмен для рангов, Кендалл для порядковых данных";Корреляция и ее коэффициенты;4
Как работает Federated Learning и в каких сценариях он наиболее эффективен?;Обучение моделей на децентрализованных данных без их передачи на сервер. Эффективен для privacy-sensitive сценариев: healthcare, мобильные устройства, где данные нельзя централизовать.;Подход к обучению моделей на данных которые остаются на устройствах пользователей. Эффективен для защиты приватности и работы с распределенными данными.;3
С какими проблемами сталкиваются при применении анализ данных, и как их решают?;Анализ данных используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Анализ данных нужно только программистам.;2
Что понимается под признаковым пространством (feature space)?;Признаковое пространство — это многомерное пространство, где каждая ось соответствует отдельному признаку, а каждая точка — объекту с набором характеристик.;Признаковое пространство — это пространство, где каждый объект представлен набором признаков.;5
Какие проблемы возникают при использовании масштабируемые системы?;Масштабируемые системы используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Технологии позволяют улучшать качество аналитики, находить закономерности и предсказывать события.;4
Сравнительный анализ алгоритмов кластеризации;Алгоритмы кластеризации сравниваются по масштабируемости, устойчивости к шуму и вычислительной эффективности;Сравнение алгоритмов кластеризации;2
Перечислите разновидности сложных сетей, назовите их характеристики.;Разновидности: случайные графы (Эрдёша–Реньи), безмасштабные сети (Барбаши–Альберт), сети тесного мира (Уоттса–Строгаца), ориентированные и взвешенные сети.;Различают случайные графы, сети тесного мира и безмасштабные, у них разные топологии и распределения степеней.;3
Что такое уровень значимости, как он определяется, как влияет на решение о принятии гипотезы?;Уровень значимости ? — вероятность ошибки первого рода (отклонение H0 при её истинности). Обычно ? = 0.05. Если p < ?, H0 отклоняется. Чем меньше ?, тем строже критерий.;Уровень значимости — это вероятность ошибки первого рода, обычно 0.05.;5
Примеры задач с большими графами;Большие графы применяются для анализа социальных сетей (обнаружение сообществ, измерение влияния), в рекомендательных системах (коллаборативная фильтрация), биоинформатике (изучение взаимодействий белков) и веб-аналитике (ранжирование страниц);Анализ социальных взаимодействий, построение рекомендаций и исследование биологических систем являются основными областями применения больших графов;4
Как развитие компьютерное зрение влияет на будущее цифровых технологий?;Компьютерное зрение используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;5
Что такое data compression в Big Data?;Уменьшение размера данных для экономии места и ускорения передачи;Оптимизация хранения данных;2
Как принято формулировать нулевую гипотезу;Нулевая гипотеза формулируется как утверждение об отсутствии статистически значимого эффекта или различий;Гипотеза об отсутствии эффекта;2
Какие проблемы возникают при использовании мониторинг больших данных?;Мониторинг больших данных используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Мониторинг больших данных используется бизнесом для оптимизации процессов, анализа клиентов и прогнозирования.;4
Какие алгоритмы машинного обучения относятся к обучению с учителем?;Линейная регрессия, логистическая регрессия, SVM, деревья решений, случайный лес, градиентный бустинг, k-NN, нейронные сети. Все используют размеченные данные для обучения.;Регрессия и классификация: линейные модели, деревья, SVM, нейросети, ансамбли. Используют данные с метками для обучения предсказательных моделей.;5
Как внедрение классификация данных влияет на процессы в организациях?;Классификация данных используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;4
Как внедрение обработка данных влияет на процессы в организациях?;Обработка данных применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Обработка данных нужно только программистам.;2
Что такое Apache Hive?;Система управления данными в Hadoop, предоставляющая SQL-подобный язык запросов (HiveQL) для обработки структурированных данных в распределенном хранилище HDFS, с преобразованием запросов в MapReduce или Tez jobs.;Инструмент для выполнения SQL запросов к данным в HDFS. Преобразует HiveQL в задачи для обработки больших данных.;4
Что такое Hadoop и каковы его основные компоненты?;Hadoop — это фреймворк для распределенной обработки больших данных. Основные компоненты: HDFS (файловая система), YARN (планировщик ресурсов), MapReduce (модель вычислений).;Hadoop — программа для работы с данными в распределенной среде.;3
Структуры и типы данных в R;Векторы, матрицы, списки, фреймы данных, факторы - основные структуры хранения данных;Разные типы данных в языке R;2
Какие инструменты используются для работы с data warehouses?;Технологии data warehouses позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Технологии data warehouses позволяют компаниям обрабатывать большие объёмы разнородных данных, выявлять сложные закономерности и принимать обоснованные решения.;5
Что такое Kubernetes?;Оркестратор контейнеров для автоматизации развертывания и управления приложениями.;Платформа для запуска и управления Docker контейнерами в больших масштабах.;3
Фундаментальное свойство статистического обучения;Компромисс между смещением и дисперсией (bias-variance tradeoff) - ключевое свойство, определяющее обобщающую способность моделей;Компромисс между смещением и дисперсией;4
Какие риски связаны с применением ETL-пайплайны?;Etl-пайплайны помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Etl-пайплайны обеспечивает анализ потоковых данных, улучшает прогнозирование, помогает автоматизировать процессы и повышает точность аналитических моделей.;5
В чем сходства и различия векторов, матриц, фреймов и факторов в R?;Векторы и матрицы - гомогенные данные, фреймы - гетерогенные по колонкам. Факторы - категориальные с уровнями. Все поддерживают индексацию, но разную обработку.;Разные типы данных в R с разными свойствами.;2
Что такое Data Lineage;Data Lineage — это отслеживание происхождения, перемещения и трансформации данных от источника до конечного использования, включая все промежуточные этапы.;Документирование полного пути данных от источника;4
Что такое Apache Kafka?;Распределенная потоковая платформа обмена сообщениями для обработки потоков данных в реальном времени.;Apache Kafka - это распределенная потоковая платформа, которая работает как publish-subscribe messaging system, позволяющая обрабатывать большие объемы потоковых данных в реальном времени с высокой пропускной способностью и отказоустойчивостью.;5
Перечислите основные задачи анализа сетей на графах. Приведите примеры.;Основные задачи: поиск сообществ, определение центральности, анализ кратчайших путей, выявление аномалий, моделирование распространения информации.;Задачи анализа сетей включают: выявление сообществ, определение центральных вершин (degree, betweenness, closeness), вычисление кратчайших путей (алгоритмы Дейкстры, Флойда–Уоршелла), анализ потоков и распространения информации в социальных и коммуникационных сетях.;5
Разновидности сложных сетей;Сети можно классифицировать на однородные, масштабно-инвариантные, малого мира и иерархические в зависимости от их структурных свойств;Сети малого мира имеют высокий коэффициент кластеризации и короткие средние пути, безмасштабные сети следуют степенному закону распределения;4
Обучение с учителем и без учителя;Обучение с учителем использует размеченные данные, а без учителя обнаруживает скрытые структуры в данных без меток;Обучение с учителем использует размеченные данные для построения моделей;5
Какие инструменты используются для работы с обработка потоковых данных?;Обработка потоковых данных используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Обработка потоковых данных используется для обработки информации и улучшения решений.;3
Когда использовать Graph Database вместо реляционной для хранения данных?;Graph DB лучше когда данные имеют сложные связи и запросы ориентированы на отношения (социальные сети, рекомендации, fraud detection). Реляционные - для структурированных данных с простыми связями.;Graph DB когда важны связи между объектами, реляционные для табличных данных.;3
Почему организации переходят на технологии data lakes?;Data lakes используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Data lakes применяется в некоторых компаниях для анализа данных.;3
Генеральная совокупность и выборка;Совокупность - все объекты исследования, выборка - часть совокупности для анализа;Генеральная совокупность и репрезентативная выборка из нее;3
Каковы условия остановки ветвления дерева?;Остановка при достижении максимальной глубины, минимального числа samples в узле, отсутствии улучшения качества или pure node;Условия остановки включают максимальную глубину и минимальное число samples;5
Какие стратегии использовать для обработки данных с changing schema в data lakes?;Schema evolution, schema on read, использование форматов с backward compatibility, metadata management, data validation pipelines.;Schema evolution, schema on read, совместимые форматы. Подходы к изменяющимся схемам в data lakes.;4
Какие реальные кейсы демонстрируют эффективность большие данные?;Большие данные применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Большие данные нужно только программистам.;2
Что такое топик в Kafka;Топик — это логический канал или категория, в которую производители публикуют сообщения и из которой потребители читают сообщения. Сообщения в топике упорядочены.;Топик в Kafka — это категория или feed name, к которой публикуются сообщения. Каждый топик разделен на партиции — упорядоченные, неизменяемые последовательности записей, которые реплицируются и распределяются по кластеру для обеспечения отказоустойчивости, масштабируемости и параллельной обработки.;5
Что такое нейронные сети и какие задачи оно решает?;Нейронные сети помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Нейронные сети применяется в бизнесе и иногда в науке для анализа данных.;3
Примеры задач с большими графами;Большие графы применяются для анализа социальных сетей (обнаружение сообществ, измерение влияния), в рекомендательных системах (коллаборативная фильтрация), биоинформатике (изучение взаимодействий белков) и веб-аналитике (ранжирование страниц);Графовые структуры используются для решения разнообразных задач в различных предметных областях;2
Какие проблемы возникают при использовании распределённые вычисления?;Технологии распределённые вычисления позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Распределённые вычисления обеспечивает анализ потоковых данных, улучшает прогнозирование, помогает автоматизировать процессы и повышает точность аналитических моделей.;5
Определение термина «большие данные»;Большие данные представляют собой огромные объемы разнородной информации, требующие специальных технологий обработки;Большие данные это огромные объемы разнородной информации;5
Как внедрение NLP влияет на процессы в организациях?;Nlp используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Помогает работать с данными и строить модели.;3
Что такое Data Lake и чем он отличается от Data Warehouse?;Data Lake — это централизованное хранилище, где данные сохраняются в исходном виде. Data Warehouse — структурированное хранилище для анализа. Главное отличие — степень структурированности данных.;Data Lake — это хранилище сырых данных, пригодное для гибкой обработки, в отличие от Data Warehouse, где данные уже обработаны и структурированы для отчетности.;4
Свойства эластичности и надежности сложных сетей.;Эластичность описывает способность сети сохранять функции при удалении вершин, надежность — устойчивость к отказам и атакам. Безмасштабные сети устойчивы к случайным сбоям, но уязвимы к целевым атакам.;Эластичность характеризует способность сети сохранять основные функции при нарушениях структуры  надежность отражает устойчивость к отказам узлов и ребер. Безмасштабные сети обладают высокой устойчивостью к случайным сбоям.;4
Какие подходы использовать для обработки графовых данных в распределенных системах?;Специализированные графовые базы (Neo4j), графовые обработчики (GraphX), алгоритмы для распределенных графов (Pregel), оптимизация хранения графовых структур, partitioning по вершинам или ребрам.;Специальные системы для работы с графами, алгоритмы для распределенной обработки связей между данными.;3
Что такое data quality monitoring?;Непрерывный мониторинг качества данных по метрикам completeness, accuracy, consistency;Проверка качества данных;3
Достоинства и недостатки деревьев решений;Достоинства: интерпретируемость, работа с категориальными признаками, не требуют масштабирования. Недостатки: склонность к переобучению, нестабильность, чувствительность к шуму;Достоинства интерпретируемости и недостатки склонности к переобучению;5
Принципы глубокого обучения в нейросетях. Преимущества сверточных сетей.;Глубокое обучение использует многослойные нейронные сети (MLP, CNN, RNN) для автоматического извлечения признаков. CNN эффективны в задачах CV благодаря сверткам (convolution) и pooling. Формула свертки: y = ?(x*w).;CNN применяются для работы с картинками, потому что они выделяют признаки.;4
Примеры задач с большими графами;Большие графы используются в социальных сетях, рекомендательных системах и биоинформатике для анализа связей;Графы в анализе данных;2
Как развивается направление data lakes в последние годы?;Технологии data lakes позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Это что?то связанное с данными, но используется редко.;2
Какие навыки необходимы специалисту для работы с data mining?;Data mining применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;4
Как внедрение data mining влияет на процессы в организациях?;Data mining используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;5
Векторы, матрицы, фреймы в R;Векторы хранят однотипные данные, матрицы - двумерные массивы, фреймы - таблицы с разными типами колонок;Разные структуры для хранения данных в R;4
Типы языка R, примеры;Вектор, матрица, список, фрейм данных, фактор;Вектор (c(1,2,3)), матрица (matrix(1:4,2)), список (list(a=1)), фрейм (data.frame()), фактор (factor()) для категориальных данных;5
Какие гарантии доставки предоставляет Kafka;At most once: сообщения могут быть потеряны. At least once: сообщения могут быть доставлены повторно. Exactly once: каждое сообщение доставляется ровно один раз.;Kafka обеспечивает три семантики доставки: at-most-once (потенциальная потеря сообщений), at-least-once (гарантированная доставка с возможными дубликатами) и exactly-once (идиоматическая обработка через транзакционные producer'ы и идемпотентность, исключающая дублирование и потери).;5
Какие метрики используются для оценки качества регрессионных моделей?;MSE, RMSE, MAE, R?, MAPE. Каждая метрика имеет свои преимущества: MSE чувствительна к выбросам, MAE более устойчива, R? показывает долю объясненной дисперсии.;MSE (средняя квадратичная ошибка), RMSE, MAE (средняя абсолютная), R-квадрат, MAPE. Выбор зависит от задачи и важности больших ошибок.;5
Какие инструменты используются для работы с масштабируемые системы?;Технологии масштабируемые системы позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Технологии позволяют улучшать качество аналитики, находить закономерности и предсказывать события.;4
Назовите и поясните меры качества для языковых моделей.;Меры: Perplexity = exp(-1/N * ? log P(w_i)), BLEU (оценка совпадений n-грамм с эталоном), ROUGE (recall на уровне фраз), METEOR (комбинация точности и полноты).;Перплексия, BLEU, ROUGE — стандартные метрики для NLP. Перплексия = exp(-1/N * ? log P(w_i)).;5
Как обеспечить воспроизводимость экспериментов в ML и data science?;Version control для кода и данных, фиксация seed значений, контейнеризация (Docker), detailed logging, MLflow для отслеживания экспериментов.;Сохранять все необходимое чтобы повторить эксперимент.;2
Требования ACID. CAP-теорема, BASE архитектура: как и к каким хранилищам данных эти понятия применяются.;ACID (Atomicity, Consistency, Isolation, Durability) — свойства транзакционных систем (OLTP). CAP-теорема утверждает невозможность одновременного обеспечения согласованности (C), доступности (A) и устойчивости к разделению (P). BASE (Basically Available, Soft-state, Eventually consistent) описывает принципы NoSQL систем.;ACID — это правила баз данных, CAP описывает баланс, BASE относится к NoSQL.;4
Почему организации переходят на технологии кластеризация данных?;Кластеризация данных используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Это что?то связанное с данными, но используется редко.;2
Как развивается направление in-memory обработка в последние годы?;Технологии in-memory обработка позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Технологии позволяют улучшать качество аналитики, находить закономерности и предсказывать события.;4
Что такое Apache Airflow?;Платформа для оркестрации и мониторинга рабочих процессов данных.;Инструмент для автоматизации задач в data engineering.;2
Как выбрать между реляционной и документной БД для хранения сложных структур?;Реляционная для строгой схемы и сложных запросов, документная для гибкой схемы и иерархических данных. Выбор зависит от требований к целостности и запросам.;Реляционная для структурированных данных, документная для гибких схем. Выбор based on структуры данных и типов запросов.;4
Какие подходы использовать для feature selection в задачах с тысячами признаков?;Filter methods (correlation, mutual info), wrapper methods (recursive feature elimination), embedded methods (L1 regularization), domain knowledge. Начинать с фильтров для быстрого сокращения.;Статистические методы, алгоритмические подходы и экспертные знания для выбора наиболее важных признаков из тысяч.;3
Где применяется data mining в промышленности и бизнесе?;Data mining применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Это просто работа с таблицами. Не очень полезно.;2
Что такое 'регуляризация' в машинном обучении?;Регуляризация — это метод уменьшения переобучения за счёт добавления штрафов к функции потерь.;Регуляризация помогает модели не переобучаться.;4
Что означает 'Batch Normalization'?;Batch Normalization — это техника нормализации входов слоёв нейросети, ускоряющая обучение и повышающая стабильность.;Batch Normalization делает сеть устойчивой.;2
Почему организации переходят на технологии хранилища данных?;Хранилища данных используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Это что?то связанное с данными, но используется редко.;2
Как большие данные используется в научных исследованиях?;Большие данные используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;4
Какие методы использовать для обработки данных с высокой cardinality в feature engineering?;Target encoding, hashing trick, frequency encoding, embedding learning, categorical embedding с нейросетями, grouping редких категорий.;Target encoding, hashing, frequency encoding, embedding. Методы для категориальных данных со многими значениями.;4
Какие риски связаны с использованием модели прогнозирования в критически важных системах?;Модели прогнозирования используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;5
Что такое feature store?;Централизованное хранилище для управления и обслуживания признаков ML моделей;Хранилище признаков для машинного обучения;4
Использование гистограммы для обработки фото;Гистограммы яркости используются для анализа тонального диапазона изображений, коррекции контраста и выполнения операций по улучшению качества;Гистограммы позволяют анализировать распределение тонов, выполнять выравнивание гистограммы для улучшения контраста и корректировать цветовой баланс;4
Как NLP используется в научных исследованиях?;Nlp применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Nlp применяется в бизнесе и иногда в науке для анализа данных.;3
Какие этапы включает проект, основанный на использовании предиктивная аналитика?;Предиктивная аналитика используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Предиктивная аналитика применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;5
Что такое data observability?;Способность понимать состояние данных через мониторинг, отслеживание и оповещения;Комплексный подход к пониманию здоровья данных через мониторинг, трейсинг и алертинг;5
Как внедрение глубокое обучение влияет на процессы в организациях?;Глубокое обучение помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Глубокое обучение применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;5
Что такое 'оценка точности модели'?;Оценка точности модели — это процесс измерения доли правильных предсказаний модели относительно всех предсказаний.;Это сравнение данных и результатов без формул.;2
Какие бывают виды регрессионного анализа?;"Линейная, полиномиальная, логистическая, ридж, лассо регрессия; каждая решает специфические задачи";Линейная, логистическая, регуляризованная;3
Какие подходы использовать для оптимизации памяти в Python при обработке больших данных?;Использование генераторов, efficient data structures, memory mapping, chunk processing, удаление неиспользуемых объектов, использование специализированных библиотек.;Методы уменьшения использования памяти в Python при работе с большими данными.;3
Как выполняется преобразование данных и зачем нужна их очистка?;Преобразование включает нормализацию, агрегацию, обогащение. Очистка нужна для удаления шума, исправления ошибок, обработки пропусков для повышения качества моделей.;Изменение данных и удаление ошибок перед использованием в моделях.;3
Что такое gradient boosting?;Метод машинного обучения, где несколько слабых моделей (обычно деревья) последовательно обучаются, каждая новая модель исправляет ошибки предыдущих.;Gradient boosting - это ансамблевый метод, в котором модели строятся последовательно, где каждая последующая модель обучается на ошибках предыдущих с использованием градиентного спуска для минимизации функции потерь.;5
Как развивается направление ETL-пайплайны в последние годы?;Etl-пайплайны используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Etl-пайплайны используется для обработки информации и улучшения решений.;3
Что такое кросс-валидация и зачем она нужна?;Метод оценки модели путем многократного разбиения данных на тренировочную и тестовую выборки. Нужна для более надежной оценки обобщающей способности и настройки гиперпараметров.;Метод тестирования моделей машинного обучения.;2
Какие риски связаны с применением предобработка данных?;Предобработка данных помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Предобработка данных применяется в финансах, медицине, рекламе и IT, помогает анализировать данные и строить модели.;4
Как тестируются независимые и парные выборки?;Независимые выборки тестируются с помощью t-теста Стьюдента или U-критерия Манна-Уитни, а парные выборки - с использованием парного t-теста или критерия Вилкоксона;Проверка различий между группами данных;2
Что такое Spark и чем он отличается от Hadoop?;Apache Spark — это платформа для распределенных вычислений, быстрее Hadoop MapReduce за счёт работы в памяти (in-memory). Поддерживает потоковую обработку данных и имеет библиотеки для SQL и машинного обучения.;Spark — программа для обработки данных, похожа на Hadoop.;3
Что представляет собой алгоритм k-means?;K-means — это метод кластеризации, основанный на минимизации суммы квадратов расстояний между точками и центрами кластеров. Итеративно пересчитывает центры кластеров до сходимости.;K-means — алгоритм, который делит данные на группы по близости признаков, минимизируя расстояния до центров кластеров.;5
Какие метрики используются для оценки бинарной классификации?;Accuracy, Precision, Recall, F1-score, ROC-AUC, PR-AUC, Confusion Matrix. Выбор зависит от задачи и дисбаланса классов.;Показатели качества для задач классификации с двумя классами.;2
Нарисуйте (опишите) схему классификации методов машинного обучения;Классификация методов ML включает обучение с учителем (классификация, регрессия), без учителя (кластеризация, снижение размерности), с подкреплением и полу-контролируемое обучение;Классификация методов включает обучение с учителем и без учителя;5
Что такое feature importance?;Методы оценки важности признаков для прогнозов модели.;Способ оценки вклада каждого признака в прогнозы модели. Помогает понять модель и отобрать наиболее значимые фичи.;4
Что такое 'функция активации' в нейросети?;Функция активации определяет, будет ли нейрон активирован, и вносит нелинейность в модель.;Функция активации управляет выходом нейрона.;3
Какие этапы включает проект, основанный на использовании NLP?;Nlp применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;4
Перечислите основные задачи анализа сетей на графах. Приведите примеры.;Основные задачи: поиск сообществ, определение центральности, анализ кратчайших путей, выявление аномалий, моделирование распространения информации.;Анализ графов включает задачи поиска сообществ, выявления центральных вершин (центральность), вычисления кратчайших путей и моделирования процессов распространения в сетях.;4
В чем преимущества применения машинное обучение по сравнению с традиционными методами?;Машинное обучение используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Машинное обучение применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;4
Охарактеризуйте хранилища OLAP и OLTP;"OLTP для операционных транзакций, OLAP для аналитических запросов; разная оптимизация";Базы данных для разных задач;2
Что понимается под термином 'Data Mining'?;Data Mining — это процесс извлечения ранее неизвестных, практически полезных и интерпретируемых знаний из больших объемов данных.;Data Mining — это метод анализа данных, позволяющий находить зависимости между показателями.;4
Какие компании активно используют ETL-процессы и зачем?;Etl-процессы помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Это просто работа с таблицами. Не очень полезно.;2
Как работает технология In-Memory Computing в современных СУБД?;Хранение и обработка данных в оперативной памяти вместо диска. Обеспечивает sub-millisecond latency для transactional и analytical workloads.;Данные хранятся в RAM для мгновенного доступа. Обеспечивает миллисекундную задержку для транзакционных систем и аналитических запросов, ускоряя обработку в разы.;5
Что такое word embeddings и какие модели используются для их создания?;Word embeddings - векторные представления слов, создаваемые моделями word2vec, GloVe, fastText, которые capture семантические и синтаксические отношения между словами;Word embeddings - векторные представления слов, создаваемые word2vec;5
Понятия репликации и шардинга;Репликация создает копии данных для отказоустойчивости, шардинг распределяет данные между серверами;Репликация обеспечивает доступность данных;4
Сколько данных оптимально использовать для обучения моделей?;Зависит от сложности задачи: для простых моделей достаточно тысяч примеров, для глубокого обучения - миллионы. Важен баланс между объемом и качеством разметки.;Чем сложнее модель, тем больше данных нужно. Но важнее качество данных чем количество. Тысячи - для простых задач, миллионы - для сложных.;4
Что такое p-value в статистике?;Вероятность получить наблюдаемые или более экстремальные результаты при условии, что нулевая гипотеза верна.;P-value показывает вероятность того, что найденные в данных различия произошли случайно. Чем меньше p-value, тем менее вероятно, что нулевая гипотеза верна.;5
Как организовать data quality checks в ETL процессах?;Automated validation rules, data profiling, constraint checking, statistical tests, anomaly detection, alerting on quality issues.;Система проверки качества данных в ETL пайплайнах.;3
Как развивается направление масштабируемые системы в последние годы?;Масштабируемые системы используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Масштабируемые системы применяется в финансах, медицине, рекламе и IT, помогает анализировать данные и строить модели.;4
Какие методы используются для обработки пропущенных значений в данных?;Удаление строк с пропусками, импутация средним/медианой, предсказание значений с помощью ML моделей, интерполяция для временных рядов, создание отдельной категории для пропусков.;Удаление строк если пропусков мало, заполнение средним/модой, использование алгоритмов предсказания, интерполяция для временных данных. Выбор метода зависит от природы пропусков.;5
Для чего нужна гипотеза о равенстве средних;Гипотеза о равенстве средних позволяет статистически проверить различия между средними значениями групп;Сравнение средних значений;3
Что такое дисперсия данных и что она показывает?;Дисперсия — это мера разброса данных относительно среднего значения. Вычисляется как среднее квадратов отклонений: D = ?(xi - ?)^2 / n.;Дисперсия измеряет разброс данных.;3
Как обеспечивается отказоустойчивость в Kafka;Через репликацию партиций на несколько брокеров. Одна реплика является лидером для чтения/записи, остальные — followers. При падении лидера одна из реплик становится новым лидером.;Механизм репликации обеспечивает отказоустойчивость: каждая партиция реплицируется на заданное число брокеров, один из которых является лидером (обслуживает запросы), а остальные — последователями. При потере лидера контроллер автоматически выбирает нового лидера из последователей.;4
Как развитие классификация данных влияет на будущее цифровых технологий?;Классификация данных используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Классификация данных нужно только программистам.;2
Что такое Apache Kafka?;Распределенная потоковая платформа обмена сообщениями для обработки потоков данных в реальном времени.;Платформа для работы с потоками данных, которая передает сообщения между приложениями.;3
Архитектура хранилищ данных;Современная архитектура хранилищ данных включает многоуровневую структуру с уровнями приема, обработки, хранения и анализа информации, использующую ETL-процессы, data lakes и специализированные витрины данных для различных бизнес-потребностей;Многоуровневая организация систем хранения с процессами ETL и data lakes для управления корпоративными данными;4
Сравнительный анализ алгоритмов кластеризации;Алгоритмы кластеризации сравниваются по масштабируемости, чувствительности к шуму, способности находить кластеры сложной формы и вычислительной сложности;Анализ алгоритмов по производительности и качеству кластеризации;3
NoSQL классификация хранилищ;NoSQL базы данных классифицируются на документные хранилища, хранилища ключ-значение, колоночные базы данных и графовые базы данных в зависимости от модели данных и способа организации хранения информации;Документные БД, key-value хранилища, колоночные и графовые базы данных;3
Примеры задач с большими графами;Большие графы используются в социальных сетях для анализа сообществ, в рекомендательных системах и биоинформатике для изучения белковых взаимодействий;Графовые модели в социальных сетях и рекомендательных системах;3
Где применяется глубокое обучение в промышленности и бизнесе?;Глубокое обучение помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;4
Что такое federated learning?;Подход когда модель обучается на децентрализованных данных без их централизации;Обучение модели на распределенных данных без их объединения;4
Понятие корреляции, коэффициент корреляции Пирсона, Спирмена, Кендела.;Корреляция — статистическая мера связи между переменными. Коэффициент Пирсона измеряет линейную зависимость (r = cov(X,Y)/(?X?Y)), Спирмена — ранговую, Кендела — степень согласованности пар.;Корреляция — это зависимость между двумя признаками. Пирсон — для чисел, Спирмен — для рангов, Кендел — для порядковых данных.;3
Структуры и типы данных в языке R, привести примеры.;В R присутствуют структуры данных: vector, matrix, data.frame, list, factor. Примеры: vector(c(1,2,3)), matrix(1:9, nrow=3), data.frame(x=1:3, y=c('a','b','c')).;Основные структуры: vector, matrix, list, data.frame, factor. Примеры: vector(c(1,2,3)), data.frame(x=1:3, y=c('A','B','C')).;5
Нормальное распределение;Нормальное распределение характеризуется симметричной колоколообразной формой, параметрами ? (среднее) и ? (стандартное отклонение), встречается во многих природных явлениях;Распределение Гаусса с плотностью f(x) = (1/??2?)e^(-(x-?)?/2??), где 68.3% данных в ?±?, 95.4% в ?±2?, 99.7% в ?±3?, является предельным распределением по ЦПТ;5
Сравнительная характеристика R и Python;R - для статистики и визуализации, Python - универсальный с библиотеками для ML;R специализирован на статистическом анализе, Python более универсален для ML и продакшена;4
Что такое federated learning?;Подход когда модель обучается на децентрализованных данных без их централизации;Обучение ML моделей на данных которые остаются на устройствах пользователей без передачи на центральный сервер;5
Что такое 'обучение с учителем' в машинном обучении?;Обучение с учителем — это метод, при котором модель обучается на размеченных данных, где каждому входному значению соответствует известный правильный ответ.;Это когда учат нейросеть, и она потом сама все делает без данных.;2
Сколько данных лучше взять для обучения: побольше или поменьше?;Зависит от сложности задачи: для сложных моделей нужно больше данных, но важнее качество и репрезентативность;Лучше брать достаточно данных для сложности задачи;5
Примеры задач, решаемых с помощью больших графов.;Большие графы применяются для анализа социальных сетей, поиска путей в транспортных системах, моделирования связей в биоинформатике, рекомендаций и кибербезопасности.;Графы помогают анализировать сети, маршруты, связи между пользователями.;4
Охарактеризуйте хранилища OLAP и OLTP;"OLTP для операционных транзакций, OLAP для аналитических запросов; разная оптимизация";OLTP для операционных транзакций, OLAP для аналитических запросов с разной оптимизацией;5
Как нейронные сети помогает в анализе больших объемов данных?;Нейронные сети помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Это просто работа с таблицами. Не очень полезно.;2
Что такое гиперпараметры модели?;Гиперпараметры — это параметры, значения которых задаются до обучения модели и влияют на её архитектуру и процесс обучения, например скорость обучения или количество слоёв.;Гиперпараметры — это параметры, которые задаются заранее и влияют на процесс обучения модели.;5
Для чего нужны гипотезы в анализе данных;Гипотезы позволяют формулировать проверяемые утверждения и проводить статистическую проверку научных предположений;Проверка предположений о данных;2
Как выбрать между различными алгоритмами кластеризации для конкретной задачи?;Анализировать форму кластеров (K-means для spherical, DBSCAN для произвольных), наличие шума (DBSCAN robust к выбросам), знание числа кластеров (K-means требует k), размер данных.;Выбирать алгоритм based on формы данных, наличия шума, необходимости знать число кластеров заранее и размера dataset'а.;3
Что такое статистическое обучение;Раздел машинного обучения, основанный на статистических методах и вероятностных моделях;Обучение с использованием статистики;2
Что такое data skew в распределенных системах?;Неравномерное распределение данных или нагрузки между узлами кластера;Проблема неравномерной нагрузки;2
Какие этапы включает проект, основанный на использовании анализ данных?;Анализ данных используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Анализ данных применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;5
Что такое Data Lake и в чем его преимущества перед Data Warehouse?;Data Lake — это хранилище, где данные сохраняются в исходном виде. Преимущества: гибкость, возможность работы с сырыми и разнородными данными, масштабируемость. Data Warehouse хранит структурированные данные.;Data Lake хранит данные в сыром виде, в отличие от Data Warehouse, где данные структурированы.;5
Метрики качества для моделей регрессии;Основные метрики включают RMSE, MAE, MAPE и R? для оценки точности регрессионных моделей и их предсказательной способности;RMSE чувствительна к выбросам, MAE более робастна, MAPE для относительных ошибок, R? показывает долю объясненной дисперсии;4
Какие риски связаны с использованием обработка данных в критически важных системах?;Обработка данных применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;4
Как работает алгоритм Diffusion Models в генеративном AI?;Постепенное добавление шума к данным с последующим обучению обратному процессу восстановления. Создает высококачественные изображения через итеративное уточнение.;Добавляет шум к данным затем учится восстанавливать оригинал через обратный диффузионный процесс. Генерирует качественные изображения через последовательное удаление шума.;5
Что такое ARIMA модель?;Модель для прогнозирования временных рядов, учитывающая автокорреляцию и дифференцирование.;Алгоритм для предсказания значений на основе исторических данных.;2
Что такое метод главных компонент (PCA)?;Метод снижения размерности данных через проецирование на ортогональные компоненты с максимальной дисперсией.;Способ упрощения данных для машинного обучения.;2
Как модели прогнозирования используется в научных исследованиях?;Модели прогнозирования используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Это просто работа с таблицами. Не очень полезно.;2
Виды связи между переменными при корреляции.;Корреляция отражает степень и направление линейной связи между двумя переменными. Связи могут быть положительные, отрицательные или нулевые. Для оценки используется коэффициент корреляции Пирсона или Спирмена.;Корреляция бывает положительная, отрицательная и нулевая. Пример — рост и вес.;4
Как понимать «уровень статистической достоверности»? Это ли вероятность ошибки?;Уровень статистической достоверности (p-value) показывает вероятность того, что наблюдаемый эффект возник случайно. Чем меньше p-value, тем выше достоверность результата. Он не равен вероятности ошибки напрямую, но связан с ней через уровень значимости ?.;Это вероятность ошибки.;2
Как развитие NLP влияет на будущее цифровых технологий?;Nlp используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;5
Основные метрики больших графов;Ключевые метрики включают диаметр графа, плотность связей, коэффициент кластеризации и различные меры центральности;Метрики для оценки свойств сетей;3
Что такое машинное обучение и какие задачи оно решает?;Машинное обучение применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Машинное обучение нужно только программистам.;2
Как работает технология MapReduce в экосистеме Hadoop?;MapReduce разделяет обработку данных на этапы Map (разбиение и фильтрация) и Reduce (агрегация), позволяя распределенно обрабатывать большие объемы информации на кластерах;Обработка данных в Hadoop;2
Какие стратегии использовать для миграции данных между разными системами хранения?;Инкрементальная миграция, dual write during transition, проверка консистентности, откат на предыдущую версию, мониторинг производительности, постепенное переключение трафика.;Поэтапный перенос данных, обеспечение консистентности during миграции, возможность отката и мониторинг процесса перехода.;3
Сколько данных лучше взять для обучения — побольше или поменьше?;Количество данных для обучения должно быть достаточным для генерализации модели. Однако избыточные данные при низком качестве не повышают точность. Оптимальный объем зависит от сложности задачи и модели.;Оптимальный объем данных должен обеспечивать баланс между скоростью обучения и обобщающей способностью модели.;5
В каких областях деятельности используются большие данные, привести примеры.;Большие данные применяются в маркетинге, финансах, медицине, промышленности, транспорте и государственном управлении. Примеры: прогнозирование спроса, анализ поведения клиентов, медицинская диагностика, предиктивное обслуживание оборудования.;Большие данные — это просто большие таблицы, где много строк и столбцов. Их применяют только в экономике.;2
Какие методы использовать для балансировки классов в задачах классификации с сильным дисбалансом?;Oversampling (SMOTE), undersampling, изменение весов классов в функции потерь, использование алгоритмов устойчивых к дисбалансу, ансамблирование.;Методы увеличения редкого класса или уменьшения частого, взвешивание ошибок, специальные алгоритмы для несбалансированных данных.;3
Преимущества и недостатки непараметрических моделей;Непараметрические модели обладают гибкостью, но требуют значительных вычислительных ресурсов и объемов данных;Гибкость моделей и затраты;2
Какие основные инструменты и технологии используются для работы с обработка данных?;Обработка данных помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Это просто работа с таблицами. Не очень полезно.;2
Какие инструменты используются для работы с системы логирования?;Системы логирования используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Системы логирования обеспечивает анализ потоковых данных, улучшает прогнозирование, помогает автоматизировать процессы и повышает точность аналитических моделей.;5
Что такое p-value в статистике?;Вероятность получить наблюдаемые или более экстремальные результаты при условии, что нулевая гипотеза верна.;Это статистический показатель для проверки гипотез. Показывает значимость результатов.;3
Что такое data replication в распределенных системах?;Создание копий данных на разных узлах для обеспечения отказоустойчивости и доступности;Создание копий данных для резервирования;3
Какие основные характеристики и вызовы больших данных (4V, 8V)?;4V: Volume (объем), Velocity (скорость), Variety (разнообразие), Veracity (достоверность). 8V добавляют: Value, Variability, Visualization, Validity.;4V - объем, скорость, разнообразие типов, качество данных. 8V добавляют бизнес-аспекты: ценность, изменчивость и другие.;4
Какие типы join существуют в Spark и когда их использовать?;Inner join, left outer, right outer, full outer, cross join. Выбор зависит от требуемого результата и наличия данных в обеих таблицах.;Inner join для общих записей, left/right join для сохранения всех записей одной таблицы, full outer для всех записей обеих таблиц.;5
Что означает термин 'обучение с подкреплением'?;Обучение с подкреплением — это тип обучения, при котором агент взаимодействует со средой, получая вознаграждение за правильные действия.;Обучение с подкреплением — это подход, где агент учится на опыте, получая вознаграждения и штрафы.;5
Виды столбчатых диаграмм и их интерпретация;Столбчатые диаграммы включают вертикальные, горизонтальные, сгруппированные и составные типы, которые интерпретируются через сравнение высот столбцов для анализа категориальных данных;Графики в виде столбиков для сравнения величин;2
Что такое data skew в распределенных системах?;Неравномерное распределение данных или нагрузки между узлами кластера;Неравномерное распределение данных между партициями что вызывает дисбаланс нагрузки;4
Виды связи между переменными при корреляции;"Положительная, отрицательная, нелинейная, ложная корреляция; сила связи от -1 до +1";Типы корреляционных связей;2
Что такое YARN?;Компонент Hadoop для управления ресурсами кластера и планирования задач. Отделяет функции управления от модели обработки данных.;Часть Hadoop для управления задачами.;2
Какие показатели характеризуют качество данных?;Полнота, точность, непротиворечивость, актуальность, достоверность, уникальность, целостность, своевременность.;Отсутствие пропусков, правильность значений, соответствие форматам.;3
Векторы, матрицы, фреймы и факторы в R. Сходство и различия, способы обработки.;Векторы и матрицы содержат данные одного типа, data.frame — разных типов, factor используется для категориальных данных. Обработка осуществляется функциями length(), dim(), apply(), summary().;Различия: вектор — одномерный, матрица — двумерная, data.frame хранит разные типы данных, factor используется для категорий.;4
Что такое трансформер (Transformer) в NLP?;Архитектура нейросетей на основе механизма внимания, исключающая рекуррентные и сверточные слои для обработки последовательностей.;Нейросеть для работы с текстом, где внимание определяет важность разных слов. Легко обучается на больших данных.;4
Как развитие кластеризация влияет на будущее цифровых технологий?;Кластеризация применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Кластеризация нужно только программистам.;2
Как проектировать систему для обработки данных IoT устройств с высокой частотой обновления?;Использовать потоковые платформы (Kafka, Flink), колоночные форматы хранения, сжатие данных, агрегацию на edge устройствах, мониторинг пропускной способности и задержек.;Потоковая обработка через Kafka/Flink, эффективные форматы хранения типа Parquet, сжатие данных, предварительная агрегация на устройствах, постоянный мониторинг производительности и задержек системы.;5
Для чего нужны индексы Gain и Gini? В чём суть индекса Gini.;Индексы Gain и Gini используются в деревьях решений для выбора оптимального признака при разбиении узлов. Индекс Gini измеряет неоднородность данных и стремится к нулю для чистых узлов.;Метрики для деревьев;2
Для чего нужны индексы Gain и Gini?;Gain и Gini используются в деревьях решений для выбора оптимального признака при разбиении узла;Индексы Gain и Gini нужны для выбора признаков в деревьях;5
Основные вызовы больших данных;Ключевые вызовы включают объем (Volume), скорость (Velocity), разнообразие (Variety) и достоверность (Veracity) данных, требующие специальных подходов к обработке;4V: большой объем данных, высокая скорость генерации, разнообразие форматов, вопросы достоверности и качества данных;3
Векторы, матрицы, фреймы в R;Векторы хранят однотипные данные, матрицы - двумерные массивы, фреймы - таблицы с разными типами колонок;В языке R используются различные структуры для хранения данных;5
Какие этапы включает проект, основанный на использовании анализ данных?;Анализ данных помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Анализ данных — это что-то про компьютеры. Применяется редко.;2
Почему организации переходят на технологии кластеризация данных?;Технологии кластеризация данных позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Кластеризация данных почти нигде не применяется. Это просто большие таблицы.;2
Характерные черты безмасштабных сетей;Степенное распределение степеней, наличие хабов, устойчивость к случайным отказам, уязвимость к targeted attacks;Безмасштабные сети имеют степенное распределение и хабы;5
Какие основные инструменты и технологии используются для работы с кластеризация?;Кластеризация используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Кластеризация — это что-то про компьютеры. Применяется редко.;2
Что такое Apache Hive?;Система управления данными в Hadoop, предоставляющая SQL-подобный язык запросов (HiveQL) для обработки структурированных данных в распределенном хранилище HDFS, с преобразованием запросов в MapReduce или Tez jobs.;Система для выполнения SQL-запросов к данным в Hadoop. Позволяет работать с большими данными используя знакомый SQL-синтаксис, преобразуя запросы в задачи MapReduce.;5
Какие методы борьбы с переобучением вы знаете?;Регуляризация L1/L2, dropout, early stopping, увеличение данных, упрощение модели, кросс-валидация, augmentation данных.;Разные способы чтобы модель не переобучалась.;2
Что такое MLOps;MLOps — это практика внедрения и поддержки ML моделей в production через автоматизацию, мониторинг и управление жизненным циклом моделей.;Методология для управления жизненным циклом ML моделей в продакшене;4
Почему технологии data warehouses стали критически важны?;Data warehouses используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Это что?то связанное с данными, но используется редко.;2
Какие основные инструменты и технологии используются для работы с модели прогнозирования?;Модели прогнозирования применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;4
Как принято формулировать нулевую гипотезу;Нулевая гипотеза формулируется как утверждение об отсутствии статистически значимого эффекта или различий;Нулевая гипотеза утверждает об отсутствии эффекта;4
С какими проблемами сталкиваются при применении data mining, и как их решают?;Data mining используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Data mining применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;5
Преимущества и недостатки непараметрических моделей;Непараметрические модели гибки и не требуют предположений о распределении данных, но могут требовать больших объемов данных и вычислительных ресурсов;Модели которые не делают строгих предположений о виде распределения данных;2
Векторы, матрицы, фреймы в R;Вектор - одномерный массив, матрица - двумерный, фрейм - таблица с разными типами данных;Векторы (atomic), матрицы (2D), фреймы (таблицы с колонками);4
Каковы условия остановки ветвления дерева?;Условия остановки включают достижение максимальной глубины, минимального числа образцов в узле, отсутствие улучшения качества разбиения или достижение чистого узла.;Условия по глубине, количеству samples и качеству разбиения;4
Какие реальные примеры использования системы логирования существуют?;Системы логирования используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Технологии системы логирования позволяют компаниям обрабатывать большие объёмы разнородных данных, выявлять сложные закономерности и принимать обоснованные решения.;5
Какие навыки необходимы специалисту для работы с анализ данных?;Анализ данных используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;5
Что такое статистическая гипотеза;Статистическая гипотеза представляет собой формальное проверяемое предположение о свойствах генеральной совокупности или параметрах распределения, которое может быть подтверждено или опровергнуто с помощью статистических методов тестирования;Предположение о характеристиках данных, которое можно проверить статистическими методами;2
Почему организации переходят на технологии data warehouses?;Технологии data warehouses позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Это что?то связанное с данными, но используется редко.;2
С какими проблемами сталкиваются при применении анализ данных, и как их решают?;Анализ данных помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Анализ данных нужно только программистам.;2
В каких областях деятельности используются большие данные, привести примеры;Большие данные используются в финансах (обнаружение мошенничества), ритейле (рекомендательные системы), здравоохранении (персонализированная медицина), транспорте (оптимизация маршрутов) и социальных сетях.;Большие данные используются в финансах, ритейле, здравоохранении и транспорте;5
Какие риски связаны с использованием NLP в критически важных системах?;Nlp применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Nlp применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;5
Какие основные инструменты и технологии используются для работы с нейронные сети?;Нейронные сети используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Нейронные сети применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;5
Какие способы визуализации корреляции изучались в курсе Big Data?;Изучались диаграммы рассеяния, тепловые карты корреляции, матричные графики и параллельные координаты для визуализации взаимосвязей между переменными;Изучались диаграммы рассеяния, тепловые карты и матричные графики корреляции;5
Какие метрики используются для оценки бинарной классификации?;Accuracy, Precision, Recall, F1-score, ROC-AUC, PR-AUC, Confusion Matrix. Выбор зависит от задачи и дисбаланса классов.;Точность, полнота, F-мера. Разные метрики для разных сценариев классификации.;3
Закономерности динамики сложных сетей и распространения информации;Сети развиваются по степенным законам, информация распространяется каскадно через влиятельные узлы;Сложные сети демонстрируют степенное распределение связей и рост через предпочтительное присоединение. Распространение информации происходит каскадно через хабы, при этом порог восприятия зависит от связности узлов;5
С какими проблемами сталкиваются при применении модели прогнозирования, и как их решают?;Модели прогнозирования помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Модели прогнозирования — это что-то про компьютеры. Применяется редко.;2
Типы языка R, примеры;Вектор, матрица, список, фрейм данных, фактор;Вектор (атомарные данные), матрица (2D), фрейм (таблицы), фактор (категории);4
Обучение с учителем и без учителя;Обучение с учителем использует размеченные данные с известными ответами, а без учителя обнаруживает скрытые структуры в данных без меток;Обучение с учителем использует размеченные данные, без учителя работает с неразмеченными;5
Что такое Data Catalog;Data Catalog — это централизованный реестр метаданных, который обеспечивает discoverability, понимание и управление данными в организации.;Централизованный каталог метаданных с поиском и lineage;4
Какие подходы использовать для обработки графовых данных в распределенных системах?;Специализированные графовые базы (Neo4j), графовые обработчики (GraphX), алгоритмы для распределенных графов (Pregel), оптимизация хранения графовых структур, partitioning по вершинам или ребрам.;Графовые СУБД, распределенные графовые обработчики, алгоритмы типа Pregel, эффективное хранение графов, стратегии партиционирования для балансировки нагрузки при обходах графа.;5
Стадии разработки систем ML;Процесс разработки включает сбор данных, предобработку, проектирование признаков, обучение модели, валидацию, развертывание и мониторинг производительности;Data collection, preprocessing and feature engineering, model training and validation, deployment, performance monitoring and maintenance;4
Какие стратегии использовать для обработки данных с changing schema в data lakes?;Schema evolution, schema on read, использование форматов с backward compatibility, metadata management, data validation pipelines.;Обработка данных с меняющейся схемой.;2
Назовите характеристики качества данных;Полнота, точность, непротиворечивость, актуальность, достоверность, релевантность данных;Характеристики качества данных;4
Как принято формулировать нулевую гипотезу;Утверждение об отсутствии статистически значимых различий или эффектов в исследуемых данных;Статистическое предположение об отсутствии значимых эффектов;4
Какие риски связаны с использованием предиктивная аналитика в критически важных системах?;Предиктивная аналитика используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Используется для прогнозов и анализа информации.;3
Какие основные инструменты и технологии используются для работы с глубокое обучение?;Глубокое обучение помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Помогает работать с данными и строить модели.;3
Для чего нужна гипотеза о равенстве средних;Для статистической проверки различий между средними значениями двух групп или условий;Проверка различий между группами;2
Как машинное обучение применяется для автоматизации рутинных процессов?;Машинное обучение помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;5
Как компьютерное зрение применяется для автоматизации рутинных процессов?;Компьютерное зрение применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Компьютерное зрение нужно только программистам.;2
Какие основные инструменты и технологии используются для работы с ETL-процессы?;Etl-процессы помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;4
Для чего нужна гипотеза о равенстве средних;Гипотеза о равенстве средних позволяет статистически проверить различия между средними значениями групп;Проверка различий средних;2
В каких областях деятельности используются большие данные, привести примеры;Используются в финансах (fraud detection), ритейле (recommendations), healthcare (personalized medicine), транспорте (route optimization);Большие данные используются в финансах, ритейле и медицине;5
В чем различия между R и Python для анализа данных?;R - специализирован для статистики и визуализации, богатые статистические пакеты. Python - универсальный, лучше для ML и production систем. R удобнее для исследований, Python - для промышленной разработки.;R - статистика и визуализация, Python - ML и разработка. Разные сильные стороны для разных задач анализа данных.;4
Порядок тестирования гипотезы о равенстве средних;Формулировка гипотез, проверка условий, расчет статистики, сравнение с критическим значением;Формулировка гипотез, проверка нормальности, расчет t-статистики, принятие решения;4
Для чего нужна гипотеза о равенстве средних;Для статистической проверки различий между средними значениями двух групп или условий;Для сравнения средних значений в двух выборках;3
Как организовать feature engineering для NLP задач с большими текстовыми данными?;TF-IDF, word embeddings (Word2Vec, GloVe), contextual embeddings (BERT), character-level features, topic modeling (LDA), syntactic features (POS tagging).;TF-IDF, word embeddings, контекстные представления, тематическое моделирование, синтаксические признаки. Выбирать методы based on задачи и объема данных.;4
Что такое Data Mesh;Data Mesh — это децентрализованная архитектура управления данными, где данные организованы по доменам с владельцами и стандартизированными интерфейсами.;Архитектура где данные по доменам;3
Какие проблемы возникают при использовании in-memory обработка?;Технологии in-memory обработка позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Эти технологии помогают работать с информацией и делать прогнозы.;3
Какие инструменты используются для работы с кластеризация данных?;Кластеризация данных помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Технологии позволяют улучшать качество аналитики, находить закономерности и предсказывать события.;4
Как NLP помогает в анализе больших объемов данных?;Nlp применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Помогает работать с данными и строить модели.;3
Преобразование и очистка данных;Процесс преобразования включает нормализацию, кодирование категориальных переменных, обработку пропущенных значений и выбросов для улучшения качества данных;Стандартизация числовых признаков, one-hot encoding категориальных, импутация пропусков, обнаружение и обработка выбросов;4
Какие проблемы возникают при использовании масштабируемые системы?;Масштабируемые системы помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Масштабируемые системы нужно только программистам, обычным компаниям оно бесполезно.;2
Векторы, матрицы, фреймы и факторы в R;Векторы - атомарные данные, матрицы - 2D массивы, фреймы - таблицы, факторы - категориальные переменные;Основные структуры R;3
Векторы, матрицы, фреймы в R;Вектор - одномерный массив, матрица - двумерный, фрейм - таблица с разными типами данных;Структуры данных в R;2
Нормальное распределение;Нормальное распределение характеризуется симметричной колоколообразной формой, параметрами ? и ?, встречается во многих природных явлениях;Распределение в виде колокола;2
Какие этапы включает проект, основанный на использовании компьютерное зрение?;Компьютерное зрение применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Используется для прогнозов и анализа информации.;3
Как тестируются независимые и парные выборки?;"Независимые: t-test, Mann-Whitney; парные: paired t-test, Wilcoxon signed-rank test";t-test для независимых и парных выборок;3
Обучение с подкреплением и ансамбли;Обучение с подкреплением основано на взаимодействии со средой, ансамбли комбинируют несколько моделей;Разные методы машинного обучения;4
Как принято формулировать нулевую гипотезу;Утверждение об отсутствии статистически значимых различий или эффектов в исследуемых данных;Гипотеза о том, что ничего не изменилось;2
Как развитие NLP влияет на будущее цифровых технологий?;Nlp применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Используется для прогнозов и анализа информации.;3
Что такое 'ошибка модели'?;Ошибка модели — это разница между предсказанными и истинными значениями целевой переменной.;Ошибка — это когда модель не обучилась правильно.;3
Какие основные инструменты и технологии используются для работы с рекомендательные системы?;Рекомендательные системы применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Это просто работа с таблицами. Не очень полезно.;2
Мотивация происхождения NoSQL;Необходимость работы с неструктурированными данными и горизонтального масштабирования систем;Появление новых типов баз данных;2
Какие реальные кейсы демонстрируют эффективность компьютерное зрение?;Компьютерное зрение используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Компьютерное зрение применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;4
Что означает термин 'оверфиттинг'?;Оверфиттинг — это ситуация, когда модель слишком точно подстраивается под обучающие данные, теряя способность обобщать.;Это когда модель учится наизусть.;3
Требования ACID. CAP?теорема, BASE?архитектура;ACID - гарантии целостности транзакций, CAP - невозможность одновременно обеспечить согласованность, доступность и устойчивость к разделению;ACID обеспечивает надежность транзакций в SQL-системах. CAP-теорема доказывает, что распределенные системы могут гарантировать только 2 из 3 свойств. BASE (Basically Available, Soft state, Eventually consistent) - альтернатива ACID для NoSQL с конечной согласованностью;5
Фундаментальное свойство статистического обучения;Компромисс между смещением и дисперсией (bias-variance tradeoff) - ключевое свойство, определяющее обобщающую способность моделей;Баланс в обучении моделей;2
Что такое data skew в распределенных системах?;Неравномерное распределение данных или нагрузки между узлами кластера;Дисбаланс в распределении данных по узлам;3
Обучение с подкреплением и ансамбли;Обучение с подкреплением основано на взаимодействии со средой, ансамбли комбинируют несколько моделей;RL и ансамблевые методы;3
Какие риски связаны с использованием компьютерное зрение в критически важных системах?;Компьютерное зрение используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;5
Что такое Apache Superset?;BI платформа с открытым кодом для визуализации и исследования данных через веб-интерфейс.;Инструмент для визуализации данных. Создание дашбордов и отчетов для бизнес-аналитики.;3
Какие реальные примеры использования распределённые вычисления существуют?;Технологии распределённые вычисления позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Распределённые вычисления применяется в финансах, медицине, рекламе и IT, помогает анализировать данные и строить модели.;4
В чем преимущества применения нейронные сети по сравнению с традиционными методами?;Нейронные сети используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Нейронные сети — это что-то про компьютеры. Применяется редко.;2
Каковы закономерности динамики сложных сетей и законы распространения информации в них.;Закономерности включают рост и предпочтительное присоединение, эволюцию степени узлов, каскадные эффекты и диффузионные процессы по законам SIR и SI моделей.;Динамика сетей описывается ростом узлов и распространением по моделям SIR.;3
Как кластеризация данных влияет на эффективность бизнеса?;Кластеризация данных используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Кластеризация данных нужно только программистам, обычным компаниям оно бесполезно.;2
Основные задачи Data Analysis;Описательная аналитика, диагностика, прогнозирование, рекомендации - основные направления анализа;Описание, диагностика, прогнозирование и рекомендательные системы;3
Перечислить типы языка R, привести примеры.;Основные типы данных R: numeric (числовой, пример 3.14), integer (целый, пример 10L), character (строка, пример 'data'), logical (логический, пример TRUE), complex (комплексное число, пример 2+3i).;Типы данных: numeric, integer, character, logical, complex. Например: 3.14, 5L, 'data', TRUE, 2+4i.;5
Как работает алгоритм Diffusion Models в генеративном AI?;Постепенное добавление шума к данным с последующим обучению обратному процессу восстановления. Создает высококачественные изображения через итеративное уточнение.;Процесс добавления и последующего удаления шума для генерации данных. Создает изображения через многошаговый процесс реконструкции из зашумленного состояния.;4
Что означает термин 'оверфиттинг'?;Оверфиттинг — это ситуация, когда модель слишком точно подстраивается под обучающие данные, теряя способность обобщать.;Оверфиттинг — это переобучение модели, когда она запоминает данные и плохо работает на новых.;5
Какие риски связаны с применением data warehouses?;Data warehouses используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Технологии data warehouses позволяют компаниям обрабатывать большие объёмы разнородных данных, выявлять сложные закономерности и принимать обоснованные решения.;5
Какие типы join существуют в Spark и когда их использовать?;Inner join, left outer, right outer, full outer, cross join. Выбор зависит от требуемого результата и наличия данных в обеих таблицах.;Inner, left, right, outer joins. Inner когда нужны только совпадающие записи, outer когда нужно сохранить все записи одной или обеих таблиц.;4
С какими проблемами сталкиваются при применении машинное обучение, и как их решают?;Машинное обучение используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Машинное обучение применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;5
Какие компании активно используют ETL-процессы и зачем?;Etl-процессы помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;4
Как работает технология Homomorphic Encryption для конфиденциальных вычислений?;Позволяет выполнять вычисления на зашифрованных данных без расшифровки. Сохраняет конфиденциальность при обработке в облаке и совместном использовании данных.;Шифрование для безопасных вычислений на зашифрованных данных.;2
Как внедрение глубокое обучение влияет на процессы в организациях?;Глубокое обучение помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;4
«Меры изменчивости»: что к ним относится?;К мерам изменчивости относятся дисперсия, стандартное отклонение, размах, межквартильный размах и среднее абсолютное отклонение;Показатели разброса данных;2
В чём суть алгоритмов нахождения квадратичной ошибки?;Минимизация суммы квадратов разностей между предсказанными и фактическими значениями для нахождения оптимальных параметров модели;Суть в минимизации квадратичной ошибки между предсказаниями и данными;5
Что такое регуляризация в машинном обучении?;Метод предотвращения переобучения путем добавления штрафа за сложность модели к функции потерь.;Это техника для борьбы с переобучением через добавление штрафа к весам модели.;4
Почему организации переходят на технологии мониторинг больших данных?;Технологии мониторинг больших данных позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Это что?то связанное с данными, но используется редко.;2
Что такое линейная регрессия?;Линейная регрессия — это статистический метод, описывающий зависимость между независимыми переменными X и зависимой переменной Y в виде линейной функции Y = ?0 + ?1X + ?.;Линейная регрессия — это прогнозирование на основе прямой линии.;3
Какие реальные кейсы демонстрируют эффективность кластеризация?;Кластеризация применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;5
Что представляет собой алгоритм k-means?;K-means — это метод кластеризации, основанный на минимизации суммы квадратов расстояний между точками и центрами кластеров. Итеративно пересчитывает центры кластеров до сходимости.;Алгоритм группирует похожие объекты. Центры кластеров пересчитываются.;3
Что такое Apache Airflow?;Платформа для оркестрации и мониторинга рабочих процессов данных.;Система для управления и запуска ETL процессов и задач обработки данных по расписанию.;3
Как модели прогнозирования используется в научных исследованиях?;Модели прогнозирования помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Модели прогнозирования нужно только программистам.;2
Преимущества CNN и их задачи;"CNN эффективны для распознавания образов, обнаружения объектов, сегментации; преимущества - локальная связность, параметризация";Плюсы сверточных сетей;2
Что такое 'регуляризация' в машинном обучении?;Регуляризация — это метод уменьшения переобучения за счёт добавления штрафов к функции потерь.;Регуляризация — это ограничение параметров модели.;2
Что такое Data Lake?;Хранилище неструктурированных и полуструктурированных данных в исходном формате.;Хранилище для больших объемов разнородных данных в исходном виде, которое сохраняет все детали и позволяет гибко анализировать данные позже.;4
Какие методы использовать для обработки временных рядов с пропущенными значениями?;Интерполяция (линейная, сплайн), forward/backward fill, статистические методы (скользящее среднее), ML методы (ARIMA, Prophet). Выбор зависит от природы пропусков и требований к точности.;Линейная интерполяция, заполнение предыдущими/следующими значениями, скользящее среднее, методы на основе временных рядов типа ARIMA. Важно учитывать паттерн пропусков (MCAR, MAR, MNAR) при выборе метода.;5
"Понятие корреляции; коэффициенты Пирсона, Спирмена, Кендалла";"Корреляция - мера линейной связи; Пирсон для нормальных данных, Спирмен для рангов, Кендалл для порядковых данных";Меры связи переменных;2
Как развивается направление хранилища данных в последние годы?;Технологии хранилища данных позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Хранилища данных используется для обработки информации и улучшения решений.;3
Что такое Apache Hadoop?;Фреймфорк для распределенной обработки больших данных, состоящий из HDFS (распределенная файловая система) и MapReduce (модель программирования).;Система для больших данных, которая хранит и обрабатывает информацию на многих компьютерах одновременно.;3
Что такое Apache Iceberg;Apache Iceberg — это open-source table format для аналитических datasets, обеспечивающий ACID семантику, hidden partitioning и schema evolution поверх cloud object stores.;Табличный формат для аналитики;3
Как характеристика Velocity влияет на выбор архитектуры обработки данных?;Высокая Velocity требует streaming архитектур (Kafka, Flink, Spark Streaming) вместо batch processing, так как данные должны обрабатываться в реальном времени с минимальной задержкой.;Быстрые данные нужно обрабатывать специальными системами.;2
Как мониторить качество ML модели в продакшене?;Отслеживать accuracy/precision/recall на отложенной выборке, мониторить data drift и concept drift, отслеживать бизнес-метрики.;Следить за метриками модели на новых данных, отслеживать изменения в распределении входных признаков и целей. Настроить алерты при значительном ухудшении качества.;4
Что понимается под признаковым пространством (feature space)?;Признаковое пространство — это многомерное пространство, где каждая ось соответствует отдельному признаку, а каждая точка — объекту с набором характеристик.;Пространство признаков — это таблица с признаками и объектами.;3
Почему организации переходят на технологии системы логирования?;Технологии системы логирования позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Системы логирования используется бизнесом для оптимизации процессов, анализа клиентов и прогнозирования.;4
Что такое уровень значимости;Уровень значимости ? представляет собой вероятность совершить ошибку первого рода, то есть отвергнуть верную нулевую гипотезу в статистическом тестировании, обычно устанавливается на уровне 0.05 или 0.01;Порог для принятия статистических решений об отклонении или принятии гипотез в анализе;3
Виды связи между переменными при корреляции;Связи могут быть разными по направлению и силе.;Если одна растёт, другая может меняться, но не всегда понятно как.;3
Как развитие машинное обучение влияет на будущее цифровых технологий?;Машинное обучение помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Машинное обучение применяется в бизнесе и иногда в науке для анализа данных.;3
Какие компании активно используют компьютерное зрение и зачем?;Компьютерное зрение применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Компьютерное зрение нужно только программистам.;2
Охарактеризовать конструкции языка R;Язык R предоставляет векторы для атомарных данных, матрицы для двумерных массивов, списки для гетерогенных коллекций, фреймы данных для табличной организации и факторы для категориальных переменных;Структуры данных в R;2
Назовите характеристики качества данных;Полнота, точность, непротиворечивость, актуальность, достоверность, релевантность данных;Полнота, точность, актуальность данных;3
Сравнительный анализ алгоритмов кластеризации;Алгоритмы кластеризации сравниваются по масштабируемости, устойчивости к шуму и вычислительной эффективности;Алгоритмы кластеризации сравниваются по масштабируемости и устойчивости к шуму;5
Какие реальные кейсы демонстрируют эффективность data mining?;Data mining используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;4
Как работает технология In-Memory Computing в современных СУБД?;Хранение и обработка данных в оперативной памяти вместо диска. Обеспечивает sub-millisecond latency для transactional и analytical workloads.;Использование оперативной памяти для хранения данных вместо дисков для увеличения скорости работы.;2
Какие реальные примеры использования хранилища данных существуют?;Хранилища данных используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Хранилища данных обеспечивает анализ потоковых данных, улучшает прогнозирование, помогает автоматизировать процессы и повышает точность аналитических моделей.;5
Как выбрать между реляционной и документной БД для хранения сложных структур?;Реляционная для строгой схемы и сложных запросов, документная для гибкой схемы и иерархических данных. Выбор зависит от требований к целостности и запросам.;Выбор БД для сложных данных.;2
Как внедрение анализ данных влияет на процессы в организациях?;Анализ данных применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Анализ данных нужно только программистам.;2
Что такое 'градиентное исчезновение'?;Градиентное исчезновение — это ситуация, когда градиенты становятся слишком малыми, что замедляет или останавливает обучение нейросети.;Это когда при обучении градиенты становятся маленькими и сеть не учится.;4
Что такое ZooKeeper в Kafka;ZooKeeper используется для управления метаданными кластера, выбора контроллера, отслеживания живых брокеров и потребителей, хранения конфигурации.;В архитектуре Kafka ZooKeeper функционирует как распределенная система координации: хранит метаданные кластера (брокеры, топики, партиции), управляет членством брокеров, осуществляет выбор контроллера, отслеживает консьюмер-группы и смещения, а также хранит конфигурации квот и ACL.;5
Принципы глубокого обучения в нейросетях;Глубокое обучение использует многослойные нейросети для автоматического извлечения признаков из данных различной природы;Глубокое обучение использует многослойные нейросети для извлечения признаков из данных;4
Что такое перекрёстная проверка (cross-validation)?;Перекрёстная проверка — это метод оценки обобщающей способности модели, при котором данные делятся на несколько частей, и обучение происходит поочередно на различных подвыборках, а проверка — на оставшихся.;Это проверка данных.;2
Сравнительная характеристика R и Python.;R — это специализированный язык для статистики и визуализации, Python — универсальный язык с библиотеками для анализа данных (NumPy, pandas, scikit-learn). R более мощен для статистических тестов, Python — для интеграции и масштабируемых решений.;R используется для статистики, Python — для программирования.;3
Что такое статистическая гипотеза? Какие виды гипотез вы знаете?;Статистическая гипотеза — это предположение о параметрах генеральной совокупности. Различают нулевую гипотезу H0 и альтернативную H1. Пример: H0: ?1 = ?2, H1: ?1 ? ?2.;Статистическая гипотеза — это предположение о данных, может быть нулевая и альтернативная.;5
Почему технологии обработка потоковых данных стали критически важны?;Технологии обработка потоковых данных позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Обработка потоковых данных нужно только программистам, обычным компаниям оно бесполезно.;2
Какие методы использовать для обнаружения аномалий в многомерных временных рядах?;Многомерные статистические методы (Mahalanobis distance), матричные профили, нейросетевые подходы (LSTM autoencoders), изолирующие леса, анализ главных компонент с reconstruction error.;Методы поиска аномалий в данных с несколькими переменными и временными метками.;2
Какие проблемы возникают при использовании системы логирования?;Системы логирования помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Технологии позволяют улучшать качество аналитики, находить закономерности и предсказывать события.;4
Для чего нужны индексы Gain и Gini? В чём суть индекса Gini.;Индексы Gain и Gini используются в деревьях решений для выбора оптимального признака при разбиении узлов. Индекс Gini измеряет неоднородность данных и стремится к нулю для чистых узлов.;Индексы для выбора разбиений, Gini измеряет неоднородность;4
Что такое 'дерево решений'?;Дерево решений — это модель, которая представляет процесс принятия решений в виде иерархии правил, ведущих от корня к листьям.;Это просто дерево с вариантами ответов, как в тесте.;3
Что такое MLOps?;Практики CI/CD для развертывания и мониторинга моделей машинного обучения.;Методология, которая объединяет машинное обучение с DevOps практиками для обеспечения воспроизводимости, масштабируемости и надежности ML систем в продакшене.;4
Что означает термин 'переподгонка' (overfitting)?;Переподгонка — это ситуация, когда модель слишком хорошо запоминает обучающую выборку, теряя способность обобщать на новых данных.;Это когда модель долго учится и перестает давать точные ответы.;3
Что такое retention period;Retention period — это время, в течение котором сообщения хранятся в Kafka до удаления. Может задаваться по времени или по размеру данных.;Retention period — это политика хранения данных в Kafka, определяющая максимальное время (по сроку) или объем (по размеру), в течение которых сообщения сохраняются в партициях топика перед удалением, что обеспечивает контроль над использованием дискового пространства и соответствие требованиям хранения данных.;5
Как развивается направление data lakes в последние годы?;Data lakes используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Data lakes используется для обработки информации и улучшения решений.;3
Что такое 4V в Big Data и объясните каждую характеристику?;Volume (объем данных), Velocity (скорость генерации и обработки), Variety (разнообразие форматов), Veracity (достоверность и качество данных). Эти характеристики определяют сложности работы с большими данными.;Свойства больших данных - размер, скорость и разные типы.;2
Какие этапы включает разработка систем машинного обучения?;Сбор данных, подготовка и очистка, feature engineering, выбор модели, обучение, валидация, тестирование, развертывание, мониторинг.;1. Сбор данных 2. Предобработка 3. Feature engineering 4. Выбор алгоритма 5. Обучение 6. Валидация 7. Тестирование 8. Деплой 9. Мониторинг;5
Где применяется нейронные сети в промышленности и бизнесе?;Нейронные сети используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Это просто работа с таблицами. Не очень полезно.;2
В чем разница между горизонтальным и вертикальным масштабированием в контексте Big Data?;Горизонтальное масштабирование - добавление новых узлов в кластер, вертикальное - увеличение ресурсов существующих серверов. Big Data системы предпочитают горизонтальное масштабирование как более экономичное и отказоустойчивое.;Горизонтальное - добавление новых серверов в кластер, вертикальное - улучшение существующих серверов. Big Data использует горизонтальное масштабирование так как оно дешевле и надежнее для больших объемов.;5
Что такое F1-score?;Гармоническое среднее между precision и recall.;F1-score - это гармоническое среднее между precision и recall, которое обеспечивает баланс между этими двумя метриками и особенно полезно при несбалансированных классах.;5
Обучение с подкреплением и ансамбли;Обучение с подкреплением основано на взаимодействии со средой, ансамбли комбинируют несколько моделей;Обучение с подкреплением и ансамблевые методы обучения;5
Какие методы балансировки классов в несбалансированных данных?;Для балансировки классов используются oversampling (SMOTE), undersampling, взвешивание классов и генеративные модели для создания синтетических примеров;Выравнивание распределения классов;2
Метрики качества для моделей регрессии;Для оценки регрессионных моделей используются RMSE (среднеквадратичная ошибка), MAE (средняя абсолютная ошибка), MAPE (средняя абсолютная процентная ошибка) и R? (коэффициент детерминации), которые измеряют различные аспекты точности предсказаний;RMSE и MAE оценивают абсолютные ошибки предсказания, MAPE - относительные ошибки, а R? показывает качество подгонки модели к данным;4
Основные инструменты аналитики больших данных, провести сравнительную характеристику.;К основным инструментам аналитики больших данных относятся Apache Hadoop, Spark, Flink, Hive, Pig, а также BI-платформы вроде Tableau и Power BI. Hadoop обеспечивает распределённое хранение (HDFS) и обработку, Spark — высокую скорость вычислений в оперативной памяти, Hive — SQL-подобный доступ к данным.;К инструментам больших данных относятся Hadoop (HDFS, MapReduce), Spark (RDD, DataFrame API), Hive, Flink, Tableau, Power BI. Hadoop решает задачи хранения, Spark — параллельной обработки в оперативной памяти.;5
Примеры задач, решаемых с помощью больших графов;Используются для разных связей.;Графы — это когда соединены узлы и линии, как в соцсетях.;3
Что такое 'нормализация данных'?;"Нормализация данных — это процесс приведения признаков к единому масштабу для корректной работы алгоритмов машинного обучения.,""Это просто изменение значений";чтобы были одинаковые.;3
Генеральная совокупность и выборка;Совокупность - все объекты исследования, выборка - часть совокупности для анализа;Полная совокупность объектов и ее представительная часть;4
Обучение с учителем и без учителя;Обучение с учителем использует размеченные данные с известными ответами, а без учителя обнаруживает скрытые структуры в данных без меток;С учителем - работа с размеченными данными, без учителя - поиск паттернов в неразмеченных данных;3
Как оптимизировать хранение sparse данных в колоночных форматах?;Использование efficient encoding для sparse колонок, compression algorithms, отказ от хранения null значений, специализированные форматы для sparse матриц.;Эффективное кодирование, сжатие, исключение null. Оптимизация хранения разреженных данных в колоночных форматах.;4
Как работает Delta Lake и какие проблемы ACID он решает в data lakes?;Открытый формат хранения поверх data lakes с ACID транзакциями, schema enforcement, time travel. Решает проблемы consistency, изоляции и надежности в традиционных data lakes.;Формат добавляющий ACID транзакции в data lakes. Решает проблемы целостности данных и конкурентного доступа в больших хранилищах.;3
Что такое регрессионный анализ;Статистический метод моделирования зависимостей между переменными для прогнозирования численных значений;Метод для предсказания чисел на основе данных;2
Основные инструменты аналитики больших данных;Hadoop, Spark, NoSQL БД, облачные платформы. Hadoop для хранения, Spark для обработки, NoSQL для неструктурированных данных;Есть разные программы для работы с данными, например Excel и базы данных;2
Что такое MLOps?;Практики CI/CD для развертывания и мониторинга моделей машинного обучения.;Подход к организации процесса разработки и внедрения моделей машинного обучения в production.;3
Какие метрики используются для оценки качества регрессионных моделей?;MSE, RMSE, MAE, R?, MAPE. Каждая метрика имеет свои преимущества: MSE чувствительна к выбросам, MAE более устойчива, R? показывает долю объясненной дисперсии.;Показатели точности предсказаний для задач регрессии.;2
Какие стратегии использовать для оптимизации производительности Spark при работе с большими данными?;Кэширование часто используемых DataFrame, правильное партиционирование данных, использование broadcast join для маленьких таблиц, настройка памяти исполнителей, выбор оптимального формата хранения.;Кэшировать данные, правильно партиционировать, настраивать память и использовать хорошие форматы хранения.;3
В каких сферах применяются большие данные и каковы примеры их использования?;Большие данные используются в медицине (анализ медицинских изображений), ритейле (персонализированные рекомендации), финансах (fraud detection), транспорте (оптимизация маршрутов), IoT (умные города).;В медицине для диагностики по снимкам, в интернет-магазинах для рекомендаций товаров, в банках для обнаружения мошенничества, в логистике для построения маршрутов.;5
Как оценивается качество рекомендательных систем?;Для оценки рекомендательных систем используются Precision@K, Recall@K, NDCG, MAP и метрики разнообразия рекомендаций;Метрики для рекомендаций;2
Как внедрение большие данные влияет на процессы в организациях?;Большие данные применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Большие данные — это что-то про компьютеры. Применяется редко.;2
Какие основные инструменты и технологии используются для работы с глубокое обучение?;Глубокое обучение применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Это просто работа с таблицами. Не очень полезно.;2
NoSQL. Классификация NoSQL-хранилищ (типы). Их особенности. Примеры распределенных хранилищ.;Типы NoSQL: документо-ориентированные (MongoDB), ключ-значение (Redis), графовые (Neo4j), колонночные (Cassandra). Особенности — отсутствие фиксированной схемы, горизонтальное масштабирование, высокая доступность.;NoSQL — это просто большие базы данных без SQL.;3
Что такое нейронная сеть и где она применяется?;Нейронная сеть — это вычислительная модель, имитирующая работу нейронов мозга, применяемая для распознавания образов, прогнозирования и обработки естественного языка.;Нейронная сеть — это когда компьютер работает как мозг, она используется в ИИ.;2
В чем преимущества применения глубокое обучение по сравнению с традиционными методами?;Глубокое обучение применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;4
Что такое ансамблевые методы?;Комбинация нескольких моделей для улучшения прогнозной способности и устойчивости.;Когда берут много моделей и усредняют их результаты.;2
Как работает градиентный бустинг и чем отличается от случайного леса?;Градиентный бустинг последовательно строит деревья, каждое следующее исправляет ошибки предыдущего, тогда как случайный лес строит деревья независимо и усредняет результат;Алгоритмы ансамблевого обучения;2
В чем разница между горизонтальным и вертикальным масштабированием в контексте Big Data?;Горизонтальное масштабирование - добавление новых узлов в кластер, вертикальное - увеличение ресурсов существующих серверов. Big Data системы предпочитают горизонтальное масштабирование как более экономичное и отказоустойчивое.;Горизонтальное масштабирование добавляет узлы, вертикальное улучшает существующие. В Big Data обычно используют горизонтальное.;3
Принцип массивных вычислений в R;Векторизованные операции позволяют эффективно обрабатывать большие массивы данных без использования циклов, используя оптимизированные низкоуровневые функции;Обработка данных с помощью векторных операций вместо циклов для повышения производительности;2
Что такое learning rate в градиентном спуске?;Гиперпараметр, определяющий размер шага на каждой итерации градиентного спуска. Слишком высокий learning rate может привести к расходимости, слишком низкий - к медленной сходимости или застреванию в локальных минимумах.;Параметр который определяет насколько сильно обновляются веса модели на каждом шаге обучения. Нужно подбирать баланс - слишком большой шаг может пропустить минимум, слишком маленький будет долго обучаться.;5
Сколько данных лучше взять для обучения: побольше или поменьше?;Объем данных для обучения должен быть достаточным для репрезентативности, но важнее качество данных. Для сложных моделей требуется больше данных, но необходим баланс с вычислительными ресурсами.;Нужно достаточно данных для обучения моделей;3
Как масштабируемые системы влияет на эффективность бизнеса?;Масштабируемые системы используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Это что?то связанное с данными, но используется редко.;2
Что такое word2vec?;Алгоритм для создания векторных представлений слов на основе их контекста.;Метод получения векторных эмбеддингов слов, где слова с похожим значением располагаются рядом в векторном пространстве на основе анализа контекстов их употребления.;4
Почему технологии распределённые вычисления стали критически важны?;Распределённые вычисления помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Распределённые вычисления широко применяется в промышленности, здравоохранении, финансах и государственных системах. Позволяет анализировать большие массивы данных, строить точные модели и улучшать эффективность процессов.;5
Что понимается под термином 'Data Mining'?;Data Mining — это процесс извлечения ранее неизвестных, практически полезных и интерпретируемых знаний из больших объемов данных.;Data Mining — это просто копирование данных из базы.;2
Разница между линейной и логистической регрессией;Линейная регрессия моделирует непрерывные количественные зависимости между переменными, тогда как логистическая регрессия предсказывает вероятности бинарной или мультиклассовой классификации с использованием сигмоидной функции;Линейная регрессия для регрессионного анализа, логистическая для задач классификации;4
Понятие регрессии. Как используется этот вид анализа?;Регрессия — статистический метод, моделирующий зависимость целевой переменной Y от факторов X1, X2,..., Xn. Применяется для прогнозирования и анализа влияния факторов.;Регрессионный анализ описывает зависимость Y = f(X1,...,Xn) для прогнозирования и интерпретации влияния факторов. Применяется в эконометрике, Data Mining и машинном обучении для построения предиктивных моделей.;5
Как рекомендательные системы применяется для автоматизации рутинных процессов?;Рекомендательные системы используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Рекомендательные системы применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;5
Как характеристика Velocity влияет на выбор архитектуры обработки данных?;Высокая Velocity требует streaming архитектур (Kafka, Flink, Spark Streaming) вместо batch processing, так как данные должны обрабатываться в реальном времени с минимальной задержкой.;Скорость данных определяет выбор между потоковой и пакетной обработкой. Высокая скорость требует streaming.;3
Как проектировать систему для обработки геопространственных данных в реальном времени?;Использовать специализированные БД (PostGIS), пространственные индексы (R-tree, Quad-tree), распределенные системы для масштабирования, streaming frameworks для real-time обработки.;Специализированные гео-БД типа PostGIS, пространственные индексы для быстрого поиска, распределенные системы для масштабирования и streaming frameworks для обработки в реальном времени. Важно оптимизировать запросы по расстоянию и областям.;5
Зачем нужны рекуррентные нейросети?;Рекуррентные нейросети (RNN) используются для работы с последовательными данными — текст, временные ряды, речь. Основная идея — наличие памяти о предыдущих состояниях. Формула: h_t = f(Wx_t + Uh_{t-1}).;RNN применяются для анализа временных рядов и текстов, так как запоминают предыдущее состояние.;5
В чем преимущества применения классификация данных по сравнению с традиционными методами?;Классификация данных применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Используется для прогнозов и анализа информации.;3
Какие проблемы возникают при использовании кластеризация данных?;Кластеризация данных помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Кластеризация данных используется для обработки информации и улучшения решений.;3
Что такое Hadoop и каковы его основные компоненты?;Hadoop — это фреймворк для распределенной обработки больших данных. Основные компоненты: HDFS (файловая система), YARN (планировщик ресурсов), MapReduce (модель вычислений).;Hadoop — это платформа для хранения и анализа данных, основа — HDFS и MapReduce.;4
Что такое data mesh архитектура?;Децентрализованный подход к управлению данными с domain-oriented ownership;Архитектура где данные управляются децентрализовано domain-командами с самодостаточными data products;5
Что такое 'ошибка модели'?;"Ошибка модели — это разница между предсказанными и истинными значениями целевой переменной.,""Ошибка — это то";насколько прогноз модели не совпадает с реальностью.;4
Что такое DBSCAN?;Алгоритм кластеризации на основе плотности, способный находить кластеры произвольной формы и выбросы.;Метод поиска кластеров по плотности данных. Лучше чем k-means для сложных форм.;3
Где применяется предиктивная аналитика в промышленности и бизнесе?;Предиктивная аналитика применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;4
Для чего нужны ключи сообщений в Kafka;Ключи сообщений определяют, в какую партицию топика будет записано сообщение. Сообщения с одинаковым ключом попадают в одну партицию, сохраняя порядок.;Ключи сообщений в Kafka служат для детерминированного распределения сообщений по партициям (через хэширование ключа) и обеспечения порядка обработки связанных сообщений — все сообщения с одинаковым ключом попадают в одну партицию и сохраняют порядок относительно друг друга.;5
Классификация методов Data Mining;Классификация, кластеризация, регрессия, ассоциативные правила, анализ последовательностей;Классификация (категоризация), кластеризация (группировка), регрессия (прогнозирование), ассоциация (связи);3
Для чего нужны индексы Gain и Gini?;Gain и Gini используются в деревьях решений для выбора оптимального признака при разбиении узла;Для выбора признаков в деревьях;2
Как выбрать между колоночным и строчным хранением данных для аналитических нагрузок?;Колоночное хранилище лучше для аналитических запросов с агрегациями по немногим колонкам, строчное - для OLTP с операциями над целыми строками. Использовать колоночные форматы (Parquet, ORC) для data warehousing.;Колоночное хранение для аналитики где часто агрегируют данные по колонкам. Строчное для транзакционных систем где работают с полными записями.;4
С какими проблемами сталкиваются при применении компьютерное зрение, и как их решают?;Компьютерное зрение применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Компьютерное зрение нужно только программистам.;2
Что такое CAP-теорема и как она применяется в Big Data системах?;CAP-теорема утверждает, что распределенная система может гарантировать только два из трех свойств: Consistency (консистентность), Availability (доступность), Partition Tolerance (устойчивость к разделению). В Big Data обычно жертвуют строгой консистентностью ради доступности и partition tolerance.;CAP-теорема говорит что распределенная система может обеспечить только два из трех: консистентность, доступность или устойчивость к сетевым сбоям. В Big Data часто выбирают доступность и устойчивость к разделению.;5
Что такое метод главных компонент (PCA)?;Метод снижения размерности данных через проецирование на ортогональные компоненты с максимальной дисперсией.;Метод уменьшения размерности данных через выделение основных компонент.;3
Структуры и типы данных в языке R, привести примеры.;В R присутствуют структуры данных: vector, matrix, data.frame, list, factor. Примеры: vector(c(1,2,3)), matrix(1:9, nrow=3), data.frame(x=1:3, y=c('a','b','c')).;Основные структуры данных: vector, matrix, data.frame, list, factor.;4
Обучение с подкреплением и ансамбли;"RL - обучение через взаимодействие со средой; ансамбли - комбинация нескольких моделей";Обучение с подкреплением и ансамблевые методы как подходы;3
Какие методы feature selection используются в машинном обучении?;Методы отбора признаков включают фильтры (correlation), встроенные методы (L1-регуляризация) и методы-обертки (recursive feature elimination);Методы отбора признаков включают фильтры и встроенные методы;5
Как обрабатывать выбросы (outliers) в данных перед построением ML модели?;Анализировать природу выбросов: удалять если это ошибки измерения, использовать robust методы если это реальные значения, трансформировать данные, применять алгоритмы устойчивые к выбросам.;Анализировать природу выбросов - удалять если ошибки, иначе использовать robust алгоритмы. Применять методы обнаружения выбросов и решать сохранять или преобразовывать их.;4
Как развивается направление предобработка данных в последние годы?;Предобработка данных помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Предобработка данных используется бизнесом для оптимизации процессов, анализа клиентов и прогнозирования.;4
Что такое Big Data и каковы её основные характеристики?;Big Data — это технологии и методы обработки чрезвычайно больших объёмов данных, характеризующихся 5V: Volume, Velocity, Variety, Veracity, Value. Применяются в финансах, здравоохранении, промышленности.;Big Data — это большие данные, обрабатываемые специальными инструментами, имеет характеристики объема и скорости.;4
Основные задачи Data Analysis;Описательная аналитика, диагностика, прогнозирование, прескриптивная аналитика для принятия решений;Описание, диагностика, прогноз;3
Какие риски связаны с применением data warehouses?;Data warehouses используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Data warehouses нужно только программистам, обычным компаниям оно бесполезно.;2
Что такое ELT процесс?;Процесс загрузки данных перед их преобразованием в целевой системе.;Альтернатива ETL, где преобразование данных происходит после их загрузки в целевую систему.;3
Как рекомендуется разделять данные для обучения моделей?;60-80% тренировочные, 10-20% валидационные, 10-20% тестовые. Для кросс-валидации - k-fold разбиение. Зависит от объема данных.;Обычно 70% train, 15% validation, 15% test. При малых данных - кросс-валидация. При больших - можно 80/10/10. Важно сохранять распределение классов.;5
Что такое schema evolution в Big Data?;Возможность изменения схемы данных без потери совместимости с существующими данными;Изменение формата данных;2
Понятия репликации и шардинга;Репликация создает копии данных для отказоустойчивости, шардинг распределяет данные между серверами;Репликация для надежности, шардинг для масштабирования;3
Как организовать data quality checks в ETL процессах?;Automated validation rules, data profiling, constraint checking, statistical tests, anomaly detection, alerting on quality issues.;Автоматическая валидация, профилирование, проверка constraints. Мониторинг качества данных в ETL.;4
Перечислить стадии разработки систем машинного обучения.;Стадии разработки систем машинного обучения: сбор данных, очистка и подготовка, выделение признаков, выбор модели, обучение, оценка качества, внедрение и мониторинг.;Основные этапы: сбор, очистка, извлечение признаков, обучение, тестирование и мониторинг модели.;5
Что такое машинное обучение?;Машинное обучение — это раздел искусственного интеллекта, изучающий методы построения алгоритмов, способных самостоятельно выявлять закономерности в данных и принимать решения без явного программирования.;Это обучение компьютера.;2
Какие этапы включает проект, основанный на использовании ETL-процессы?;Etl-процессы используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Etl-процессы применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;5
Что такое MapReduce?;Модель программирования для обработки больших объемов данных в распределенных кластерах, состоящая из этапов Map (фильтрация и сортировка) и Reduce (агрегация результатов).;Алгоритм для работы с большими данными в Hadoop.;2
Что такое переобучение (overfitting)?;Ситуация, когда модель слишком точно подстраивается под тренировочные данные, включая их шум, теряя способность к обобщению на новых данных.;Это когда модель работает идеально на старых данных, но плохо на новых из-за излишней сложности и запоминания данных.;4
Интегральные метрики качества;К интегральным метрикам относятся ROC-AUC, Precision-Recall AUC, F1-score и R?, которые агрегируют различные аспекты качества модели в единый показатель;ROC-AUC оценивает качество классификации across всех thresholds, F1 объединяет precision и recall, R? измеряет долю объясненной дисперсии;3
Какие стратегии использовать для оптимизации производительности Spark при работе с большими данными?;Кэширование часто используемых DataFrame, правильное партиционирование данных, использование broadcast join для маленьких таблиц, настройка памяти исполнителей, выбор оптимального формата хранения.;Разные методы ускорения Spark приложений.;2
Как проектировать систему для обработки данных IoT устройств с высокой частотой обновления?;Использовать потоковые платформы (Kafka, Flink), колоночные форматы хранения, сжатие данных, агрегацию на edge устройствах, мониторинг пропускной способности и задержек.;Потоковые системы для real-time обработки, оптимизированные форматы хранения, сжатие данных, edge computing для уменьшения нагрузки, мониторинг метрик системы.;4
Какие основные инструменты используются для аналитики больших данных и их сравнение?;Hadoop (HDFS, MapReduce) для хранения и пакетной обработки, Spark для in-memory вычислений, Kafka для потоковой обработки, NoSQL БД для неструктурированных данных. Сравнение по производительности, масштабируемости, use cases.;Hadoop - распределенное хранение и обработка, Spark - быстрые вычисления, Kafka - потоки данных. Разные инструменты для разных типов обработки.;4
Какие стратегии использовать для управления памятью в Spark при работе с большими датасетами?;Настройка memory fractions, использование off-heap memory, сериализация данных, кэширование с правильными уровнями хранения, мониторинг GC, разделение памяти между execution и storage.;Оптимизация памяти executor'ов, off-heap memory, эффективная сериализация, настройка кэширования, мониторинг GC и балансировка памяти между задачами и хранением.;4
Стадии разработки систем ML;Полный процесс разработки систем машинного обучения включает сбор и подготовку данных, проектирование признаков, обучение моделей, валидацию результатов и развертывание в production-среде;Основные этапы создания и внедрения систем машинного обучения в эксплуатацию;2
Что такое статистическая гипотеза? Какие виды гипотез вы знаете?;Статистическая гипотеза - это предположение о свойствах генеральной совокупности, проверяемое статистическими методами. Виды: нулевая (об отсутствии эффекта) и альтернативная (о наличии эффекта);Нулевая и альтернативная гипотезы для статистического тестирования;4
Какие реальные примеры использования обработка потоковых данных существуют?;Технологии обработка потоковых данных позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Обработка потоковых данных используется для обработки информации и улучшения решений.;3
Почему технологии хранилища данных стали критически важны?;Хранилища данных используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Хранилища данных используется для обработки информации и улучшения решений.;3
В чем преимущества применения машинное обучение по сравнению с традиционными методами?;Машинное обучение помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;4
Примеры задач с большими графов;Социальные сети, рекомендательные системы, биоинформатика, транспортные сети, веб-графы;Задачи анализа больших графов;4
Что такое SHAP values?;Метод объяснения предсказаний ML моделей на основе теории игр, показывающий вклад каждого признака.;Значения которые показывают вклад каждого признака в конкретное предсказание модели. Основаны на Shapley values из теории игр для справедливого распределения вклада.;5
Каковы условия остановки ветвления дерева?;Остановка при достижении максимальной глубины, минимального числа samples в узле, отсутствии улучшения качества или pure node;Когда дерево перестает расти;2
Какие методы использовать для обработки категориальных переменных с большим количеством уникальных значений?;Target encoding, frequency encoding, embedding layers для нейросетей, grouping редких категорий, hash encoding. Избегать one-hot encoding при большом cardinality.;Target encoding, frequency encoding, embedding, группировка редких значений. Избегать one-hot encoding когда много уникальных категорий.;4
Определение термина «большие данные»;Большие данные представляют собой огромные объемы разнородной информации, требующие специальных технологий обработки;Большие объемы данных разных типов;4
Зачем нужно уменьшение размерностей?;Уменьшение размерностей позволяет избавиться от избыточных признаков, ускорить обучение и избежать переобучения. Методы: PCA, t-SNE, LDA. Формула PCA: var(max(W^T X)).;PCA уменьшает количество признаков, сохраняя максимум дисперсии данных.;5
Что такое корреляция в анализе данных?;Корреляция — это статистическая мера взаимосвязи между двумя переменными. Она показывает направление и силу связи, выражается коэффициентом r в диапазоне от -1 до +1.;Это сравнение данных.;2
Какие компании активно используют рекомендательные системы и зачем?;Рекомендательные системы помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Используется для прогнозов и анализа информации.;3
Для чего нужны гипотезы в анализе данных;Гипотезы позволяют формулировать проверяемые утверждения и проводить статистическую проверку научных предположений;Гипотезы необходимы для статистической проверки различных утверждений;5
Что такое data catalog?;Централизованный реестр метаданных для обнаружения и понимания данных;Каталог информации о данных;3
Почему технологии ETL-пайплайны стали критически важны?;Etl-пайплайны используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Etl-пайплайны применяется в финансах, медицине, рекламе и IT, помогает анализировать данные и строить модели.;4
Какие основные инструменты и технологии используются для работы с большие данные?;Большие данные помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Большие данные — это что-то про компьютеры. Применяется редко.;2
С какими проблемами сталкиваются при применении кластеризация, и как их решают?;Кластеризация используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Кластеризация применяется в бизнесе и иногда в науке для анализа данных.;3
Преобразование и очистка данных;Процесс преобразования включает нормализацию, кодирование категориальных переменных, обработку пропущенных значений и выбросов для улучшения качества данных;Изменение формата данных чтобы сделать их пригодными для анализа;2
Как понимать «уровень статистической достоверности»? Это ли вероятность ошибки?;Уровень статистической достоверности (p-value) показывает вероятность того, что наблюдаемый эффект возник случайно. Чем меньше p-value, тем выше достоверность результата. Он не равен вероятности ошибки напрямую, но связан с ней через уровень значимости ?.;p-value — показатель статистической значимости, который отражает вероятность случайного эффекта.;5
Почему организации переходят на технологии системы логирования?;Технологии системы логирования позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Системы логирования почти нигде не применяется. Это просто большие таблицы.;2
Что такое метод опорных векторов (SVM)?;Метод опорных векторов — это алгоритм классификации, который ищет гиперплоскость, максимально разделяющую данные разных классов.;SVM — это метод машинного обучения для деления данных.;2
Метрики качества для моделей регрессии;Для оценки регрессионных моделей используются RMSE (среднеквадратичная ошибка), MAE (средняя абсолютная ошибка), MAPE (средняя абсолютная процентная ошибка) и R? (коэффициент детерминации), которые измеряют различные аспекты точности предсказаний;Метрики ошибок оценивают точность предсказаний в разных единицах измерения, а коэффициент детерминации показывает объясняющую способность регрессионной модели;5
Нарисуйте (опишите) схему классификации методов машинного обучения;Классификация методов ML включает обучение с учителем (классификация, регрессия), без учителя (кластеризация, снижение размерности), с подкреплением и полу-контролируемое обучение;Классификация методов на обучение с учителем, без учителя и с подкреплением;4
Что такое MLOps и как он отличается от традиционного DevOps?;Практики для автоматизации жизненного цикла ML моделей включая эксперименты, deployment, мониторинг. Отличается необходимостью управления данными, моделями, экспериментированием и дрейфом.;MLOps расширяет DevOps для ML: управление данными, версионирование моделей, экспериментирование, мониторинг дрейфа. Включает специфичные для ML этапы кроме традиционного CI/CD.;5
Почему организации переходят на технологии мониторинг больших данных?;Технологии мониторинг больших данных позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Эти технологии помогают работать с информацией и делать прогнозы.;3
Способы графического представления данных;Гистограммы, диаграммы рассеяния, box plots, линейные графики. Выбор зависит от типа данных и цели;Гистограммы для распределения непрерывных данных, scatter plots для анализа связей, box plots для сравнения распределений, линейные графики для временных рядов. Выбор определяется природой данных и аналитическими задачами;5
Фундаментальное свойство статистического обучения;Компромисс между смещением и дисперсией (bias-variance tradeoff) - ключевое свойство, определяющее обобщающую способность моделей;Bias-variance tradeoff;3
В каких пропорциях разделять данные перед обучением;70-80% обучение, 15-20% валидация, 15-20% тестирование. Зависит от объема данных;Делить данные на части для обучения и проверки;2
Что такое feature engineering?;Процесс создания и отбора признаков для улучшения качества моделей машинного обучения.;Процесс подготовки и создания признаков из исходных данных чтобы улучшить работу алгоритмов машинного обучения.;4
Суть алгоритмов связных компонент и покрывающего дерева;Алгоритм связных компонент находит группы связанных узлов в графе, а алгоритм покрывающего дерева находит минимальный набор рёбер, соединяющий все вершины;Методы для анализа графовых структур;2
Какие стратегии использовать для управления памятью в Spark при работе с большими датасетами?;Настройка memory fractions, использование off-heap memory, сериализация данных, кэширование с правильными уровнями хранения, мониторинг GC, разделение памяти между execution и storage.;Настройка памяти executor'ов, использование off-heap memory, эффективная сериализация, выбор правильных уровней кэширования, мониторинг garbage collection, балансировка памяти между выполнением задач и хранением данных.;5
Фундаментальное свойство статистического обучения;Фундаментальным свойством является компромисс между смещением и дисперсией (bias-variance tradeoff), который определяет способность модели к обобщению на новых данных;Bias-variance tradeoff как ключевое свойство обучения;4
Что такое Big Data и каковы её основные характеристики?;Big Data — это технологии и методы обработки чрезвычайно больших объёмов данных, характеризующихся 5V: Volume, Velocity, Variety, Veracity, Value. Применяются в финансах, здравоохранении, промышленности.;Большие данные — это просто много информации, которую нужно анализировать.;3
Зачем нужно уменьшение размерностей?;Уменьшение размерностей позволяет избавиться от избыточных признаков, ускорить обучение и избежать переобучения. Методы: PCA, t-SNE, LDA. Формула PCA: var(max(W^T X)).;Уменьшение размерностей помогает быстрее обучать модели.;4
Какие навыки необходимы специалисту для работы с ETL-процессы?;Etl-процессы используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;4
Какие методы feature selection используются в машинном обучении?;Методы отбора признаков включают фильтры (correlation), встроенные методы (L1-регуляризация) и методы-обертки (recursive feature elimination);Различные подходы к отбору информативных признаков;4
Какие типы шкал измерения данных существуют в статистике?;Номинальная (категории без порядка), порядковая (категории с порядком), интервальная (числа с равными интервалами), относительная (числа с абсолютным нулем).;Номинальная - названия категорий, порядковая - ранги, интервальная - температуры, относительная - вес, рост. Каждая шкала определяет допустимые операции.;5
Основные вызовы больших данных;Volume, Velocity, Variety, Veracity - основные характеристики и challenges больших данных;Объем, скорость, разнообразие и достоверность данных;3
Что такое статистическая гипотеза;Статистическая гипотеза представляет собой формальное проверяемое предположение о свойствах генеральной совокупности или параметрах распределения, которое может быть подтверждено или опровергнуто с помощью статистических методов тестирования;Утверждение о параметрах распределения или свойствах данных, проверяемое статистическими критериями;3
Шаги построения дендрограммы;Построение дендрограммы включает вычисление матрицы расстояний, применение агломеративного алгоритма кластеризации и визуализацию иерархической структуры слияния кластеров;Шаги построения включают вычисление матрицы расстояний и агломеративную кластеризацию;5
Какие подходы использовать для оптимизации запросов в колоночных базах данных?;Predicate pushdown, column pruning, использование статистик для планирования запросов, оптимизация формата хранения, сжатие данных, правильное партиционирование.;Predicate pushdown, чтение только необходимых колонок, использование статистик, оптимизация форматов хранения и партиционирования для ускорения запросов в колоночных БД.;4
Данные, информация, знания — в чём отличия?;Данные - сырые факты, информация - структурированные данные, знания - проверенные закономерности;Разные уровни понимания;2
Нормальное распределение;Нормальное распределение характеризуется симметричной колоколообразной формой и определенными параметрами центра и dispersion;Распределение с симметричной формой;4
Какие риски связаны с применением распределённые вычисления?;Распределённые вычисления помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Технологии распределённые вычисления позволяют компаниям обрабатывать большие объёмы разнородных данных, выявлять сложные закономерности и принимать обоснованные решения.;5
Как специалисты анализируют данные в рамках in-memory обработка?;In-memory обработка помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Эти технологии помогают работать с информацией и делать прогнозы.;3
Обучение с подкреплением и ансамбли — основные разновидности и принципы;Обучение с подкреплением включает Q-learning и политические градиенты, ансамбли используют бэггинг, бустинг и стэкинг для улучшения предсказательной способности моделей;RL через взаимодействие со средой, ансамбли через комбинацию моделей;3
Что такое Apache Parquet?;Колоночный формат хранения данных с эффективным сжатием и кодированием.;Parquet - это колоночный формат хранения, оптимизированный для больших данных, обеспечивающий эффективное сжатие, быстрый доступ к колонкам и совместимость с различными фреймворками обработки.;5
Когда использовать линейные, а когда нелинейные модели?;"Линейные - при линейных зависимостях, нелинейные - при сложных паттернов; выбор через анализ остатков";Линейные модели для линейных зависимостей, нелинейные для сложных;5
Что такое feature engineering и какие методы используются?;Feature engineering - процесс создания и отбора признаков, включающий кодирование категориальных переменных, создание полиномиальных features и отбор наиболее значимых признаков;Создание признаков для моделей;2
Что такое Apache ZooKeeper?;Централизованный сервис для поддержания конфигурационной информации, именования, распределенной синхронизации и предоставления групповых сервисов в распределенных системах.;Система для координации распределенных приложений. Помогает управлять конфигурацией и синхронизацией в кластере.;4
Архитектура хранилищ данных.;Классическая архитектура хранилища включает уровни: источник данных, ETL-процесс (Extract, Transform, Load), слой хранения (Data Warehouse), слой аналитики (OLAP-кубы, BI-инструменты). Возможны схемы: звезда, снежинка, галактика.;Хранилище данных строится по схеме звезды и включает слои данных.;4
Что такое F1-score?;Гармоническое среднее между precision и recall.;Метрика, которая объединяет precision и recall в одно число, балансируя между точностью предсказаний и полнотой охвата позитивных случаев.;4
Примеры задач с большими графами;Большие графы используются в социальных сетях для анализа сообществ, в рекомендательных системах и биоинформатике для изучения белковых взаимодействий;Применение графов для решения различных задач анализа данных;2
Перечислите основные метрики больших графов;Основные метрики больших графов включают диаметр, плотность, коэффициент кластеризации, центральность по степени, посредничеству и близости;Метрики: диаметр, плотность, кластеризация, степени центральности для анализа графов;4
Какие навыки необходимы специалисту для работы с анализ данных?;Анализ данных используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;4
Перечислите основные задачи анализа сетей на графах. Приведите примеры.;Основные задачи: поиск сообществ, определение центральности, анализ кратчайших путей, выявление аномалий, моделирование распространения информации.;Главные задачи — анализ узлов и связей, поиск похожих элементов.;2
Принципы глубокого обучения в нейросетях. Преимущества сверточных сетей.;Глубокое обучение использует многослойные нейронные сети (MLP, CNN, RNN) для автоматического извлечения признаков. CNN эффективны в задачах CV благодаря сверткам (convolution) и pooling. Формула свертки: y = ?(x*w).;CNN — это нейросети, которые делают фильтры.;2
Что такое Apache Kafka и для каких задач он используется?;Распределенная потоковая платформа для обработки данных в реальном времени. Используется для построения data pipelines, event-driven архитектур, streaming приложений.;Система для обработки потоков данных. Используется для передачи сообщений между системами, обработки событий, построения реального времени приложений.;4
Как работает Federated Learning и в каких сценариях он наиболее эффективен?;Обучение моделей на децентрализованных данных без их передачи на сервер. Эффективен для privacy-sensitive сценариев: healthcare, мобильные устройства, где данные нельзя централизовать.;Децентрализованное обучение без передачи исходных данных. Наиболее эффективен когда данные конфиденциальны или распределены по многим устройствам (IoT, мобильные приложения).;4
В чем разница между batch processing и stream processing?;Batch processing обрабатывает данные пачками с задержкой, stream processing обрабатывает данные в реальном времени по мере поступления.;Batch - периодическая обработка, stream - постоянная обработка. Для разных сценариев использования.;3
Что такое нормализация данных?;Приведение данных к единому масштабу без исказации соотношений.;Приведение данных к общему масштабу перед обработкой.;3
Назовите меры центральной тенденции;Основные меры центральной тенденции включают среднее арифметическое, медиану и моду распределения;Среднее и медиана;2
Что такое data catalog?;Централизованный реестр метаданных для обнаружения и понимания данных;База метаданных;2
Как работает механизм Adaptive Query Execution в Spark 3.0 и какие проблемы он решает?;AQE динамически переоптимизирует план запроса во время выполнения на основе реальной статистики данных. Решает проблемы ошибочных оценок размера данных, неоптимальных join стратегий и партиционирования.;Новая функция в Spark для ускорения запросов через адаптацию during выполнения.;2
Назовите характеристики качества данных;Полнота, точность, непротиворечивость, актуальность, достоверность, релевантность данных;Характеристики качества данных включают полноту и точность;5
Что такое Data Lake и чем он отличается от Data Warehouse?;Data Lake — это централизованное хранилище, где данные сохраняются в исходном виде. Data Warehouse — структурированное хранилище для анализа. Главное отличие — степень структурированности данных.;Data Lake — это репозиторий сырых, неструктурированных данных, предназначенный для гибкой аналитики. Data Warehouse — это оптимизированное хранилище структурированных данных, применяемое для BI и отчетности.;5
Как реализовать инкрементальную обработку данных в ETL пайплайнах?;Использовать Change Data Capture (CDC), watermarking для потоковых данных, инкрементальные snapshot'ы, обработку только дельт изменений вместо полных данных.;CDC для захвата изменений, обработка только новых/измененных данных, использование watermark в потоках, обеспечение идемпотентности операций.;4
Разновидности сложных сетей;Однородные, масштабно-инвариантные, малого мира, иерархические, случайные сети;Разновидности включают однородные и безмасштабные сети;5
Что такое recall и precision?;Precision - точность предсказаний, recall - полнота охвата реальных позитивных случаев.;Precision показывает долю верно предсказанных позитивных случаев среди всех предсказанных позитивными, а recall - долю верно найденных позитивных случаев среди всех реально позитивных.;5
Сколько данных лучше для обучения;Объем данных для обучения моделей машинного обучения должен быть достаточным для обеспечения репрезентативности выборки при обязательном условии обеспечения высокого качества данных и их релевантности решаемой задаче;Зависит от конкретной задачи, сложности модели и требуемой точности предсказаний;3
Основные вызовы больших данных (4V, 8V).;Основные характеристики больших данных обозначаются как 4V: Volume (объем), Velocity (скорость), Variety (разнообразие), Veracity (достоверность). В расширенной модели 8V добавляются Value (ценность), Variability (изменчивость), Visualization (визуализация), Vulnerability (уязвимость).;Основные свойства — объем, скорость, разнообразие. Иногда добавляют ценность.;3
Что такое 'градиентный спуск'?;Градиентный спуск — это алгоритм оптимизации, который минимизирует функцию потерь, изменяя параметры модели в направлении антиградиента.;Градиентный спуск — это способ поиска минимума ошибки шаг за шагом.;4
Каким образом выполняется преобразование данных, почему нужна очистка данных?;Преобразование данных выполняется для приведения данных к единому формату и структуры. Очистка необходима для устранения пропусков, дубликатов и ошибок, повышая достоверность анализа.;Очистка данных не нужна, если данных много. Преобразование не требуется.;2
В чем разница между supervised и unsupervised learning?;Supervised learning использует размеченные данные с метками, unsupervised работает с данными без меток.;Supervised - с учителем, unsupervised - без учителя, по-разному работают с данными.;3
Понятие регрессии;Моделирование связи между переменными для прогнозирования;Статистический метод для моделирования и прогнозирования непрерывных переменных на основе предикторов;4
Как большие данные помогает в анализе больших объемов данных?;Большие данные применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Используется для прогнозов и анализа информации.;3
Что такое 'градиентный спуск'?;Градиентный спуск — это алгоритм оптимизации, который минимизирует функцию потерь, изменяя параметры модели в направлении антиградиента.;Градиентный спуск — это метод минимизации ошибки за счёт корректировки параметров модели.;5
Меры качества для языковых моделей;Основные меры качества включают перплексию для оценки модели, BLEU для машинного перевода, ROUGE для суммаризации и метрики точности;Меры качества включают perplexity, BLEU и ROUGE для языковых моделей;5
Как нейронные сети используется в научных исследованиях?;Нейронные сети применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;4
Что такое Data Lake и в чем его преимущества перед Data Warehouse?;Data Lake — это хранилище, где данные сохраняются в исходном виде. Преимущества: гибкость, возможность работы с сырыми и разнородными данными, масштабируемость. Data Warehouse хранит структурированные данные.;Data Lake — это программа для работы с базами.;2
Какие подходы использовать для оптимизации памяти в Python при обработке больших данных?;Использование генераторов, efficient data structures, memory mapping, chunk processing, удаление неиспользуемых объектов, использование специализированных библиотек.;Оптимизация памяти в Python.;2
Что такое Apache Spark SQL?;Модуль Spark для работы со структурированными данными с использованием SQL-подобного синтаксиса.;Компонент Spark для выполнения SQL-запросов к структурированным данным с поддержкой различных форматов и источников.;4
Структуры и типы данных в R;Основные структуры данных в R включают векторы, матрицы, списки, data frames и factors, каждая с определенными свойствами и методами обработки;Векторы хранят атомарные данные одного типа, матрицы - двумерные массивы, списки - упорядоченные коллекции объектов разных типов, data frames - табличные структуры с колонками разных типов, factors - для хранения категориальных переменных с уровнями;5
Почему организации переходят на технологии big data?;Big data используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Технологии позволяют улучшать качество аналитики, находить закономерности и предсказывать события.;4
Виды связи между переменными при корреляции;Связи — это когда данные как-то связаны.;Когда одно число большое, другое тоже большое.;2
Что такое регрессионный анализ, какие задачи DM можно проводить с его помощью?;Регрессионный анализ — метод моделирования зависимости переменной Y от одной или нескольких переменных X. Применяется для прогнозирования, оценки влияния факторов и аппроксимации зависимостей.;Регрессионный анализ используется для построения функциональных зависимостей между переменными (Y=f(X1,…,Xn)), анализа влияния факторов, прогнозирования значений и выявления закономерностей в Data Mining.;5
Зачем нужны рекуррентные нейросети;Для обработки последовательных данных: текст, речь, временные ряды. Сохраняют контекст;Обрабатывают текст и временные ряды, запоминают предыдущие данные;3
Какие подходы использовать для обработки hierarchical данных в SQL?;Recursive CTEs, hierarchical queries, nested sets model, adjacency list, materialized paths, использование специализированных расширений.;Обработка иерархических данных в SQL.;2
Почему технологии масштабируемые системы стали критически важны?;Технологии масштабируемые системы позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Технологии позволяют улучшать качество аналитики, находить закономерности и предсказывать события.;4
Нормальное распределение;Нормальное распределение характеризуется симметричной колоколообразной формой, параметрами ? и ?, встречается во многих природных явлениях;Колоколообразное распределение с ? и ?;4
Boxplot и его интерпретация, связь с другими элементами анализа;Boxplot визуализирует распределение данных через медиану, квартили и выбросы, тесно связан с описательной статистикой и используется для сравнения распределений и выявления аномалий в наборах данных;Визуализация распределения через медиану и квартили, связанная с описательной статистикой для анализа данных;4
В чем разница между данными, информацией и знаниями?;Данные - сырые факты, информация - обработанные данные с контекстом, знания - информация + понимание и опыт для принятия решений.;Данные - исходные значения, информация - обработанные данные, знания - применение информации на практике.;4
Примеры задач с большими графов;Социальные сети, рекомендательные системы, биоинформатика, транспортные сети, веб-графы;Применение графовых моделей;2
Нарисуйте схему классификации методов машинного обучения.;Методы ML классифицируются на обучение с учителем, без учителя и с подкреплением. Также выделяют подтипы — классификация, регрессия, кластеризация, ассоциативные правила, ансамблевые методы.;Все методы машинного обучения делятся на supervised и unsupervised, также есть reinforcement learning.;5
Как нейронные сети используется в научных исследованиях?;Нейронные сети используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Нейронные сети — это что-то про компьютеры. Применяется редко.;2
Как развитие глубокое обучение влияет на будущее цифровых технологий?;Глубокое обучение используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Глубокое обучение нужно только программистам.;2
Data Mining vs. Machine Learning — в чём отличия?;Data Mining фокусируется на обнаружении паттернов в данных, а Machine Learning - на построении прогнозных моделей;Data Mining и Machine Learning имеют разные фокусы;4
Что такое Docker контейнер?;Легковесная изолированная среда для запуска приложений со всеми зависимостями.;Технология для запуска программ в изоляции.;2
Что такое Apache Beam?;Унифицированная модель для определения пайплайнов обработки данных, работающая с разными рантаймами.;Фреймворк для создания пайплайнов обработки данных, который может работать поверх Apache Spark, Flink или Google Cloud Dataflow. Позволяет писать код один раз и запускать на разных execution engines.;5
Что такое checkpointing в распределенных системах?;Сохранение состояния системы в устойчивое хранилище для восстановления после сбоев;Периодическое сохранение состояния вычислений в надежное хранилище для восстановления после отказов;5
NoSQL классификация хранилищ;NoSQL базы данных классифицируются на документные, хранилища ключ-значение, колоночные и графовые в зависимости от модели данных и способа организации хранения;По модели данных: документные для гибких JSON-документов, ключ-значение для простых пар, колоночные для аналитических запросов, графовые для связанных данных с отношениями;5
Как оптимизировать хранение sparse данных в колоночных форматах?;Использование efficient encoding для sparse колонок, compression algorithms, отказ от хранения null значений, специализированные форматы для sparse матриц.;Методы оптимизации хранения данных с большим количеством пропусков.;3
Что такое 'дерево решений'?;Дерево решений — это модель, которая представляет процесс принятия решений в виде иерархии правил, ведущих от корня к листьям.;Это структура для хранения данных в виде дерева.;2
Разница описательных и предсказательных задач;Описательные задачи анализируют существующие данные, предсказательные строят модели для прогнозирования;Анализ прошлого и предсказание будущего;2
Какие основные инструменты и технологии используются для работы с машинное обучение?;Машинное обучение используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;4
В чем преимущества применения модели прогнозирования по сравнению с традиционными методами?;Модели прогнозирования применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Модели прогнозирования применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;5
Что означает 'precision' в классификации?;"Precision — это доля правильно предсказанных положительных примеров среди всех предсказанных как положительные.,""Precision — это мера, показывающая";сколько предсказанных положительных объектов действительно являются положительными.;5
Что такое Apache Spark SQL?;Модуль Spark для работы со структурированными данными с использованием SQL-подобного синтаксиса.;Spark SQL позволяет работать со структурированными данными в Spark, используя либо SQL запросы, либо DataFrame API, обеспечивая оптимизацию запросов через Catalyst optimizer.;5
Примеры задач, решаемых с помощью больших графов.;Большие графы применяются для анализа социальных сетей, поиска путей в транспортных системах, моделирования связей в биоинформатике, рекомендаций и кибербезопасности.;Графы используют в соцсетях и маршрутах.;3
Примеры задач, решаемых с помощью больших графов;Большие графы применяются для анализа социальных сетей, рекомендательных систем, биоинформатики (белковые взаимодействия), транспортных сетей и веб-графов (PageRank);Большие графы применяются для анализа социальных сетей и рекомендательных систем;5
Как оптимизировать data shuffling в распределенных вычислениях?;Minimize shuffling, use broadcast variables, optimize partitioning, use accumulators для агрегаций, filter early, use efficient serialization.;Способы уменьшения перемешивания данных в распределенных системах.;3
Как предобработка данных применяется в современных компаниях?;Предобработка данных помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Это что?то связанное с данными, но используется редко.;2
Перечислите основные задачи анализа сетей на графах;Основные задачи включают обнаружение сообществ, вычисление центральности узлов, поиск кратчайших путей, анализ связности и выявление влиятельных узлов в сетевых структурах;Основные задачи анализа сетей включают обнаружение сообществ, вычисление центральности узлов и поиск кратчайших путей в графах;5
Обучение с учителем и без учителя;Обучение с учителем использует размеченные данные, а без учителя обнаруживает скрытые структуры в данных без меток;Обучение с метками и без;2
Какие методы используются для обработки временных рядов?;Для временных рядов применяются ARIMA, экспоненциальное сглаживание, методы на основе машинного обучения (LSTM, Prophet) и анализ трендов/сезонности;Классические и современные методы анализа временных рядов;4
Как нейронные сети помогает в анализе больших объемов данных?;Нейронные сети помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Нейронные сети нужно только программистам.;2
Как оценивается качество рекомендательных систем?;Для оценки рекомендательных систем используются Precision@K, Recall@K, NDCG, MAP и метрики разнообразия рекомендаций;Показатели точности и полноты рекомендаций;3
Что такое 'обучающая выборка'?;Обучающая выборка — это часть данных, используемая для настройки параметров модели.;Это набор примеров, на которых потом тестируют модель.;3
Что такое визуализация данных и для чего она нужна?;Визуализация данных — это процесс представления информации в графическом виде для облегчения восприятия закономерностей и связей. Используются графики, диаграммы, карты тепла и интерактивные панели.;Визуализация нужна, чтобы наглядно показывать данные, например через графики.;5
Зачем нужна мера близости в кластеризации? Достоинства графовых алгоритмов;Мера близости определяет схожесть объектов для группировки. Графовые алгоритмы эффективны для работы с разреженными данными и выявления сложных структур;Меры близости для кластеризации, преимущества графовых методов;3
Какие метрики используются для оценки моделей в задачах мультиклассовой классификации?;Для мультиклассовой классификации используются accuracy, macro/micro averaged precision/recall, F1-score и confusion matrix для детального анализа ошибок;Для мультиклассовой классификации используются accuracy и F1-score;5
Когда использовать градиентный бустинг вместо случайного леса?;Бустинг когда важна максимальная точность и есть время на тонкую настройку, случайный лес когда нужна robustness и скорость обучения.;Градиентный бустинг обычно дает лучшую точность но требует careful tuning гиперпараметров и дольше обучается. Random Forest более robust к шуму, менее склонен к переобучению и быстрее обучается. Для небольших датасетов бустинг часто лучше, для больших - можно начать с Random Forest.;5
Что такое data pipeline?;Автоматизированный процесс перемещения и преобразования данных от источника до потребителя.;Набор процессов для перемещения данных между системами. Включает ETL/ELT операции и обеспечивает надежную доставку.;4
Что такое HDFS и как обеспечивается отказоустойчивость?;Распределенная файловая система Hadoop. Отказоустойчивость обеспечивается репликацией данных на несколько узлов (по умолчанию 3 копии) и rack-aware размещением.;HDFS хранит данные распределенно. Репликация на несколько серверов гарантирует доступность данных при сбоях оборудования.;4
Структуры и типы данных в R;Векторы, матрицы, списки, фреймы данных, факторы - основные структуры хранения данных;Векторы, матрицы, списки, фреймы данных, факторы и их свойства;4
Обучение с учителем и без учителя. Приведите примеры методов.;Supervised learning использует размеченные данные, примеры: линейная регрессия, логистическая регрессия, SVM. Unsupervised learning использует неразмеченные данные, примеры: k-means, PCA, иерархическая кластеризация.;Обучение с учителем — это когда алгоритм сам выбирает данные.;2
С какими проблемами сталкиваются при применении нейронные сети, и как их решают?;Нейронные сети используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Нейронные сети нужно только программистам.;2
Где применяется анализ данных в промышленности и бизнесе?;Анализ данных применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;4
Какие риски связаны с использованием NLP в критически важных системах?;Nlp помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Nlp применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;4
Как тестируются независимые и парные выборки?;Независимые выборки тестируются с помощью t-теста Стьюдента или U-критерия Манна-Уитни, а парные выборки - с использованием парного t-теста или критерия Вилкоксона;Для независимых выборок используется t-тест, для парных - парный t-тест;3
Для чего нужна гипотеза о равенстве средних;Для статистической проверки различий между средними значениями двух групп или условий;Для проверки статистической значимости различий средних;4
Опишите процесс ETL и его этапы.;ETL (Extract, Transform, Load) — это процесс извлечения данных из источников, их преобразования в нужный формат и загрузки в целевое хранилище. Основные этапы: Extract, Transform, Load.;ETL — процесс извлечения, преобразования и загрузки данных: Extract, Transform, Load.;5
Для чего нужны индексы Gain и Gini? В чём суть индекса Gini.;Индексы Gain и Gini используются в деревьях решений для выбора оптимального признака при разбиении узлов. Индекс Gini измеряет неоднородность данных и стремится к нулю для чистых узлов.;Gain и Gini для выбора признаков в деревьях;3
Принцип работы SVM;Метод опорных векторов находит гиперплоскость с максимальным зазором для разделения классов в пространстве признаков;Алгоритм для классификации;2
Архитектура хранилищ данных.;Классическая архитектура хранилища включает уровни: источник данных, ETL-процесс (Extract, Transform, Load), слой хранения (Data Warehouse), слой аналитики (OLAP-кубы, BI-инструменты). Возможны схемы: звезда, снежинка, галактика.;Архитектура хранилищ — это структура таблиц в Excel.;2
Обучение с подкреплением и ансамбли;Обучение с подкреплением основано на взаимодействии агента со средой для максимизации награды, а ансамбли объединяют несколько моделей для улучшения прогнозирования;Два разных метода машинного обучения;2
Какие этапы включает проект, основанный на использовании глубокое обучение?;Глубокое обучение применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Глубокое обучение применяется в бизнесе и иногда в науке для анализа данных.;3
Принцип массивных вычислений в R;Векторизованные операции позволяют эффективно обрабатывать большие массивы данных без использования циклов, используя оптимизированные низкоуровневые функции;Использование векторных и матричных операций, которые выполняются на уровне компилированного кода для ускорения вычислений с большими данными;4
Как рекомендательные системы помогает в анализе больших объемов данных?;Рекомендательные системы применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Рекомендательные системы применяется в бизнесе и иногда в науке для анализа данных.;3
Что означает термин 'обучение с подкреплением'?;Обучение с подкреплением — это тип обучения, при котором агент взаимодействует со средой, получая вознаграждение за правильные действия.;Это когда программа сама себя проверяет.;2
Что такое reinforcement learning и где применяется?;Reinforcement learning - обучение с подкреплением, где агент учится через взаимодействие со средой, применяется в робототехнике, играх и рекомендательных системах;Reinforcement learning - обучение через взаимодействие со средой;5
Что такое ETL процесс?;Процесс извлечения данных из источников, их преобразования в нужный формат и загрузки в целевую систему.;Это перемещение данных из одного места в другое с некоторой обработкой по пути.;3
Что такое MapReduce и из каких этапов состоит?;Модель программирования для обработки больших данных. Состоит из Map (фильтрация и сортировка) и Reduce (агрегация результатов).;MapReduce: этап Map обрабатывает входные данные и выдает пары ключ-значение, этап Reduce агрегирует результаты по ключам.;5
Как выбрать между L1 и L2 регуляризацией для линейной модели?;L1 (Lasso) лучше когда нужен отбор признаков и интерпретируемость, L2 (Ridge) когда важна стабильность и все признаки потенциально полезны. L1 обнуляет неважные веса, L2 только уменьшает их.;L1 убирает неважные фичи, L2 уменьшает все веса. Выбор зависит от задачи и данных.;3
Какие структуры данных используются в R и их примеры?;"Вектор (c(1,2,3)), матрица (matrix(1:6, nrow=2)), список (list(1, ""a"", TRUE)), data frame (data.frame(x=1:3, y=c(""a"",""b"",""c""))), фактор (factor(c(""A"",""B"",""A""))).";Основные структуры: векторы, матрицы, таблицы данных. Используются для хранения и обработки информации.;3
Характерные черты безмасштабных сетей;Степенное распределение степеней, наличие хабов, устойчивость к случайным отказам, уязвимость к targeted attacks;Power law, хабы, устойчивость;3
Обучение с учителем и без учителя;Обучение с учителем использует размеченные данные с известными ответами, а без учителя обнаруживает скрытые структуры в данных без меток;Обучение с учителем для классификации и регрессии, без учителя для кластеризации;4
Как специалисты анализируют данные в рамках масштабируемые системы?;Масштабируемые системы используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Эти технологии помогают работать с информацией и делать прогнозы.;3
Как развивается направление data warehouses в последние годы?;Технологии data warehouses позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Технологии data warehouses позволяют компаниям обрабатывать большие объёмы разнородных данных, выявлять сложные закономерности и принимать обоснованные решения.;5
Что представляет собой алгоритм k-means?;K-means — это метод кластеризации, основанный на минимизации суммы квадратов расстояний между точками и центрами кластеров. Итеративно пересчитывает центры кластеров до сходимости.;K-means просто делит данные на части случайным образом.;2
Почему организации переходят на технологии ETL-пайплайны?;Etl-пайплайны помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Etl-пайплайны широко применяется в промышленности, здравоохранении, финансах и государственных системах. Позволяет анализировать большие массивы данных, строить точные модели и улучшать эффективность процессов.;5
С какими проблемами сталкиваются при применении классификация данных, и как их решают?;Классификация данных помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Классификация данных применяется в бизнесе и иногда в науке для анализа данных.;3
Как организовать мониторинг качества данных в реальном времени?;Потоковая проверка метрик качества (completeness, accuracy, consistency), автоматические алерты при отклонениях, dashboard для визуализации, интеграция с data lineage для отслеживания проблем.;Потоковый мониторинг метрик качества, алертинг при аномалиях, визуализация на дашбордах, отслеживание происхождения данных для диагностики проблем.;4
Какие проблемы возникают при использовании предобработка данных?;Технологии предобработка данных позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Технологии позволяют улучшать качество аналитики, находить закономерности и предсказывать события.;4
Преимущества и недостатки непараметрических моделей;Непараметрические модели обладают гибкостью, но требуют значительных вычислительных ресурсов и объемов данных;Модели гибкие но требуют много ресурсов;4
Что означает дисперсия выборки?;Дисперсия выборки — это мера разброса значений относительно среднего. Вычисляется как среднее квадратов отклонений от выборочного среднего.;Это что-то вроде отклонения данных.;3
Что такое reinforcement learning и где применяется?;Reinforcement learning - обучение с подкреплением, где агент учится через взаимодействие со средой, применяется в робототехнике, играх и рекомендательных системах;Метод обучения с наградой за действия;3
Принципы глубокого обучения в нейросетях;Глубокое обучение использует многослойные нейронные сети для автоматического извлечения признаков из данных, CNN специализируются на обработке изображений с помощью сверточных слоев;Глубокие нейросети автоматически извлекают признаки, сверточные сети для работы с изображениями;4
Где применяется классификация данных в промышленности и бизнесе?;Классификация данных помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;5
Что такое пайплайны бенчмарки и SOTA, как и для чего они используются?,;"Пайплайн — последовательность шагов обработки данных и обучения модели. Бенчмарк — набор стандартных задач и метрик для сравнения моделей. SOTA (State Of The Art) — лучшие результаты на этих задачах.,""Пайплайн — это цепочка обработки данных";бенчмарки и SOTA нужны для сравнения моделей.;5
Какие риски связаны с применением ETL-пайплайны?;Etl-пайплайны используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Etl-пайплайны почти нигде не применяется. Это просто большие таблицы.;2
Что такое L1 и L2 регуляризация?;L1 (Lasso) добавляет штраф за абсолютные значения весов, L2 (Ridge) - за квадраты весов.;L1 использует штраф по модулю весов и может обнулять неважные признаки, L2 использует квадратичный штраф и уменьшает все веса пропорционально.;4
Что такое MapReduce?;Модель программирования для обработки больших объемов данных в распределенных кластерах, состоящая из этапов Map (фильтрация и сортировка) и Reduce (агрегация результатов).;Программная модель для распределенной обработки больших данных. Этап Map обрабатывает входные данные и выдает пары ключ-значение, этап Reduce агрегирует результаты по ключам. Основа Hadoop.;5
В чем сходства и различия векторов, матриц, фреймов и факторов в R?;Векторы и матрицы - гомогенные данные, фреймы - гетерогенные по колонкам. Факторы - категориальные с уровнями. Все поддерживают индексацию, но разную обработку.;Векторы и матрицы - одинаковый тип элементов, фреймы - разные типы. Факторы для категорий. Разные методы обработки и анализа.;4
Процесс познания (от гипотезы к функции);Процесс включает формулировку гипотезы, сбор данных, построение модели, валидацию и создание прогнозной функции;Процесс от гипотезы к функции включает сбор данных и построение модели;5
Охарактеризуйте хранилища OLAP и OLTP;"OLTP для операционных транзакций, OLAP для аналитических запросов; разная оптимизация";OLTP - операции в реальном времени, OLAP - анализ исторических данных;3
Какие инструменты используются для работы с мониторинг больших данных?;Технологии мониторинг больших данных позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Эти технологии помогают работать с информацией и делать прогнозы.;3
Перечислите основные задачи анализа сетей на графах. Приведите примеры.;Основные задачи: поиск сообществ, определение центральности, анализ кратчайших путей, выявление аномалий, моделирование распространения информации.;К задачам анализа графов относят поиск сообществ, центральных узлов и путей между ними.;3
Как big data применяется в современных компаниях?;Технологии big data позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Big data нужно только программистам, обычным компаниям оно бесполезно.;2
Какие методы использовать для detection outliers в многомерных данных?;Mahalanobis distance, isolation forest, local outlier factor, DBSCAN, PCA-based methods, autoencoders reconstruction error.;Многомерные методы обнаружения выбросов: статистические, кластеризация, нейросетевые подходы.;4
Какие реальные кейсы демонстрируют эффективность рекомендательные системы?;Рекомендательные системы используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Рекомендательные системы нужно только программистам.;2
Как классификация данных используется в научных исследованиях?;Классификация данных используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Помогает работать с данными и строить модели.;3
Какие основные инструменты и технологии используются для работы с рекомендательные системы?;Рекомендательные системы помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Рекомендательные системы применяется в бизнесе и иногда в науке для анализа данных.;3
Назовите и поясните метрики качества для компьютерного зрения.;Используются метрики IoU = (S ? P) / (S ? P), mAP (mean Average Precision), Pixel Accuracy, Dice = 2|A ? B| / (|A| + |B|).;IoU — это пересечение делить на объединение.;3
Преимущества CNN и их задач;"CNN эффективны для распознавания образов, обнаружения объектов, сегментации; преимущества - локальная связность, параметризация";Для изображений и распознавания;3
Какие основные инструменты и технологии используются для работы с обработка данных?;Обработка данных помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;5
Назовите меры центральной тенденции;Среднее арифметическое, медиана и мода - основные меры центра распределения данных;Среднее значение и другие показатели;2
Как data lakes влияет на эффективность бизнеса?;Технологии data lakes позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Data lakes обеспечивает анализ потоковых данных, улучшает прогнозирование, помогает автоматизировать процессы и повышает точность аналитических моделей.;5
Какие подходы использовать для real-time агрегации потоковых данных?;Tumbling windows, sliding windows, session windows, incremental aggregation, использование stateful processing, оптимизация с помощью approximate algorithms.;Методы агрегации данных в реальном времени с использованием окон.;3
Для чего нужна гипотеза о равенстве средних;Для статистической проверки различий между средними значениями двух групп или условий;Для статистической проверки различий между средними значениями;5
Что такое A/B тестирование?;Статистический метод сравнения двух версий для определения лучшей на основе метрик.;Сравнение двух версий продукта чтобы понять какая работает лучше.;3
Назовите виды связи между переменными при корреляции.;Связь может быть положительной, отрицательной и нулевой  сильной, средней или слабой по модулю коэффициента корреляции.;Различают положительную, отрицательную и нулевую корреляцию. По модулю коэффициента r выделяют слабую, умеренную и сильную связь: |r|<0.3 — слабая, 0.3?|r|<0.7 — умеренная, |r|?0.7 — сильная.;5
Какие реальные кейсы демонстрируют эффективность кластеризация?;Кластеризация используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;4
Что такое data partitioning в Big Data?;Разделение данных на меньшие части для распределенной обработки и хранения, что улучшает производительность и управляемость;Дробление данных для обработки на нескольких серверах;3
Почему организации переходят на технологии предобработка данных?;Предобработка данных помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Эти технологии помогают работать с информацией и делать прогнозы.;3
Примеры использования гистограммы;Гистограммы применяются для анализа распределения яркости в обработке изображений, контроля качества в производстве через анализ распределения параметров продукции;Гистограммы используют в разных областях;2
Что такое Synthetic Data Generation и когда его использование оправдано?;Создание искусственных данных сохраняющих статистические свойства реальных. Оправдано при недостатке данных, privacy concerns, testing систем, imbalance correction.;Создание синтетических данных с характеристиками реальных. Применение: нехватка данных, конфиденциальность, тестирование ML систем, решение проблем дисбаланса.;4
Что такое MLOps?;Практики CI/CD для развертывания и мониторинга ML моделей в продакшене;Методология объединяющая машинное обучение и DevOps для надежного развертывания моделей;5
Какие этапы включает проект, основанный на использовании анализ данных?;Анализ данных применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Используется для прогнозов и анализа информации.;3
Какие реальные примеры использования хранилища данных существуют?;Технологии хранилища данных позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Хранилища данных обеспечивает анализ потоковых данных, улучшает прогнозирование, помогает автоматизировать процессы и повышает точность аналитических моделей.;5
Принципы и инструменты аналитики Big Data;Аналитика больших данных основана на принципах распределенной обработки, использования специализированных фреймворков и облачных технологий для работы с большими объемами информации;Методы и инструменты для анализа очень больших наборов данных;2
Типы деревьев решений и индексы;Основные типы деревьев решений включают CART и C4.5, использующие индексы Джини, энтропию и gain ratio для выбора разделяющих признаков;CART строит бинарные деревья с индексом Джини, C4.5 создает деревья с множественным ветвлением используя gain ratio для избежания переобучения;4
Что понимается под 'стандартизацией данных'?;Стандартизация — это преобразование признаков таким образом, чтобы их среднее значение было равно нулю, а стандартное отклонение — единице.;Это процесс приведения данных к одной шкале, обычно с нулевым средним.;4
Что такое статистическое обучение;Раздел машинного обучения, основанный на статистических методах и вероятностных моделях;Основано на статистических методах и вероятностных моделях для машинного обучения;5
Назовите, поясните и подкрепите формулами метрики качества для моделей регрессии.;Основные метрики: MAE = (1/n)*?|y - ?|, MSE = (1/n)*?(y - ?)^2, RMSE = sqrt(MSE), R^2 = 1 - ?(y - ?)^2 / ?(y - y?)^2.;MSE и RMSE показывают ошибку модели, R2 — качество объяснения дисперсии.;4
Какие основные инструменты используются для аналитики больших данных и их сравнение?;Hadoop (HDFS, MapReduce) для хранения и пакетной обработки, Spark для in-memory вычислений, Kafka для потоковой обработки, NoSQL БД для неструктурированных данных. Сравнение по производительности, масштабируемости, use cases.;Разные программы для анализа больших данных.;2
В чем преимущества применения предиктивная аналитика по сравнению с традиционными методами?;Предиктивная аналитика применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Это просто работа с таблицами. Не очень полезно.;2
Какие подходы использовать для обработки полуструктурированных данных (JSON, XML) в Big Data системах?;Использование форматов с schema evolution (Avro, Parquet), извлечение полей в отдельные колонки, хранение в native формате с индексацией, использование специализированных функций для querying.;Форматы с поддержкой schema evolution, извлечение часто используемых полей в отдельные колонки, хранение в исходном формате с индексацией, специальные функции для запросов к полуструктурированным данным в системах типа Spark SQL.;5
Какие методы использовать для балансировки классов в задачах классификации с сильным дисбалансом?;Oversampling (SMOTE), undersampling, изменение весов классов в функции потерь, использование алгоритмов устойчивых к дисбалансу, ансамблирование.;SMOTE для синтетического oversampling'а, undersampling мажоритарного класса, взвешивание классов в loss function, алгоритмы типа BalancedRandomForest, ансамбли методов. Выбор зависит от объема данных и стоимости ошибок.;5
Как специалисты анализируют данные в рамках big data?;Big data помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Big data широко применяется в промышленности, здравоохранении, финансах и государственных системах. Позволяет анализировать большие массивы данных, строить точные модели и улучшать эффективность процессов.;5
Что такое CAP-теорема и как она применяется в Big Data системах?;CAP-теорема утверждает, что распределенная система может гарантировать только два из трех свойств: Consistency (консистентность), Availability (доступность), Partition Tolerance (устойчивость к разделению). В Big Data обычно жертвуют строгой консистентностью ради доступности и partition tolerance.;Теорема о трех свойствах распределенных систем. В Big Data обычно жертвуют консистентностью для обеспечения доступности и отказоустойчивости.;4
Как распределённые вычисления применяется в современных компаниях?;Технологии распределённые вычисления позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Распределённые вычисления обеспечивает анализ потоковых данных, улучшает прогнозирование, помогает автоматизировать процессы и повышает точность аналитических моделей.;5
Когда использовать Graph Database вместо реляционной для хранения данных?;Graph DB лучше когда данные имеют сложные связи и запросы ориентированы на отношения (социальные сети, рекомендации, fraud detection). Реляционные - для структурированных данных с простыми связями.;Graph DB для сложных связей между данными, реляционные для табличных структур. Выбор зависит от природы данных и типов запросов.;4
Как оптимизировать производительность запросов к partitioned данным?;Partition pruning, predicate pushdown, statistics usage, optimal partition size, partition key selection based on query patterns.;Оптимизация запросов к партиционированным данным.;2
Что такое L1 и L2 регуляризация?;L1 (Lasso) добавляет штраф за абсолютные значения весов, L2 (Ridge) - за квадраты весов.;Методы улучшения моделей машинного обучения через ограничение параметров.;2
Как компьютерное зрение используется в научных исследованиях?;Компьютерное зрение применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Компьютерное зрение нужно только программистам.;2
Что такое топик в Kafka;Топик — это логический канал или категория, в которую производители публикуют сообщения и из которой потребители читают сообщения. Сообщения в топике упорядочены.;Топик — это распределенный лог сообщений, разделенный на партиции для горизонтального масштабирования. Каждая партиция представляет собой упорядоченную, неизменяемую последовательность сообщений, которая реплицируется across несколько брокеров для отказоустойчивости.;4
Почему организации переходят на технологии data lakes?;Data lakes помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Data lakes обеспечивает анализ потоковых данных, улучшает прогнозирование, помогает автоматизировать процессы и повышает точность аналитических моделей.;5
В чем преимущества применения предиктивная аналитика по сравнению с традиционными методами?;Предиктивная аналитика используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Предиктивная аналитика — это что-то про компьютеры. Применяется редко.;2
В чем разница между batch processing и stream processing?;Batch processing обрабатывает данные пачками с задержкой, stream processing обрабатывает данные в реальном времени по мере поступления.;Два типа обработки данных - пакетная и потоковая.;2
Перечислите шкалы измерений. Приведите примеры их использования;Номинальная (пол, цвет), порядковая (уровень образования), интервальная (температура), относительная (вес, доход);Номинальная, порядковая, интервальная, относительная;3
Каковы факторы, влияющие на коэффициент корреляции?;Коэффициент корреляции зависит от линейности данных, наличия выбросов, дисперсии, размера выборки и точности измерений.;Коэффициент корреляции изменяется под влиянием дисперсии переменных, выбросов, распределения данных и объема выборки.;4
Как выбрать между колоночным и строчным хранением данных для аналитических нагрузок?;Колоночное хранилище лучше для аналитических запросов с агрегациями по немногим колонкам, строчное - для OLTP с операциями над целыми строками. Использовать колоночные форматы (Parquet, ORC) для data warehousing.;Разные способы хранения данных для разных задач.;2
Измерение качества модели анализа данных;Качество моделей оценивается с помощью метрик accuracy, precision, recall, F1-score для классификации и RMSE, MAE, R? для регрессии;"Для классификации: accuracy (общая точность), precision (точность положительного класса), recall (полнота), F1-score (гармоническое среднее), ROC-AUC (площадь под кривой); для регрессии: RMSE (среднеквадратичная ошибка), MAE (средняя абсолютная ошибка), R? (коэффициент детерминации)";5
Что такое exactly-once semantics в stream processing?;Гарантия что каждое сообщение будет обработано ровно один раз без дублирования или потерь;Тип гарантии в потоковой обработке;2
Как специалисты анализируют данные в рамках мониторинг больших данных?;Мониторинг больших данных помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Технологии позволяют улучшать качество аналитики, находить закономерности и предсказывать события.;4
Какие типы данных существуют в языке R?;Numeric, integer, character, logical, complex. Специальные: NA для пропусков, NULL, factors для категориальных данных. Векторы базовых типов.;Числа, текст, логические значения, категориальные переменные. Разные типы для разных видов данных.;3
Как развивается направление обработка потоковых данных в последние годы?;Обработка потоковых данных используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Эти технологии помогают работать с информацией и делать прогнозы.;3
Какие типы данных существуют в языке R?;Numeric, integer, character, logical, complex. Специальные: NA для пропусков, NULL, factors для категориальных данных. Векторы базовых типов.;Разные виды переменных в R.;2
Принцип массивных вычислений в R;Векторизованные операции в R позволяют эффективно обрабатывать большие объемы данных без использования циклов через применение оптимизированных встроенных функций и операций;В R используются векторизованные операции для эффективной обработки больших объемов данных без циклов;5
Что означает 'precision' в классификации?;Precision — это доля правильно предсказанных положительных примеров среди всех предсказанных как положительные.;Precision — это насколько модель попала в цель.;3
Что такое 'валидация модели'?;Валидация — это процесс проверки качества обученной модели на независимых данных, не участвовавших в обучении.;Валидация — это проверка модели на данных, которые не использовались при обучении.;5
Что такое recall и precision?;Precision - точность предсказаний, recall - полнота охвата реальных позитивных случаев.;Это метрики для оценки моделей классификации, которые показывают разные аспекты качества.;3
Что такое ETL процесс?;Процесс извлечения данных из источников, их преобразования в нужный формат и загрузки в целевую систему.;Процесс, при котором данные извлекаются из источников, преобразуются и очищаются, а затем загружаются в базу данных для анализа.;4
Что такое Vector Database и для каких задач она оптимальна?;Специализированная БД для хранения и поиска векторных эмбеддингов. Оптимальна для semantic search, рекомендательных систем, similarity search в больших наборах данных.;База данных для работы с векторными данными и поиска сходств.;2
Что такое 'обучающая выборка'?;Обучающая выборка — это часть данных, используемая для настройки параметров модели.;Обучающая выборка — это данные, на которых модель обучается и подбирает параметры.;5
Примеры использования гистограммы;Гистограммы применяются для анализа распределения яркости в обработке изображений, контроля качества в производстве через анализ распределения параметров продукции;В компьютерном зрении - коррекция яркости и контраста, в производстве - контроль размеров и параметров изделий;3
Какие основные инструменты и технологии используются для работы с большие данные?;Большие данные используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Большие данные нужно только программистам.;2
Обучение с подкреплением и ансамбли;Обучение с подкреплением основано на взаимодействии со средой, ансамбли комбинируют несколько моделей;Обучение с подкреплением и ансамблевые методы обучения;5
Для чего нужны гипотезы в анализе данных;Гипотезы позволяют формулировать проверяемые утверждения и проводить статистическую проверку научных предположений;Для статистической проверки теорий;3
Что такое пайплайны бенчмарки и SOTA, как и для чего они используются?,;"Пайплайн — последовательность шагов обработки данных и обучения модели. Бенчмарк — набор стандартных задач и метрик для сравнения моделей. SOTA (State Of The Art) — лучшие результаты на этих задачах.,""Пайплайн — это просто процесс";а SOTA — лучшие модели.;3
Требования ACID. CAP?теорема, BASE?архитектура;ACID - гарантии целостности транзакций, CAP - невозможность одновременно обеспечить согласованность, доступность и устойчивость к разделению;ACID для баз данных, CAP про распределенные системы;2
Какие риски связаны с применением data warehouses?;Технологии data warehouses позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Это что?то связанное с данными, но используется редко.;2
Что такое линейная регрессия?;Линейная регрессия — это статистический метод, описывающий зависимость между независимыми переменными X и зависимой переменной Y в виде линейной функции Y = ?0 + ?1X + ?.;Это просто зависимость между числами.;2
Опишите процесс ETL и его этапы.;ETL (Extract, Transform, Load) — это процесс извлечения данных из источников, их преобразования в нужный формат и загрузки в целевое хранилище. Основные этапы: Extract, Transform, Load.;ETL — программа для обработки файлов.;2
Виды связи между переменными при корреляции.;Корреляция отражает степень и направление линейной связи между двумя переменными. Связи могут быть положительные, отрицательные или нулевые. Для оценки используется коэффициент корреляции Пирсона или Спирмена.;Связь бывает, когда одно влияет на другое.;2
Что такое consumer groups;Consumer group — это группа потребителей, которые совместно обрабатывают сообщения из топика. Каждое сообщение доставляется только одному потребителю в группе.;Consumer groups в Kafka обеспечивают механизм горизонтального масштабирования обработки сообщений: консьюмеры в группе координируют распределение партиций между собой, гарантируя, что каждая партиция потребляется только одним консьюмером группы, что позволяет достичь балансировки нагрузки и отказоустойчивости.;5
Какие проблемы возникают при использовании data warehouses?;Data warehouses помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Data warehouses используется бизнесом для оптимизации процессов, анализа клиентов и прогнозирования.;4
Данные, информация, знания – в чем отличия?;Данные — это необработанные факты и измерения. Информация — это данные, прошедшие интерпретацию. Знания — это результат анализа информации, ведущий к принятию решений. Пример: данные — цифры продаж, информация — динамика продаж, знание — вывод о сезонности спроса.;Данные — это информация, а знания — результат размышлений.;3
Data Mining vs. Machine Learning — в чём отличия?;Data Mining фокусируется на обнаружении паттернов в существующих данных, тогда как Machine Learning ориентирован на построение моделей для прогнозирования на новых данных;Data Mining фокусируется на паттернах, Machine Learning на прогнозных моделях;5
Какие навыки необходимы специалисту для работы с нейронные сети?;Нейронные сети используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Используется для прогнозов и анализа информации.;3
Какие особенности архитектуры потоковой обработки данных?;Архитектура потоковой обработки включает ingestion слои (Kafka), processing (Spark Streaming, Flink) и sink слои для хранения, обеспечивая обработку в реальном времени;Компоненты для работы с потоковыми данными;3
Что такое 'регуляризация' в машинном обучении?;"Регуляризация — это метод уменьшения переобучения за счёт добавления штрафов к функции потерь.,""Регуляризация снижает переобучение";добавляя штрафы за сложные модели.;5
Какие компании активно используют большие данные и зачем?;Большие данные помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Большие данные применяется в бизнесе и иногда в науке для анализа данных.;3
Где применяется NLP в промышленности и бизнесе?;Nlp применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;4
Зачем нужна мера близости в кластеризации? Достоинства графовых алгоритмов;Мера близости определяет схожесть объектов для группировки. Графовые алгоритмы эффективны для работы с разреженными данными и выявления сложных структур;Мера близости определяет схожесть объектов, графовые алгоритмы эффективны для сложных данных;5
«Меры изменчивости»: что к ним относится?;К мерам изменчивости относятся дисперсия, стандартное отклонение, размах, межквартильный размах и среднее абсолютное отклонение;Дисперсия, стандартное отклонение, размах как меры изменчивости;3
Что такое Apache Arrow?;Формат in-memory для колоночного хранения данных с нулевой сериализацией для ускорения анализа.;Формат для быстрой работы с данными.;2
Boxplot и его интерпретация, связь с другими элементами анализа;Boxplot визуализирует распределение данных через медиану, квартили и выбросы, тесно связан с описательной статистикой и используется для сравнения распределений и выявления аномалий в наборах данных;Диаграмма для отображения ключевых характеристик распределения и сравнения различных групп данных между собой;3
Что такое точность (accuracy) в машинном обучении?;Точность — это метрика, определяющая долю правильных предсказаний от общего числа наблюдений: Accuracy = (TP + TN) / (TP + TN + FP + FN).;Точность — это доля правильных ответов от общего количества предсказаний.;4
Что такое schema evolution в Big Data?;Возможность изменения схемы данных без потери совместимости с существующими данными;Изменение схемы данных с поддержкой обратной совместимости;4
Метрики качества для моделей регрессии;Основные метрики включают RMSE, MAE, MAPE и R? для оценки точности регрессионных моделей и их предсказательной способности;Метрики для оценки ошибок предсказания и объясняющей способности регрессии;5
Как проектировать систему для обработки геопространственных данных в реальном времени?;Использовать специализированные БД (PostGIS), пространственные индексы (R-tree, Quad-tree), распределенные системы для масштабирования, streaming frameworks для real-time обработки.;Гео-ориентированные базы данных, пространственные индексы, распределенная обработка и потоковые системы. Учитывать требования к spatial queries и реальному времени.;4
Стандарты жизненного цикла Big Data: CRISP?DM;CRISP-DM включает этапы бизнес-понимания, понимания данных, подготовки, моделирования, оценки и внедрения;Этапы CRISP-DM для анализа данных;3
Что означает 'Batch Normalization'?;Batch Normalization — это техника нормализации входов слоёв нейросети, ускоряющая обучение и повышающая стабильность.;Batch Normalization нормализует данные в нейронных сетях для ускорения обучения.;5
Как выполняется преобразование данных и зачем нужна их очистка?;Преобразование включает нормализацию, агрегацию, обогащение. Очистка нужна для удаления шума, исправления ошибок, обработки пропусков для повышения качества моделей.;Преобразование - изменение формата и структуры данных. Очистка устраняет ошибки и пропуски для лучшего качества анализа.;4
Какие основные характеристики и вызовы больших данных (4V, 8V)?;4V: Volume (объем), Velocity (скорость), Variety (разнообразие), Veracity (достоверность). 8V добавляют: Value, Variability, Visualization, Validity.;Основные 4V: объем, скорость, разнообразие, достоверность. Расширенные 8V включают ценность, изменчивость, визуализацию, валидность. Это определяет сложности обработки.;5
Свойства эластичности и надежности сложных сетей.;Эластичность описывает способность сети сохранять функции при удалении вершин, надежность — устойчивость к отказам и атакам. Безмасштабные сети устойчивы к случайным сбоям, но уязвимы к целевым атакам.;Надежность — это устойчивость сети, эластичность — ее гибкость.;2
Метрики качества для моделей регрессии;Основные метрики включают RMSE, MAE, MAPE и R? для оценки точности регрессионных моделей и их предсказательной способности;Метрики ошибок и коэффициенты для оценки регрессионных моделей;3
В чем сходства и различия векторов, матриц, фреймов и факторов в R?;Векторы и матрицы - гомогенные данные, фреймы - гетерогенные по колонкам. Факторы - категориальные с уровнями. Все поддерживают индексацию, но разную обработку.;Разные структуры для разных целей. Векторы и матрицы для чисел, фреймы для таблиц, факторы для категорий.;3
Виды столбчатых диаграмм и их интерпретация;Столбчатые диаграммы включают вертикальные, горизонтальные, сгруппированные и составные типы, которые интерпретируются через сравнение высот столбцов для анализа категориальных данных;Основные типы столбчатых диаграмм: вертикальные, горизонтальные, сгруппированные;4
Какие методы использовать для detection data drift в production ML systems?;Statistical tests (KS, PSI), monitoring prediction distributions, concept drift detection algorithms, feature distribution monitoring, performance metrics tracking.;Детектирование дрейфа данных в production.;2
Какие компании активно используют ETL-процессы и зачем?;Etl-процессы помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Помогает работать с данными и строить модели.;3
Как проектировать систему для обработки данных IoT устройств с высокой частотой обновления?;Использовать потоковые платформы (Kafka, Flink), колоночные форматы хранения, сжатие данных, агрегацию на edge устройствах, мониторинг пропускной способности и задержек.;Системы реального времени, эффективное хранение, предобработка данных на устройствах для снижения нагрузки.;3
Разница описательных и предсказательных задач;Описательные анализируют текущие данные, предсказательные строят прогнозы на будущее;Анализ прошлого и предсказание будущего;2
В чем разница между данными, информацией и знаниями?;Данные - сырые факты, информация - обработанные данные с контекстом, знания - информация + понимание и опыт для принятия решений.;Разные уровни обработки и использования сведений.;2
Какие типы данных существуют в языке R?;Numeric, integer, character, logical, complex. Специальные: NA для пропусков, NULL, factors для категориальных данных. Векторы базовых типов.;Числовые, текстовые, логические, факторы. Специальные значения для пропусков и нечисловых данных.;4
Какие методы feature selection используются в машинном обучении?;Методы отбора признаков включают фильтры (correlation), встроенные методы (L1-регуляризация) и методы-обертки (recursive feature elimination);Фильтры, встроенные методы и обертки для выбора фич;3
Перечислите основные метрики больших графов.;Основные метрики: степень вершины (degree), средняя длина пути (L), кластерный коэффициент (C), центральность по посредничеству (betweenness), собственная центральность (eigenvector), плотность графа и диаметр.;Метрики включают степень и диаметр графа.;4
Почему технологии системы логирования стали критически важны?;Системы логирования используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Системы логирования применяется в некоторых компаниях для анализа данных.;3
Что такое переобучение модели?;Переобучение — это ситуация, когда модель слишком точно подстраивается под обучающие данные и теряет способность обобщать закономерности. Основные признаки — высокая точность на обучающей выборке и низкая на тестовой.;Переобучение — это когда модель слишком точно запоминает обучающие данные и плохо работает на новых.;5
Характерные черты безмасштабных сетей;Безмасштабные сети имеют степенное распределение степеней узлов, содержат хабы и демонстрируют устойчивость к случайным отказам но уязвимы к целевым атакам;Сети с определенными свойствами распределения связей между узлами;2
Что такое data skew в распределенных системах?;Неравномерное распределение данных или нагрузки между узлами кластера;Проблема когда данные или нагрузка неравномерно распределены между узлами, что приводит к медленным узлам;5
Принципы глубокого обучения в нейросетях;Глубокое обучение использует многослойные нейронные сети для автоматического извлечения признаков из данных, CNN специализируются на обработке изображений с помощью сверточных слоев;Многослойные сети учатся распознавать сложные паттерны в информации;3
Примеры задач с большими графами;Большие графы применяются для анализа социальных сетей (обнаружение сообществ, измерение влияния), в рекомендательных системах (коллаборативная фильтрация), биоинформатике (изучение взаимодействий белков) и веб-аналитике (ранжирование страниц);Социальный сетевой анализ, персональные рекомендации и исследования в биоинформатике представляют ключевые направления использования больших графовых моделей;5
Как оптимизировать memory usage в Spark при работе с wide transformations?;Увеличение памяти исполнителей, использование off-heap memory, оптимизация serialization, уменьшение размера данных перед shuffling, использование broadcast variables.;Методы уменьшения использования памяти при wide transformations в Spark.;3
Что такое ELT процесс?;Процесс загрузки данных перед их преобразованием в целевой системе.;Подход к обработке данных, при котором данные извлекаются из источников, загружаются в целевую систему без преобразований, а затем трансформируются уже внутри этой системы.;4
Какие реальные примеры использования in-memory обработка существуют?;Технологии in-memory обработка позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;In-memory обработка обеспечивает анализ потоковых данных, улучшает прогнозирование, помогает автоматизировать процессы и повышает точность аналитических моделей.;5
Зачем нужна мера близости в кластеризации? Достоинства графовых алгоритмов;Мера близости определяет схожесть объектов для группировки. Графовые алгоритмы эффективны для работы с разреженными данными и выявления сложных структур;Меры близости определяют схожесть, графовые алгоритмы для сложных структур;4
Как распределённые вычисления влияет на эффективность бизнеса?;Распределённые вычисления используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Распределённые вычисления используется для обработки информации и улучшения решений.;3
Что такое data warehouse?;Централизованное хранилище интегрированных данных из различных источников, оптимизированное для анализа и отчетности, с поддержкой исторических данных и структурированной схемой.;Большая база данных для бизнес-аналитики.;2
Что такое Apache Cassandra?;Распределенная NoSQL база данных с высокой доступностью и масштабируемостью, использующая модель column-family.;База данных для больших объемов информации.;2
Сравнительный анализ алгоритмов кластеризации;Алгоритмы кластеризации сравниваются по масштабируемости, чувствительности к шуму, способности находить кластеры сложной формы и вычислительной сложности;Сравнение разных методов группировки данных по их свойствам;2
Как машинное обучение помогает в анализе больших объемов данных?;Машинное обучение применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;5
Назовите меры центральной тенденции;Среднее арифметическое, медиана и мода - основные меры центра распределения данных;Среднее арифметическое, медиана и мода характеризуют центр распределения;4
Каковы факторы, влияющие на коэффициент корреляции?;Коэффициент корреляции зависит от линейности данных, наличия выбросов, дисперсии, размера выборки и точности измерений.;На корреляцию влияет погрешность, размер выборки и форма графика.;2
Как организовать мониторинг производительности распределенных data processing jobs?;Metrics collection (throughput, latency, resource usage), distributed tracing, alerting on anomalies, dashboard visualization, correlation с business metrics.;Мониторинг метрик, tracing, алерты, дашборды. Отслеживание производительности распределенных задач.;4
Как big data применяется в современных компаниях?;Технологии big data позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Технологии big data позволяют компаниям обрабатывать большие объёмы разнородных данных, выявлять сложные закономерности и принимать обоснованные решения.;5
Какие проблемы возникают при использовании ETL-пайплайны?;Технологии ETL-пайплайны позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Технологии ETL-пайплайны позволяют компаниям обрабатывать большие объёмы разнородных данных, выявлять сложные закономерности и принимать обоснованные решения.;5
Что такое PostgreSQL?;Реляционная СУБД с открытым исходным кодом, поддерживающая расширенные типы данных и SQL стандарты.;Реляционная база данных с открытым исходным кодом. Альтернатива коммерческим СУБД с хорошей функциональностью.;3
Способы графического представления данных;Гистограммы, диаграммы рассеяния, box plots, линейные графики. Выбор зависит от типа данных и цели;Гистограммы (распределение), диаграммы рассеяния (корреляция), box plots (статистики), линейные графики (динамика). Выбор по типу данных;4
Как работает механизм Adaptive Query Execution в Spark 3.0 и какие проблемы он решает?;AQE динамически переоптимизирует план запроса во время выполнения на основе реальной статистики данных. Решает проблемы ошибочных оценок размера данных, неоптимальных join стратегий и партиционирования.;Динамическая оптимизация запросов в Spark 3.0. Решает проблемы с оценкой размера данных и выбором неэффективных join стратегий через перепланирование during выполнения.;4
Как классификация данных применяется для автоматизации рутинных процессов?;Классификация данных применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Классификация данных применяется в бизнесе и иногда в науке для анализа данных.;3
Что такое Neuromorphic Computing и как оно применяется в AI?;Архитектура вычислений имитирующая работу человеческого мозга. Применяется для энергоэффективного AI, real-time обработки сенсорных данных, edge computing.;Нейроморфные вычисления - hardware имитирующий нейроны. Применение: энергоэффективные AI системы, обработка в реальном времени, встроенные AI решения.;4
Что такое 'градиентное исчезновение'?;Градиентное исчезновение — это ситуация, когда градиенты становятся слишком малыми, что замедляет или останавливает обучение нейросети.;Градиентное исчезновение — это уменьшение градиентов, мешающее обучению модели.;5
Какие вы знаете интегральные метрики качества, привести формулы и примеры.;Интегральные метрики: ROC-AUC (площадь под кривой зависимости TPR от FPR), PR-AUC (площадь под кривой Precision-Recall), LogLoss = -1/N * ?[y*log(p) + (1 - y)*log(1 - p)].;ROC-AUC — это площадь под кривой, чем больше, тем лучше.;4
Какие основные инструменты и технологии используются для работы с машинное обучение?;Машинное обучение используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Помогает работать с данными и строить модели.;3
Какие методы использовать для обнаружения concept drift в ML моделей?;Statistical tests (KS test, PSI), monitoring performance metrics, drift detection algorithms (ADWIN, DDM), анализ распределения предсказаний и фактических значений.;Отслеживание статистик данных и метрик модели, использование алгоритмов для обнаружения изменений в данных с течением времени.;3
Что такое статистическая гипотеза;Статистическая гипотеза представляет собой проверяемое предположение о свойствах генеральной совокупности, которое может быть подтверждено или опровергнуто с помощью статистических тестов;Предположение о характеристиках данных которое можно проверить статистическими методами;2
Что такое ZooKeeper в Kafka;ZooKeeper используется для управления метаданными кластера, выбора контроллера, отслеживания живых брокеров и потребителей, хранения конфигурации.;ZooKeeper служит распределенным координатором: хранит метаданные кластера (список брокеров, топиков, партиций), управляет выбором контроллера, отслеживает живые узлы и хранит конфигурации ACL.;4
Что означает 'Batch Normalization'?;Batch Normalization — это техника нормализации входов слоёв нейросети, ускоряющая обучение и повышающая стабильность.;Batch Normalization выравнивает данные для лучшего обучения.;4
Какие навыки необходимы специалисту для работы с рекомендательные системы?;Рекомендательные системы помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;5
Почему организации переходят на технологии мониторинг больших данных?;Мониторинг больших данных используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Технологии мониторинг больших данных позволяют компаниям обрабатывать большие объёмы разнородных данных, выявлять сложные закономерности и принимать обоснованные решения.;5
Как обрабатывать выбросы (outliers) в данных перед построением ML модели?;Анализировать природу выбросов: удалять если это ошибки измерения, использовать robust методы если это реальные значения, трансформировать данные, применять алгоритмы устойчивые к выбросам.;Определить являются ли выбросы ошибками или реальными значениями. Удалять если ошибки, иначе использовать устойчивые алгоритмы или методы трансформации. Можно использовать IQR или z-score для detection.;5
Какие этапы включает проект, основанный на использовании модели прогнозирования?;Модели прогнозирования применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Модели прогнозирования применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;5
Что такое Apache Beam?;Унифицированная модель для определения пайплайнов обработки данных, работающая с разными рантаймами.;Система для создания потоков обработки данных, которая работает с разными платформами.;3
Обучение с подкреплением и ансамбли — основные разновидности и принципы;Обучение с подкреплением включает Q-learning и политические градиенты, ансамбли используют бэггинг, бустинг и стэкинг для улучшения предсказательной способности моделей;Методы машинного обучения с разными подходами;2
Какие способы визуализации корреляции были изучены в курсе Big Data?;Основные способы: корреляционная матрица, тепловая карта (heatmap), диаграмма рассеяния (scatter plot), графики зависимости и парные диаграммы (pairplot).;Для визуализации корреляции используются корреляционные матрицы с цветовым кодированием (heatmap), диаграммы рассеяния (scatter plot), парные графики (pairplot) и визуализация плотности распределения. Это позволяет быстро выявить силу и направление связей.;5
Как обрабатывать выбросы (outliers) в данных перед построением ML модели?;Анализировать природу выбросов: удалять если это ошибки измерения, использовать robust методы если это реальные значения, трансформировать данные, применять алгоритмы устойчивые к выбросам.;Обнаруживать выбросы и либо удалять их, либо использовать алгоритмы которые к ним устойчивы.;3
Что такое collaborative filtering?;Метод рекомендательных систем, основанный на поведении и предпочтениях пользователей.;Система предложения товаров пользователям интернет-магазинов.;2
Data Mining vs. Machine Learning — в чём отличия?;Data Mining фокусируется на обнаружении паттернов в существующих данных, тогда как Machine Learning ориентирован на построение моделей для прогнозирования на новых данных;Разные подходы к анализу;2
Как понимать «уровень статистической достоверности»?;Это вероятность того, что результат не случайный.;Если результат достоверен, то он подтверждён статистикой.;4
Что такое Data Mesh архитектура и как она решает проблемы централизованных data lakes?;Децентрализованный подход, где данные управляются domain-командами как продукты. Решает проблемы монолитных data lakes: bottlenecks, низкое качество данных, сложность масштабирования.;Data Mesh - архитектура с domain-oriented ownership данных. Каждая команда отвечает за свои data products. Решает проблемы масштабирования и качества данных в централизованных data lakes.;5
Преимущества CNN и их задач;"CNN эффективны для распознавания образов, обнаружения объектов, сегментации; преимущества - локальная связность, параметризация";CNN имеют преимущества для задач компьютерного зрения;5
Что такое Quantum Machine Learning и какие преимущества оно обещает?;Применение квантовых вычислений для ML алгоритмов. Обещает экспоненциальное ускорение для optimization problems, quantum feature spaces, обработки больших данных.;Объединение квантовых вычислений и машинного обучения. Может ускорить определенные типы вычислений и открыть новые возможности для AI.;3
Как организовать A/B тестирование для ML моделей в продакшене?;Canary deployments, постепенный rollout, monitoring ключевых метрик, статистические тесты для значимости, учет network effects и long-term impact.;Тестировать на группе пользователей, сравнивать метрики, использовать статистику для проверки значимости различий.;3
Data Mining vs. Machine Learning — в чём отличия?;Data Mining ориентирован на обнаружение скрытых паттернов и закономерностей в существующих данных, тогда как Machine Learning сосредоточен на построении алгоритмов, способных обучаться и делать прогнозы на новых данных;Два разных подхода к работе с информацией в компьютерных системах;2
Что такое кластеризация и какие задачи оно решает?;Кластеризация используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Кластеризация нужно только программистам.;2
В чем разница между параметрами и гиперпараметрами модели?;Параметры настраиваются автоматически в процессе обучения на данных (веса модели). Гиперпараметры задаются до обучения и управляют самим процессом обучения (скорость обучения, глубина дерева).;И то, и другое — это настройки для алгоритмов. Чем лучше их подобрать, тем точнее будет модель.;2
Что такое GraphQL?;Язык запросов для API, позволяющий клиентам запрашивать только нужные данные.;Альтернатива REST API, где клиент может запросить именно те поля и связи, которые ему нужны, в одном запросе, а не получать фиксированные ответы эндпоинтов.;4
Как организовать data lineage в сложных ETL пайплайнах?;Automated lineage tracking, metadata management, data provenance recording, impact analysis capabilities, integration с orchestration tools, visualization dependencies.;Автоматическое отслеживание lineage, управление метаданными, запись происхождения данных. Анализ влияния изменений и визуализация зависимостей.;5
Какие проблемы возникают при использовании кластеризация данных?;Кластеризация данных используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Кластеризация данных используется для обработки информации и улучшения решений.;3
Что такое feature importance?;Методы оценки важности признаков для прогнозов модели.;Методы для определения того, какие признаки наиболее сильно влияют на предсказания модели. Включают permutation importance, SHAP values, feature importance из деревьев и коэффициенты линейных моделей.;5
С какими проблемами сталкиваются при применении NLP, и как их решают?;Nlp применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Это просто работа с таблицами. Не очень полезно.;2
В чем различия между R и Python для анализа данных?;R - специализирован для статистики и визуализации, богатые статистические пакеты. Python - универсальный, лучше для ML и production систем. R удобнее для исследований, Python - для промышленной разработки.;R лучше для статистики, Python для машинного обучения. Оба используются в анализе данных.;3
Как проектировать систему для обработки геопространственных данных в реальном времени?;Использовать специализированные БД (PostGIS), пространственные индексы (R-tree, Quad-tree), распределенные системы для масштабирования, streaming frameworks для real-time обработки.;Специальные базы для геоданных, пространственные индексы и системы реального времени для обработки местоположений.;3
Преимущества и недостатки непараметрических моделей;Непараметрические модели гибки и не требуют предположений о распределении данных, но могут требовать больших объемов данных и вычислительных ресурсов;Плюсы и минусы моделей без строгих предположений;2
Виды связи между переменными при корреляции.;Корреляция отражает степень и направление линейной связи между двумя переменными. Связи могут быть положительные, отрицательные или нулевые. Для оценки используется коэффициент корреляции Пирсона или Спирмена.;Корреляция показывает, связаны ли переменные. Бывает положительная и отрицательная связь.;3
Почему организации переходят на технологии распределённые вычисления?;Распределённые вычисления используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Технологии позволяют улучшать качество аналитики, находить закономерности и предсказывать события.;4
Основные вызовы больших данных;Volume, Velocity, Variety, Veracity - основные характеристики и challenges больших данных;Проблемы работы с большими данными;2
Виды связи между переменными при корреляции;"Положительная, отрицательная, нелинейная, ложная корреляция; сила связи от -1 до +1";Виды корреляционных зависимостей;4
Как кластеризация помогает в анализе больших объемов данных?;Кластеризация используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Кластеризация — это что-то про компьютеры. Применяется редко.;2
Что такое attention mechanism?;Механизм, позволяющий модели фокусироваться на relevant частях входных данных.;Компонент нейронных сетей, который помогает модели концентрироваться на наиболее важных частях входных данных для принятия решений.;3
Что такое word2vec?;Алгоритм для создания векторных представлений слов на основе их контекста.;Техника преобразования слов в векторы для использования в машинном обучении, учитывающая семантические связи.;3
С какими проблемами сталкиваются при применении классификация данных, и как их решают?;Классификация данных применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Классификация данных — это что-то про компьютеры. Применяется редко.;2
Что такое A/B тестирование?;Статистический метод сравнения двух версий для определения лучшей на основе метрик.;Метод сравнения двух вариантов системы путем разделения трафика и измерения различий в ключевых метриках для принятия решения.;4
Основные вызовы больших данных;Основные вызовы больших данных включают объем (Volume), скорость (Velocity), разнообразие (Variety) и достоверность (Veracity) данных;Volume, Velocity, Variety данные;3
Типы деревьев решений и индексы;Основные типы алгоритмов деревьев решений включают CART и C4.5, которые используют различные индексы для разделения данных, такие как индекс Джини, энтропия и коэффициент gain ratio;Для деревьев решений используются различные типы алгоритмов и индексов оценки качества разбиения данных на узлах;5
Разница между линейной и логистической регрессией;Линейная регрессия моделирует непрерывные количественные зависимости между переменными, тогда как логистическая регрессия предсказывает вероятности бинарной или мультиклассовой классификации с использованием сигмоидной функции;Линейная регрессия для прогнозирования чисел, логистическая для классификации на категории;3
Генеральная совокупность и выборка;Генеральная совокупность включает все объекты исследования, выборка является ее представительной частью;Все объекты и их часть;2
Какие инструменты используются для работы с масштабируемые системы?;Масштабируемые системы используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Эти технологии помогают работать с информацией и делать прогнозы.;3
Что такое рекомендательные системы и какие задачи оно решает?;Рекомендательные системы используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;4
Как внедрение обработка данных влияет на процессы в организациях?;Обработка данных используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Обработка данных — это что-то про компьютеры. Применяется редко.;2
Что такое Apache Kafka и для каких задач он используется?;Распределенная потоковая платформа для обработки данных в реальном времени. Используется для построения data pipelines, event-driven архитектур, streaming приложений.;Инструмент для работы с потоками данных в реальном времени. Для сбора и обработки непрерывных данных.;3
Как внедрение анализ данных влияет на процессы в организациях?;Анализ данных применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Анализ данных применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;5
Какие реальные примеры использования предобработка данных существуют?;Технологии предобработка данных позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Предобработка данных обеспечивает анализ потоковых данных, улучшает прогнозирование, помогает автоматизировать процессы и повышает точность аналитических моделей.;5
NoSQL классификация хранилищ;NoSQL базы данных классифицируются на документные, хранилища ключ-значение, колоночные и графовые в зависимости от модели данных и способа организации хранения;Основные категории нереляционных баз данных по типу структуры хранения информации;2
Свойства описательных статистик;Меры центральной тенденции, меры изменчивости и показатели формы распределения данных;Основные характеристики набора данных;2
Примеры задач, решаемых с помощью больших графов;Используются для анализа связей и маршрутов.;Применяются в сетях и при анализе друзей в соцсетях.;4
Наивный байесовский алгоритм;Наивный байесовский классификатор основан на теореме Байеса и предполагает условную независимость признаков при заданном классе для упрощения вычислений апостериорных вероятностей;Наивный байесовский алгоритм использует теорему Байеса для классификации данных;5
Где применяется NLP в промышленности и бизнесе?;Nlp помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Помогает работать с данными и строить модели.;3
Почему организации переходят на технологии предобработка данных?;Технологии предобработка данных позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Это что?то связанное с данными, но используется редко.;2
Что понимают под переобучением модели?;Переобучение — это ситуация, когда модель слишком точно подстраивается под обучающую выборку, теряя способность обобщать знания на новые данные.;Переобучение происходит, когда модель слишком сильно подстраивается под обучающие данные и плохо работает на новых.;5
Что такое Apache ZooKeeper?;Централизованный сервис для поддержания конфигурационной информации, именования, распределенной синхронизации и предоставления групповых сервисов в распределенных системах.;Какая-то система из Apache для больших данных.;2
Что представляет собой метод k-means?;k-means — это алгоритм кластеризации, основанный на минимизации расстояний между объектами и центрами кластеров.;k-means — это алгоритм кластеризации, где центр обновляется итерационно.;4
Что такое точность (accuracy) в машинном обучении?;Точность — это метрика, определяющая долю правильных предсказаний от общего числа наблюдений: Accuracy = (TP + TN) / (TP + TN + FP + FN).;Accuracy показывает долю верных предсказаний среди всех примеров.;5
Какие метрики используются для оценки моделей в задачах мультиклассовой классификации?;Для мультиклассовой классификации используются accuracy, macro/micro averaged precision/recall, F1-score и confusion matrix для детального анализа ошибок;Метрики точности и полноты для нескольких классов;3
Характерные черты безмасштабных сетей;Безмасштабные сети имеют степенное распределение степеней узлов, содержат хабы и демонстрируют устойчивость к случайным отказам но уязвимы к целевым атакам;P(k) ~ k^(-?), наличие узлов с очень высокой степенью (хабы), малый диаметр, свойство тесного мира;3
Что такое batch normalization?;Техника ускорения обучения глубоких нейронных сетей путем нормализации входов каждого слоя к нулевому среднему и единичной дисперсии для каждого мини-батча, что решает проблему internal covariate shift.;Метод который нормализует выходы слоев нейронной сети для каждого мини-батча. Ускоряет обучение, позволяет использовать более высокие learning rates и уменьшает чувствительность к инициализации весов.;5
Что такое HDFS и как обеспечивается отказоустойчивость?;Распределенная файловая система Hadoop. Отказоустойчивость обеспечивается репликацией данных на несколько узлов (по умолчанию 3 копии) и rack-aware размещением.;Файловая система Hadoop с защитой от сбоев через дублирование данных.;2
Какие риски связаны с применением хранилища данных?;Хранилища данных помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Технологии позволяют улучшать качество аналитики, находить закономерности и предсказывать события.;4
Перечислите основные метрики больших графов.;Основные метрики: степень вершины (degree), средняя длина пути (L), кластерный коэффициент (C), центральность по посредничеству (betweenness), собственная центральность (eigenvector), плотность графа и диаметр.;Метрики — это просто количество вершин и рёбер.;3
Зачем нужно уменьшение размерностей?;Уменьшение размерностей позволяет снизить вычислительную сложность, устранить мультиколлинеарность и улучшить интерпретируемость моделей;Чтобы упростить данные;2
Какие этапы включает проект, основанный на использовании data mining?;Data mining используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;4
В чем преимущества применения NLP по сравнению с традиционными методами?;Nlp применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Это просто работа с таблицами. Не очень полезно.;2
Какие компании активно используют предиктивная аналитика и зачем?;Предиктивная аналитика помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Предиктивная аналитика применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;4
Сколько данных лучше для обучения;Объем данных для обучения моделей машинного обучения должен быть достаточным для обеспечения репрезентативности выборки при обязательном условии обеспечения высокого качества данных и их релевантности решаемой задаче;Баланс между объемом данных и их качеством является критически важным фактором;4
Какие этапы включает проект, основанный на использовании большие данные?;Большие данные применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;5
Принципы и инструменты аналитики Big Data;Аналитика больших данных основана на принципах распределенной обработки, использования специализированных фреймворков Hadoop и Spark, NoSQL баз данных и облачных технологий;Аналитика больших данных основана на распределенной обработке с Hadoop, Spark и NoSQL;5
Почему технологии масштабируемые системы стали критически важны?;Технологии масштабируемые системы позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Масштабируемые системы применяется в некоторых компаниях для анализа данных.;3
В каких пропорциях разделять данные перед обучением;70-80% обучение, 15-20% валидация, 15-20% тестирование. Зависит от объема данных;Стандартное разделение: 70% обучение, 15% валидация (подбор гиперпараметров), 15% тестирование (финальная оценка). При малых данных - k-fold кросс-валидация;5
Как организовать data lineage в сложных ETL пайплайнах?;Automated lineage tracking, metadata management, data provenance recording, impact analysis capabilities, integration с orchestration tools, visualization dependencies.;Автоматическое отслеживание, метаданные, запись provenance. Анализ impact'а и визуализация зависимостей данных.;4
Нарисуйте (опишите) схему классификации методов машинного обучения;Классификация методов ML включает обучение с учителем (классификация, регрессия), без учителя (кластеризация, снижение размерности), с подкреплением и полу-контролируемое обучение;С учителем, без учителя, с подкреплением - основные категории;3
Как тестируются независимые и парные выборки?;"Независимые: t-test, Mann-Whitney; парные: paired t-test, Wilcoxon signed-rank test";Независимые выборки тестируются t-test, парные paired t-test;5
Что такое data observability?;Способность понимать состояние данных через мониторинг, отслеживание и оповещения;Наблюдаемость за данными и их пайплайнами;4
Что такое MongoDB?;Документо-ориентированная NoSQL база данных с гибкой JSON-подобной схемой документов.;NoSQL база для документов. Использует JSON-like формат и не требует строгой схемы.;3
Метрики качества для компьютерного зрения;"Accuracy, Precision, Recall для классификации; mAP, IoU для детекции объектов; Dice coefficient для сегментации изображений";"Для классификации: Accuracy, Precision, Recall; для детекции: mAP, IoU; для сегментации: Dice";4
Что такое нормализация данных?;Нормализация — это преобразование данных в единую шкалу, чтобы устранить различия в масштабе признаков. Пример: приведение значений к диапазону [0,1].;Это когда данные приводят к одному масштабу.;4
Как развивается направление системы логирования в последние годы?;Системы логирования помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Системы логирования применяется в финансах, медицине, рекламе и IT, помогает анализировать данные и строить модели.;4
«Меры изменчивости»: что к ним относится?;К мерам изменчивости относятся дисперсия, стандартное отклонение, размах, межквартильный размах и среднее абсолютное отклонение;К мерам изменчивости относятся дисперсия, стандартное отклонение и размах;5
Что такое batch normalization?;Техника ускорения обучения глубоких нейронных сетей путем нормализации входов каждого слоя к нулевому среднему и единичной дисперсии для каждого мини-батча, что решает проблему internal covariate shift.;Метод улучшения нейросетей через обработку данных.;2
Как организовать систему кэширования для ускорения аналитических запросов к большим данным?;Многоуровневое кэширование (in-memory, SSD, disk), инвалидация кэша на основе TTL или изменений данных, предварительная агрегация, использование распределенных кэшей (Redis, Memcached).;Кэширование на нескольких уровнях, автоматическое обновление кэша, предвычисление результатов для частых запросов.;3
Свойства эластичности и надёжности сложных сетей;Эластичность - устойчивость к нагрузкам, надежность - отказоустойчивость. Зависит от структуры сети;Эластичность - способность сохранять функциональность при нагрузке, надежность - устойчивость к отказам узлов. Определяется структурой сети;4
Для чего нужна гипотеза о равенстве средних;Гипотеза о равенстве средних позволяет статистически проверить различия между средними значениями групп;Проверка различий средних;2
Для чего нужна гипотеза о равенстве средних;Гипотеза о равенстве средних позволяет статистически проверить различия между средними значениями групп;Гипотеза нужна для проверки различий средних;5
Что такое ZooKeeper в Kafka;ZooKeeper используется для управления метаданными кластера, выбора контроллера, отслеживания живых брокеров и потребителей, хранения конфигурации.;Это служба для координации в кластере.;2
Что такое transfer learning и в каких задачах он применяется?;Transfer learning - использование предобученных моделей для решения новых задач, применяется когда мало размеченных данных, особенно в компьютерном зрении и NLP;Использование готовых моделей;2
Какие типы данных используются в Big Data и чем они отличаются?;"В Big Data выделяют структурированные, неструктурированные и полуструктурированные данные. Структурированные хранятся в таблицах, неструктурированные — это тексты, изображения, видео; полуструктурированные — JSON, XML.";Есть разные данные — тексты, числа, картинки.;3
Работа кластеризатора k-means;Итеративный алгоритм с центроидами, минимизация внутрикластерного расстояния;Группирует точки по близости;2
Как data lakes влияет на эффективность бизнеса?;Технологии data lakes позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Data lakes применяется в финансах, медицине, рекламе и IT, помогает анализировать данные и строить модели.;4
Преимущества и недостатки непараметрических моделей;Непараметрические модели гибки и не требуют предположений о распределении данных, но могут требовать больших объемов данных и вычислительных ресурсов;Гибкость моделей и их вычислительная сложность;3
Что такое Adam optimizer?;Алгоритм оптимизации для градиентного спуска, сочетающий преимущества RMSProp и Momentum с адаптивным learning rate.;Метод настройки весов в нейросетях.;2
Почему технологии хранилища данных стали критически важны?;Технологии хранилища данных позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Хранилища данных нужно только программистам, обычным компаниям оно бесполезно.;2
Что такое Apache Flink?;Фреймворк для распределенной обработки потоковых и пакетных данных с низкой задержкой.;Система для обработки потоковых данных в реальном времени с гарантированной доставкой и управлением состоянием. Эффективна для сложных event-driven приложений.;4
Какие навыки необходимы специалисту для работы с классификация данных?;Классификация данных используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;4
Разновидности сложных сетей;Сети можно классифицировать на однородные, масштабно-инвариантные, малого мира и иерархические в зависимости от их структурных свойств;Однородные сети имеют равномерное распределение связей, безмасштабные - степенное распределение;3
Какие существуют типы машинного обучения?;Машинное обучение делится на три типа: обучение с учителем (Supervised Learning), обучение без учителя (Unsupervised Learning) и обучение с подкреплением (Reinforcement Learning). Каждый тип отличается способом обучения модели.;Есть обучение с учителем, без учителя и с подкреплением.;4
Как кластеризация данных применяется в современных компаниях?;Кластеризация данных используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Кластеризация данных нужно только программистам, обычным компаниям оно бесполезно.;2
Какие методы использовать для обработки категориальных переменных с большим количеством уникальных значений?;Target encoding, frequency encoding, embedding layers для нейросетей, grouping редких категорий, hash encoding. Избегать one-hot encoding при большом cardinality.;Способы преобразования категориальных признаков с многими значениями.;2
Как классификация данных используется в научных исследованиях?;Классификация данных используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;4
Что такое градиентный спуск?;Градиентный спуск — это итерационный метод оптимизации, который изменяет параметры модели в направлении, уменьшающем значение функции потерь, пропорционально антиградиенту.;Градиентный спуск — это метод оптимизации, который ищет минимум функции ошибки, изменяя параметры модели по направлению градиента.;5
Какие знаете алгоритмы классификации;Основные алгоритмы классификации включают логистическую регрессию, метод опорных векторов, деревья решений, случайный лес, наивный байесовский классификатор и k-ближайших соседей;Основные алгоритмы классификации включают логистическую регрессию, SVM и деревья решений;5
Что такое data governance в Big Data?;Управление доступностью, usability, integrity и security данных в организации;Система управления качеством, безопасностью и доступностью данных в компании;5
Определение термина 'большие данные', источники получения больших данных.;Большие данные — это совокупность структурированных и неструктурированных данных значительного объема, скорости и разнообразия, требующих специализированных методов хранения и анализа. Источники: сенсоры IoT, социальные сети, логи систем, транзакционные данные, мультимедиа.;Большие данные — это комплексные, разнородные и быстро обновляющиеся данные, поступающие из IoT, социальных сетей, сенсоров и транзакций.;5
Что такое Apache Spark RDD и чем он отличается от DataFrame?;RDD - низкоуровневая распределенная коллекция объектов, DataFrame - распределенная коллекция данных с именованными колонками и оптимизацией через Catalyst.;Два способа работы с данными в Spark.;2
Что такое Apache Flink?;Фреймворк для распределенной обработки потоковых и пакетных данных с низкой задержкой.;Платформа для обработки потоков данных с низкой задержкой, альтернатива Spark Streaming.;3
Как специалисты анализируют данные в рамках кластеризация данных?;Кластеризация данных используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Кластеризация данных используется бизнесом для оптимизации процессов, анализа клиентов и прогнозирования.;4
Параметрическая модель статистического обучения;Параметрическая модель имеет фиксированное число параметров и предполагает определенную функциональную форму зависимости;Модели с фиксированными параметрами;2
Какие стратегии использовать для обработки данных с changing schema в data lakes?;Schema evolution, schema on read, использование форматов с backward compatibility, metadata management, data validation pipelines.;Schema evolution, schema on read, совместимые форматы. Управление метаданными и валидация данных.;5
Какие реальные примеры использования обработка потоковых данных существуют?;Обработка потоковых данных используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Эти технологии помогают работать с информацией и делать прогнозы.;3
Принцип массивных вычислений в R;Векторизованные операции над целыми массивами данных вместо поэлементной обработки в циклах;Быстрые вычисления в R;2
Характерные черты безмасштабных сетей и связь с сетями тесного мира;Безмасштабные сети имеют степенное распределение степеней, наличие хабов, устойчивость к случайным отказам. Связаны с сетями тесного мира через высокую кластеризацию и короткие пути;Power law распределение и small world свойства;3
Какие реальные примеры использования распределённые вычисления существуют?;Распределённые вычисления помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Технологии позволяют улучшать качество аналитики, находить закономерности и предсказывать события.;4
Свойства эластичности и надёжности сложных сетей;"Эластичность - устойчивость к нагрузкам, надежность - отказоустойчивость; зависят от структуры и связности сети";Эластичность и надежность сетей;4
Основные инструменты аналитики больших данных;Hadoop, Spark, NoSQL БД, облачные платформы. Hadoop для хранения, Spark для обработки, NoSQL для неструктурированных данных;Hadoop (HDFS, MapReduce) для распределенного хранения, Spark для оперативной обработки в памяти, NoSQL БД для гибкого хранения неструктурированных данных;4
С какими проблемами сталкиваются при применении предиктивная аналитика, и как их решают?;Предиктивная аналитика помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Предиктивная аналитика применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;4
Как обработка потоковых данных влияет на эффективность бизнеса?;Технологии обработка потоковых данных позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Обработка потоковых данных используется бизнесом для оптимизации процессов, анализа клиентов и прогнозирования.;4
Как мониторить качество ML модели в продакшене?;Отслеживать accuracy/precision/recall на отложенной выборке, мониторить data drift и concept drift, отслеживать бизнес-метрики.;Следить чтобы модель продолжала хорошо работать на новых данных.;2
Какие инструменты используются для работы с мониторинг больших данных?;Мониторинг больших данных используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Мониторинг больших данных широко применяется в промышленности, здравоохранении, финансах и государственных системах. Позволяет анализировать большие массивы данных, строить точные модели и улучшать эффективность процессов.;5
Как ETL-процессы используется в научных исследованиях?;Etl-процессы используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Это просто работа с таблицами. Не очень полезно.;2
В чём суть алгоритмов нахождения квадратичной ошибки?;Алгоритмы нахождения квадратичной ошибки минимизируют сумму квадратов разностей между предсказанными и фактическими значениями для определения оптимальных параметров модели;Суть алгоритмов в минимизации суммы квадратов разностей между предсказаниями и данными;5
Что такое градиентный спуск?;Градиентный спуск — это итерационный метод оптимизации, который изменяет параметры модели в направлении, уменьшающем значение функции потерь, пропорционально антиградиенту.;Это метод уменьшения ошибки модели.;3
Что такое Delta Lake;Delta Lake — это open-source storage layer, который добавляет reliability, ACID транзакции и управление версиями к данным в data lakes поверх Parquet формата.;Storage layer с ACID транзакциями и версионированием для data lakes;4
Что такое data quality monitoring?;Непрерывный мониторинг качества данных по метрикам completeness, accuracy, consistency;Контроль данных;2
Назовите меры центральной тенденции;Основные меры центральной тенденции включают среднее арифметическое, медиану и моду распределения;Среднее, медиана и мода;3
Перечислить стадии разработки систем машинного обучения.;Стадии разработки систем машинного обучения: сбор данных, очистка и подготовка, выделение признаков, выбор модели, обучение, оценка качества, внедрение и мониторинг.;Этапы: сбор, очистка, выбор модели, обучение, оценка и внедрение.;4
Как принято формулировать нулевую гипотезу?;Как утверждение об отсутствии эффекта, различий или связи между переменными;Нулевую гипотезу формулируют как отсутствие эффекта;5
Структуры и типы данных в R;Основные структуры данных в R включают векторы, матрицы, списки, data frames и factors, каждая с определенными свойствами и методами обработки;Векторы (однотипные данные), матрицы (двумерные массивы), списки (разнотипные коллекции), data frames (таблицы с разными типами колонок), factors (категориальные переменные);4
Как data mining применяется для автоматизации рутинных процессов?;Data mining применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Data mining нужно только программистам.;2
Нарисуйте (опишите) схему классификации методов машинного обучения;Классификация включает обучение с учителем, без учителя, с подкреплением и полу-контролируемое обучение;Классификация методов машинного обучения;4
Виды распределения данных и примеры;Репликация, шардинг, партиционирование. Примеры: Master-Slave, горизонтальное разделение;Репликация - копирование данных, шардинг - разделение по серверам. Master-Slave архитектура;3
Какие риски связаны с использованием ETL-процессы в критически важных системах?;Etl-процессы применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Помогает работать с данными и строить модели.;3
Какие методы обработки естественного языка используются в аналитике больших данных?;В NLP для больших данных применяются word2vec, BERT, TF-IDF, обработка n-грамм и методы тематического моделирования для извлечения смысла из текстовых данных;Современные подходы к обработке текстовых данных в Big Data;4
Как организовать versioning для ML моделей в production?;Model registry, version metadata, A/B testing инфраструктура, rollback capabilities, dependency tracking, reproducibility guarantees.;Model registry для версионирования, метаданные версий, A/B тестирование. Возможность отката и гарантии воспроизводимости.;5
Что такое F1-score?;Гармоническое среднее между precision и recall.;Показатель точности модели машинного обучения.;2
Что такое Data Catalog;Data Catalog — это централизованный реестр метаданных, который обеспечивает discoverability, понимание и управление данными в организации.;Система для поиска и описания данных;3
Определение термина «большие данные»;Большие объемы разнородных данных, требующие специальных технологий обработки и хранения;Данные больших объемов, скоростей и разнообразия;3
Какие стратегии использовать для миграции данных между разными системами хранения?;Инкрементальная миграция, dual write during transition, проверка консистентности, откат на предыдущую версию, мониторинг производительности, постепенное переключение трафика.;Поэтапная миграция данных, dual write в обе системы during переходного периода, верификация консистентности, план отката, мониторинг производительности, постепенное перенаправление запросов на новую систему.;5
Что включает в себя модель 8V для Big Data?;Volume, Velocity, Variety, Veracity, Value, Variability, Visualization, Validity. Эта модель охватывает технические и бизнес-аспекты больших данных от сбора до извлечения ценности.;Все 8 характеристик: Volume, Velocity, Variety, Veracity, Value, Variability, Visualization, Validity. Полное описание сложностей и возможностей больших данных.;5
Какие инструменты используются для работы с масштабируемые системы?;Технологии масштабируемые системы позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Масштабируемые системы применяется в финансах, медицине, рекламе и IT, помогает анализировать данные и строить модели.;4
Как работает технология Homomorphic Encryption для конфиденциальных вычислений?;Позволяет выполнять вычисления на зашифрованных данных без расшифровки. Сохраняет конфиденциальность при обработке в облаке и совместном использовании данных.;Вычисления на зашифрованных данных без необходимости их расшифровки. Обеспечивает privacy при обработке в cloud, позволяет работать с чувствительными данными безопасно.;5
Какие методы борьбы с переобучением вы знаете?;Регуляризация L1/L2, dropout, early stopping, увеличение данных, упрощение модели, кросс-валидация, augmentation данных.;Регуляризация, dropout в нейросетях, early stopping, сбор больше данных, уменьшение сложности модели, использование кросс-валидации.;5
Сколько данных лучше взять для обучения: побольше или поменьше?;Зависит от сложности задачи: для сложных моделей нужно больше данных, но важнее качество и репрезентативность;Оптимальный объем данных для обучения;4
Что такое Data Warehouse;Data Warehouse — это централизованное хранилище интегрированных данных из различных источников, оптимизированное для аналитики и отчетности.;Хранилище для аналитики;2
Что такое ансамблевые методы?;Комбинация нескольких моделей для улучшения прогнозной способности и устойчивости.;Подход, когда несколько моделей объединяются для получения более точного предсказания. Включает бэггинг, бустинг и стекинг.;4
Разница между линейной и логистической регрессией;Линейная регрессия предсказывает непрерывные числовые значения, тогда как логистическая регрессия предсказывает вероятности бинарной или мультиклассовой классификации с использованием сигмоидной функции активации;Линейная регрессия для регрессии, логистическая для классификации;4
Как data warehouses влияет на эффективность бизнеса?;Data warehouses помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Технологии позволяют улучшать качество аналитики, находить закономерности и предсказывать события.;4
Какие способы визуализации корреляции изучались в курсе Big Data?;Изучались диаграммы рассеяния, тепловые карты корреляции, матричные графики и параллельные координаты для визуализации взаимосвязей между переменными;Графики для связи переменных;2
Определение термина «большие данные»;Большие данные представляют собой огромные объемы разнородной информации, требующие специальных технологий обработки;Большие объемы разнородных данных;3
Где применяется кластеризация в промышленности и бизнесе?;Кластеризация применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Это просто работа с таблицами. Не очень полезно.;2
Какие реальные примеры использования in-memory обработка существуют?;In-memory обработка используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;In-memory обработка используется для обработки информации и улучшения решений.;3
Понятия репликации и шардинга;Репликация создает копии данных для отказоустойчивости, шардинг распределяет данные между серверами;Репликация создает копии данных для повышения надежности системы;5
Как принято формулировать нулевую гипотезу?;Как утверждение об отсутствии эффекта, различий или связи между переменными;Формулировка нулевой гипотезы;4
Что такое нейронная сеть и где она применяется?;Нейронная сеть — это вычислительная модель, имитирующая работу нейронов мозга, применяемая для распознавания образов, прогнозирования и обработки естественного языка.;Нейронная сеть — математическая модель, имитирующая биологические нейроны. Применяется для распознавания изображений, речи и прогнозирования.;4
Как организовать data quality checks в ETL процессах?;Automated validation rules, data profiling, constraint checking, statistical tests, anomaly detection, alerting on quality issues.;Проверка качества в ETL.;2
Основные задачи Data Analysis;К основным задачам относятся описательная аналитика, диагностика проблем, прогнозирование и прескриптивная аналитика;Разные типы аналитических задач;4
Что такое нормализация данных?;Нормализация данных — это процесс приведения признаков к единому масштабу для повышения точности и стабильности алгоритмов.;Нормализация делает данные примерно одинаковыми по величине.;4
Как внедрение модели прогнозирования влияет на процессы в организациях?;Модели прогнозирования применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;4
Меры качества для языковых моделей;Основные меры качества включают перплексию для оценки модели, BLEU для машинного перевода, ROUGE для суммаризации и метрики точности;Perplexity для оценки моделей, BLEU для перевода, ROUGE для суммаризации текстов;3
Уровень статистической достоверности;Вероятность того, что результат не случаен. Не вероятность ошибки, а доверие к результату;Показывает надежность результата. 95% значит результат надежный;3
Как развитие машинное обучение влияет на будущее цифровых технологий?;Машинное обучение используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Машинное обучение применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;4
Типы деревьев решений и индексы;Основные типы алгоритмов деревьев решений включают CART и C4.5, которые используют различные индексы для разделения данных, такие как индекс Джини, энтропия и коэффициент gain ratio;Алгоритмы деревьев решений и критерии для выбора оптимальных правил разделения признаков;3
Что делает алгоритм k-ближайших соседей (kNN)?;"kNN классифицирует объект на основе классов его ближайших соседей в пространстве признаков.,""kNN определяет класс объекта";ориентируясь на ближайших соседей в данных.;5
Что такое градиентный спуск?;Градиентный спуск — это итерационный метод оптимизации, который изменяет параметры модели в направлении, уменьшающем значение функции потерь, пропорционально антиградиенту.;Метод оптимизации, где параметры модели корректируются, чтобы снизить ошибку.;4
Векторы, матрицы, фреймы в R;Вектор - одномерный массив, матрица - двумерный, фрейм - таблица с разными типами данных;Векторы - одномерные массивы, матрицы - двумерные, фреймы - таблицы с разными типами;5
Метрики качества для моделей регрессии;Основные метрики включают RMSE, MAE, MAPE и R? для оценки точности регрессионных моделей и их предсказательной способности;RMSE (среднеквадратичная ошибка), MAE (средняя абсолютная ошибка), MAPE (средняя абсолютная процентная ошибка), R? (коэффициент детерминации);3
Данные, информация, знания — в чём отличия?;Данные - сырые факты, информация - структурированные данные, знания - проверенные закономерности;Данные это сырые факты, информация это структурированные данные;5
Закономерности динамики сложных сетей;Предпочтительное присоединение, рост по степенному закону, small-world эффект, кластеризация;Preferential attachment, small-world;3
Принцип работы RandomForest;Ансамбль деревьев, бэггинг, случайный выбор признаков;Это алгоритм для предсказаний, использует деревья;2
Как мониторинг больших данных влияет на эффективность бизнеса?;Мониторинг больших данных помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Технологии позволяют улучшать качество аналитики, находить закономерности и предсказывать события.;4
Типы деревьев решений и индексы;Основные типы деревьев решений включают CART и C4.5, использующие индексы Джини, энтропию и gain ratio для выбора разделяющих признаков;Алгоритмы построения деревьев для классификации и регрессии с различными критериями разделения;2
Что такое статистическое обучение;Раздел машинного обучения, основанный на статистических методах и вероятностных моделях;Статистические методы и вероятностные модели для обучения алгоритмов;4
Как рекомендательные системы помогает в анализе больших объемов данных?;Рекомендательные системы применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;5
Что такое data replication в распределенных системах?;Создание копий данных на разных узлах для обеспечения отказоустойчивости и доступности;Дублирование данных на разных узлах кластера для повышения надежности системы;4
Что включает в себя модель 8V для Big Data?;Volume, Velocity, Variety, Veracity, Value, Variability, Visualization, Validity. Эта модель охватывает технические и бизнес-аспекты больших данных от сбора до извлечения ценности.;Восемь V: объем, скорость, разнообразие, достоверность, ценность, изменчивость, визуализация и валидность.;3
Какие этапы включает проект, основанный на использовании обработка данных?;Обработка данных применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;5
Процесс познания (от гипотезы к функции);Процесс включает формулировку гипотезы, сбор данных, построение модели, валидацию и создание прогнозной функции;Гипотеза - данные - модель - функция;3
Нарисуйте (опишите) схему классификации методов машинного обучения;Классификация методов ML включает обучение с учителем (классификация, регрессия), без учителя (кластеризация, снижение размерности), с подкреплением и полу-контролируемое обучение;Группировка алгоритмов машинного обучения;2
Принцип массивных вычислений в R;Векторизованные операции над целыми массивами данных вместо поэлементной обработки в циклах;Принцип векторизованных вычислений;4
Характерные черты безмасштабных сетей и связь с сетями тесного мира;Безмасштабные сети имеют степенное распределение степеней, наличие хабов, устойчивость к случайным отказам. Связаны с сетями тесного мира через высокую кластеризацию и короткие пути;Степенное распределение, хабы и связь с сетями малого мира;4
Что такое переобучение (overfitting) и как его предотвратить?;Модель слишком точно подстраивается под тренировочные данные и плого работает на новых. Методы предотвращения: регуляризация, кросс-валидация, упрощение модели, увеличение данных.;Ситуация плохого обобщения модели и методы ее решения.;2
Что такое трансформер (Transformer) в NLP?;Архитектура нейросетей на основе механизма внимания, исключающая рекуррентные и сверточные слои для обработки последовательностей.;Какая-то современная модель для текста, лучше старых методов.;2
Что такое random forest?;Ансамблевый метод, строящий множество решающих деревьев на случайных подвыборках данных и признаков.;Алгоритм из многих деревьев решений. Работает лучше чем одно дерево и устойчив к шуму.;3
Шаги построения дендрограммы;Построение дендрограммы включает вычисление матрицы расстояний, применение агломеративного алгоритма кластеризации и визуализацию иерархической структуры слияния кластеров;Расчет матрицы расстояний, последовательное объединение кластеров и построение древовидной структуры;3
Какие методы обработки естественного языка используются в аналитике больших данных?;В NLP для больших данных применяются word2vec, BERT, TF-IDF, обработка n-грамм и методы тематического моделирования для извлечения смысла из текстовых данных;Алгоритмы для анализа текстовой информации;3
Какие методы использовать для обнаружения аномалий в многомерных временных рядах?;Многомерные статистические методы (Mahalanobis distance), матричные профили, нейросетевые подходы (LSTM autoencoders), изолирующие леса, анализ главных компонент с reconstruction error.;Многомерные статистические методы, нейросети для временных рядов, алгоритмы обнаружения выбросов, анализ компонент. Учитывать временную природу и корреляции между переменными.;4
Какие инструменты используются для работы с предобработка данных?;Технологии предобработка данных позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Предобработка данных применяется в некоторых компаниях для анализа данных.;3
Какие методы обработки пропущенных значений в данных вы знаете?;Для обработки пропущенных значений используются удаление строк, импутация средним/медианой, предсказание с помощью моделей и интерполяция, выбор метода зависит от природы пропусков и объема данных;Методы импутации и удаления пропусков в наборах данных;4
Какие компании активно используют нейронные сети и зачем?;Нейронные сети используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;5
Примеры задач с большими графами;Большие графы используются в социальных сетях, рекомендательных системах и биоинформатике для анализа связей;Соцсети и рекомендации с графами;3
Какие риски связаны с применением обработка потоковых данных?;Обработка потоковых данных используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Обработка потоковых данных применяется в некоторых компаниях для анализа данных.;3
Какие риски связаны с применением распределённые вычисления?;Распределённые вычисления используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Распределённые вычисления используется бизнесом для оптимизации процессов, анализа клиентов и прогнозирования.;4
Boxplot и его интерпретация, связь с другими элементами анализа;"Boxplot показывает медиану, квартили, выбросы; связан с описательной статистикой и проверкой распределений";Boxplot для анализа распределения данных;4
Почему организации переходят на технологии big data?;Big data помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Big data используется для обработки информации и улучшения решений.;3
Как ETL-процессы используется в научных исследованиях?;Etl-процессы применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;5
В каких пропорциях рекомендуют разделять данные перед обучением и на какие части?;Обычно данные делятся на три части: обучающую 70%, валидационную 15% и тестовую 15%. Это обеспечивает корректную оценку модели без переобучения.;Данные делятся на обучающую, тестовую и валидационную части, примерно 70/15/15.;4
Критерии качества кластеризации;Silhouette score, Davies-Bouldin index, Calinski-Harabasz index - метрики оценки кластеров;Silhouette, Davies-Bouldin, Calinski-Harabasz индексы;3
Определение термина 'большие данные', источники получения больших данных.;Большие данные — это совокупность структурированных и неструктурированных данных значительного объема, скорости и разнообразия, требующих специализированных методов хранения и анализа. Источники: сенсоры IoT, социальные сети, логи систем, транзакционные данные, мультимедиа.;Большие данные — это массивы различной информации, требующие анализа с помощью специальных инструментов.;4
Что такое крос-валидация по временным рядам?;Специальные методы валидации для временных рядов, сохраняющие временной порядок данных.;Методы валидации для временных рядов, где данные разбиваются с учетом временного порядка - тренировка на прошлом, тест на будущем, без перемешивания.;4
Какие компании активно используют глубокое обучение и зачем?;Глубокое обучение применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Это просто работа с таблицами. Не очень полезно.;2
Как понимать «уровень статистической достоверности»?;Это показатель.;Это что-то вроде процента уверенности.;2
Метрики качества для моделей регрессии;Для оценки регрессионных моделей используются RMSE (среднеквадратичная ошибка), MAE (средняя абсолютная ошибка), MAPE (средняя абсолютная процентная ошибка) и R? (коэффициент детерминации), которые измеряют различные аспекты точности предсказаний;Метрики ошибок показывают величину расхождения предсказаний с реальными значениями, а R? измеряет долю объясненной дисперсии;3
Что такое 'обучающая выборка'?;Обучающая выборка — это часть данных, используемая для настройки параметров модели.;Это те данные, которые нужны, чтобы модель могла что-то предсказывать.;4
Какие компании активно используют ETL-процессы и зачем?;Etl-процессы используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;4
Метрики качества для компьютерного зрения;"Accuracy, Precision, Recall для классификации; mAP, IoU для детекции объектов; Dice coefficient для сегментации изображений";Accuracy показывает общую точность, Precision - точность предсказаний, Recall - полноту;3
Что такое 'кластеризация'?;Кластеризация — это процесс разделения множества объектов на группы (кластеры) так, чтобы объекты внутри одной группы были похожи, а между группами — различались.;Кластеризация — это группировка данных, но не всегда по схожим признакам.;3
Что такое ZooKeeper в Kafka;ZooKeeper используется для управления метаданными кластера, выбора контроллера, отслеживания живых брокеров и потребителей, хранения конфигурации.;ZooKeeper выполняет функции координации: отслеживает состояние брокеров, управляет конфигурацией топиков и партиций, координирует выбор лидера.;3
Что такое переобучение модели?;Переобучение — это ситуация, когда модель слишком точно подстраивается под обучающие данные и теряет способность обобщать закономерности. Основные признаки — высокая точность на обучающей выборке и низкая на тестовой.;Модель переобучается, если она выдает слишком точные результаты на тех же данных.;3
Принципы глубокого обучения в нейросетях;Глубокое обучение использует многослойные нейронные сети для автоматического извлечения признаков из данных, CNN специализируются на обработке изображений;Backpropagation для обучения, нелинейные активации, CNN используют convolutional layers для пространственных признаков и pooling для уменьшения размерности;4
Примеры задач с большими графами;Большие графы используются в социальных сетях, рекомендательных системах и биоинформатике для анализа связей;Задачи: соцсети, рекомендации, биоинформатика;4
Что такое feature engineering и какие методы используются?;Feature engineering - процесс создания и отбора признаков, включающий кодирование категориальных переменных, создание полиномиальных features и отбор наиболее значимых признаков;Feature engineering - процесс создания и отбора признаков для машинного обучения;5
Параметрическая модель статистического обучения;Параметрическая модель имеет фиксированное число параметров и предполагает определенную функциональную форму зависимости;Параметрические модели имеют ограниченное число параметров;4
Как нейронные сети применяется для автоматизации рутинных процессов?;Нейронные сети применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Нейронные сети применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;5
Что такое кросс-валидация?;Метод оценки модели, при котором данные разбиваются на k частей, модель обучается на k-1 частях и проверяется на оставшейся части, процесс повторяется k раз.;Способ проверки модели на разных наборах данных чтобы оценить ее работу.;3
Почему организации переходят на технологии обработка потоковых данных?;Обработка потоковых данных помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Эти технологии помогают работать с информацией и делать прогнозы.;3
Что такое Docker контейнер?;Легковесная изолированная среда для запуска приложений со всеми зависимостями.;Docker контейнер - это стандартизированная единица программного обеспечения, которая инкапсулирует приложение со всеми его зависимостями, обеспечивая переносимость и воспроизводимость между разными средами.;5
Суть алгоритмов связных компонент и покрывающего дерева;Связные компоненты находят группы связанных узлов, покрывающее дерево - минимальный набор рёбер, соединяющий все узлы;Алгоритмы для графов;2
Для чего нужны индексы Gain и Gini?;Gain и Gini используются в деревьях решений для выбора оптимального признака при разбиении узла;Gain и Gini для деревьев решений;4
С какими проблемами сталкиваются при применении кластеризация, и как их решают?;Кластеризация помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Кластеризация применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;4
Для чего нужна гипотеза о равенстве средних;Гипотеза о равенстве средних позволяет статистически проверить различия между средними значениями групп;Для сравнения средних в группах;4
Что такое data quality monitoring?;Непрерывный мониторинг качества данных по метрикам completeness, accuracy, consistency;Автоматический контроль качества данных в реальном времени;4
Какие стратегии использовать для backup и recovery больших datasets?;Incremental backups, snapshotting, geographic replication, versioned storage, automated recovery procedures, regular testing восстановления.;Инкрементальные бэкапы, снапшоты, репликация. Автоматическое восстановление и регулярные тесты.;4
Разница между линейной и логистической регрессией;Линейная регрессия предсказывает непрерывные числовые значения, тогда как логистическая регрессия предсказывает вероятности бинарной или мультиклассовой классификации с использованием сигмоидной функции активации;Разные типы регрессии;2
Факторы, влияющие на коэффициент корреляции;На корреляцию влияют выбросы, нелинейность связи, гетерогенность данных, размер выборки и наличие скрытых переменных;На коэффициент корреляции влияют выбросы и нелинейность связи;5
Сколько данных лучше для обучения;Объем данных для обучения должен быть достаточным для репрезентативности, но важнее качество данных и их соответствие решаемой задаче;Большие объемы данных обычно улучшают качество моделей машинного обучения;2
Что такое кластеризация и какие задачи оно решает?;Кластеризация применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Кластеризация нужно только программистам.;2
Какие навыки необходимы специалисту для работы с глубокое обучение?;Глубокое обучение применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Глубокое обучение — это что-то про компьютеры. Применяется редко.;2
Параметрическая модель статистического обучения;Модель с фиксированным числом параметров, заданная функциональной формой и распределением ошибок;Модель с определенной структурой и ограниченным числом параметров;3
Структуры и типы данных в R;Векторы, матрицы, списки, фреймы данных, факторы - основные структуры хранения данных;Векторы, матрицы, списки, фреймы данных и факторы как основные структуры;5
Что такое Apache Kafka и для чего используется?;Распределенная потоковая платформа для обработки данных в реальном времени. Используется для построения data pipelines, event-driven архитектур, streaming приложений.;Система для обработки потоковых данных.;2
Характерные черты безмасштабных сетей;Степенное распределение степеней, наличие хабов, устойчивость к случайным отказам, уязвимость к targeted attacks;Особенности безмасштабных сетей;2
Как развитие ETL-процессы влияет на будущее цифровых технологий?;Etl-процессы помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;5
Как организовать систему для ML feature serving в реальном времени?;Feature store с low-latency API, online/offline feature consistency, versioning, monitoring feature quality, scalable serving infrastructure.;Feature store с быстрым API, консистентность фич, версионирование, мониторинг качества. Масштабируемая инфраструктура для serving'а.;5
В каких сферах применяются большие данные и каковы примеры их использования?;Большие данные используются в медицине (анализ медицинских изображений), ритейле (персонализированные рекомендации), финансах (fraud detection), транспорте (оптимизация маршрутов), IoT (умные города).;В современных технологиях и бизнесе для работы с информацией.;2
Нормальное распределение;Нормальное распределение характеризуется симметричной колоколообразной формой, параметрами ? (среднее) и ? (стандартное отклонение), встречается во многих природных явлениях;Распределение с плотностью вероятности f(x) = (1/??2?)exp(-(x-?)?/2??), 68% данных в пределах ?±?;3
Как компьютерное зрение помогает в анализе больших объемов данных?;Компьютерное зрение используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Компьютерное зрение применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;5
Критерии качества кластеризации;Метрики оценки кластеризации включают Silhouette score, Davies-Bouldin index и Calinski-Harabasz index для измерения компактности и разделимости кластеров;Silhouette score измеряет схожесть объектов внутри кластеров, Davies-Bouldin оценивает среднее сходство между кластерами, Calinski-Harabasz анализирует отношение межкластерной дисперсии к внутрикластерной;4
Преимущества и недостатки непараметрических моделей;Непараметрические модели гибки и не требуют предположений о распределении данных, но могут требовать больших объемов данных и вычислительных ресурсов;Адаптивность к данным и требования к ресурсам;4
Что такое 'валидация модели'?;Валидация — это процесс проверки качества обученной модели на независимых данных, не участвовавших в обучении.;Это когда проверяют, работает ли модель на тех же данных.;3
Что такое нормализация данных?;Нормализация — это преобразование данных в единую шкалу, чтобы устранить различия в масштабе признаков. Пример: приведение значений к диапазону [0,1].;Это когда данные выравнивают.;3
NoSQL классификация хранилищ;NoSQL базы данных классифицируются на документные, хранилища ключ-значение, колоночные и графовые в зависимости от модели данных и способа организации хранения;Документные (MongoDB), ключ-значение (Redis), колоночные (Cassandra), графовые (Neo4j) - каждая оптимизирована для определенного типа запросов и данных;4
NoSQL классификация хранилищ;NoSQL базы данных классифицируются на документные хранилища, хранилища ключ-значение, колоночные базы данных и графовые базы данных в зависимости от модели данных и способа организации хранения информации;NoSQL базы данных классифицируются на несколько основных типов по модели данных;5
Как обрабатывать пропущенные значения в данных перед обучением модели?;Зависит от природы пропусков: удаление строк если мало пропусков, импутация средним/медианой для числовых, модой для категориальных, либо использование алгоритмов, поддерживающих пропуски.;Заполнить пропуски какими-то значениями чтобы модель могла работать.;2
Как кластеризация используется в научных исследованиях?;Кластеризация применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Кластеризация применяется в бизнесе и иногда в науке для анализа данных.;3
Какие риски связаны с применением распределённые вычисления?;Технологии распределённые вычисления позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Распределённые вычисления почти нигде не применяется. Это просто большие таблицы.;2
Как развитие большие данные влияет на будущее цифровых технологий?;Большие данные используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;4
Как data warehouses влияет на эффективность бизнеса?;Data warehouses помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Data warehouses применяется в финансах, медицине, рекламе и IT, помогает анализировать данные и строить модели.;4
Для чего нужны ключи сообщений в Kafka;Ключи сообщений определяют, в какую партицию топика будет записано сообщение. Сообщения с одинаковым ключом попадают в одну партицию, сохраняя порядок.;Ключи влияют на распределение сообщений по партициям.;2
Что такое пайплайны, бенчмарки и SOTA, как и для чего используются?;Пайплайны автоматизируют процессы обработки данных, бенчмарки устанавливают эталоны сравнения, SOTA (State-of-the-Art) представляет передовые методы в области;Пайплайны для автоматизации, бенчмарки для сравнения, SOTA для лучших методов;4
Какие вы знаете интегральные метрики качества, привести формулы и примеры.;Интегральные метрики: ROC-AUC (площадь под кривой зависимости TPR от FPR), PR-AUC (площадь под кривой Precision-Recall), LogLoss = -1/N * ?[y*log(p) + (1 - y)*log(1 - p)].;Интегральные метрики — ROC-AUC, PR-AUC, LogLoss, они учитывают баланс между Precision и Recall.;5
Виды столбчатых диаграмм и их интерпретация;"Столбчатые диаграммы включают вертикальные, горизонтальные, сгруппированные и stacked; интерпретируются через сравнение величин категорий";Столбчатые диаграммы включают вертикальные и горизонтальные типы;5
Структуры и типы данных в языке R;"""В R присутствуют структуры данных: vector, matrix, data.frame, list, factor. Примеры: vector(c(1,2,3)), matrix(1:9, nrow=3), data.frame(x=1:3, y=c('a','b','c')).";Основные структуры — вектор и таблица.;3
Как нейронные сети используется в научных исследованиях?;Нейронные сети используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;5
Как специалисты анализируют данные в рамках data lakes?;Data lakes помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Технологии data lakes позволяют компаниям обрабатывать большие объёмы разнородных данных, выявлять сложные закономерности и принимать обоснованные решения.;5
В чем разница между batch processing и stream processing?;Batch processing обрабатывает данные пачками с задержкой, stream processing обрабатывает данные в реальном времени по мере поступления.;Batch для данных которые накопились, stream для данных которые приходят постоянно. Разные подходы для разных задач.;3
Как развивается направление in-memory обработка в последние годы?;In-memory обработка помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;In-memory обработка нужно только программистам, обычным компаниям оно бесполезно.;2
Закономерности динамики сложных сетей и распространения информации;Сети развиваются по степенным законам, информация распространяется каскадно через влиятельные узлы;Сети растут предпочтительным присоединением, информация идет через центральные узлы;3
Что такое MLOps и как он отличается от традиционного DevOps?;Практики для автоматизации жизненного цикла ML моделей включая эксперименты, deployment, мониторинг. Отличается необходимостью управления данными, моделями, экспериментированием и дрейфом.;Подход к управлению ML проектами включающий версионирование данных, экспериментов и моделей в отличие от традиционного DevOps для кода.;3
Почему технологии data warehouses стали критически важны?;Data warehouses помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Data warehouses почти нигде не применяется. Это просто большие таблицы.;2
Почему организации переходят на технологии хранилища данных?;Хранилища данных помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Технологии хранилища данных позволяют компаниям обрабатывать большие объёмы разнородных данных, выявлять сложные закономерности и принимать обоснованные решения.;5
Как кластеризация помогает в анализе больших объемов данных?;Кластеризация используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Помогает работать с данными и строить модели.;3
Что такое перекрёстная проверка (cross-validation)?;Перекрёстная проверка — это метод оценки обобщающей способности модели, при котором данные делятся на несколько частей, и обучение происходит поочередно на различных подвыборках, а проверка — на оставшихся.;Cross-validation — это метод проверки модели, при котором данные делятся на части для оценки точности.;5
Что означает термин 'кластеризация'?;Кластеризация — это метод анализа данных, при котором объекты объединяются в группы (кластеры) на основе схожести признаков без использования заранее известных меток.;Кластеризация — это способ разделить данные на группы.;3
Что такое CAP-теорема и как она применяется в Big Data системах?;CAP-теорема утверждает, что распределенная система может гарантировать только два из трех свойств: Consistency (консистентность), Availability (доступность), Partition Tolerance (устойчивость к разделению). В Big Data обычно жертвуют строгой консистентностью ради доступности и partition tolerance.;Теорема про ограничения распределенных систем. В больших данных важнее доступность чем строгая консистентность.;3
Свойства описательных статистик;Меры центральной тенденции, изменчивости и формы распределения данных;Описательные статистики;2
Что такое Apache Spark и в чем его преимущество перед Hadoop MapReduce?;Это фреймворк для распределенной обработки больших данных. Ключевое преимущество — выполнение операций в оперативной памяти (in-memory), что значительно ускоряет итерационные алгоритмы и интерактивную аналитику по сравнению с дисковыми операциями MapReduce.;Spark — это инструмент для обработки данных. Он быстрее, чем старые системы, потому что использует память, а не диск.;3
Как характеристика Velocity влияет на выбор архитектуры обработки данных?;Высокая Velocity требует streaming архитектур (Kafka, Flink, Spark Streaming) вместо batch processing, так как данные должны обрабатываться в реальном времени с минимальной задержкой.;При высокой скорости поступления данных нужны streaming системы типа Kafka или Flink, а не пакетная обработка. Это позволяет обрабатывать данные в реальном времени.;5
Что такое Apache Hive?;Система управления данными в Hadoop, предоставляющая SQL-подобный язык запросов (HiveQL) для обработки структурированных данных в распределенном хранилище HDFS, с преобразованием запросов в MapReduce или Tez jobs.;SQL-интерфейс для работы с Hadoop. Позволяет писать запросы к большим данным.;3
Для чего нужны ключи сообщений в Kafka;Ключи сообщений определяют, в какую партицию топика будет записано сообщение. Сообщения с одинаковым ключом попадают в одну партицию, сохраняя порядок.;Ключи сообщений используются для гарантии порядка обработки связанных сообщений: сообщения с одинаковым ключом всегда направляются в одну партицию.;3
Что такое data drift?;Изменение распределения входных данных со временем, ухудшающее качество модели.;Проблема когда модель устаревает и перестает правильно работать.;2
Параметрическая модель статистического обучения;Модель с фиксированным числом параметров, заданная функциональной формой и распределением ошибок;Модель с фиксированным числом параметров и заданной функциональной формой;5
Что такое Data Mesh;Data Mesh — это децентрализованная архитектура управления данными, где данные организованы по доменам с владельцами и стандартизированными интерфейсами.;Новый подход к данным;2
Что такое A/B тестирование?;Статистический метод сравнения двух версий для определения лучшей на основе метрик.;Способ проверки разных вариантов дизайна или функционала.;2
Структуры и типы данных в R;Основные структуры данных в R включают векторы для атомарных данных, матрицы для двумерных массивов, списки для разнотипных коллекций, фреймы данных для таблиц и факторы для категориальных переменных;В R есть векторы, матрицы, списки и фреймы данных;4
Как глубокое обучение помогает в анализе больших объемов данных?;Глубокое обучение помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Глубокое обучение — это что-то про компьютеры. Применяется редко.;2
Какие компании активно используют data mining и зачем?;Data mining применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Data mining нужно только программистам.;2
Какие компании активно используют машинное обучение и зачем?;Машинное обучение применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Машинное обучение применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;5
Как NLP применяется для автоматизации рутинных процессов?;Nlp используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Nlp нужно только программистам.;2
Что такое MLOps?;Практики CI/CD для развертывания и мониторинга моделей машинного обучения.;MLOps - это набор практик для автоматизации и стандартизации жизненного цикла ML моделей, включая версионирование данных и кода, автоматическое обучение, развертывание и мониторинг в продакшене.;5
Как работает технология Homomorphic Encryption для конфиденциальных вычислений?;Позволяет выполнять вычисления на зашифрованных данных без расшифровки. Сохраняет конфиденциальность при обработке в облаке и совместном использовании данных.;Шифрование позволяющее производить операции с данными без дешифрации. Критично для конфиденциальных вычислений в облаке и работы с приватными данными.;4
Какие этапы включает проект, основанный на использовании модели прогнозирования?;Модели прогнозирования применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;5
Разновидности сложных сетей;Сложные сети можно классифицировать на однородные, масштабно-инвариантные, сети малого мира и иерархические структуры, каждая из которых обладает уникальными свойствами и характеристиками;Классификация сложных сетей включает несколько основных типов с различными свойствами;4
Для чего нужны партиции в Kafka;Партиции позволяют масштабировать обработку сообщений параллельно, распределяя нагрузку между несколькими потребителями. Каждая партиция гарантирует порядок сообщений.;Партиции обеспечивают параллелизм обработки: разные партиции топика могут обрабатываться разными консьюмерами в группе, что увеличивает пропускную способность системы.;3
Что такое learning rate в градиентном спуске?;Гиперпараметр, определяющий размер шага на каждой итерации градиентного спуска. Слишком высокий learning rate может привести к расходимости, слишком низкий - к медленной сходимости или застреванию в локальных минимумах.;Один из параметров для настройки алгоритмов.;2
Каков порядок обработки данных при тестировании гипотезы о равенстве;"какие тесты должны быть пройдены, какие требования к данным выдвигаются?,""Проверяется нормальность распределения (Shapiro–Wilk), гомогенность дисперсий (Levene), после чего применяют t-тест для независимых или парных выборок. Требования: независимость наблюдений, интервал/отношение шкалы.";Применяются тесты Шапиро и Левена для проверки условий t-теста.;3
Какие методы использовать для detection data drift в production ML systems?;Statistical tests (KS, PSI), monitoring prediction distributions, concept drift detection algorithms, feature distribution monitoring, performance metrics tracking.;Статистические тесты, мониторинг предсказаний, алгоритмы дрейфа. Отслеживание изменений в данных и качестве модели.;4
Что означает термин 'кластеризация'?;Кластеризация — это метод анализа данных, при котором объекты объединяются в группы (кластеры) на основе схожести признаков без использования заранее известных меток.;Кластеризация — это группировка данных по схожим характеристикам.;5
Что такое статистическая гипотеза? Какие виды гипотез вы знаете?;Статистическая гипотеза — это предположение о параметрах генеральной совокупности. Различают нулевую гипотезу H0 и альтернативную H1. Пример: H0: ?1 = ?2, H1: ?1 ? ?2.;Гипотеза — это математическое ожидание, которое сравнивают.;2
Что такое регуляризация в машинном обучении?;Регуляризация — это метод предотвращения переобучения за счёт добавления штрафа за сложность модели в функцию потерь (например, L1, L2).;Регуляризация помогает улучшить обобщение модели.;3
Как организовать versioning для ML моделей в production?;Model registry, version metadata, A/B testing инфраструктура, rollback capabilities, dependency tracking, reproducibility guarantees.;Версионирование ML моделей.;2
Какие методы балансировки классов в несбалансированных данных?;Для балансировки классов используются oversampling (SMOTE), undersampling, взвешивание классов и генеративные модели для создания синтетических примеров;Техники работы с несбалансированными наборами данных;3
Что такое NoSQL базы данных и чем они отличаются от реляционных?;NoSQL базы данных представляют собой системы хранения данных, не использующие табличную модель. Они обеспечивают гибкую структуру, масштабируемость и высокую производительность, в отличие от реляционных, которые используют SQL и строгие схемы.;NoSQL базы — это хранилища, где данные могут быть неструктурированными, они быстрее SQL при больших объёмах.;4
Как мониторинг больших данных влияет на эффективность бизнеса?;Мониторинг больших данных помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Мониторинг больших данных почти нигде не применяется. Это просто большие таблицы.;2
Принципы и инструменты аналитики Big Data;Аналитика больших данных основана на принципах распределенной обработки, использования специализированных фреймворков и облачных технологий для работы с большими объемами информации;Использование Hadoop, Spark, NoSQL баз данных и облачных платформ для обработки больших данных;3
Какие риски связаны с использованием обработка данных в критически важных системах?;Обработка данных помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;4
Как работает градиентный бустинг и чем отличается от случайного леса?;Градиентный бустинг последовательно строит деревья, каждое следующее исправляет ошибки предыдущего, тогда как случайный лес строит деревья независимо и усредняет результат;Последовательное vs параллельное построение деревьев;3
Примеры задач, решаемых с помощью больших графов;Большие графы применяются для анализа социальных сетей, транспортных систем, биоинформатики, рекомендательных систем и сетевой безопасности.;Графы нужны для поиска связей между объектами, например, в соцсетях или маршрутах транспорта.;5
Принцип массивных вычислений в R;Векторизованные операции позволяют эффективно обрабатывать большие массивы данных без использования циклов, используя оптимизированные низкоуровневые функции;Векторизация позволяет применять операции ко всем элементам данных одновременно, используя оптимизированные функции написанные на C/Fortran, что значительно ускоряет обработку больших массивов;5
Что такое нормализация данных и зачем она нужна?;Нормализация данных — это процесс приведения числовых признаков к общему масштабу, чтобы исключить влияние разницы в единицах измерения на обучение модели. Применяется методы Min-Max, Z-score, логарифмирование.;Нормализация нужна, чтобы данные были одного порядка. Например, все значения приводятся к диапазону 0-1.;4
Почему организации переходят на технологии in-memory обработка?;In-memory обработка помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;In-memory обработка применяется в некоторых компаниях для анализа данных.;3
Как рекомендательные системы применяется для автоматизации рутинных процессов?;Рекомендательные системы применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Рекомендательные системы применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;5
Принцип работы SVM;Метод опорных векторов находит гиперплоскость с максимальным зазором для разделения классов в пространстве признаков;SVM решает задачу квадратичной оптимизации для максимизации зазора между классами, использует опорные векторы определяющие границу, применяет kernel functions (linear, polynomial, RBF) для нелинейного разделения в feature space;5
Почему организации переходят на технологии хранилища данных?;Хранилища данных используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Хранилища данных применяется в некоторых компаниях для анализа данных.;3
Что такое Data Lineage;Data Lineage — это отслеживание происхождения, перемещения и трансформации данных от источника до конечного использования, включая все промежуточные этапы.;Отслеживание данных;2
Какие реальные кейсы демонстрируют эффективность машинное обучение?;Машинное обучение помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Машинное обучение нужно только программистам.;2
Какие методы используются для снижения размерности данных?;PCA (метод главных компонент), t-SNE, UMAP, autoencoders, feature selection. Уменьшают количество признаков сохраняя важную информацию.;Способы сокращения числа переменных в наборе данных.;2
Как масштабируемые системы влияет на эффективность бизнеса?;Технологии масштабируемые системы позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Масштабируемые системы широко применяется в промышленности, здравоохранении, финансах и государственных системах. Позволяет анализировать большие массивы данных, строить точные модели и улучшать эффективность процессов.;5
В каких пропорциях разделять данные перед обучением;70-80% обучение, 15-20% валидация, 15-20% тестирование. Зависит от объема данных;Обычно 70-80% обучение, 10-15% валидация, 10-15% тестирование. При малых данных используют кросс-валидацию;4
Что такое SMOTE?;Метод синтеза новых примеров для балансировки несбалансированных наборов данных.;SMOTE (Synthetic Minority Over-sampling Technique) генерирует синтетические примеры для миноритарного класса путем интерполяции между существующими примерами, решая проблему несбалансированности данных.;5
Как специалисты анализируют данные в рамках масштабируемые системы?;Технологии масштабируемые системы позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Масштабируемые системы применяется в некоторых компаниях для анализа данных.;3
Что такое Spark и чем он отличается от Hadoop?;Apache Spark — это платформа для распределенных вычислений, быстрее Hadoop MapReduce за счёт работы в памяти (in-memory). Поддерживает потоковую обработку данных и имеет библиотеки для SQL и машинного обучения.;Spark — система для распределенных вычислений, быстрее Hadoop, так как использует память для обработки.;5
Нормальное распределение;Нормальное распределение характеризуется симметричной колоколообразной формой, параметрами ? (среднее) и ? (стандартное отклонение), встречается во многих природных явлениях;Симметричное распределение вероятностей с характерной формой колокола;2
Преимущества и недостатки непараметрических моделей;Непараметрические модели гибки и не требуют предположений о распределении данных, но могут требовать больших объемов данных и вычислительных ресурсов;Гибкость без предположений о распределении и высокие вычислительные затраты;5
Назовите меры центральной тенденции;Среднее арифметическое, медиана и мода - основные меры центра распределения данных;Среднее, медиана и мода для описания центра данных;3
Что такое data catalog?;Централизованный реестр метаданных для обнаружения и понимания данных;Система для поиска и описания доступных данных в компании;4
Что такое рекомендательные системы и какие задачи оно решает?;Рекомендательные системы помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;5
Что такое PostgreSQL?;Реляционная СУБД с открытым исходным кодом, поддерживающая расширенные типы данных и SQL стандарты.;База данных для веб-приложений.;2
Суть алгоритмов связных компонент и покрывающего дерева;Алгоритм связных компонент находит группы связанных узлов в графе, а алгоритм покрывающего дерева находит минимальный набор рёбер, соединяющий все вершины;Алгоритмы для нахождения связных компонент и покрывающих деревьев в графах;4
Что такое Kubernetes?;Оркестратор контейнеров для автоматизации развертывания и управления приложениями.;Инструмент для работы с контейнерами в облаке.;2
Что такое Apache HBase?;Распределенная column-oriented NoSQL база данных, построенная поверх HDFS для random read/write доступа к большим данным.;NoSQL БД на основе Hadoop. Обеспечивает реальный доступ к большим данным с низкой задержкой. Использует HDFS для хранения.;5
Векторы, матрицы, фреймы в R;Векторы хранят однотипные данные, матрицы - двумерные массивы, фреймы - таблицы с разными типами колонок;Структуры данных в языке R;2
Что такое dbt (data build tool)?;Инструмент для трансформации данных в хранилищах через SQL с тестированием и документацией.;Инструмент для трансформации данных в SQL-ориентированном подходе. Помогает организовать ETL процессы с тестами и документацией.;4
Критерии качества кластеризации;Silhouette score, Davies-Bouldin index, Calinski-Harabasz index - метрики оценки кластеров;Метрики компактности и разделимости кластеров;4
Какие риски связаны с использованием data mining в критически важных системах?;Data mining помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;5
Какие типы шкал измерения данных существуют в статистике?;Номинальная (категории без порядка), порядковая (категории с порядком), интервальная (числа с равными интервалами), относительная (числа с абсолютным нулем).;4 типа шкал: номинальная, порядковая, интервальная, относительная. Различаются по уровню информации и допустимым операциям.;4
Как рекомендательные системы используется в научных исследованиях?;Рекомендательные системы помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Помогает работать с данными и строить модели.;3
Какие основные инструменты и технологии используются для работы с кластеризация?;Кластеризация помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Это просто работа с таблицами. Не очень полезно.;2
Какие компании активно используют глубокое обучение и зачем?;Глубокое обучение помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Это просто работа с таблицами. Не очень полезно.;2
Как ETL-процессы применяется для автоматизации рутинных процессов?;Etl-процессы помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;5
Что такое ARIMA модель?;Модель для прогнозирования временных рядов, учитывающая автокорреляцию и дифференцирование.;ARIMA (Autoregressive Integrated Moving Average) сочетает авторегрессию, интегрирование для стационарности и скользящее среднее для моделирования временных рядов с тенденциями и сезонностью.;5
Где применяется классификация данных в промышленности и бизнесе?;Классификация данных используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Помогает работать с данными и строить модели.;3
Что такое 'оценка точности модели'?;"Оценка точности модели — это процесс измерения доли правильных предсказаний модели относительно всех предсказаний.,""Точность показывает";сколько предсказаний модель сделала верно.;4
С какими проблемами сталкиваются при применении машинное обучение, и как их решают?;Машинное обучение помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Это просто работа с таблицами. Не очень полезно.;2
Как модели прогнозирования используется в научных исследованиях?;Модели прогнозирования используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;5
Что такое ETL процесс?;Процесс извлечения данных из источников, их преобразования в нужный формат и загрузки в целевую систему.;Это способ переноса информации между разными системами и базами данных.;2
Что такое feature store?;Централизованное хранилище для управления и обслуживания признаков ML моделей.;Feature store - это система, которая обеспечивает хранение, версионирование, доступ и обслуживание features для обучения и inference ML моделей, гарантируя консистентность между разными стадиями ML пайплайна.;5
Виды неопределённости в анализе данных;Источники неопределенности включают ошибки измерений, sampling variability, model uncertainty и epistemic uncertainty due to limited knowledge;Aleatoric uncertainty (шум в данных), epistemic uncertainty (незнание истинной модели), ошибки спецификации модели;4
Что такое TF-IDF?;Статистическая мера важности слова в документе относительно коллекции документов.;Алгоритм для определения значимости слов в текстовых документах на основе их частотности.;3
Сколько данных лучше взять для обучения: побольше или поменьше?;Объем данных для обучения должен быть достаточным для репрезентативности, но важнее качество данных. Для сложных моделей требуется больше данных, но необходим баланс с вычислительными ресурсами.;Объем данных должен быть достаточным для репрезентативности;4
Как большие данные помогает в анализе больших объемов данных?;Большие данные применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;4
Какие основные инструменты и технологии используются для работы с обработка данных?;Обработка данных помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Обработка данных применяется в бизнесе и иногда в науке для анализа данных.;3
Как data mining используется в научных исследованиях?;Data mining применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Data mining применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;5
Что такое крос-валидация по временным рядам?;Специальные методы валидации для временных рядов, сохраняющие временной порядок данных.;Особый способ валидации моделей для временных рядов, где важно сохранять последовательность данных во времени.;3
В чем разница между горизонтальным и вертикальным масштабированием в контексте Big Data?;Горизонтальное масштабирование - добавление новых узлов в кластер, вертикальное - увеличение ресурсов существующих серверов. Big Data системы предпочитают горизонтальное масштабирование как более экономичное и отказоустойчивое.;Горизонтальное - больше серверов, вертикальное - более мощные серверы. Big Data предпочитает горизонтальное масштабирование для лучшей масштабируемости и отказоустойчивости.;4
Как предобработка данных влияет на эффективность бизнеса?;Предобработка данных используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Предобработка данных нужно только программистам, обычным компаниям оно бесполезно.;2
Что такое нормализация данных?;Нормализация данных — это процесс приведения признаков к единому масштабу для повышения точности и стабильности алгоритмов.;Нормализация — это способ изменить значения данных.;2
Какие алгоритмы лежат в основе методов выделения сообществ? Дайте общее описание шагов выполнения этих алгоритмов.;Алгоритмы выделения сообществ включают методы модульности (Лувен, Ньюман-Гирван), спектральные методы и итерационные подходы. Основные шаги: построение графа, вычисление меры модульности Q, итеративное объединение или разбиение узлов до оптимума Q.;Методы выделения сообществ используют модульность и спектральные подходы. Основной принцип — минимизация потерь связи между группами.;5
Что такое R-squared?;Статистическая мера, показывающая долю дисперсии зависимой переменной, объясненную моделью.;Метрика для регрессионных моделей. Показывает качество предсказаний модели.;3
Что такое feature store?;Централизованное хранилище для управления и обслуживания признаков ML моделей;База данных для фич;3
Как in-memory обработка влияет на эффективность бизнеса?;Технологии in-memory обработка позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;In-memory обработка нужно только программистам, обычным компаниям оно бесполезно.;2
Что такое attention mechanism?;Механизм, позволяющий модели фокусироваться на relevant частях входных данных.;Механизм, который учит модель уделять разное внимание различным элементам входных данных в зависимости от контекста, что особенно важно в seq2seq моделях и трансформерах.;4
Как мониторить качество ML модели в продакшене?;Отслеживать accuracy/precision/recall на отложенной выборке, мониторить data drift и concept drift, отслеживать бизнес-метрики.;Регулярно вычислять метрики качества на свежих данных, отслеживать распределение входных фич (data drift) и соотношение предсказаний и фактических значений (concept drift). Также мониторить бизнес-метрики которые влияют на модель.;5
Какие методы используются для снижения размерности данных?;PCA (метод главных компонент), t-SNE, UMAP, autoencoders, feature selection. Уменьшают количество признаков сохраняя важную информацию.;Алгоритмы уменьшения количества признаков в данных для упрощения анализа.;3
С какими проблемами сталкиваются при применении data mining, и как их решают?;Data mining применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Data mining нужно только программистам.;2
Какие компании активно используют рекомендательные системы и зачем?;Рекомендательные системы применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Рекомендательные системы нужно только программистам.;2
Как выполняется преобразование данных и зачем нужна их очистка?;Преобразование включает нормализацию, агрегацию, обогащение. Очистка нужна для удаления шума, исправления ошибок, обработки пропусков для повышения качества моделей.;Подготовка данных к использованию.;2
Измерение качества модели анализа данных;Качество моделей анализа данных оценивается с помощью метрик accuracy, precision, recall, F1-score для классификации и RMSE, MAE, R? для регрессионных моделей;Качество моделей оценивается метриками accuracy, precision, recall, F1-score и RMSE, MAE, R?;5
Шаги построения дендрограммы;Построение дендрограммы включает вычисление матрицы расстояний между объектами, применение агломеративного алгоритма кластеризации с выбором меры связи и визуализацию иерархической структуры слияния кластеров;Построение дендрограммы включает несколько шагов от расчета расстояний до визуализации;5
Измерение качества модели анализа данных;Качество моделей оценивается с помощью метрик accuracy, precision, recall, F1-score для классификации и RMSE, MAE, R? для регрессии;Оценка того насколько хорошо модель предсказывает;2
Что такое Apache Kafka;Apache Kafka — это распределенная потоковая платформа для обработки потоков данных в реальном времени. Состоит из производителей, потребителей, брокеров и тем.;Это система для обмена сообщениями.;2
Data Mining vs. Machine Learning — в чём отличия?;Data Mining фокусируется на обнаружении паттернов в существующих данных, тогда как Machine Learning ориентирован на построение моделей для прогнозирования на новых данных;DM - поиск закономерностей, ML - создание прогнозных моделей;3
Как работает механизм shuffle в Spark?;Перераспределение данных между партициями при операциях типа groupBy или join. Включает сортировку, хэширование и сетевую передачу данных между узлами.;Процесс перемешивания данных между разными партициями при выполнении определенных операций.;3
Что такое машинное обучение и каковы его основные типы?;Машинное обучение — это раздел искусственного интеллекта, изучающий методы построения алгоритмов, способных обучаться на данных. Основные типы: обучение с учителем, без учителя и с подкреплением.;Машинное обучение — направление ИИ, изучающее методы, позволяющие системам обучаться из данных и улучшать результаты без явного программирования. Основные подходы: обучение с учителем, без учителя и с подкреплением.;5
Что такое 'ошибка модели'?;Ошибка модели — это разница между предсказанными и истинными значениями целевой переменной.;Ошибка модели — это разница между реальными и предсказанными значениями.;5
В чем разница между batch processing и stream processing?;Batch processing обрабатывает данные пачками с задержкой, stream processing обрабатывает данные в реальном времени по мере поступления.;Batch processing работает с накопленными данными периодически (например, раз в день), имеет большую задержку но высокую пропускную способность. Stream processing обрабатывает данные сразу при поступлении, малая задержка но сложнее в реализации и отладке.;5
Что такое Apache Cassandra?;Распределенная NoSQL база данных с высокой доступностью и масштабируемостью, использующая модель column-family.;NoSQL база данных с высокой производительностью записи. Масштабируется горизонтально и обеспечивает высокую доступность.;4
Что такое retention period;Retention period — это время, в течение котором сообщения хранятся в Kafka до удаления. Может задаваться по времени или по размеру данных.;Период хранения определяет, как долго сообщения сохраняются в топике перед автоматическим удалением.;3
Что такое кросс-валидация?;Метод оценки модели, при котором данные разбиваются на k частей, модель обучается на k-1 частях и проверяется на оставшейся части, процесс повторяется k раз.;Метод, когда данные делят на несколько частей и многократно тестируют модель на разных комбинациях этих частей для оценки качества.;4
Какие этапы включает проект, основанный на использовании глубокое обучение?;Глубокое обучение применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Помогает работать с данными и строить модели.;3
Достоинства и недостатки деревьев решений;"Достоинства: интерпретируемость, не требуют нормализации; недостатки: склонность к переобучению, нестабильность";Плюсы и минусы деревьев;2
Почему организации переходят на технологии хранилища данных?;Технологии хранилища данных позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Эти технологии помогают работать с информацией и делать прогнозы.;3
Данные, информация, знания — в чём отличия?;Данные - сырые факты, информация - структурированные данные, знания - проверенные закономерности;От сырых данных к знаниям;4
В чём суть алгоритмов нахождения квадратичной ошибки?;Алгоритмы нахождения квадратичной ошибки минимизируют сумму квадратов разностей между предсказанными и фактическими значениями для определения оптимальных параметров модели;Суть в минимизации суммы квадратов отклонений;4
Генеральная совокупность и выборка;Генеральная совокупность включает все объекты исследования, выборка является ее представительной частью;Все объекты и их часть;2
Для чего нужны гипотезы в анализе данных;Для формулировки проверяемых утверждений и статистической проверки научных предположений;Для проверки предположений о данных;2
Как развитие классификация данных влияет на будущее цифровых технологий?;Классификация данных используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Используется для прогнозов и анализа информации.;3
Что означает термин 'переподгонка' (overfitting)?;Переподгонка — это ситуация, когда модель слишком хорошо запоминает обучающую выборку, теряя способность обобщать на новых данных.;Переподгонка — это когда модель хорошо работает на обучении, но плохо на новых данных.;5
Что такое gradient boosting?;Метод машинного обучения, где несколько слабых моделей (обычно деревья) последовательно обучаются, каждая новая модель исправляет ошибки предыдущих.;Алгоритм, который объединяет много простых моделей чтобы получить одну сильную.;3
С какими проблемами сталкиваются при применении кластеризация, и как их решают?;Кластеризация помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Помогает работать с данными и строить модели.;3
Как работает технология Homomorphic Encryption для конфиденциальных вычислений?;Позволяет выполнять вычислений на зашифрованных данных без расшифровки. Сохраняет конфиденциальность при обработке в облаке и совместном использовании данных.;Метод шифрования который позволяет обрабатывать данные оставаясь зашифрованными. Важно для защиты приватности в облачных вычислениях.;3
Сравнительная характеристика R и Python.;R — это специализированный язык для статистики и визуализации, Python — универсальный язык с библиотеками для анализа данных (NumPy, pandas, scikit-learn). R более мощен для статистических тестов, Python — для интеграции и масштабируемых решений.;R лучше для статистики, Python — для инженерных задач и машинного обучения.;4
Разновидности сложных сетей;Сложные сети можно классифицировать на однородные, масштабно-инвариантные, сети малого мира и иерархические структуры, каждая из которых обладает уникальными свойствами и характеристиками;Разные виды сложных сетей отличаются по своим структурным особенностям и закономерностям;3
Какие этапы включает проект, основанный на использовании машинное обучение?;Машинное обучение используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Используется для прогнозов и анализа информации.;3
Где применяется машинное обучение в промышленности и бизнесе?;Машинное обучение помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Машинное обучение применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;4
Использование гистограммы для обработки фото;Гистограммы яркости широко применяются в обработке изображений для анализа тонального диапазона, коррекции контраста, выполнения операций выравнивания гистограммы и улучшения общего качества визуального контента;Графики распределения яркости пикселей используются для анализа и коррекции изображений;2
Как развитие большие данные влияет на будущее цифровых технологий?;Большие данные применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Большие данные применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;5
Что такое пайплайны бенчмарки и SOTA, как и для чего они используются?,;Пайплайн — последовательность шагов обработки данных и обучения модели. Бенчмарк — набор стандартных задач и метрик для сравнения моделей. SOTA (State Of The Art) — лучшие результаты на этих задачах.;SOTA — это про лучшие результаты.;2
Что такое exactly-once semantics в stream processing?;Гарантия что каждое сообщение будет обработано ровно один раз без дублирования или потерь;Обработка каждого события ровно один раз;3
Мотивация происхождения NoSQL.;NoSQL возник как ответ на ограниченность реляционных баз в масштабируемости и гибкости. Цель — работа с неструктурированными и распределёнными данными, высокая производительность и горизонтальное масштабирование.;NoSQL нужен, потому что SQL старый и неудобный.;3
Какие основные инструменты и технологии используются для работы с анализ данных?;Анализ данных помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Используется для прогнозов и анализа информации.;3
Что такое Spark и чем он отличается от Hadoop?;Apache Spark — это платформа для распределенных вычислений, быстрее Hadoop MapReduce за счёт работы в памяти (in-memory). Поддерживает потоковую обработку данных и имеет библиотеки для SQL и машинного обучения.;Spark — это язык программирования для больших данных.;2
Критерии качества кластеризации;К критериям качества относятся Silhouette score, Davies-Bouldin index и Calinski-Harabasz index;Метрики оценки кластеров;2
Понятия репликации и шардинга;Репликация создает копии данных для отказоустойчивости, шардинг распределяет данные между серверами;Копирование и распределение данных;2
Какие стратегии использовать для backup и recovery больших datasets?;Incremental backups, snapshotting, geographic replication, versioned storage, automated recovery procedures, regular testing восстановления.;Стратегии бэкапа больших данных.;2
Что такое нормализация данных и зачем она нужна?;Нормализация данных — это процесс приведения числовых признаков к общему масштабу, чтобы исключить влияние разницы в единицах измерения на обучение модели. Применяется методы Min-Max, Z-score, логарифмирование.;Нормализация — это масштабирование признаков, чтобы они имели сопоставимые значения. Например, Min-Max нормализация переводит данные в диапазон [0,1].;5
Шкалы измерений, примеры;Номинальная, порядковая, интервальная, относительная;Номинальная (категории без порядка), порядковая (ранги), интервальная (разности), относительная (нулевая точка);4
Что такое data lineage?;Отслеживание происхождения данных и их преобразований от источника до потребителя;Трассировка происхождения данных и всех преобразований через пайплайны обработки;5
С какими проблемами сталкиваются при применении компьютерное зрение, и как их решают?;Компьютерное зрение помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Используется для прогнозов и анализа информации.;3
Что такое L1 и L2 регуляризация?;L1 (Lasso) добавляет штраф за абсолютные значения весов, L2 (Ridge) - за квадраты весов.;Два разных способа регуляризации моделей для борьбы с переобучением через добавление штрафа к весам.;3
Как обеспечить консистентность данных в распределенной системе при сетевых разделах?;Использовать consensus алгоритмы (Raft, Paxos), кворумные операции, конфликтующее разрешение на основе временных меток или векторов версий, eventual consistency с механизмами согласования.;Алгоритмы консенсуса, кворумные операции, механизмы разрешения конфликтов, eventual consistency с процедурами согласования после восстановления сети.;4
Что такое статистическая гипотеза;Статистическая гипотеза представляет собой проверяемое предположение о свойствах генеральной совокупности, которое может быть подтверждено или опровергнуто с помощью статистических тестов;Формализованное предположение о свойствах генеральной совокупности которое формулируется как нулевая и альтернативная гипотеза и проверяется с использованием статистических тестов на основе выборочных данных;5
Что такое Apache Spark RDD и чем он отличается от DataFrame?;RDD - низкоуровневая распределенная коллекция объектов, DataFrame - распределенная коллекция данных с именованными колонками и оптимизацией через Catalyst.;RDD работает с объектами без оптимизации, DataFrame имеет схему и использует Catalyst optimizer для лучшей производительности запросов.;5
Назовите характеристики качества данных.;К характеристикам качества данных относятся полнота, точность, актуальность, непротиворечивость, целостность и доступность.;Качество данных оценивается по точности, полноте, актуальности, непротиворечивости, целостности и доступности.;5
Какие реальные кейсы демонстрируют эффективность ETL-процессы?;Etl-процессы помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;5
Что такое 'дерево решений'?;Дерево решений — это модель, которая представляет процесс принятия решений в виде иерархии правил, ведущих от корня к листьям.;Дерево решений — это структура, где на каждом уровне проверяется условие и принимается решение.;5
Что такое Apache Arrow?;Формат in-memory для колоночного хранения данных с нулевой сериализацией для ускорения анализа.;Формат для хранения данных в памяти. Оптимизирован для аналитических запросов и быстрого обмена между системами.;4
Каким образом выполняется преобразование данных;"""Преобразование данных выполняется для приведения данных к единому формату и структуры. Очистка необходима для устранения пропусков, дубликатов и ошибок, повышая достоверность анализа.";Трансформация данных используется для унификации формата очистка данных — для удаления пропусков и ошибок.;5
Какие реальные примеры использования in-memory обработка существуют?;Технологии in-memory обработка позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;In-memory обработка применяется в некоторых компаниях для анализа данных.;3
Какие знаете алгоритмы классификации;Основные алгоритмы классификации включают логистическую регрессию, метод опорных векторов, деревья решений, случайный лес, наивный байесовский классификатор и k-ближайших соседей;Популярные методы для решения задач классификации в машинном обучении и их основные характеристики;2
Как внедрение глубокое обучение влияет на процессы в организациях?;Глубокое обучение применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Глубокое обучение применяется в бизнесе и иногда в науке для анализа данных.;3
Что такое federated learning?;Подход когда модель обучается на децентрализованных данных без их централизации;Децентрализованное обучение моделей;3
Сравнительный анализ алгоритмов кластеризации;Алгоритмы кластеризации сравниваются по масштабируемости, чувствительности к шуму, способности находить кластеры сложной формы и вычислительной сложности;K-means (O(n), сферические кластеры), DBSCAN (обнаружение шума, произвольные формы), Hierarchical (O(n?), иерархическая структура), GMM (вероятностный подход);4
Как ETL-процессы используется в научных исследованиях?;Etl-процессы помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Etl-процессы применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;4
Что такое Apache Beam?;Унифицированная модель для определения пайплайнов обработки данных, работающая с разными рантаймами.;Инструмент для построения пайплайнов данных с единым API для batch и stream обработки. Поддерживает разные системы выполнения типа Spark или Flink.;4
Как data lakes влияет на эффективность бизнеса?;Data lakes помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Это что?то связанное с данными, но используется редко.;2
Как принято формулировать нулевую гипотезу?;Нулевая гипотеза (H0) утверждает отсутствие различий или эффектов: H0: ?1 = ?2. Альтернативная H1 утверждает обратное. Проверяется через статистический критерий (например, t-тест).;H0 — гипотеза, утверждающая отсутствие различий между выборками.;4
Что такое предиктивная аналитика и какие задачи оно решает?;Предиктивная аналитика помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;4
Какие реальные кейсы демонстрируют эффективность большие данные?;Большие данные используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;5
Принцип массивных вычислений в R;Векторизованные операции в R позволяют эффективно обрабатывать большие объемы данных без использования циклов через применение оптимизированных встроенных функций и операций;Векторизация операций в R обеспечивает высокую производительность при работе с данными;3
Что такое Edge AI и какие вызовы оно решает по сравнению с cloud AI?;Выполнение AI моделей на edge устройствах вместо облака. Решает проблемы latency, bandwidth, privacy, offline работы в IoT, мобильных и embedded системах.;Запуск AI на устройствах а не в облаке. Решает проблемы задержки, пропускной способности, конфиденциальности, работы без интернета для IoT и мобильных приложений.;5
Для чего нужны индексы Gain и Gini?;Gain и Gini используются в деревьях решений для выбора оптимального признака при разбиении узла;Индексы для разбиения в деревьях;3
Что такое data observability?;Способность понимать состояние данных через мониторинг, отслеживание и оповещения;Мониторинг данных;3
Какие риски связаны с использованием компьютерное зрение в критически важных системах?;Компьютерное зрение помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Используется для прогнозов и анализа информации.;3
Какие проблемы возникают при использовании обработка потоковых данных?;Обработка потоковых данных используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Обработка потоковых данных используется бизнесом для оптимизации процессов, анализа клиентов и прогнозирования.;4
С какими проблемами сталкиваются при применении компьютерное зрение, и как их решают?;Компьютерное зрение помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Компьютерное зрение применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;4
Что такое Feature Store;Feature Store — это централизованное хранилище для управления, версионирования и обслуживания признаков машинного обучения в production средах.;Система для хранения и версионирования признаков ML моделей с API для доступа;4
Что означает 'Batch Normalization'?;Batch Normalization — это техника нормализации входов слоёв нейросети, ускоряющая обучение и повышающая стабильность.;Batch Normalization улучшает обучение сети.;3
Принципы глубокого обучения в нейросетях;Глубокое обучение использует многослойные нейросети для автоматического извлечения признаков, CNN специализированы для изображений;Глубокие нейросети для извлечения признаков;4
Что такое Edge AI и какие вызовы оно решает по сравнению с cloud AI?;Выполнение AI моделей на edge устройствах вместо облака. Решает проблемы latency, bandwidth, privacy, offline работы в IoT, мобильных и embedded системах.;ИИ работающий на устройствах а не в облаке для уменьшения задержек и защиты приватности.;2
В чем разница между параметрами и гиперпараметрами модели?;Параметры настраиваются автоматически в процессе обучения на данных (веса модели). Гиперпараметры задаются до обучения и управляют самим процессом обучения (скорость обучения, глубина дерева).;Параметры — это внутренние настройки модели, а гиперпараметры — это внешние настройки, которые тоже нужно настраивать.;3
Понятие регрессии. Как используется этот вид анализа?;Регрессия — статистический метод, моделирующий зависимость целевой переменной Y от факторов X1, X2,..., Xn. Применяется для прогнозирования и анализа влияния факторов.;Регрессия — это прогнозирование.;2
Почему технологии data lakes стали критически важны?;Технологии data lakes позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Data lakes используется для обработки информации и улучшения решений.;3
Как data mining используется в научных исследованиях?;Data mining применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Data mining — это что-то про компьютеры. Применяется редко.;2
Почему технологии системы логирования стали критически важны?;Системы логирования помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Системы логирования применяется в некоторых компаниях для анализа данных.;3
Закономерности динамики сложных сетей и распространения информации;Сети развиваются по степенным законам, информация распространяется каскадно через влиятельные узлы;В сетях есть какие-то закономерности, информация передается от человека к человеку;2
Сравнительный анализ алгоритмов кластеризации;Алгоритмы кластеризации сравниваются по масштабируемости, устойчивости к шуму и вычислительной эффективности;Сравнение алгоритмов по масштабируемости;3
Какие реальные кейсы демонстрируют эффективность модели прогнозирования?;Модели прогнозирования используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Используется для прогнозов и анализа информации.;3
Перечислите основные метрики больших графов.;Основные метрики: степень вершины (degree), средняя длина пути (L), кластерный коэффициент (C), центральность по посредничеству (betweenness), собственная центральность (eigenvector), плотность графа и диаметр.;Метрики графа — это значения по осям координат.;2
Охарактеризуйте хранилища OLAP и OLTP;OLTP системы оптимизированы для операционных транзакций, OLAP для аналитических запросов и отчетности;OLTP для транзакций, OLAP для анализа;3
Основные инструменты аналитики больших данных, провести сравнительную характеристику.;К основным инструментам аналитики больших данных относятся Apache Hadoop, Spark, Flink, Hive, Pig, а также BI-платформы вроде Tableau и Power BI. Hadoop обеспечивает распределённое хранение (HDFS) и обработку, Spark — высокую скорость вычислений в оперативной памяти, Hive — SQL-подобный доступ к данным.;Основные инструменты больших данных: Hadoop, Spark, Hive, Flink, Tableau, Power BI. Hadoop отвечает за хранение, Spark — за обработку данных в памяти.;4
Обучение с подкреплением и ансамбли;Обучение с подкреплением основано на взаимодействии агента со средой для максимизации награды, а ансамбли объединяют несколько моделей для улучшения прогнозирования;Обучение с подкреплением основано на взаимодействии со средой, а ансамбли объединяют модели;5
Какие методы использовать для обработки категориальных переменных с большим количеством уникальных значений?;Target encoding, frequency encoding, embedding layers для нейросетей, grouping редких категорий, hash encoding. Избегать one-hot encoding при большом cardinality.;Специальные методы кодирования для категориальных переменных с высокой cardinality вместо one-hot encoding.;3
Что такое Data Mesh;Data Mesh — это децентрализованная архитектура управления данными, где данные организованы по доменам с владельцами и стандартизированными интерфейсами.;Организационная архитектура с доменной ownership данных и self-serve платформой;5
"Понятие корреляции; коэффициенты Пирсона, Спирмена, Кендалла";"Корреляция - мера линейной связи; Пирсон для нормальных данных, Спирмен для рангов, Кендалл для порядковых данных";Коэффициенты корреляции Пирсона, Спирмена;3
Что такое градиентный спуск?;Градиентный спуск — это итерационный метод оптимизации, который изменяет параметры модели в направлении, уменьшающем значение функции потерь, пропорционально антиградиенту.;Это поиск минимума.;2
Виды распределения данных и примеры;Репликация, шардинг, партиционирование. Примеры: Master-Slave, горизонтальное разделение;Данные можно распределять разными способами;2
Генеральная совокупность и выборка;Совокупность - все объекты исследования, выборка - часть совокупности для анализа;Все данные и их часть;2
Как выбрать между реляционной и документной БД для хранения сложных структур?;Реляционная для строгой схемы и сложных запросов, документная для гибкой схемы и иерархических данных. Выбор зависит от требований к целостности и запросам.;Разные БД для разных структур данных и требований к запросам.;3
Как развитие data mining влияет на будущее цифровых технологий?;Data mining применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Data mining применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;5
Основные инструменты аналитики больших данных;Hadoop, Spark, NoSQL БД, облачные платформы. Hadoop для хранения, Spark для обработки, NoSQL для неструктурированных данных;Экосистема Hadoop обеспечивает распределенное хранение (HDFS) и обработку (MapReduce). Spark предоставляет быструю обработку в памяти. NoSQL базы (MongoDB, Cassandra) работают с неструктурированными данными. Облачные платформы (AWS, GCP) масштабируют ресурсы;5
Какие этапы включает проект, основанный на использовании модели прогнозирования?;Модели прогнозирования помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Используется для прогнозов и анализа информации.;3
Для чего нужны гипотезы в анализе данных;Гипотезы позволяют формулировать проверяемые утверждения и проводить статистическую проверку научных предположений;Гипотезы используются для проверки утверждений;4
В каких областях деятельности используются большие данные, привести примеры.;Большие данные применяются в маркетинге, финансах, медицине, промышленности, транспорте и государственном управлении. Примеры: прогнозирование спроса, анализ поведения клиентов, медицинская диагностика, предиктивное обслуживание оборудования.;Большие данные применяется в маркетинге, финансах, здравоохранении, промышленности и транспорте, например для анализа клиентов и предсказания поломок.;5
Закономерности динамики сложных сетей;Предпочтительное присоединение, рост по степенному закону, small-world эффект, кластеризация;Закономерности развития сложных сетей;4
Характерные черты безмасштабных сетей;Безмасштабные сети имеют степенное распределение степеней узлов, содержат хабы и демонстрируют устойчивость к случайным отказам но уязвимы к целевым атакам;Степенное распределение P(k) ? k^(-?) с 2<?<3, наличие highly connected hubs, robustness to random failures но fragility to targeted attacks, small-world property;4
С какими проблемами сталкиваются при применении предиктивная аналитика, и как их решают?;Предиктивная аналитика используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;5
Достоинства и недостатки деревьев решений;"Достоинства: интерпретируемость, не требуют нормализации; недостатки: склонность к переобучению, нестабильность";Интерпретируемость vs переобучение;3
Как специалисты анализируют данные в рамках распределённые вычисления?;Технологии распределённые вычисления позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Распределённые вычисления используется для обработки информации и улучшения решений.;3
Что такое eventual consistency и в каких Big Data системах она используется?;Eventual consistency - модель согласованности, где обновления eventually распространяются на все узлы, но не гарантируется немедленная консистентность. Используется в Cassandra, DynamoDB, где доступность важнее строгой консистентности.;Согласованность которая достигается со временем. Используется в системах где не нужна мгновенная консистентность данных.;3
Структуры и типы данных в R;Основные структуры включают векторы, матрицы, списки, фреймы данных и факторы для различных типов данных;В R используются различные структуры для данных;4
Как внедрение предиктивная аналитика влияет на процессы в организациях?;Предиктивная аналитика применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;4
Как развивается направление in-memory обработка в последние годы?;In-memory обработка используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;In-memory обработка используется для обработки информации и улучшения решений.;3
Фундаментальное свойство статистического обучения;Фундаментальным свойством является компромисс между смещением и дисперсией (bias-variance tradeoff), который определяет способность модели к обобщению на новых данных;Компромисс между точностью и обобщающей способностью;3
Как рекомендательные системы применяется для автоматизации рутинных процессов?;Рекомендательные системы помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;4
Преимущества и недостатки непараметрических моделей;Непараметрические модели гибки и не требуют предположений о распределении данных, но могут требовать больших объемов данных и вычислительных ресурсов;"Преимущества: гибкость, способность улавливать сложные паттерны; недостатки: потребность в больших данных, медленная работа, сложность интерпретации";4
Меры качества для языковых моделей;Основные метрики включают перплексию для оценки модели, BLEU для перевода и ROUGE для суммаризации текстов;Perplexity, BLEU и ROUGE метрики;3
Как развитие рекомендательные системы влияет на будущее цифровых технологий?;Рекомендательные системы помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Рекомендательные системы применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;5
Какие проблемы возникают при использовании хранилища данных?;Хранилища данных используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Хранилища данных почти нигде не применяется. Это просто большие таблицы.;2
Что такое Data Mining и какие задачи он решает?;Data Mining — это процесс извлечения полезных знаний из больших массивов данных с использованием статистических, математических и машинных методов. Применяется для прогнозирования, классификации, кластеризации и выявления аномалий.;Data Mining — это анализ данных, чтобы найти зависимости и закономерности.;4
Что такое пайплайны, бенчмарки и SOTA, как и для чего используются?;Пайплайны автоматизируют процессы обработки данных, бенчмарки устанавливают эталоны сравнения, SOTA (State-of-the-Art) представляет передовые методы в области;Пайплайны автоматизируют процессы, бенчмарки устанавливают эталоны, SOTA представляет передовые методы;5
Что такое learning rate в градиентном спуске?;Гиперпараметр, определяющий размер шага на каждой итерации градиентного спуска. Слишком высокий learning rate может привести к расходимости, слишком низкий - к медленной сходимости или застреванию в локальных минимумах.;Параметр скорости обучения модели. Влияет на то как быстро модель сходится к решению. Важно выбирать правильное значение.;4
Что такое data pipeline?;Автоматизированный процесс перемещения и преобразования данных от источника до потребителя.;Способ переноса данных между разными системами.;2
Что такое Apache Spark и в чем его преимущества перед Hadoop?;Распределенный фреймворк для обработки данных с in-memory вычислениями. Преимущества: выше скорость за счет работы в памяти, богатый API, поддержка streaming и ML.;Современная система для больших данных. Быстрее чем Hadoop благодаря оптимизации использования памяти.;3
Какие основные инструменты и технологии используются для работы с большие данные?;Большие данные применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Большие данные — это что-то про компьютеры. Применяется редко.;2
Основные метрики больших графов;Диаметр, плотность, кластеризация, центральность - ключевые метрики сетевого анализа;Диаметр, плотность, кластеризация, различные меры центральности;4
Для чего нужны партиции в Kafka;Партиции позволяют масштабировать обработку сообщений параллельно, распределяя нагрузку между несколькими потребителями. Каждая партиция гарантирует порядок сообщений.;Чтобы обрабатывать сообщения параллельно.;2
Какие проблемы возникают при использовании data lakes?;Data lakes используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Технологии data lakes позволяют компаниям обрабатывать большие объёмы разнородных данных, выявлять сложные закономерности и принимать обоснованные решения.;5
Что такое MongoDB?;Документо-ориентированная NoSQL база данных с гибкой JSON-подобной схемой документов.;NoSQL БД которая хранит данные в виде документов BSON. Гибкая схема, горизонтальное масштабирование и мощный язык запросов. Популярна для веб-приложений.;5
Какие риски связаны с использованием компьютерное зрение в критически важных системах?;Компьютерное зрение помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Компьютерное зрение применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;4
Почему технологии big data стали критически важны?;Big data помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Технологии big data позволяют компаниям обрабатывать большие объёмы разнородных данных, выявлять сложные закономерности и принимать обоснованные решения.;5
Что такое 4V в Big Data и объясните каждую характеристику?;Volume (объем данных), Velocity (скорость генерации и обработки), Variety (разнообразие форматов), Veracity (достоверность и качество данных). Эти характеристики определяют сложности работы с большими данными.;Четыре характеристики больших данных: объем, скорость, разнообразие и достоверность.;3
Что такое Data Lake и чем он отличается от Data Warehouse?;Data Lake — это хранилище, в котором данные сохраняются в исходном, неструктурированном виде. В отличие от Data Warehouse, где данные предварительно обрабатываются и структурируются, Data Lake предназначен для гибкого анализа и машинного обучения.;Data Lake — это просто место для хранения всех данных без структуры, в отличие от Data Warehouse, где всё организовано.;2
Критерии качества кластеризации;К критериям качества относятся Silhouette score, Davies-Bouldin index и Calinski-Harabasz index;Метрики для оценки кластеризации;4
Что такое dropout в нейросетях?;Метод регуляризации, при котором случайно выбранные нейроны игнорируются во время обучения для предотвращения переобучения.;Метод когда часть нейронов отключается во время тренировки. Борется с переобучением.;3
Какие риски связаны с применением предобработка данных?;Технологии предобработка данных позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Предобработка данных используется для обработки информации и улучшения решений.;3
Принцип массивных вычислений в R;Векторизованные операции позволяют эффективно обрабатывать большие массивы данных без использования циклов, используя оптимизированные низкоуровневые функции;Применение операций ко всем элементам вектора или матрицы одновременно через встроенные функции;3
Что такое feature engineering и какие методы он включает?;Создание и преобразование признаков для улучшения качества ML моделей: кодирование категориальных переменных, масштабирование, создание полиномиальных признаков, извлечение признаков из дат и текстов.;Процесс создания и преобразования переменных для машинного обучения из исходных данных.;3
Как работает технология Data Virtualization и какие проблемы она решает?;Предоставляет unified view данных без физического перемещения. Решает проблемы data silos, уменьшает latency доступа, упрощает data governance в распределенных системах.;Виртуальное объединение данных из разных систем без физической интеграции. Решает проблемы разрозненных данных и сложности доступа к множеству источников.;4
Принцип массивных вычислений в R;Векторизованные операции над целыми массивами данных вместо поэлементной обработки в циклах;Принцип массивных вычислений это векторизованные операции;5
Стандартизация и нормализация переменных: зачем нужны?;Стандартизация и нормализация обеспечивают сопоставимость признаков, улучшают сходимость алгоритмов и повышают точность моделей машинного обучения;Для улучшения работы алгоритмов ML;4
Принципы и инструменты аналитики. Задачи и компетенции аналитиков Big Data;Принципы включают data-driven подход, итеративность, автоматизацию. Инструменты: Hadoop, Spark, NoSQL. Задачи: анализ паттернов, прогнозирование. Компетенции: статистика, программирование, доменные знания;Принципы включают data-driven подход, инструменты Hadoop и Spark;5
Как работает механизм Adaptive Query Execution в Spark 3.0 и какие проблемы он решает?;AQE динамически переоптимизирует план запроса во время выполнения на основе реальной статистики данных. Решает проблемы ошибочных оценок размера данных, неоптимальных join стратегий и партиционирования.;Механизм в Spark 3 для улучшения производительности запросов через динамическую оптимизацию на основе реальных данных during выполнения.;3
Какие риски связаны с использованием нейронные сети в критически важных системах?;Нейронные сети применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;5
Что такое топик в Kafka;Топик — это логический канал или категория, в которую производители публикуют сообщения и из которой потребители читают сообщения. Сообщения в топике упорядочены.;Топик представляет собой именованный канал сообщений, который делится на партиции для обеспечения масштабируемости и параллельной обработки. Сообщения в пределах одной партиции сохраняют порядок следования.;3
Какие типы машинного обучения существуют?;Существует три типа машинного обучения: с учителем, без учителя и с подкреплением. Первый использует размеченные данные, второй — неразмеченные, третий — обучение через взаимодействие с средой.;Типы машинного обучения: с учителем, без учителя и с подкреплением.;5
Как in-memory обработка применяется в современных компаниях?;Технологии in-memory обработка позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;In-memory обработка обеспечивает анализ потоковых данных, улучшает прогнозирование, помогает автоматизировать процессы и повышает точность аналитических моделей.;5
Что такое Hadoop и каковы его основные компоненты?;Hadoop — это фреймворк для распределенной обработки больших данных. Основные компоненты: HDFS (файловая система), YARN (планировщик ресурсов), MapReduce (модель вычислений).;Hadoop — это сервер для хранения информации.;2
Какие методы балансировки классов в несбалансированных данных?;Для балансировки классов используются oversampling (SMOTE), undersampling, взвешивание классов и генеративные модели для создания синтетических примеров;SMOTE, undersampling и другие методы балансировки;4
Что понимается под 'стандартизацией данных'?;Стандартизация — это преобразование признаков таким образом, чтобы их среднее значение было равно нулю, а стандартное отклонение — единице.;Стандартизация — это метод, при котором данные центрируются и нормируются относительно стандартного отклонения.;5
Что такое confusion matrix?;Таблица для оценки классификации, показывает true/false positive/negative предсказания модели.;Это таблица, которая показывает сколько правильных и неправильных предсказаний сделала модель для каждого класса, на основе чего считаются точность, полнота и другие метрики.;4
В каких пропорциях рекомендуют разделять данные перед обучением и на какие части?;Обычно данные делятся на три части: обучающую 70%, валидационную 15% и тестовую 15%. Это обеспечивает корректную оценку модели без переобучения.;Разделение данных не требуется, модель обучается на всех данных сразу.;2
Какие типы нейронных сетей используются в компьютерном зрении?;В компьютерном зрении применяются сверточные нейронные сети (CNN), автокодировщики, R-CNN для детекции объектов и U-Net для сегментации изображений;Нейросети для работы с изображениями;2
Меры качества для языковых моделей;Perplexity, BLEU, ROUGE - основные метрики оценки качества языковых моделей и переводов;Метрики для оценки текстовых моделей;2
Что такое SHAP values?;Метод объяснения предсказаний ML моделей на основе теории игр, показывающий вклад каждого признака.;Способ понять вклад признаков в предсказание модели. Помогает объяснить решения алгоритма.;3
Процесс познания (от гипотезы к функции);Процесс включает формулировку гипотезы, сбор и подготовку данных, построение модели, валидацию результатов и создание прогнозной функции для практического применения;От гипотезы через анализ данных к созданию функции;4
Как специалисты анализируют данные в рамках системы логирования?;Технологии системы логирования позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Системы логирования нужно только программистам, обычным компаниям оно бесполезно.;2
Какие риски связаны с применением хранилища данных?;Хранилища данных используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Хранилища данных обеспечивает анализ потоковых данных, улучшает прогнозирование, помогает автоматизировать процессы и повышает точность аналитических моделей.;5
Как принято формулировать нулевую гипотезу;Утверждение об отсутствии статистически значимых различий или эффектов в исследуемых данных;Предположение об отсутствии различий между группами;3
Что такое data locality в Hadoop?;Принцип обработки данных на том же узле где они хранятся для уменьшения сетевого трафика;Обработка данных на месте их хранения;3
Какие структуры данных используются в R и их примеры?;"Вектор (c(1,2,3)), матрица (matrix(1:6, nrow=2)), список (list(1, ""a"", TRUE)), data frame (data.frame(x=1:3, y=c(""a"",""b"",""c""))), фактор (factor(c(""A"",""B"",""A""))).";Вектор - одномерный массив, матрица - двумерный, список - разнотипные элементы, data frame - таблица с данными, фактор - категориальные переменные. Примеры: c(1,2,3), matrix(1:4,2,2).;5
Способы графического представления данных;Гистограммы, диаграммы рассеяния, box plots, линейные графики. Выбор зависит от типа данных и цели;Графики и диаграммы для визуализации;2
Виды неопределённости в анализе данных;Источники неопределенности включают ошибки измерений, sampling variability, model uncertainty и epistemic uncertainty due to limited knowledge;Случайные ошибки измерений, систематические смещения, неопределенность из-за ограниченной выборки;3
Что такое нейронная сеть и где она применяется?;Нейронная сеть — это вычислительная модель, имитирующая работу нейронов мозга, применяемая для распознавания образов, прогнозирования и обработки естественного языка.;Нейронная сеть — математическая модель, основанная на соединениях искусственных нейронов, применяется в задачах классификации, распознавания речи, изображений, машинного перевода и анализа данных.;5
Какие проблемы возникают при использовании предобработка данных?;Технологии предобработка данных позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Предобработка данных используется бизнесом для оптимизации процессов, анализа клиентов и прогнозирования.;4
Что такое метод главных компонент (PCA)?;Метод снижения размерности данных через проецирование на ортогональные компоненты с максимальной дисперсией.;PCA преобразует признаки в новые ортогональные компоненты, упорядоченные по убыванию дисперсии, что позволяет сократить размерность данных с минимальной потерей информации.;5
Как организовать мониторинг качества данных в реальном времени?;Потоковая проверка метрик качества (completeness, accuracy, consistency), автоматические алерты при отклонениях, dashboard для визуализации, интеграция с data lineage для отслеживания проблем.;Система отслеживания качества данных в реальном времени.;2
Что такое точность (accuracy) в машинном обучении?;Точность — это метрика, определяющая долю правильных предсказаний от общего числа наблюдений: Accuracy = (TP + TN) / (TP + TN + FP + FN).;Это показатель, сколько раз модель предсказала верно.;3
Как хранилища данных применяется в современных компаниях?;Технологии хранилища данных позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Хранилища данных широко применяется в промышленности, здравоохранении, финансах и государственных системах. Позволяет анализировать большие массивы данных, строить точные модели и улучшать эффективность процессов.;5
Метрики качества для моделей регрессии;Для оценки регрессионных моделей применяются RMSE, MAE, MAPE и коэффициент детерминации R?;Метрики оценки включают RMSE, MAE и R?;3
Как принято формулировать нулевую гипотезу;Нулевая гипотеза формулируется как утверждение об отсутствии статистически значимого эффекта или различий;Нулевая гипотеза формулируется как утверждение об отсутствии статистических различий;5
С какими проблемами сталкиваются при применении глубокое обучение, и как их решают?;Глубокое обучение помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Глубокое обучение — это что-то про компьютеры. Применяется редко.;2
Что такое data drift?;Изменение распределения входных данных со временем, ухудшающее качество модели.;Явление, при котором распределение данных в продакшене отклоняется от распределения данных, на которых обучалась модель, что снижает ее точность и требует детектирования и адаптации.;4
Что такое Vector Database и для каких задач она оптимальна?;Специализированная БД для хранения и поиска векторных эмбеддингов. Оптимальна для semantic search, рекомендательных систем, similarity search в больших наборах данных.;Специальная база для хранения векторов и поиска похожих элементов. Для задач где нужно находить схожие объекты по векторным представлениям.;3
Что такое Data Lake и в чем его преимущества перед Data Warehouse?;Data Lake — это хранилище, где данные сохраняются в исходном виде. Преимущества: гибкость, возможность работы с сырыми и разнородными данными, масштабируемость. Data Warehouse хранит структурированные данные.;Data Lake — хранилище необработанных данных, более гибкое, чем классический склад данных.;4
Метрики качества для компьютерного зрения;"Accuracy, Precision, Recall, F1-score для классификации; mAP, IoU для детекции; Dice coefficient для сегментации";Accuracy, mAP, IoU для компьютерного зрения;3
Примеры задач с большими графами;Большие графы используются в социальных сетях для анализа сообществ, в рекомендательных системах и биоинформатике для изучения белковых взаимодействий;Социальные сети, рекомендательные системы и научные исследования с графами;5
Какие риски связаны с применением in-memory обработка?;In-memory обработка используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;In-memory обработка используется бизнесом для оптимизации процессов, анализа клиентов и прогнозирования.;4
Какие риски связаны с использованием машинное обучение в критически важных системах?;Машинное обучение помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;4
Как развитие классификация данных влияет на будущее цифровых технологий?;Классификация данных применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Используется для прогнозов и анализа информации.;3
Перечислить типы языка R, привести примеры.;Основные типы данных R: numeric (числовой, пример 3.14), integer (целый, пример 10L), character (строка, пример 'data'), logical (логический, пример TRUE), complex (комплексное число, пример 2+3i).;Типы данных: numeric, integer, character, logical, complex. Например, 10L, 'abc', TRUE.;4
Структуры и типы данных в R;Основные структуры данных в R включают векторы для атомарных данных, матрицы для двумерных массивов, списки для разнотипных коллекций, фреймы данных для таблиц и факторы для категориальных переменных;Основные структуры данных в R включают векторы, матрицы, списки, фреймы данных и факторы;5
Какие методы использовать для обработки данных с высокой cardinality в feature engineering?;Target encoding, hashing trick, frequency encoding, embedding learning, categorical embedding с нейросетями, grouping редких категорий.;Обработка признаков с высокой cardinality.;2
Какие основные инструменты и технологии используются для работы с классификация данных?;Классификация данных используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Классификация данных применяется в бизнесе и иногда в науке для анализа данных.;3
Что такое Apache Iceberg;Apache Iceberg — это open-source table format для аналитических datasets, обеспечивающий ACID семантику, hidden partitioning и schema evolution поверх cloud object stores.;Высокопроизводительный табличный формат с транзакциями и hidden partitioning;5
Как развивается направление предобработка данных в последние годы?;Предобработка данных используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Эти технологии помогают работать с информацией и делать прогнозы.;3
Мотивация происхождения NoSQL.;NoSQL возник как ответ на ограниченность реляционных баз в масштабируемости и гибкости. Цель — работа с неструктурированными и распределёнными данными, высокая производительность и горизонтальное масштабирование.;NoSQL появился для работы с большими объёмами данных, требующими масштабируемости и гибкости хранения.;5
Что такое Data Warehouse;Data Warehouse — это централизованное хранилище интегрированных данных из различных источников, оптимизированное для аналитики и отчетности.;Интегрированное хранилище с очищенными данными для аналитических workloads;5
Что такое data locality в Hadoop?;Принцип обработки данных на том же узле где они хранятся для уменьшения сетевого трафика;Выполнение вычислений рядом с данными для минимизации передачи данных по сети;4
Стандарты жизненного цикла Big Data: CRISP?DM;CRISP-DM представляет собой стандартизированный процесс, включающий 6 этапов: бизнес-понимание, понимание данных, подготовка данных, моделирование, оценка и внедрение;CRISP-DM включает этапы от бизнес-понимания до внедрения моделей;4
Какие алгоритмы машинного обучения относятся к обучению с учителем?;Линейная регрессия, логистическая регрессия, SVM, деревья решений, случайный лес, градиентный бустинг, k-NN, нейронные сети. Все используют размеченные данные для обучения.;Алгоритмы использующие размеченные данные для обучения.;2
Что такое confusion matrix?;Таблица для оценки классификации, показывает true/false positive/negative предсказания модели.;Это метод для проверки точности алгоритма машинного обучения.;2
Какие показатели характеризуют качество данных?;Полнота, точность, непротиворечивость, актуальность, достоверность, уникальность, целостность, своевременность.;Completeness, accuracy, consistency, timeliness, validity, uniqueness, integrity. Данные должны быть полными, точными, непротиворечивыми и актуальными.;5
Что такое статистическое обучение;Статистическое обучение объединяет методы статистики и машинного обучения для построения прогнозных моделей;Статистическое обучение объединяет методы статистики для построения моделей;5
Назовите критерии качества кластеризации и поясните их значение и когда они используются.;Критерии качества: внутрикластерная дисперсия (SSW), межкластерная дисперсия (SSB), индекс силуэта, индекс Дэвиса-Болдина, индекс Калински-Харабаса. Применяются для оценки плотности и разделимости кластеров.;Критерии включают индекс силуэта и дисперсию между и внутри кластеров. Используются для оценки точности кластеризации.;5
Что такое Apache Hadoop?;Фреймворк для распределенной обработки больших данных, состоящий из HDFS (распределенная файловая система) и MapReduce (модель программирования).;Это технология для работы с данными, которую используют крупные компании.;2
Что такое уровень значимости;Уровень значимости ? представляет собой вероятность совершить ошибку первого рода, то есть отвергнуть верную нулевую гипотезу в статистическом тестировании, обычно устанавливается на уровне 0.05 или 0.01;Уровень значимости это статистический параметр, определяющий вероятность ошибки при тестировании гипотез;5
Где применяется data mining в промышленности и бизнесе?;Data mining используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;4
Какие признаки создавать для временных рядов при feature engineering?;Лаги, скользящие статистики (mean, std), временные характеристики (час, день недели), фичи из Fourier transform, difference.;Прошлые значения, средние за окно, время суток и день недели. Сезонные компоненты и тренды.;3
Какие инструменты используются для работы с мониторинг больших данных?;Мониторинг больших данных используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Технологии мониторинг больших данных позволяют компаниям обрабатывать большие объёмы разнородных данных, выявлять сложные закономерности и принимать обоснованные решения.;5
Наивный байесовский алгоритм;Наивный байесовский классификатор основан на теореме Байеса и предполагает условную независимость признаков при заданном классе для упрощения вычислений апостериорных вероятностей;Простой вероятностный классификатор, использующий теорему Байеса для предсказаний;2
Каковы условия остановки ветвления дерева?;Остановка при достижении максимальной глубины, минимального числа samples в узле, отсутствии улучшения качества или pure node;Максимальная глубина и минимальные samples;3
Фундаментальное свойство статистического обучения;Фундаментальным свойством является компромисс между смещением и дисперсией (bias-variance tradeoff), который определяет способность модели к обобщению на новых данных;Баланс в машинном обучении;2
Векторы, матрицы, фреймы и факторы в R;Векторы - атомарные данные, матрицы - 2D массивы, фреймы - таблицы, факторы - категориальные переменные;Типы данных в языке R;4
Какие инструменты используются для работы с ETL-пайплайны?;Etl-пайплайны помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Это что?то связанное с данными, но используется редко.;2
Какие реальные примеры использования масштабируемые системы существуют?;Технологии масштабируемые системы позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Масштабируемые системы используется для обработки информации и улучшения решений.;3
Какие навыки необходимы специалисту для работы с машинное обучение?;Машинное обучение помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;5
Что такое Adam optimizer?;Алгоритм оптимизации для градиентного спуска, сочетающий преимущества RMSProp и Momentum с адаптивным learning rate.;Алгоритм оптимизации для нейронных сетей. Хорошо работает для разных задач.;3
Какие навыки необходимы специалисту для работы с NLP?;Nlp помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Nlp применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;4
Что такое 'функция активации' в нейросети?;Функция активации определяет, будет ли нейрон активирован, и вносит нелинейность в модель.;Функция активации добавляет нелинейность в работу нейрона, позволяя модели решать сложные задачи.;5
«Меры изменчивости»: что к ним относится?;Дисперсия, стандартное отклонение, размах, межквартильный размах, среднее абсолютное отклонение;Показатели разброса;2
Примеры задач с большими графами;Большие графы используются в социальных сетях, рекомендательных системах и биоинформатике для анализа связей;Большие графы используются в социальных сетях и рекомендательных системах;5
Почему технологии хранилища данных стали критически важны?;Технологии хранилища данных позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Хранилища данных применяется в финансах, медицине, рекламе и IT, помогает анализировать данные и строить модели.;4
Что такое гиперпараметры модели?;Гиперпараметры — это параметры, значения которых задаются до обучения модели и влияют на её архитектуру и процесс обучения, например скорость обучения или количество слоёв.;Это параметры модели.;3
Какие инструменты используются для работы с кластеризация данных?;Кластеризация данных используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Кластеризация данных нужно только программистам, обычным компаниям оно бесполезно.;2
Как организовать data quality checks в ETL процессах?;Automated validation rules, data profiling, constraint checking, statistical tests, anomaly detection, alerting on quality issues.;Автоматические правила валидации, профилирование данных, проверка ограничений. Статистические тесты и алертинг при проблемах качества.;5
Какие подходы использовать для оптимизации запросов в колоночных базах данных?;Predicate pushdown, column pruning, использование статистик для планирования запросов, оптимизация формата хранения, сжатие данных, правильное партиционирование.;Способы сделать запросы быстрее в колоночных базах.;2
Что такое exactly-once semantics в stream processing?;Гарантия что каждое сообщение будет обработано ровно один раз без дублирования или потерь;Гарантия однократной обработки каждого сообщения в потоковых системах;4
Что означает термин 'оверфиттинг'?;Оверфиттинг — это ситуация, когда модель слишком точно подстраивается под обучающие данные, теряя способность обобщать.;Это когда модель делает ошибки из-за переобучения.;2
Критерии качества кластеризации;Метрики оценки кластеризации включают Silhouette score, Davies-Bouldin index и Calinski-Harabasz index для измерения компактности и разделимости кластеров;Показатели для оценки того насколько хорошо работает кластеризация;2
Какие методы использовать для обнаружения аномалий в многомерных временных рядах?;Многомерные статистические методы (Mahalanobis distance), матричные профили, нейросетевые подходы (LSTM autoencoders), изолирующие леса, анализ главных компонент с reconstruction error.;Специальные алгоритмы для многомерных временных данных, сочетающие анализ корреляций и временных паттернов.;3
Что такое регрессионный анализ, какие задачи DM можно проводить с его помощью?;Регрессионный анализ — метод моделирования зависимости переменной Y от одной или нескольких переменных X. Применяется для прогнозирования, оценки влияния факторов и аппроксимации зависимостей.;Регрессионный анализ — статистический метод, позволяющий построить модель зависимости целевой переменной от признаков. Применяется для прогнозирования и анализа влияния факторов.;4
Какие риски связаны с применением предобработка данных?;Технологии предобработка данных позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Технологии позволяют улучшать качество аналитики, находить закономерности и предсказывать события.;4
Меры изменчивости;Дисперсия, стандартное отклонение, размах, межквартильный размах - показатели разброса данных;Дисперсия, стандартное отклонение, размах и межквартильный размах являются мерами изменчивости;5
Что такое YARN?;Компонент Hadoop для управления ресурсами кластера и планирования задач. Отделяет функции управления от модели обработки данных.;Компонент Hadoop для управления ресурсами. Планирует выполнение задач в кластере.;3
Что такое data serialization в Big Data?;Преобразование объектов в формат для передачи по сети или хранения;Преобразование данных в формат для передачи между системами;4
Нормальное распределение;Нормальное распределение характеризуется симметричной колоколообразной формой и определенными параметрами центра и dispersion;Распределение с симметричной формой;4
Примеры задач с большими графами;Большие графы используются в социальных сетях для анализа сообществ, в рекомендательных системах и биоинформатике для изучения белковых взаимодействий;Анализ социальных графов (обнаружение сообществ, измерение центральности), рекомендательные системы на графах (Personalized PageRank), биоинформатика (анализ метаболических путей), интернет-поиск (алгоритм PageRank), транспортные сети (кратчайшие пути);5
Векторы, матрицы, фреймы и факторы в R. Сходство и различия, способы обработки.;Векторы и матрицы содержат данные одного типа, data.frame — разных типов, factor используется для категориальных данных. Обработка осуществляется функциями length(), dim(), apply(), summary().;Векторы и матрицы содержат элементы одного типа data.frame допускает разные типы. Factor кодирует категории. Обработка выполняется функциями dim(), apply(), summary().;5
Что такое Data Lake и чем он отличается от Data Warehouse?;Data Lake — это централизованное хранилище, где данные сохраняются в исходном виде. Data Warehouse — структурированное хранилище для анализа. Главное отличие — степень структурированности данных.;Data Lake — это база, где хранятся все данные, Data Warehouse — тоже хранилище, но они разные.;2
Что такое перекрёстная проверка (cross-validation)?;Перекрёстная проверка — это метод оценки обобщающей способности модели, при котором данные делятся на несколько частей, и обучение происходит поочередно на различных подвыборках, а проверка — на оставшихся.;Это проверка модели на разных подвыборках данных.;4
Назовите характеристики качества данных.;К характеристикам качества данных относятся полнота, точность, актуальность, непротиворечивость, целостность и доступность.;Качество данных определяется точностью и полнотой.;3
Какие метрики использовать для оценки несбалансированной бинарной классификации?;Precision, Recall, F1-score, ROC-AUC, PR-AUC. Accuracy не подходит, так как может быть обманчиво высоким при дисбалансе классов.;Не использовать accuracy. Лучше смотреть на F1-score и recall для редкого класса.;3
Что такое статистическая гипотеза;Статистическая гипотеза представляет собой проверяемое предположение о свойствах генеральной совокупности, которое может быть подтверждено или опровергнуто с помощью статистических тестов;Утверждение о параметрах распределения или свойствах данных которое проверяется с использованием статистических критериев;3
Какие подходы использовать для обработки полуструктурированных данных (JSON, XML) в Big Data системах?;Использование форматов с schema evolution (Avro, Parquet), извлечение полей в отдельные колонки, хранение в native формате с индексацией, использование специализированных функций для querying.;Способы работы с JSON и XML данными в больших системах, включая преобразование в структурированный формат и специальные методы запросов.;3
Какие основные инструменты и технологии используются для работы с обработка данных?;Обработка данных используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Используется для прогнозов и анализа информации.;3
Что такое Apache Arrow?;Формат in-memory для колоночного хранения данных с нулевой сериализацией для ускорения анализа.;In-memory формат для эффективной обработки данных. Позволяет системам обмениваться данными без сериализации и ускоряет аналитические операции.;5
В каких областях деятельности используются большие данные, привести примеры;Большие данные используются в финансах (обнаружение мошенничества), ритейле (рекомендательные системы), здравоохранении (персонализированная медицина), транспорте (оптимизация маршрутов) и социальных сетях.;Применение в разных сферах;2
Обучение с учителем и без учителя;"С учителем: классификация и регрессия с размеченными данными; без учителя: кластеризация и анализ без меток";"С учителем: методы с размеченными данными; без учителя: анализ данных без целевых переменных";5
Какие алгоритмы машинного обучения относятся к обучению с учителем?;Линейная регрессия, логистическая регрессия, SVM, деревья решений, случайный лес, градиентный бустинг, k-NN, нейронные сети. Все используют размеченные данные для обучения.;Методы которые учатся на данных с правильными ответами: предсказание и классификация.;3
Какие проблемы возникают при использовании обработка потоковых данных?;Технологии обработка потоковых данных позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Обработка потоковых данных применяется в некоторых компаниях для анализа данных.;3
Как специалисты анализируют данные в рамках системы логирования?;Системы логирования используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Эти технологии помогают работать с информацией и делать прогнозы.;3
Что такое sharding в базах данных?;Горизонтальное разделение данных на основе ключа sharding для распределения нагрузки;Метод горизонтального разделения данных между несколькими серверами для масштабирования;4
Дайте определение социального графа, его типы и свойства. К какому семейству больших графов он относится?;Социальный граф представляет собой сетевую структуру взаимоотношений между людьми или организациями, включает направленные и ненаправленные, взвешенные и невзвешенные типы, обладает свойствами малого мира и кластеризации, относится к семейству масштабно-инвариантных графов;Граф социальных взаимодействий с различными типами связей и характеристиками сетевой структуры;3
Принципы и инструменты аналитики Big Data;Аналитика больших данных основана на принципах распределенной обработки, использования специализированных фреймворков Hadoop и Spark, NoSQL баз данных и облачных технологий;Анализ больших данных требует особых подходов;2
Какие методы используются для снижения размерности данных?;PCA (метод главных компонент), t-SNE, UMAP, autoencoders, feature selection. Уменьшают количество признаков сохраняя важную информацию.;PCA для линейного снижения размерности, t-SNE для визуализации, нейросетевые autoencoders. Упрощают данные без значительной потери информации.;5
Процесс познания (от гипотезы к функции);Процесс включает формулировку гипотезы, сбор и подготовку данных, построение модели, валидацию результатов и создание прогнозной функции для практического применения;Путь от идеи до готового решения;2
Основные метрики больших графов;Ключевые метрики включают диаметр графа, плотность связей, коэффициент кластеризации и различные меры центральности;Показатели для анализа графов;2
Как развитие кластеризация влияет на будущее цифровых технологий?;Кластеризация помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Кластеризация применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;5
Обучение с учителем и без учителя;Обучение с учителем использует размеченные данные, а без учителя обнаруживает скрытые структуры в данных без меток;С учителем есть метки, без учителя нет;3
Как ETL-процессы используется в научных исследованиях?;Etl-процессы используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;4
В чем преимущества применения модели прогнозирования по сравнению с традиционными методами?;Модели прогнозирования помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Это просто работа с таблицами. Не очень полезно.;2
Как понимать «уровень статистической достоверности»?;Это вероятность того, что результат не случаен. Обычно задаётся уровнем значимости ? (например, 0,05), который показывает вероятность ошибки первого рода.;Это вероятность, что результат не случайный, если уровень значимости меньше 0,05, то результат достоверен.;5
Как модели прогнозирования помогает в анализе больших объемов данных?;Модели прогнозирования используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Помогает работать с данными и строить модели.;3
Как big data влияет на эффективность бизнеса?;Big data используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Эти технологии помогают работать с информацией и делать прогнозы.;3
Принципы глубокого обучения в нейросетях;Глубокое обучение использует многослойные нейросети для автоматического извлечения признаков, CNN специализированы для изображений;Глубокие нейросети для обучения;2
Что такое корреляция в анализе данных?;Корреляция — это статистическая мера взаимосвязи между двумя переменными. Она показывает направление и силу связи, выражается коэффициентом r в диапазоне от -1 до +1.;Корреляция отражает зависимость между переменными, но без числовых примеров.;4
Суть алгоритмов связных компонент и покрывающего дерева;Связные компоненты находят группы связанных узлов, покрывающее дерево - минимальный набор рёбер, соединяющий все узлы;Поиск компонент и минимальных деревьев;3
Использование гистограммы для обработки фото;Гистограммы яркости используются для анализа тонального диапазона изображений, коррекции контраста и выполнения операций по улучшению качества;Графики распределения яркости пикселей для анализа изображений;2
Как выбрать между L1 и L2 регуляризацией для линейной модели?;L1 (Lasso) лучше когда нужен отбор признаков и интерпретируемость, L2 (Ridge) когда важна стабильность и все признаки потенциально полезны. L1 обнуляет неважные веса, L2 только уменьшает их.;L1 регуляризация полезна когда нужно автоматически выбрать наиболее важные признаки, особенно при большом количестве фич. L2 лучше когда все признаки могут быть полезны и нужно просто предотвратить переобучение.;5
Какие основные инструменты и технологии используются для работы с NLP?;Nlp помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Используется для прогнозов и анализа информации.;3
Виды столбчатых диаграмм и их интерпретация;Столбчатые диаграммы включают вертикальные, горизонтальные, сгруппированные и составные типы, которые интерпретируются через сравнение высот столбцов для анализа категориальных данных;Столбчатые диаграммы включают вертикальные, горизонтальные и сгруппированные типы для сравнения категориальных данных;5
Какие методы обработки пропущенных значений в данных вы знаете?;Для обработки пропущенных значений используются удаление строк, импутация средним/медианой, предсказание с помощью моделей и интерполяция, выбор метода зависит от природы пропусков и объема данных;Удаление или заполнение пропущенных значений;3
Данные, информация, знания – в чем отличия?;Данные — это необработанные факты и измерения. Информация — это данные, прошедшие интерпретацию. Знания — это результат анализа информации, ведущий к принятию решений. Пример: данные — цифры продаж, информация — динамика продаж, знание — вывод о сезонности спроса.;Данные — это сырые значения, Информация — обработанные данные, Базы знаний — обобщённые закономерности, применяемые для решений.;5
Закономерности динамики сложных сетей;Предпочтительное присоединение, рост по степенному закону, small-world эффект, кластеризация;Закономерности включают preferential attachment и small-world;5
С какими проблемами сталкиваются при применении ETL-процессы, и как их решают?;Etl-процессы используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;4
Как тестируются независимые и парные выборки?;Независимые выборки тестируются с помощью t-теста Стьюдента или U-критерия Манна-Уитни, а парные выборки - с использованием парного t-теста или критерия Вилкоксона;Независимые выборки тестируются t-тестом, парные выборки - парным t-тестом;5
Что такое Data Fabric;Data Fabric — это архитектурный подход, обеспечивающий единый, согласованный слой доступа к данным across разнородных источников через метаданные и семантическую интеграцию.;Единый доступ к разным источникам данных;3
Как развивается направление data lakes в последние годы?;Data lakes помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Эти технологии помогают работать с информацией и делать прогнозы.;3
Меры изменчивости;К мерам изменчивости относятся дисперсия, стандартное отклонение, размах и межквартильный размах;Показатели разброса данных;2
Как data lakes применяется в современных компаниях?;Технологии data lakes позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Эти технологии помогают работать с информацией и делать прогнозы.;3
В чём суть алгоритмов нахождения квадратичной ошибки?;Минимизация суммы квадратов разностей между предсказанными и фактическими значениями для нахождения оптимальных параметров модели;Метод наименьших квадратов;3
Какие риски связаны с применением мониторинг больших данных?;Технологии мониторинг больших данных позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Мониторинг больших данных используется для обработки информации и улучшения решений.;3
Факторы, влияющие на коэффициент корреляции;На корреляцию влияют выбросы, нелинейность связи, гетерогенность данных, размер выборки и наличие скрытых переменных;Выбросы, нелинейность, размер выборки;3
Принципы и инструменты аналитики Big Data;Аналитика больших данных основана на принципах распределенной обработки, использования специализированных фреймворков Hadoop и Spark, NoSQL баз данных и облачных технологий;Для больших данных используют Hadoop и Spark;3
В каких областях деятельности используются большие данные;"привести примеры.,""Большие данные применяются в маркетинге, финансах, медицине, промышленности, транспорте и государственном управлении. Примеры: прогнозирование спроса, анализ поведения клиентов, медицинская диагностика, предиктивное обслуживание оборудования.";Большие данные применяются в бизнесе и науке. Пример — реклама и исследования.;3
Нормальное распределение;Нормальное распределение характеризуется симметричной колоколообразной формой и определенными параметрами центра и dispersion;Колоколообразное распределение;2
Что такое уровень значимости;Уровень значимости ? представляет вероятность совершить ошибку первого рода - отвергнуть верную нулевую гипотезу, обычно устанавливается 0.05;Вероятность ложного обнаружения эффекта когда его на самом деле нет, определяет строгость статистического теста;4
Что такое data serialization в Big Data?;Преобразование объектов в формат для передачи по сети или хранения;Кодирование данных для передачи;3
Где применяется модели прогнозирования в промышленности и бизнесе?;Модели прогнозирования помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Используется для прогнозов и анализа информации.;3
Каковы условия остановки ветвления дерева?;Условия остановки включают достижение максимальной глубины, минимального числа образцов в узле, отсутствие улучшения качества разбиения или достижение чистого узла.;Максимальная глубина и минимальное число samples;3
Что такое data observability?;Способность понимать состояние данных через мониторинг, отслеживание и оповещения;Наблюдение за данными;2
Почему организации переходят на технологии data lakes?;Data lakes используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Это что?то связанное с данными, но используется редко.;2
Что такое Apache ZooKeeper?;Централизованный сервис для поддержания конфигурационной информации, именования, распределенной синхронизации и предоставления групповых сервисов в распределенных системах.;Сервис для координации распределенных систем. Обеспечивает надежное хранение конфигурации, синхронизацию между узлами и выбор лидера в кластере. Используется Kafka, Hadoop и другими системами.;5
Как проектировать систему для обработки данных IoT устройств с высокой частотой обновления?;Использовать потоковые платформы (Kafka, Flink), колоночные форматы хранения, сжатие данных, агрегацию на edge устройствах, мониторинг пропускной способности и задержек.;Архитектура для обработки данных с IoT устройств в реальном времени.;2
Перечислите и поясните с формулами и примерами метрики качества для бинарной классификации.;Основные метрики: Accuracy = (TP + TN) / (TP + FP + TN + FN), Precision = TP / (TP + FP), Recall = TP / (TP + FN), F1 = 2 * (Precision * Recall) / (Precision + Recall).;Есть точность, полнота и F1, они оценивают классификатор.;4
Какие типы нейронных сетей используются в компьютерном зрении?;В компьютерном зрении применяются сверточные нейронные сети (CNN), автокодировщики, R-CNN для детекции объектов и U-Net для сегментации изображений;В компьютерном зрении применяются сверточные нейронные сети;5
Что такое Docker контейнер?;Легковесная изолированная среда для запуска приложений со всеми зависимостями.;Способ упаковки приложений со всеми компонентами для запуска в любой среде.;3
Какие риски связаны с использованием большие данные в критически важных системах?;Большие данные применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;4
Алгоритмы выделения сообществ;Основные алгоритмы для обнаружения сообществ в сложных сетях включают метод Louvain, алгоритм Girvan-Newman и метод распространения меток, которые используют различные подходы к выявлению групп тесно связанных узлов;Методы обнаружения сетевых сообществ используют различные критерии для группировки связанных узлов;4
Почему технологии ETL-пайплайны стали критически важны?;Etl-пайплайны используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Эти технологии помогают работать с информацией и делать прогнозы.;3
Как специалисты анализируют данные в рамках системы логирования?;Технологии системы логирования позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Системы логирования используется бизнесом для оптимизации процессов, анализа клиентов и прогнозирования.;4
Какие риски связаны с использованием ETL-процессы в критически важных системах?;Etl-процессы помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;4
Что такое обучение без учителя и для чего оно используется?;Обучение без учителя применяется, когда нет размеченных данных. Основные задачи: кластеризация и снижение размерности.;Обучение без учителя работает без меток, применяется для кластеризации и снижения размерности.;5
Когда использовать Graph Database вместо реляционной для хранения данных?;Graph DB лучше когда данные имеют сложные связи и запросы ориентированы на отношения (социальные сети, рекомендации, fraud detection). Реляционные - для структурированных данных с простыми связями.;Разные типы баз для разных структур данных.;2
Какие риски связаны с использованием классификация данных в критически важных системах?;Классификация данных применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;5
Что такое data pipeline?;Автоматизированный процесс перемещения и преобразования данных от источника до потребителя.;Последовательность шагов для обработки данных: сбор, очистка, преобразование, загрузка. Автоматизирует поток данных между системами.;5
Когда использовать линейные, а когда нелинейные модели;Линейные - когда связь линейная, нелинейные - для сложных зависимостей. Проверять через визуализацию и тесты;Если данные простые - линейные, если сложные - нелинейные;2
Что такое Apache Airflow?;Платформа для оркестрации и мониторинга рабочих процессов данных.;Инструмент для создания, планирования и мониторинга рабочих процессов и пайплайнов данных с помощью Python скриптов и визуального представления зависимостей задач.;4
Что такое ELT процесс?;Процесс загрузки данных перед их преобразованием в целевой системе.;Современный способ переноса данных между системами.;2
Меры изменчивости;К мерам изменчивости относятся дисперсия, стандартное отклонение, размах и межквартильный размах;Дисперсия и стандартное отклонение для вариативности;3
Как нейронные сети применяется для автоматизации рутинных процессов?;Нейронные сети используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;4
Какие дополнительные V добавляют к расширенной модели Big Data?;Value (ценность данных), Variability (изменчивость), Visualization (визуализация), Validity (валидность данных). Эти характеристики дополняют основные 4V и подчеркивают бизнес-аспекты.;Ценность для бизнеса, изменчивость, визуализация и валидность данных как дополнительные характеристики.;3
Что такое 'функция активации' в нейросети?;Функция активации определяет, будет ли нейрон активирован, и вносит нелинейность в модель.;Функция активации решает, активировать ли нейрон.;2
Что такое большие данные и откуда они поступают?;Большие данные - огромные объемы структурированных и неструктурированных данных, которые невозможно обработать традиционными методами. Источники: соцсети, IoT устройства, транзакционные системы, сенсоры.;Данные большого объема из интернета и различных устройств. Сложны для обработки обычными способами.;3
С какими проблемами сталкиваются при применении анализ данных, и как их решают?;Анализ данных применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Это просто работа с таблицами. Не очень полезно.;2
Что такое MLOps?;Практики CI/CD для развертывания и мониторинга ML моделей в продакшене;DevOps для машинного обучения;3
Примеры использования гистограммы;Гистограммы применяются для анализа распределения яркости в обработке изображений, контроля качества в производстве через анализ распределения параметров продукции;Гистограммы применяются для анализа яркости изображений и контроля качества продукции;5
В чем сходства и различия векторов, матриц, фреймов и факторов в R?;Векторы и матрицы - гомогенные данные, фреймы - гетерогенные по колонкам. Факторы - категориальные с уровнями. Все поддерживают индексацию, но разную обработку.;Векторы/матрицы - один тип данных, фреймы - разные типы в колонках. Факторы - категории с уровнями. Общее: индексация, разные операции. Фреймы похожи на таблицы БД.;5
Что такое 'F1-мера'?;F1-мера — это гармоническое среднее между precision и recall, отражающее баланс между точностью и полнотой.;F1 — это средняя оценка между точностью и полнотой.;4
Примеры задач с большими графами;Большие графы применяются в социальных сетях, рекомендательных системах и биоинформатике для анализа сложных связей;Графы используются в социальных сетях и рекомендательных системах;4
Какие навыки необходимы специалисту для работы с компьютерное зрение?;Компьютерное зрение помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;4
Как работает метод главных компонент (PCA) для снижения размерности?;PCA находит новые ортогональные оси, которые максимизируют дисперсию данных, проецируя их в пространство меньшей размерности с сохранением максимальной информации;Преобразование данных в пространство главных компонент;3
Как мониторинг больших данных применяется в современных компаниях?;Технологии мониторинг больших данных позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Мониторинг больших данных почти нигде не применяется. Это просто большие таблицы.;2
Зачем нужно уменьшение размерностей?;Уменьшение размерностей позволяет избавиться от избыточных признаков, ускорить обучение и избежать переобучения. Методы: PCA, t-SNE, LDA. Формула PCA: var(max(W^T X)).;Уменьшение размерностей — это удаление столбцов из таблицы.;2
Что такое PostgreSQL?;Реляционная СУБД с открытым исходным кодом, поддерживающая расширенные типы данных и SQL стандарты.;Продвинутая open-source реляционная БД. Поддерживает JSON, геопространственные данные, полнотекстовый поиск и имеет богатый набор функций.;5
Какие этапы включает проект, основанный на использовании нейронные сети?;Нейронные сети используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Это просто работа с таблицами. Не очень полезно.;2
Что означает 'precision' в классификации?;Precision — это доля правильно предсказанных положительных примеров среди всех предсказанных как положительные.;Precision показывает точность положительных предсказаний.;4
Что делает алгоритм k-ближайших соседей (kNN)?;"kNN классифицирует объект на основе классов его ближайших соседей в пространстве признаков.,""Это алгоритм";который ищет соседей.;2
Что такое Quantum Machine Learning и какие преимущества оно обещает?;Применение квантовых вычислений для ML алгоритмов. Обещает экспоненциальное ускорение для optimization problems, quantum feature spaces, обработки больших данных.;Использование квантовых компьютеров для ML. Преимущества: ускорение сложных оптимизаций, работа с высокоразмерными пространствами признаков, новые алгоритмы.;5
Какие методы использовать для обработки потоковых данных с изменяющейся схемой?;Schema registry с валидацией, compatible evolution, default значения для новых полей, обработка unknown fields, graceful degradation при несовместимости.;Подходы для работы с изменяющейся структурой данных в потоках.;3
Что такое нейронные сети с резкими связями (ResNet)?;Архитектура CNN с skip-connections для решения проблемы исчезающего градиента в глубоких сетях.;Архитектура сверточных сетей с остаточными блоками, где connections перескакивают через слои. Решает проблему исчезающих градиентов в глубоких сетях.;4
Сколько данных лучше для обучения;Объем данных для обучения должен быть достаточным для репрезентативности, но важнее качество данных и их соответствие решаемой задаче;Необходим баланс между объемом данных и вычислительными ресурсами, учитывая сложность модели;3
Обучение с подкреплением и ансамбли — основные разновидности и принципы;Обучение с подкреплением включает Q-learning и политические градиенты, ансамбли используют бэггинг, бустинг и стэкинг для улучшения предсказательной способности моделей;Обучение с подкреплением использует Q-learning, ансамбли - бэггинг и бустинг;4
Какие этапы включает проект, основанный на использовании нейронные сети?;Нейронные сети используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Используется для прогнозов и анализа информации.;3
Какие проблемы возникают при использовании ETL-пайплайны?;Технологии ETL-пайплайны позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Технологии ETL-пайплайны позволяют компаниям обрабатывать большие объёмы разнородных данных, выявлять сложные закономерности и принимать обоснованные решения.;5
Принципы глубокого обучения в нейросетях;Глубокое обучение использует многослойные нейросети для автоматического извлечения признаков из данных различной природы;Многослойные нейросети для извлечения признаков;2
Как кластеризация используется в научных исследованиях?;Кластеризация используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Кластеризация — это что-то про компьютеры. Применяется редко.;2
Что такое Apache Spark RDD и чем он отличается от DataFrame?;RDD - низкоуровневая распределенная коллекция объектов, DataFrame - распределенная коллекция данных с именованными колонками и оптимизацией через Catalyst.;RDD для низкоуровневых операций, DataFrame для структурированных данных с автоматической оптимизацией.;4
Что такое 'ошибка модели'?;Ошибка модели — это разница между предсказанными и истинными значениями целевой переменной.;Ошибка — это когда модель ломается.;2
С какими проблемами сталкиваются при применении предиктивная аналитика, и как их решают?;Предиктивная аналитика используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Предиктивная аналитика применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;4
Какие гарантии доставки предоставляет Kafka;At most once: сообщения могут быть потеряны. At least once: сообщения могут быть доставлены повторно. Exactly once: каждое сообщение доставляется ровно один раз.;Есть разные уровни гарантий доставки.;2
В чем разница между данными, информацией и знаниями?;Данные - сырые факты, информация - обработанные данные с контекстом, знания - информация + понимание и опыт для принятия решений.;Данные - цифры и факты, информация - структурированные данные со смыслом, знания - информация, используемая для решений и прогнозов.;5
Метрики качества для моделей регрессии;Для оценки регрессионных моделей применяются RMSE, MAE, MAPE и коэффициент детерминации R?;Для оценки регрессионных моделей применяются метрики RMSE, MAE и коэффициент R?;5
Как специалисты анализируют данные в рамках ETL-пайплайны?;Технологии ETL-пайплайны позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Etl-пайплайны используется для обработки информации и улучшения решений.;3
Какие компании активно используют обработка данных и зачем?;Обработка данных применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Это просто работа с таблицами. Не очень полезно.;2
Что такое ансамблевые методы?;Комбинация нескольких моделей для улучшения прогнозной способности и устойчивости.;Использование нескольких алгоритмов вместе чтобы улучшить точность прогнозирования.;3
Виды связи между переменными при корреляции;"Положительная, отрицательная, нелинейная, ложная корреляция; сила связи от -1 до +1";Связи бывают положительные, отрицательные и нелинейные;5
Почему организации переходят на технологии обработка потоковых данных?;Обработка потоковых данных помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Обработка потоковых данных почти нигде не применяется. Это просто большие таблицы.;2
Как внедрение data mining влияет на процессы в организациях?;Data mining применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;5
Что такое Apache Spark и в чем его преимущества перед Hadoop?;Распределенный фреймворк для обработки данных с in-memory вычислениями. Преимущества: выше скорость за счет работы в памяти, богатый API, поддержка streaming и ML.;Система для распределенной обработки данных. Быстрее Hadoop из-за работы в памяти, удобный API, встроенные библиотеки для streaming и машинного обучения.;5
Что такое data locality в Hadoop?;Принцип обработки данных на том же узле где они хранятся для уменьшения сетевого трафика;Обработка данных на том же сервере где они хранятся, чтобы избежать передачи по сети и ускорить обработку;5
Что такое рекомендательные системы и какие задачи оно решает?;Рекомендательные системы применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;5
Векторы, матрицы, фреймы и факторы в R;Векторы - атомарные данные, матрицы - 2D массивы, фреймы - таблицы, факторы - категориальные переменные;Структуры данных в R;2
Что такое lambda architecture и из каких компонентов она состоит?;Архитектура для обработки Big Data, сочетающая batch и stream processing. Состоит из batch layer (обработка всех данных), speed layer (реaltime обработка) и serving layer (объединение результатов).;Сложная архитектура для больших данных с разными типами обработки.;2
Векторы, матрицы, фреймы и факторы в R. Сходство и различия, способы обработки.;Векторы и матрицы содержат данные одного типа, data.frame — разных типов, factor используется для категориальных данных. Обработка осуществляется функциями length(), dim(), apply(), summary().;Векторы — одномерные, матрицы — двумерные, работают схоже.;3
Что такое Zero-shot и Few-shot learning в современных LLM и как они работают?;Способность моделей выполнять задачи без явного обучения (zero-shot) или с немногими примерами (few-shot). Работает через prompting и использование знаний полученных при претренинге.;Возможность моделей решать новые задачи без полного переобучения. Основано на предварительном обучении на огромных объемах текстовых данных.;3
Как специалисты анализируют данные в рамках предобработка данных?;Предобработка данных помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Технологии позволяют улучшать качество аналитики, находить закономерности и предсказывать события.;4
Сколько данных лучше для обучения;Объем данных для обучения должен быть достаточным для репрезентативности, но важнее качество данных и их соответствие решаемой задаче;Объем данных должен быть пропорционален сложности задачи и модели, при этом данные должны быть репрезентативными и качественными;4
Что такое data warehouse?;Централизованное хранилище интегрированных данных из различных источников, оптимизированное для анализа и отчетности, с поддержкой исторических данных и структурированной схемой.;База данных для аналитики и отчетов. Хранит большие объемы информации из разных источников.;3
Что такое schema evolution в Big Data?;Возможность изменения схемы данных без потери совместимости с существующими данными;Обновление структуры данных без проблем;3
Назовите меры центральной тенденции;Среднее арифметическое, медиана и мода - основные меры центра распределения данных;Среднее арифметическое, медиана и мода являются основными мерами центральной тенденции;5
Что такое Adam optimizer?;Алгоритм оптимизации для градиентного спуска, сочетающий преимущества RMSProp и Momentum с адаптивным learning rate.;Популярный оптимизатор для глубокого обучения. Адаптирует learning rate для каждого параметра и использует momentum.;4
Основные компоненты Kafka;Producer: отправляет сообщения. Consumer: читает сообщения. Broker: сервер Kafka. Topic: категория/канал сообщений. Partition: часть топика. ZooKeeper: координация кластера.;Основные компоненты включают продюсеров (отправка данных), консьюмеров (чтение данных), брокеров (узлы хранения), топики (логические каналы), партиции (для параллелизма) и ZooKeeper для управления метаданными.;3
Какие типы машинного обучения существуют?;Существует три типа машинного обучения: с учителем, без учителя и с подкреплением. Первый использует размеченные данные, второй — неразмеченные, третий — обучение через взаимодействие с средой.;Машинное обучение делится на несколько видов.;3
Какие реальные примеры использования in-memory обработка существуют?;In-memory обработка используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;In-memory обработка почти нигде не применяется. Это просто большие таблицы.;2
Что такое 'градиентный спуск'?;Градиентный спуск — это алгоритм оптимизации, который минимизирует функцию потерь, изменяя параметры модели в направлении антиградиента.;Это случайный метод обучения нейросети.;2
Почему технологии масштабируемые системы стали критически важны?;Масштабируемые системы используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Технологии масштабируемые системы позволяют компаниям обрабатывать большие объёмы разнородных данных, выявлять сложные закономерности и принимать обоснованные решения.;5
Какие основные инструменты используются для аналитики больших данных и их сравнение?;Hadoop (HDFS, MapReduce) для хранения и пакетной обработки, Spark для in-memory вычислений, Kafka для потоковой обработки, NoSQL БД для неструктурированных данных. Сравнение по производительности, масштабируемости, use cases.;Популярные системы: Hadoop, Spark, Kafka. У каждой свои преимущества для работы с большими данными.;3
Что такое GraphQL?;Язык запросов для API, позволяющий клиентам запрашивать только нужные данные.;Современный способ работы с веб-сервисами и базами данных.;2
Уровень статистической достоверности;Вероятность того, что результат не случаен. Не вероятность ошибки, а доверие к результату;Статистическая достоверность (p-value) показывает вероятность получения наблюдаемых результатов при условии верности нулевой гипотезы. Не является вероятностью ошибки, а мерой доказательности против нулевой гипотезы;5
Что такое collaborative filtering?;Метод рекомендательных систем, основанный на поведении и предпочтениях пользователей.;Алгоритм рекомендаций, который предсказывает предпочтения пользователя на основе поведения похожих пользователей или оценок похожих товаров.;4
Что такое нормализация данных?;"Нормализация данных — это процесс приведения признаков к единому масштабу для повышения точности и стабильности алгоритмов.,""Нормализация данных используется для приведения признаков к одному масштабу";чтобы улучшить качество обучения.;5
Что такое Data Lake?;Хранилище неструктурированных и полуструктурированных данных в исходном формате.;Data Lake - это централизованное хранилище, позволяющее хранить огромные объемы структурированных, полуструктурированных и неструктурированных данных в их native формате для последующей обработки и анализа.;5
Какие реальные примеры использования ETL-пайплайны существуют?;Etl-пайплайны используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Эти технологии помогают работать с информацией и делать прогнозы.;3
Какие компании активно используют кластеризация и зачем?;Кластеризация помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;5
Что такое grid search?;Метод подбора гиперпараметров через exhaustive search по заранее заданной сетке значений.;Поиск лучших гиперпараметров путем проверки всех возможных комбинаций из заданного набора значений. Оценивает каждую комбинацию через кросс-валидацию.;5
Какие реальные примеры использования обработка потоковых данных существуют?;Обработка потоковых данных помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Технологии обработка потоковых данных позволяют компаниям обрабатывать большие объёмы разнородных данных, выявлять сложные закономерности и принимать обоснованные решения.;5
Основные вызовы больших данных;Основные вызовы включают объем, скорость поступления, разнообразие форматов и достоверность данных;Проблемы работы с большими данными;2
Какие инструменты используются для работы с системы логирования?;Системы логирования помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Системы логирования применяется в некоторых компаниях для анализа данных.;3
Определение термина «большие данные»;Большие данные представляют собой огромные объемы разнородной информации, требующие специальных технологий обработки;Большие объемы данных разных типов;4
Что означает термин 'оверфиттинг'?;Оверфиттинг — это ситуация, когда модель слишком точно подстраивается под обучающие данные, теряя способность обобщать.;Оверфиттинг — это когда модель слишком точная для своих данных.;4
Какие методы обработки естественного языка используются в аналитике больших данных?;В NLP для больших данных применяются word2vec, BERT, TF-IDF, обработка n-грамм и методы тематического моделирования для извлечения смысла из текстовых данных;Методы работы с текстом;2
Какие подходы использовать для оптимизации запросов в колоночных базах данных?;Predicate pushdown, column pruning, использование статистик для планирования запросов, оптимизация формата хранения, сжатие данных, правильное партиционирование.;Predicate pushdown для ранней фильтрации, column pruning для чтения только нужных колонок, использование статистик для оптимизации join'ов, эффективные форматы хранения и сжатия, грамотное партиционирование данных.;5
Разновидности сложных сетей;Однородные, масштабно-инвариантные, малого мира, иерархические, случайные сети;Однородные, безмасштабные, малого мира;3
Какие основные инструменты и технологии используются для работы с компьютерное зрение?;Компьютерное зрение используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Это просто работа с таблицами. Не очень полезно.;2
Какие подходы к детекции аномалий в больших данных?;Методы детекции аномалий включают статистические подходы, методы на основе кластеризации, изолирующие леса и нейросетевые подходы для выявления выбросов;Различные алгоритмы для обнаружения аномальных наблюдений;4
Сколько данных лучше для обучения;Объем данных для обучения моделей машинного обучения должен быть достаточным для обеспечения репрезентативности выборки при обязательном условии обеспечения высокого качества данных и их релевантности решаемой задаче;Для обучения моделей важно иметь достаточный объем качественных и репрезентативных данных для задачи;5
Как бороться с переобучением в глубоких нейронных сетях?;Dropout, batch normalization, early stopping, регуляризация L1/L2, data augmentation, уменьшение сложности сети, увеличение данных.;Использовать dropout слои, batch normalization, L2 регуляризацию, early stopping при валидации. Также помогает augmentation данных и упрощение архитектуры сети если она слишком сложная для задачи.;5
Сравнительный анализ алгоритмов кластеризации;Алгоритмы кластеризации сравниваются по масштабируемости, чувствительности к шуму, способности находить кластеры сложной формы и вычислительной сложности;Сравнение методов по скорости работы и типу находимых кластеров;4
Какие реальные кейсы демонстрируют эффективность обработка данных?;Обработка данных используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;4
Какие вы знаете интегральные метрики качества, привести формулы и примеры.;Интегральные метрики: ROC-AUC (площадь под кривой зависимости TPR от FPR), PR-AUC (площадь под кривой Precision-Recall), LogLoss = -1/N * ?[y*log(p) + (1 - y)*log(1 - p)].;Метрики вроде AUC, они показывают, насколько хороша модель.;3
Почему организации переходят на технологии big data?;Технологии big data позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Big data нужно только программистам, обычным компаниям оно бесполезно.;2
Как организовать систему для ML feature serving в реальном времени?;Feature store с low-latency API, online/offline feature consistency, versioning, monitoring feature quality, scalable serving infrastructure.;Система для быстрой подачи признаков в ML модели с отслеживанием версий и качества.;3
Что такое p-value в статистике?;Вероятность получить наблюдаемые или более экстремальные результаты при условии, что нулевая гипотеза верна.;Это вероятность случайного получения результатов. Если p-value меньше 0.05, то гипотеза отвергается.;4
Факторы, влияющие на коэффициент корреляции;На коэффициент корреляции влияют выбросы, нелинейность связи, размер выборки, гетерогенность данных и наличие скрытых переменных;Факторы, воздействующие на величину корреляции;4
Как развивается направление системы логирования в последние годы?;Системы логирования помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Системы логирования нужно только программистам, обычным компаниям оно бесполезно.;2
Что такое регуляризация в машинном обучении?;Метод предотвращения переобучения путем добавления штрафа за сложность модели к функции потерь.;Это способ сделать модель более правильной и точной.;2
Какие методы использовать для обработки потоковых данных с изменяющейся схемой?;Schema registry с валидацией, compatible evolution, default значения для новых полей, обработка unknown fields, graceful degradation при несовместимости.;Schema registry для управления версиями, backward/forward compatible изменения, default значения, обработка неизвестных полей. Поддерживать совместимость схем.;5
Что такое data partitioning в Big Data?;Разделение данных на меньшие части для распределенной обработки и хранения, что улучшает производительность и управляемость;Разделение данных на части для обработки на разных узлах кластера, ускоряет запросы и упрощает управление;5
Стадии разработки систем ML;Процесс разработки включает сбор данных, предобработку, проектирование признаков, обучение модели, валидацию, развертывание и мониторинг производительности;Сбор и очистка данных, обучение модели, оценка качества, развертывание в production;3
Как внедрение NLP влияет на процессы в организациях?;Nlp помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Nlp применяется в бизнесе и иногда в науке для анализа данных.;3
Как внедрение модели прогнозирования влияет на процессы в организациях?;Модели прогнозирования используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Это просто работа с таблицами. Не очень полезно.;2
Примеры задач с большими графами;Большие графы используются в социальных сетях для анализа сообществ, в рекомендательных системах и биоинформатике для изучения белковых взаимодействий;Анализ социальных сетей (выявление лидеров мнений), рекомендательные системы (коллаборативная фильтрация), транспортные сети (оптимизация маршрутов);3
Нормальное распределение;Нормальное распределение характеризуется симметричной колоколообразной формой и определенными параметрами центра и dispersion;Симметричное распределение вероятностей;3
Как обрабатывать пропущенные значения в данных перед обучением модели?;Зависит от природы пропусков: удаление строк если мало пропусков, импутация средним/медианой для числовых, модой для категориальных, либо использование алгоритмов, поддерживающих пропуски.;Анализировать паттерн пропусков: если MCAR - можно удалить или импутировать, если MAR/MNAR - нужно аккуратно. Для числовых: среднее, медиана, KNN импутация. Для категориальных: мода или отдельная категория. Можно также использовать алгоритмы типа XGBoost которые работают с пропусками.;5
Как модели прогнозирования помогает в анализе больших объемов данных?;Модели прогнозирования используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Модели прогнозирования применяется в бизнесе и иногда в науке для анализа данных.;3
Что такое 'регуляризация' в машинном обучении?;Регуляризация — это метод уменьшения переобучения за счёт добавления штрафов к функции потерь.;Регуляризация уменьшает ошибку.;3
Как работает метод главных компонент (PCA) для снижения размерности?;PCA находит новые ортогональные оси, которые максимизируют дисперсию данных, проецируя их в пространство меньшей размерности с сохранением максимальной информации;PCA находит ортогональные оси, максимизирующие дисперсию данных;5
Что такое уровень значимости;Уровень значимости ? представляет собой вероятность совершить ошибку первого рода, то есть отвергнуть верную нулевую гипотезу в статистическом тестировании, обычно устанавливается на уровне 0.05 или 0.01;Статистический параметр, определяющий границу для принятия решений в проверке гипотез;4
Boxplot и его интерпретация, связь с другими элементами анализа;"Boxplot показывает медиану, квартили, выбросы; связан с описательной статистикой и проверкой распределений";Показывает медиану, квартили, выбросы;3
Что такое 'F1-мера'?;F1-мера — это гармоническое среднее между precision и recall, отражающее баланс между точностью и полнотой.;F1 — это просто оценка точности.;3
Как развивается направление кластеризация данных в последние годы?;Кластеризация данных используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Технологии кластеризация данных позволяют компаниям обрабатывать большие объёмы разнородных данных, выявлять сложные закономерности и принимать обоснованные решения.;5
Что такое Apache Superset?;BI платформа с открытым кодом для визуализации и исследования данных через веб-интерфейс.;Система для построения графиков и отчетов.;2
Сравнительная характеристика R и Python;R - для статистики и визуализации, Python - универсальный с библиотеками для ML;R сложнее, Python проще. В R хорошие графики, в Python лучше ML;3
Что такое глубокое обучение и какие задачи оно решает?;Глубокое обучение применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Глубокое обучение нужно только программистам.;2
Основные метрики больших графов;Ключевые метрики включают диаметр графа, плотность связей, коэффициент кластеризации и различные меры центральности;Для анализа графов используются различные метрики оценки структуры сети;5
Сколько данных лучше взять для обучения: побольше или поменьше?;Зависит от сложности задачи: для сложных моделей нужно больше данных, но важнее качество и репрезентативность;Баланс объема и качества;3
Какие навыки необходимы специалисту для работы с NLP?;Nlp помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Это просто работа с таблицами. Не очень полезно.;2
Интегральные метрики качества;К интегральным метрикам относятся ROC-AUC, Precision-Recall AUC, F1-score и R?, агрегирующие различные аспекты качества;К интегральным метрикам относятся ROC-AUC, F1-score и R?;5
Какие риски связаны с применением предобработка данных?;Технологии предобработка данных позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Технологии позволяют улучшать качество аналитики, находить закономерности и предсказывать события.;4
Характерные черты безмасштабных сетей какова их связь с сетями тесного мира?,;"""Безмасштабные сети имеют степенное распределение степеней вершин (P(k)~k^-?), содержат хабы. Сети тесного мира характеризуются малой длиной пути и высоким коэффициентом кластеризации. Обе модели встречаются в реальных системах.";Безмасштабные сети имеют степенное распределение степеней и наличие хабов сети тесного мира характеризуются высокой кластеризацией и малым средним расстоянием между вершинами.;4
Что такое SMOTE?;Метод синтеза новых примеров для балансировки несбалансированных наборов данных.;Метод увеличения количества примеров редкого класса в наборе данных для улучшения классификации.;3
Что такое MapReduce?;Модель программирования для обработки больших объемов данных в распределенных кластерах, состоящая из этапов Map (фильтрация и сортировка) и Reduce (агрегация результатов).;Способ обработки больших данных в распределенных системах. Состоит из двух этапов - map и reduce.;3
Как работает градиентный бустинг и чем отличается от случайного леса?;Градиентный бустинг последовательно строит деревья, каждое следующее исправляет ошибки предыдущего, тогда как случайный лес строит деревья независимо и усредняет результат;Градиентный бустинг строит деревья последовательно, случайный лес - независимо;5
Что такое Zero-shot и Few-shot learning в современных LLM и как они работают?;Способность моделей выполнять задачи без явного обучения (zero-shot) или с немногими примерами (few-shot). Работает через prompting и использование знаний полученных при претренинге.;Zero-shot - решение задач без примеров, few-shot - с несколькими примерами. Работает через промпты и использование знаний из предварительного обучения на больших данных.;4
Что делает алгоритм k-ближайших соседей (kNN)?;kNN классифицирует объект на основе классов его ближайших соседей в пространстве признаков.;kNN выбирает класс по соседям.;3
Какие компании активно используют большие данные и зачем?;Большие данные помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;4
Виды распределения данных и примеры;Репликация, шардинг, партиционирование. Примеры: Master-Slave, горизонтальное разделение;Репликация (синхронная/асинхронная копия данных), шардинг (горизонтальное разделение по ключу), партиционирование (вертикальное разделение). Примеры: MySQL репликация, Cassandra шардинг, табличное партиционирование;5
Какие методы использовать для оптимизации JOIN операций в распределенных системах?;Broadcast join для маленьких таблиц, sort-merge join для отсортированных данных, hash join для больших таблиц, bucketing для предварительного разделения, использование статистик для выбора стратегии.;Broadcast join когда одна таблица мала, sort-merge join для отсортированных данных, hash join для больших таблиц, bucketing для colocated joins, использование статистик распределения для оптимизации плана выполнения.;5
Какие этапы включает проект, основанный на использовании рекомендательные системы?;Рекомендательные системы применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;5
Процесс познания (от гипотезы к функции);Процесс включает формулировку гипотезы, сбор и подготовку данных, построение модели, валидацию результатов и создание прогнозной функции для практического применения;Процесс включает формулировку гипотезы, сбор данных и построение модели;5
Нормальное распределение;Нормальное распределение характеризуется симметричной колоколообразной формой и определенными параметрами центра и dispersion;Нормальное распределение имеет симметричную колоколообразную форму;5
Какие риски связаны с применением распределённые вычисления?;Технологии распределённые вычисления позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Распределённые вычисления нужно только программистам, обычным компаниям оно бесполезно.;2
В чем преимущества применения модели прогнозирования по сравнению с традиционными методами?;Модели прогнозирования применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Модели прогнозирования нужно только программистам.;2
Закономерности динамики сложных сетей и распространения информации;Сети развиваются по степенным законам, информация распространяется каскадно через влиятельные узлы;"Сети развиваются по принципу ""богатый становится богаче"", распространение информации зависит от сетевой структуры и влиятельных узлов";4
NoSQL. Классификация NoSQL-хранилищ (типы). Их особенности. Примеры распределенных хранилищ.;Типы NoSQL: документо-ориентированные (MongoDB), ключ-значение (Redis), графовые (Neo4j), колонночные (Cassandra). Особенности — отсутствие фиксированной схемы, горизонтальное масштабирование, высокая доступность.;NoSQL включает типы: документо-ориентированные, ключ-значение, графовые, колонночные. Примеры: MongoDB, Redis, Cassandra.;5
Почему технологии обработка потоковых данных стали критически важны?;Обработка потоковых данных используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Обработка потоковых данных широко применяется в промышленности, здравоохранении, финансах и государственных системах. Позволяет анализировать большие массивы данных, строить точные модели и улучшать эффективность процессов.;5
Виды распределения данных и примеры;Основные виды распределений: нормальное (рост людей), равномерное (бросок кости), экспоненциальное (время между событиями), биномиальное (успехи в испытаниях);Типы распределений вероятностей;2
Как развитие кластеризация влияет на будущее цифровых технологий?;Кластеризация используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;4
Какие способы визуализации корреляции изучались в курсе Big Data?;Изучались диаграммы рассеяния, тепловые карты корреляции, матричные графики и параллельные координаты для визуализации взаимосвязей между переменными;Диаграммы рассеяния и тепловые карты корреляции;4
Что такое R-squared?;Статистическая мера, показывающая долю дисперсии зависимой переменной, объясненную моделью.;Метрика качества регрессии от 0 до 1. Показывает насколько хорошо модель объясняет вариацию целевой переменной. 1 - идеальное объяснение.;5
Основные инструменты аналитики больших данных;Hadoop, Spark, NoSQL БД, облачные платформы. Hadoop для хранения, Spark для обработки, NoSQL для неструктурированных данных;Hadoop хранит данные, Spark быстро обрабатывает, NoSQL для больших объемов. У каждого свои задачи;3
Использование гистограммы для обработки фото;Гистограммы яркости широко применяются в обработке изображений для анализа тонального диапазона, коррекции контраста, выполнения операций выравнивания гистограммы и улучшения общего качества визуального контента;Анализ гистограмм помогает в настройке экспозиции, баланса белого и контрастности цифровых изображений;3
Какие инструменты используются для работы с data warehouses?;Data warehouses используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Data warehouses обеспечивает анализ потоковых данных, улучшает прогнозирование, помогает автоматизировать процессы и повышает точность аналитических моделей.;5
Какие реальные кейсы демонстрируют эффективность модели прогнозирования?;Модели прогнозирования используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Используется для прогнозов и анализа информации.;3
Что такое data compression в Big Data?;Уменьшение размера данных для экономии места и ускорения передачи;Уменьшение объема данных через алгоритмы сжатия;4
Какие основные инструменты и технологии используются для работы с кластеризация?;Кластеризация используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;5
Перечислить типы языка R;"""Основные типы данных R: numeric (числовой, пример 3.14), integer (целый, пример 10L), character (строка, пример 'data'), logical (логический, пример TRUE), complex (комплексное число, пример 2+3i).";В R встречаются числовые и строковые типы.;3
Измерение качества модели анализа данных;Качество моделей анализа данных оценивается с помощью метрик accuracy, precision, recall, F1-score для классификации и RMSE, MAE, R? для регрессионных моделей;Для оценки моделей используют accuracy и precision;3
Как развитие кластеризация влияет на будущее цифровых технологий?;Кластеризация помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;5
Какие навыки необходимы специалисту для работы с модели прогнозирования?;Модели прогнозирования помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Модели прогнозирования применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;4
Как организовать data lineage в сложных ETL пайплайнах?;Automated lineage tracking, metadata management, data provenance recording, impact analysis capabilities, integration с orchestration tools, visualization dependencies.;Система отслеживания происхождения и преобразований данных в пайплайнах.;3
Что такое confusion matrix?;Таблица для оценки классификации, показывает true/false positive/negative предсказания модели.;Способ оценки качества классификации через таблицу с правильными и неправильными ответами модели.;3
Какие риски связаны с использованием data mining в критически важных системах?;Data mining используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Data mining применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;5
Какие проблемы возникают при использовании системы логирования?;Системы логирования используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Системы логирования используется бизнесом для оптимизации процессов, анализа клиентов и прогнозирования.;4
Почему технологии мониторинг больших данных стали критически важны?;Мониторинг больших данных используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Технологии мониторинг больших данных позволяют компаниям обрабатывать большие объёмы разнородных данных, выявлять сложные закономерности и принимать обоснованные решения.;5
Что такое data replication в распределенных системах?;Создание копий данных на разных узлах для обеспечения отказоустойчивости и доступности;Хранение копий данных на нескольких серверах для надежности и уменьшения времени доступа;5
Основные вызовы больших данных;Основные вызовы больших данных включают объем (Volume), скорость (Velocity), разнообразие (Variety) и достоверность (Veracity) данных;Основные вызовы включают Volume, Velocity, Variety, Veracity;5
Каков порядок обработки данных при тестировании гипотезы о равенстве;"какие тесты должны быть пройдены, какие требования к данным выдвигаются?,""Проверяется нормальность распределения (Shapiro–Wilk), гомогенность дисперсий (Levene), после чего применяют t-тест для независимых или парных выборок. Требования: независимость наблюдений, интервал/отношение шкалы.";Нужно провести тест.;2
Что такое статистическая гипотеза? Какие виды гипотез вы знаете?;Статистическая гипотеза - это предположение о свойствах генеральной совокупности, проверяемое статистическими методами. Виды: нулевая (об отсутствии эффекта) и альтернативная (о наличии эффекта);Статистическая гипотеза - предположение о свойствах совокупности, виды: нулевая и альтернативная;5
Что такое Apache Cassandra?;Распределенная NoSQL база данных с высокой доступностью и масштабируемостью, использующая модель column-family.;Распределенная база данных для больших нагрузок. Хорошо масштабируется и отказоустойчива.;3
В чем разница между supervised и unsupervised learning?;Supervised learning использует размеченные данные с метками, unsupervised работает с данными без меток.;Это разные подходы к машинному обучению, один сложнее другого.;2
Когда использовать градиентный бустинг вместо случайного леса?;Бустинг когда важна максимальная точность и есть время на тонкую настройку, случайный лес когда нужна robustness и скорость обучения.;Бустинг для сложных задач, Random Forest для простых. Оба хороши но по-разному.;2
Как специалисты анализируют данные в рамках data lakes?;Технологии data lakes позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Data lakes применяется в некоторых компаниях для анализа данных.;3
Что означает термин 'обучение с подкреплением'?;Обучение с подкреплением — это тип обучения, при котором агент взаимодействует со средой, получая вознаграждение за правильные действия.;Это метод, где модель обучается по результатам действий.;4
Меры изменчивости;Дисперсия, стандартное отклонение, размах, межквартильный размах - показатели разброса данных;Показатели разброса значений;2
Какие способы визуализации корреляции изучались в курсе Big Data?;Изучались диаграммы рассеяния, тепловые карты корреляции, матричные графики и параллельные координаты для визуализации взаимосвязей между переменными;Scatter plot, heatmap, matrix plot;3
Что такое convolutional neural network (CNN)?;Архитектура нейросетей для обработки изображений с использованием сверточных слоев.;Нейронная сеть для обработки визуальных данных, которая хорошо распознает образы и объекты на изображениях.;3
Что такое Graph Neural Networks и для каких задач они превосходят традиционные подходы?;Нейросети для графовых данных, учитывающие связи между объектами. Превосходят в задачах с relational структурами: рекомендательные системы, drug discovery, social network analysis.;Специальный тип нейросетей для данных с отношениями и связями. Показывают лучшие результаты в задачах где важна структура графа.;3
Зачем нужно уменьшение размерностей?;Уменьшение размерностей позволяет избавиться от избыточных признаков, ускорить обучение и избежать переобучения. Методы: PCA, t-SNE, LDA. Формула PCA: var(max(W^T X)).;Это нужно, чтобы удалить ненужные данные и не тратить время.;3
Как оптимизировать memory usage в Spark при работе с wide transformations?;Увеличение памяти исполнителей, использование off-heap memory, оптимизация serialization, уменьшение размера данных перед shuffling, использование broadcast variables.;Увеличение памяти executors, off-heap memory, эффективная сериализация. Уменьшение данных перед shuffling и broadcast переменные.;5
Меры качества для языковых моделей;Perplexity, BLEU, ROUGE - основные метрики оценки качества языковых моделей и переводов;Perplexity для языковых моделей, BLEU для перевода, ROUGE для суммаризации;5
Как in-memory обработка применяется в современных компаниях?;Технологии in-memory обработка позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Технологии in-memory обработка позволяют компаниям обрабатывать большие объёмы разнородных данных, выявлять сложные закономерности и принимать обоснованные решения.;5
Факторы, влияющие на коэффициент корреляции;На коэффициент корреляции влияют выбросы, нелинейность связи, размер выборки, гетерогенность данных и наличие скрытых переменных;На коэффициент корреляции влияют выбросы, нелинейность связи и размер выборки;5
Перечислите основные метрики больших графов;Основные метрики больших графов включают диаметр, плотность, коэффициент кластеризации, центральность по степени, посредничеству и близости;Основные метрики включают диаметр, плотность и коэффициенты центральности графов;5
Принципы глубокого обучения в нейросетях;Глубокое обучение использует многослойные нейросети для автоматического извлечения признаков, CNN специализированы для изображений;Многослойные сети извлекают признаки;3
Охарактеризуйте хранилища данных типа OLAP и OLTP. Назовите разницу.;OLTP (Online Transaction Processing) — системы для оперативной обработки транзакций характеризуются высокой скоростью записи и изменениями данных. OLAP (Online Analytical Processing) — системы аналитической обработки, оптимизированные для чтения и агрегации. Разница — в назначении и структуре: OLTP ориентирован на текущее состояние, OLAP — на анализ исторических данных.;OLAP и OLTP — это одно и то же, просто разные названия.;2
В каких сферах применяются большие данные и каковы примеры их использования?;Большие данные используются в медицине (анализ медицинских изображений), ритейле (персонализированные рекомендации), финансах (fraud detection), транспорте (оптимизация маршрутов), IoT (умные города).;В healthcare, e-commerce, banking, transportation. Например, рекомендательные системы и обнаружение аномалий.;4
Когда использовать линейные, а когда нелинейные модели;Линейные - когда связь линейная, нелинейные - для сложных зависимостей. Проверять через визуализацию и тесты;Линейные модели при линейной зависимости между переменными, нелинейные при сложных паттернах. Анализировать остатки и тестировать разные модели;4
Использование гистограммы для обработки фото;Гистограммы яркости используются для анализа тонального диапазона изображений, коррекции контраста и выполнения операций по улучшению качества;Анализ гистограмм помогает в коррекции экспозиции, баланса белого и контрастности изображений;3
В чем преимущества применения NLP по сравнению с традиционными методами?;Nlp помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Nlp применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;4
Почему организации переходят на технологии предобработка данных?;Технологии предобработка данных позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Предобработка данных нужно только программистам, обычным компаниям оно бесполезно.;2
Что такое кросс-валидация и зачем она нужна?;Метод оценки модели путем многократного разбиения данных на тренировочную и тестовую выборки. Нужна для более надежной оценки обобщающей способности и настройки гиперпараметров.;Техника когда данные многократно делятся на train/test для оценки модели. Позволяет получить устойчивую оценку качества и избежать переобучения на одной разбивке.;5
Какие реальные кейсы демонстрируют эффективность глубокое обучение?;Глубокое обучение используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;5
Зачем нужно уменьшение размерностей?;Уменьшение размерностей позволяет снизить вычислительную сложность, устранить мультиколлинеарность и улучшить интерпретируемость моделей;Снижение сложности и улучшение интерпретации;4
Сравнительная характеристика R и Python.;R — это специализированный язык для статистики и визуализации, Python — универсальный язык с библиотеками для анализа данных (NumPy, pandas, scikit-learn). R более мощен для статистических тестов, Python — для интеграции и масштабируемых решений.;R — специализированный язык статистики с библиотеками ggplot2, dplyr  Python — универсальный язык с библиотеками NumPy, pandas, scikit-learn.;5
Обучение с подкреплением и ансамбли;Обучение с подкреплением основано на взаимодействии агента со средой для максимизации награды, а ансамбли объединяют несколько моделей для улучшения прогнозирования;Обучение с подкреплением и ансамбли используют разные принципы;4
Что такое Apache Superset?;BI платформа с открытым кодом для визуализации и исследования данных через веб-интерфейс.;Система бизнес-аналитики с открытым кодом. Визуализация данных, дашборды и анализ через веб-интерфейс.;4
Классификация методов Data Mining;Классификация, кластеризация, регрессия, ассоциативные правила, анализ последовательностей;Классификация (деревья решений, SVM), кластеризация (k-means, иерархическая), регрессия (линейная, логистическая), ассоциативные правила (Apriori), анализ последовательностей (временные ряды, паттерны);5
Что такое Feature Store;Feature Store — это централизованное хранилище для управления, версионирования и обслуживания признаков машинного обучения в production средах.;Хранилище для фичей ML;2
Что такое 'обучение с учителем' в машинном обучении?;Обучение с учителем — это метод, при котором модель обучается на размеченных данных, где каждому входному значению соответствует известный правильный ответ.;Это обучение, где используются размеченные данные, но иногда ответы могут быть частично известны.;4
Как работает механизм shuffle в Spark?;Перераспределение данных между партициями при операциях типа groupBy или join. Включает сортировку, хэширование и сетевую передачу данных между узлами.;Перемещение данных между узлами в кластере Spark.;2
Какие проблемы возникают при использовании кластеризация данных?;Кластеризация данных помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Кластеризация данных используется для обработки информации и улучшения решений.;3
Дайте определение социального графа, его типы и свойства;Социальный граф - сеть взаимоотношений между людьми, включает directed/undirected, weighted/unweighted, обладает small-world property;Социальный граф это сеть взаимоотношений с разными типами;5
Что такое data lake и чем он отличается от data warehouse?;Data lake хранит сырые данные в любом формате, data warehouse - структурированные и обработанные данные по заданной схеме. Data lake для exploration, data warehouse для отчетности.;Data lake для необработанных данных, data warehouse для подготовленных данных. Разные подходы к хранению информации.;3
Стадии разработки систем ML;Процесс разработки включает сбор данных, предобработку, проектирование признаков, обучение модели, валидацию, развертывание и мониторинг производительности;Основные этапы создания систем машинного обучения от сбора данных до внедрения;2
Достоинства и недостатки деревьев решений;Достоинства: интерпретируемость, работа с категориальными признаками, не требуют масштабирования. Недостатки: склонность к переобучению, нестабильность, чувствительность к шуму;Преимущества интерпретируемости и недостатки переобучения;4
Какие проблемы возникают при использовании мониторинг больших данных?;Технологии мониторинг больших данных позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Мониторинг больших данных применяется в финансах, медицине, рекламе и IT, помогает анализировать данные и строить модели.;4
NoSQL. Классификация NoSQL-хранилищ (типы). Их особенности. Примеры распределенных хранилищ.;Типы NoSQL: документо-ориентированные (MongoDB), ключ-значение (Redis), графовые (Neo4j), колонночные (Cassandra). Особенности — отсутствие фиксированной схемы, горизонтальное масштабирование, высокая доступность.;Типы NoSQL — это документо-ориентированные и графовые базы, пример MongoDB.;4
Определение термина «большие данные»;Большие объемы разнородных данных, требующие специальных технологий обработки и хранения;Очень большие наборы данных;2
Что такое MLOps;MLOps — это практика внедрения и поддержки ML моделей в production через автоматизацию, мониторинг и управление жизненным циклом моделей.;Автоматизация развертывания ML моделей;3
В каких областях деятельности используются большие данные, привести примеры;Большие данные используются в финансах (обнаружение мошенничества), ритейле (рекомендательные системы), здравоохранении (персонализированная медицина), транспорте (оптимизация маршрутов) и социальных сетях.;Финансы, ритейл, медицина, транспорт;3
Примеры использования гистограммы;Гистограммы применяются для анализа распределения яркости в обработке изображений, контроля качества в производстве через анализ распределения параметров продукции;"В компьютерном зрении: histogram equalization для улучшения контрастности изображений, анализ тонального диапазона; в производстве: контроль качества через анализ распределения размеров деталей, выявление брака по отклонениям в гистограмме параметров";5
Какие этапы включает проект, основанный на использовании модели прогнозирования?;Модели прогнозирования помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Модели прогнозирования — это что-то про компьютеры. Применяется редко.;2
Что такое пайплайны, бенчмарки и SOTA, как и для чего используются?;Пайплайны автоматизируют процессы обработки данных, бенчмарки устанавливают эталоны сравнения, SOTA (State-of-the-Art) представляет передовые методы в области;Автоматизация, сравнение и передовые методы в ML;3
В чем преимущества применения data mining по сравнению с традиционными методами?;Data mining помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;5
В каких областях деятельности используются большие данные, привести примеры;Используются в финансах (fraud detection), ритейле (recommendations), healthcare (personalized medicine), транспорте (route optimization);Финансы, ритейл, медицина, транспорт;3
В чём суть алгоритмов нахождения квадратичной ошибки?;Алгоритмы нахождения квадратичной ошибки минимизируют сумму квадратов разностей между предсказанными и фактическими значениями для определения оптимальных параметров модели;Методы минимизации ошибок;2
Что такое Apache Parquet?;Колоночный формат хранения данных с эффективным сжатием и кодированием.;Тип файлов для хранения данных в системах типа Hadoop.;2
Что такое Apache Kafka и для чего используется?;Распределенная потоковая платформа для обработки данных в реальном времени. Используется для построения data pipelines, event-driven архитектур, streaming приложений.;Платформа для потоковой обработки данных. Применяется для real-time аналитики, мониторинга, передачи данных между микросервисами.;4
Свойства эластичности и надёжности сложных сетей;"Эластичность - устойчивость к нагрузкам, надежность - отказоустойчивость; зависят от структуры и связности сети";Свойства сетевой устойчивости;2
Перечислите разновидности сложных сетей, назовите их характеристики.;Разновидности: случайные графы (Эрдёша–Реньи), безмасштабные сети (Барбаши–Альберт), сети тесного мира (Уоттса–Строгаца), ориентированные и взвешенные сети.;Сложные сети делятся на случайные, безмасштабные и сети тесного мира. Для случайных — равновероятные связи, безмасштабные характеризуются степенным законом распределения степеней (P(k) ~ k^-?), сети тесного мира имеют малую длину пути и высокий кластеринг.;4
Как работает принцип векторных и матричных вычислений в R?;Векторизация позволяет применять операции ко всем элементам без циклов. Элементы обрабатываются параллельно, что ускоряет вычисления. Матричные операции используют линейную алгебру.;Способ быстрых вычислений с данными в R.;2
Охарактеризуйте хранилища OLAP и OLTP;OLTP системы оптимизированы для операционных транзакций, OLAP для аналитических запросов и отчетности;OLTP для операций, OLAP для аналитики;4
Какие реальные примеры использования предобработка данных существуют?;Предобработка данных помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Предобработка данных используется бизнесом для оптимизации процессов, анализа клиентов и прогнозирования.;4
Какие основные инструменты и технологии используются для работы с предиктивная аналитика?;Предиктивная аналитика применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Предиктивная аналитика применяется в бизнесе и иногда в науке для анализа данных.;3
Что такое уровень значимости;Уровень значимости ? представляет вероятность совершить ошибку первого рода - отвергнуть верную нулевую гипотезу, обычно устанавливается 0.05;Вероятность ошибочного отклонения нулевой гипотезы когда она на самом деле верна;2
Какие преимущества даёт использование Apache Spark по сравнению с Hadoop MapReduce?;Spark быстрее за счёт обработки данных в оперативной памяти, поддерживает потоковую обработку и имеет встроенные библиотеки для ML, SQL и графового анализа. Hadoop работает с промежуточным сохранением на диск, что медленнее.;Spark быстрее Hadoop, потому что использует память, а не диск.;5
Какие инструменты используются для работы с хранилища данных?;Технологии хранилища данных позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Хранилища данных обеспечивает анализ потоковых данных, улучшает прогнозирование, помогает автоматизировать процессы и повышает точность аналитических моделей.;5
Что такое перекрёстная проверка (cross-validation)?;Перекрёстная проверка — это метод оценки обобщающей способности модели, при котором данные делятся на несколько частей, и обучение происходит поочередно на различных подвыборках, а проверка — на оставшихся.;Это способ проверить модель.;3
Как выбрать между различными алгоритмами кластеризации для конкретной задачи?;Анализировать форму кластеров (K-means для spherical, DBSCAN для произвольных), наличие шума (DBSCAN robust к выбросам), знание числа кластеров (K-means требует k), размер данных.;Разные алгоритмы кластеризации для разных типов данных и задач.;2
Интегральные метрики качества;К интегральным метрикам относятся ROC-AUC, Precision-Recall AUC, F1-score и R?, которые агрегируют различные аспекты качества модели в единый показатель;ROC-AUC (площадь под кривой ошибок), PR-AUC для несбалансированных данных, F1-score (гармоническое среднее precision и recall), R? (коэффициент детерминации в регрессии);4
Какие основные инструменты и технологии используются для работы с рекомендательные системы?;Рекомендательные системы применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Рекомендательные системы — это что-то про компьютеры. Применяется редко.;2
Как модели прогнозирования используется в научных исследованиях?;Модели прогнозирования применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Модели прогнозирования применяется в бизнесе и иногда в науке для анализа данных.;3
Основные задачи Data Analysis;Описательная аналитика, диагностика, прогнозирование, рекомендации - основные направления анализа;Описательная аналитика, диагностика, прогнозирование и прескриптивная аналитика;5
Какие основные инструменты и технологии используются для работы с анализ данных?;Анализ данных помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;4
Что такое Apache Iceberg;Apache Iceberg — это open-source table format для аналитических datasets, обеспечивающий ACID семантику, hidden partitioning и schema evolution поверх cloud object stores.;Формат для таблиц;2
Как развивается направление хранилища данных в последние годы?;Хранилища данных используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Это что?то связанное с данными, но используется редко.;2
Какие подходы использовать для feature selection в задачах с тысячами признаков?;Filter methods (correlation, mutual info), wrapper methods (recursive feature elimination), embedded methods (L1 regularization), domain knowledge. Начинать с фильтров для быстрого сокращения.;Методы отбора самых важных признаков из большого количества.;2
Принцип массивных вычислений в R;Векторизованные операции над целыми массивами данных вместо поэлементной обработки в циклах;Векторизация операций в R;3
Что такое K-means кластеризация?;Метод кластеризации, разделяющий данные на k кластеров на основе расстояния до центроидов.;Метод машинного обучения для группировки данных в кластеры по близости точек.;3
Что такое GraphQL?;Язык запросов для API, позволяющий клиентам запрашивать только нужные данные.;Технология для создания API, которая дает клиентам гибкость в выборе получаемых данных.;3
Что такое DBSCAN?;Алгоритм кластеризации на основе плотности, способный находить кластеры произвольной формы и выбросы.;Один из способов группировки данных в машинном обучении.;2
Стандарты жизненного цикла Big Data: CRISP?DM;CRISP-DM представляет собой стандартизированный процесс, включающий 6 этапов: бизнес-понимание, понимание данных, подготовка данных, моделирование, оценка и внедрение;CRISP-DM: бизнес-анализ, данные, моделирование, внедрение;3
Какие проблемы возникают при использовании ETL-пайплайны?;Etl-пайплайны помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Etl-пайплайны нужно только программистам, обычным компаниям оно бесполезно.;2
Что такое feature store?;Централизованное хранилище для управления и обслуживания признаков ML моделей.;Место где хранятся данные для обучения алгоритмов.;2
Какие особенности архитектуры потоковой обработки данных?;Архитектура потоковой обработки включает ingestion слои (Kafka), processing (Spark Streaming, Flink) и sink слои для хранения, обеспечивая обработку в реальном времени;Слои ingestion, processing и sink в потоковой обработке;4
Почему организации переходят на технологии распределённые вычисления?;Распределённые вычисления используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Распределённые вычисления используется бизнесом для оптимизации процессов, анализа клиентов и прогнозирования.;4
Как масштабируемые системы применяется в современных компаниях?;Масштабируемые системы используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Масштабируемые системы применяется в некоторых компаниях для анализа данных.;3
Как обработка потоковых данных влияет на эффективность бизнеса?;Обработка потоковых данных используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Обработка потоковых данных широко применяется в промышленности, здравоохранении, финансах и государственных системах. Позволяет анализировать большие массивы данных, строить точные модели и улучшать эффективность процессов.;5
Как специалисты анализируют данные в рамках системы логирования?;Системы логирования используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Системы логирования применяется в некоторых компаниях для анализа данных.;3
Что такое пайплайны, бенчмарки и SOTA;Пайплайны автоматизируют процессы, бенчмарки устанавливают стандарты сравнения, SOTA представляет передовые методы;Автоматизация процессов и сравнение методов;3
Обучение с учителем и без учителя;"С учителем: классификация и регрессия с размеченными данными; без учителя: кластеризация и анализ без меток";Два типа обучения машин;2
Что такое Apache Iceberg?;Открытый табличный формат для больших данных с ACID транзакциями и версионированием.;Табличный формат для больших аналитических данных, который обеспечивает ACID транзакции, версионирование данных, schema evolution и скрытие партиционирования для улучшения производительности запросов.;5
Какие методы использовать для обнаружения аномалий в многомерных временных рядах?;Многомерные статистические методы (Mahalanobis distance), матричные профили, нейросетевые подходы (LSTM autoencoders), изолирующие леса, анализ главных компонент с reconstruction error.;Mahalanobis distance для многомерных выбросов, matrix profile для временных рядов, LSTM autoencoders, isolation forest, PCA с анализом ошибки реконструкции. Комбинировать методы для повышения точности.;5
Основные задачи Data Analysis;Описательная аналитика, диагностика, прогнозирование, прескриптивная аналитика для принятия решений;Задачи анализа данных;2
Какие навыки необходимы специалисту для работы с NLP?;Nlp применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Nlp применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;4
Разница между линейной и логистической регрессией;Линейная регрессия предсказывает непрерывные значения, логистическая - вероятности бинарной классификации;Разные типы регрессии;2
Что такое MLOps?;Практики CI/CD для развертывания и мониторинга моделей машинного обучения.;Способ управления проектами по искусственному интеллекту в компаниях.;2
«Меры изменчивости»: что к ним относится?;Дисперсия, стандартное отклонение, размах, межквартильный размах, среднее абсолютное отклонение;Дисперсия, стандартное отклонение, размах;3
Какие стратегии использовать для backup и recovery больших datasets?;Incremental backups, snapshotting, geographic replication, versioned storage, automated recovery procedures, regular testing восстановления.;Инкрементальные бэкапы, снапшоты, гео-репликация, версионирование. Автоматизированные процедуры восстановления и тестирование.;5
Как обработка данных помогает в анализе больших объемов данных?;Обработка данных используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;4
Где применяется ETL-процессы в промышленности и бизнесе?;Etl-процессы помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Используется для прогнозов и анализа информации.;3
Что такое data pipeline?;Автоматизированный процесс перемещения и преобразования данных от источника до потребителя.;Процесс перемещения данных из источника в целевую систему. Автоматизирует обработку и трансформацию данных.;3
Какие метрики использовать для оценки несбалансированной бинарной классификации?;Precision, Recall, F1-score, ROC-AUC, PR-AUC. Accuracy не подходит, так как может быть обманчиво высоким при дисбалансе классов.;F1-score, precision и recall для миноритарного класса, ROC-AUC. Избегать accuracy, так как он может вводить в заблуждение при дисбалансе.;4
Нормальное распределение;Нормальное распределение характеризуется симметричной колоколообразной формой, параметрами ? (среднее) и ? (стандартное отклонение), встречается во многих природных явлениях;Симметричное распределение где mean=median=mode, следует правилу 68-95-99.7 для стандартных отклонений, основа центральной предельной теоремы;4
Почему технологии распределённые вычисления стали критически важны?;Распределённые вычисления помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Распределённые вычисления нужно только программистам, обычным компаниям оно бесполезно.;2
Как выбрать стратегию индексации для оптимизации запросов в колоночных хранилищах?;Использовать zone maps для min/max значений, bloom filters для членства, inverted indexes для категориальных данных. Выбор зависит от типа запросов и распределения данных.;Zone maps для диапазонных запросов, bloom filters для быстрой проверки наличия, inverted indexes для фильтрации по категориям. Учитывать паттерны запросов.;5
Какие риски связаны с применением системы логирования?;Технологии системы логирования позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Системы логирования используется для обработки информации и улучшения решений.;3
Основные инструменты аналитики больших данных, провести сравнительную характеристику.;К основным инструментам аналитики больших данных относятся Apache Hadoop, Spark, Flink, Hive, Pig, а также BI-платформы вроде Tableau и Power BI. Hadoop обеспечивает распределённое хранение (HDFS) и обработку, Spark — высокую скорость вычислений в оперативной памяти, Hive — SQL-подобный доступ к данным.;Для больших данных применяются Spark и Hadoop, но можно и Excel.;3
Что такое корреляция в анализе данных?;Корреляция — это статистическая мера взаимосвязи между двумя переменными. Она показывает направление и силу связи, выражается коэффициентом r в диапазоне от -1 до +1.;Корреляция описывает, насколько сильно связаны два показателя, например рост и вес. r может быть положительным или отрицательным.;5
Как принято формулировать нулевую гипотезу?;Как утверждение об отсутствии эффекта, различий или связи между переменными;Гипотеза об отсутствии эффекта;2
Когда использовать градиентный бустинг вместо случайного леса?;Бустинг когда важна максимальная точность и есть время на тонкую настройку, случайный лес когда нужна robustness и скорость обучения.;Бустинг сложнее настраивать но часто точнее. Random Forest проще и быстрее. Выбор зависит от задачи и доступного времени.;3
Boxplot и его интерпретация, связь с другими элементами анализа;Boxplot визуализирует распределение данных через медиану, квартили и выбросы, тесно связан с описательной статистикой и используется для сравнения распределений и выявления аномалий в наборах данных;Графический способ показать как распределены числовые значения в наборе информации;2
Алгоритмы выделения сообществ;Основные алгоритмы для обнаружения сообществ в сложных сетях включают метод Louvain, алгоритм Girvan-Newman и метод распространения меток, которые используют различные подходы к выявлению групп тесно связанных узлов;Для выделения сообществ в сложных сетях используются различные алгоритмы, основанные на анализе структурных свойств графов и связей между узлами;5
Почему организации переходят на технологии data lakes?;Data lakes используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Data lakes нужно только программистам, обычным компаниям оно бесполезно.;2
Что такое dbt (data build tool)?;Инструмент для трансформации данных в хранилищах через SQL с тестированием и документацией.;Инструмент для написания SQL запросов к базам данных.;2
Какие бывают виды регрессионного анализа? Поясните логистическую регрессию и SVM;Виды регрессии включают линейную, полиномиальную, логистическую и др. Логистическая регрессия предскажает вероятности бинарной классификации, а SVM находит оптимальную разделяющую гиперплоскость;Методы для анализа зависимостей между переменными;2
Как организовать систему кэширования для ускорения аналитических запросов к большим данным?;Многоуровневое кэширование (in-memory, SSD, disk), инвалидация кэша на основе TTL или изменений данных, предварительная агрегация, использование распределенных кэшей (Redis, Memcached).;Многоуровневое кэширование с разными скоростями доступа, стратегии инвалидации based on времени или данных, предварительные агрегаты для частых запросов, распределенные in-memory кэши для кластера.;5
Какие инструменты используются для работы с data warehouses?;Data warehouses помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Data warehouses применяется в некоторых компаниях для анализа данных.;3
С какими проблемами сталкиваются при применении NLP, и как их решают?;Nlp используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Используется для прогнозов и анализа информации.;3
Виды столбчатых диаграмм и их интерпретация;"Столбчатые диаграммы включают вертикальные, горизонтальные, сгруппированные и stacked; интерпретируются через сравнение величин категорий";Разные виды столбчатых диаграмм для сравнения;4
Как работает алгоритм Diffusion Models в генеративном AI?;Постепенное добавление шума к данным с последующим обучению обратному процессу восстановления. Создает высококачественные изображения через итеративное уточнение.;Метод генерации изображений через процесс зашумливания и восстановления.;2
Какие подходы использовать для обработки графовых данных в распределенных системах?;Специализированные графовые базы (Neo4j), графовые обработчики (GraphX), алгоритмы для распределенных графов (Pregel), оптимизация хранения графовых структур, partitioning по вершинам или ребрам.;Графовые базы данных, распределенные вычислительные?? для графов, алгоритмы обхода графов, оптимизация хранения и партиционирования графовых данных.;4
Принципы глубокого обучения в нейросетях;Глубокое обучение основано на использовании нейронных сетей с множеством скрытых слоев, которые позволяют автоматически извлекать иерархические признаки из данных. Сверточные нейронные сети (CNN) специально разработаны для обработки изображений через применение сверточных фильтров и операций пулинга;Многослойные архитектуры нейросетей обучаются распознавать сложные паттерны в данных, начиная с простых признаков и заканчивая сложными представлениями;3
Порядок тестирования гипотезы о равенстве средних;Формулировка гипотез, проверка условий, расчет статистики, сравнение с критическим значением;Определение гипотез, проверка допущений, расчет p-value;3
Какие типы данных используются в Big Data и чем они отличаются?;"В Big Data выделяют структурированные, неструктурированные и полуструктурированные данные. Структурированные хранятся в таблицах, неструктурированные — это тексты, изображения, видео; полуструктурированные — JSON, XML.";Типы данных: структурированные, неструктурированные и полуструктурированные. Отличаются способом организации и хранения.;5
Охарактеризовать конструкции языка R;Язык R предоставляет векторы для атомарных данных, матрицы для двумерных массивов, списки для гетерогенных коллекций, фреймы данных для табличной организации и факторы для категориальных переменных;Основные структуры данных языка R;4
Виды распределения данных и примеры;Основные виды — нормальное, равномерное, экспоненциальное, биномиальное. Примеры: рост людей (нормальное), броски монеты (биномиальное).;Есть нормальное, равномерное и другие распределения, например, рост людей часто подчиняется нормальному.;5
Критерии качества кластеризации;К критериям качества относятся Silhouette score, Davies-Bouldin index и Calinski-Harabasz index;Показатели качества кластеризации;3
Как специалисты анализируют данные в рамках масштабируемые системы?;Масштабируемые системы используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Эти технологии помогают работать с информацией и делать прогнозы.;3
Какие типы данных используются в Big Data и чем они отличаются?;"В Big Data выделяют структурированные, неструктурированные и полуструктурированные данные. Структурированные хранятся в таблицах, неструктурированные — это тексты, изображения, видео; полуструктурированные — JSON, XML.";В Big Data бывают структурированные и неструктурированные данные, например таблицы и тексты.;4
Характерные черты безмасштабных сетей и связь с сетями тесного мира;Безмасштабные сети имеют степенное распределение степеней, наличие хабов, устойчивость к случайным отказам. Связаны с сетями тесного мира через высокую кластеризацию и короткие пути;Безмасштабные сети имеют степенное распределение и связаны с сетями тесного мира через кластеризацию;5
Что такое нейронные сети с резкими связями (ResNet)?;Архитектура CNN с skip-connections для решения проблемы исчезающего градиента в глубоких сетях.;Улучшенная архитектура нейросетей для распознавания изображений.;2
Как развивается направление мониторинг больших данных в последние годы?;Мониторинг больших данных используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Технологии мониторинг больших данных позволяют компаниям обрабатывать большие объёмы разнородных данных, выявлять сложные закономерности и принимать обоснованные решения.;5
Как организовать мониторинг качества данных в реальном времени?;Потоковая проверка метрик качества (completeness, accuracy, consistency), автоматические алерты при отклонениях, dashboard для визуализации, интеграция с data lineage для отслеживания проблем.;Реaltime проверка метрик качества данных, автоматические уведомления при нарушениях, дашборды для мониторинга, интеграция с data lineage для быстрого определения источника проблем. Важно мониторить как статистики данных, так и бизнес-метрики.;5
Как проектировать data pipeline для обработки данных с разной latency требованиями?;Lambda architecture, multi-tier processing, priority queues, separate pipelines для real-time и batch, resource allocation based on SLA.;Lambda архитектура, многоуровневая обработка, приоритетные очереди, отдельные пайплайны. Распределение ресурсов по требованиям к задержке.;5
Что такое transfer learning и в каких задачах он применяется?;Transfer learning - использование предобученных моделей для решения новых задач, применяется когда мало размеченных данных, особенно в компьютерном зрении и NLP;Метод использования предобученных моделей для новых задач;4
Как системы логирования влияет на эффективность бизнеса?;Технологии системы логирования позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Системы логирования используется для обработки информации и улучшения решений.;3
В чем преимущества применения нейронные сети по сравнению с традиционными методами?;Нейронные сети помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Нейронные сети — это что-то про компьютеры. Применяется редко.;2
Какие методы использовать для detection outliers в многомерных данных?;Mahalanobis distance, isolation forest, local outlier factor, DBSCAN, PCA-based methods, autoencoders reconstruction error.;Mahalanobis distance, isolation forest, LOF, DBSCAN. PCA и autoencoders для обнаружения выбросов в многомерных данных.;5
Какие инструменты используются для работы с in-memory обработка?;In-memory обработка помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;In-memory обработка применяется в финансах, медицине, рекламе и IT, помогает анализировать данные и строить модели.;4
Какие реальные примеры использования предобработка данных существуют?;Предобработка данных помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Технологии позволяют улучшать качество аналитики, находить закономерности и предсказывать события.;4
Что такое Data Catalog;Data Catalog — это централизованный реестр метаданных, который обеспечивает discoverability, понимание и управление данными в организации.;Каталог данных;2
Параметрическая модель статистического обучения;Параметрическая модель предполагает фиксированное число параметров и определенную функциональную форму зависимости между переменными в статистическом анализе;Параметрическая модель имеет фиксированное число параметров и заданную функциональную форму;5
Почему технологии data warehouses стали критически важны?;Data warehouses помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Data warehouses применяется в финансах, медицине, рекламе и IT, помогает анализировать данные и строить модели.;4
Преимущества и недостатки непараметрических моделей;Непараметрические модели обладают гибкостью, но требуют значительных вычислительных ресурсов и объемов данных;Гибкость моделей но большие затраты;3
Что такое 'регрессия' в машинном обучении?;Регрессия — это метод моделирования зависимости между зависимой переменной и одной или несколькими независимыми переменными.;Регрессия — это метод предсказания количественного показателя на основе других признаков.;5
Для чего нужна гипотеза о равенстве средних;Гипотеза о равенстве средних позволяет статистически проверить различия между средними значениями групп;Для сравнения средних в группах;4
Принципы глубокого обучения в нейросетях. Преимущества сверточных сетей.;Глубокое обучение использует многослойные нейронные сети (MLP, CNN, RNN) для автоматического извлечения признаков. CNN эффективны в задачах CV благодаря сверткам (convolution) и pooling. Формула свертки: y = ?(x*w).;Глубокие сети просто длиннее обычных.;3
Где применяется кластеризация в промышленности и бизнесе?;Кластеризация используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;4
Нормальное распределение;Нормальное распределение характеризуется симметричной колоколообразной формой и определенными параметрами центра и dispersion;Колоколообразное распределение;2
Какие методы использовать для обработки потоковых данных с изменяющейся схемой?;Schema registry с валидацией, compatible evolution, default значения для новых полей, обработка unknown fields, graceful degradation при несовместимости.;Обработка данных с меняющейся схемой.;2
Что такое статистическое обучение;Раздел машинного обучения, основанный на статистических методах и вероятностных моделях;Использование статистических методов для построения моделей;3
Как развитие глубокое обучение влияет на будущее цифровых технологий?;Глубокое обучение помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Глубокое обучение нужно только программистам.;2
Что такое пайплайны, бенчмарки и SOTA;Пайплайны - автоматизированные процессы обработки данных, бенчмарки - эталоны сравнения, SOTA - лучшие достижения;Инструменты для работы с данными;2
Как глубокое обучение применяется для автоматизации рутинных процессов?;Глубокое обучение используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Глубокое обучение применяется в бизнесе и иногда в науке для анализа данных.;3
Какие методы использовать для обработки потоковых данных с изменяющейся схемой?;Schema registry с валидацией, compatible evolution, default значения для новых полей, обработка unknown fields, graceful degradation при несовместимости.;Управление версиями схем, compatible изменения, значения по умолчанию. Обеспечивать работу при изменениях схемы.;4
Что такое MapReduce и из каких этапов состоит?;Модель программирования для обработки больших данных. Состоит из Map (фильтрация и сортировка) и Reduce (агрегация результатов).;Метод обработки данных в два этапа.;2
Для чего нужна гипотеза о равенстве средних;Гипотеза о равенстве средних позволяет статистически проверить различия между средними значениями групп;Гипотеза нужна для проверки различий средних;5
Какие инструменты используются для работы с масштабируемые системы?;Масштабируемые системы помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Масштабируемые системы нужно только программистам, обычным компаниям оно бесполезно.;2
Почему технологии распределённые вычисления стали критически важны?;Распределённые вычисления помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Распределённые вычисления применяется в финансах, медицине, рекламе и IT, помогает анализировать данные и строить модели.;4
Что такое переобучение (overfitting) и как его предотвратить?;Модель слишком точно подстраивается под тренировочные данные и плохо работает на новых. Методы предотвращения: регуляризация, кросс-валидация, упрощение модели, увеличение данных.;Проблема когда модель не обобщает новые данные. Использовать регуляризацию и проверку на отдельной выборке.;3
Перечислите основные задачи анализа сетей на графах;Основные задачи включают обнаружение сообществ, вычисление центральности узлов, поиск кратчайших путей, анализ связности и выявление влиятельных узлов в сетевых структурах;Ключевые задачи: обнаружение сообществ, вычисление мер центральности, поиск оптимальных маршрутов в графах;4
Виды распределения данных и примеры;Распределение — это график.;Это как когда всё примерно одинаковое.;2
Что такое Apache Parquet?;Колоночный формат хранения данных с эффективным сжатием и кодированием.;Эффективный формат для хранения табличных данных в Big Data экосистеме с хорошим сжатием.;3
Параметрическая модель статистического обучения;Параметрическая модель предполагает фиксированное число параметров и определенную функциональную форму зависимости между переменными в статистическом анализе;Модели с фиксированной параметризацией и заданными предположениями о распределении данных в статистике;3
Как принято формулировать нулевую гипотезу?;Нулевая гипотеза (H0) утверждает отсутствие различий или эффектов: H0: ?1 = ?2. Альтернативная H1 утверждает обратное. Проверяется через статистический критерий (например, t-тест).;Нулевая гипотеза — это когда ничего не меняется.;3
Что такое data warehouse?;Централизованное хранилище интегрированных данных из различных источников, оптимизированное для анализа и отчетности, с поддержкой исторических данных и структурированной схемой.;Хранилище данных которое объединяет информацию из разных источников в единую схему. Оптимизировано для аналитических запросов и отчетности, поддерживает исторические данные и обычно использует dimensional modeling.;5
Что такое Adam optimizer?;Алгоритм оптимизации для градиентного спуска, сочетающий преимущества RMSProp и Momentum с адаптивным learning rate.;Адаптивный алгоритм оптимизации для нейросетей. Комбинирует идеи momentum и адаптивного learning rate для быстрой сходимости.;5
Как внедрение классификация данных влияет на процессы в организациях?;Классификация данных применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;4
Что такое k-fold cross validation?;Метод валидации, при котором данные разбиваются на k равных частей, модель обучается на k-1 частях и тестируется на оставшейся.;Метод тестирования моделей машинного обучения.;2
Как глубокое обучение используется в научных исследованиях?;Глубокое обучение применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Это просто работа с таблицами. Не очень полезно.;2
Характерные черты безмасштабных сетей, какова их связь с сетями тесного мира?;Безмасштабные сети имеют степенное распределение степеней вершин (P(k)~k^-?), содержат хабы. Сети тесного мира характеризуются малой длиной пути и высоким коэффициентом кластеризации. Обе модели встречаются в реальных системах.;Безмасштабные сети (Барбаши–Альберт) обладают степенным распределением P(k)~k^-?, где ??[2,3], что обеспечивает наличие хабов. Сети тесного мира (Уоттса–Строгаца) имеют высокий кластеринг и короткое среднее расстояние. Реальные сети часто совмещают оба свойства.;5
Что такое MongoDB?;Документо-ориентированная NoSQL база данных с гибкой JSON-подобной схемой документов.;Документная NoSQL база данных. Хранит данные в JSON-формате, легко масштабируется и подходит для неструктурированных данных.;4
Какие навыки необходимы специалисту для работы с рекомендательные системы?;Рекомендательные системы помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;4
Основные вызовы больших данных;Основные вызовы включают объем, скорость поступления, разнообразие форматов и достоверность данных;Основные вызовы связаны с объемом, скоростью и разнообразием данных;5
Как внедрение глубокое обучение влияет на процессы в организациях?;Глубокое обучение помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;5
Зачем нужны рекуррентные нейросети?;Рекуррентные нейросети (RNN) используются для работы с последовательными данными — текст, временные ряды, речь. Основная идея — наличие памяти о предыдущих состояниях. Формула: h_t = f(Wx_t + Uh_{t-1}).;RNN используют память для работы с последовательностями.;4
Что такое машинное обучение и каковы его основные типы?;Машинное обучение — это раздел искусственного интеллекта, изучающий методы построения алгоритмов, способных обучаться на данных. Основные типы: обучение с учителем, без учителя и с подкреплением.;Машинное обучение — область ИИ, где модели обучаются на примерах. Основные типы — supervised, unsupervised и reinforcement learning.;4
Что такое eventual consistency и в каких Big Data системах она используется?;Eventual consistency - модель согласованности, где обновления eventually распространяются на все узлы, но не гарантируется немедленная консистентность. Используется в Cassandra, DynamoDB, где доступность важнее строгой консистентности.;Модель когда данные eventually согласуются между узлами. Применяется в распределенных NoSQL базах где скорость и доступность важнее мгновенной консистентности.;4
Какие алгоритмы лежат в основе методов выделения сообществ? Дайте общее описание шагов выполнения этих алгоритмов.;Алгоритмы выделения сообществ включают методы модульности (Лувен, Ньюман-Гирван), спектральные методы и итерационные подходы. Основные шаги: построение графа, вычисление меры модульности Q, итеративное объединение или разбиение узлов до оптимума Q.;Методы выделения сообществ основаны на модульности. Основной шаг — деление графа на кластеры по плотности связей.;4
Что такое Data Warehouse;Data Warehouse — это централизованное хранилище интегрированных данных из различных источников, оптимизированное для аналитики и отчетности.;Оптимизированное хранилище для бизнес-аналитики;4
Что такое dbt (data build tool)?;Инструмент для трансформации данных в хранилищах через SQL с тестированием и документацией.;Система для преобразования данных в хранилищах с помощью SQL запросов. Упрощает работу с данными.;3
Как организовать feature engineering для NLP задач с большими текстовыми данными?;TF-IDF, word embeddings (Word2Vec, GloVe), contextual embeddings (BERT), character-level features, topic modeling (LDA), syntactic features (POS tagging).;Векторные представления слов, статистические методы, контекстные эмбеддинги и лингвистические признаки для текстовых данных.;3
Основные вызовы больших данных;Основные вызовы включают объем, скорость поступления, разнообразие форматов и достоверность данных;Большие объемы, высокая скорость и разнообразие данных;4
Назовите критерии качества кластеризации и поясните их значение и когда они используются.;Критерии качества: внутрикластерная дисперсия (SSW), межкластерная дисперсия (SSB), индекс силуэта, индекс Дэвиса-Болдина, индекс Калински-Харабаса. Применяются для оценки плотности и разделимости кластеров.;Критерии — это метрики, показывающие, насколько плотные кластеры.;4
Как принято формулировать нулевую гипотезу;Утверждение об отсутствии статистически значимых различий или эффектов в исследуемых данных;Формулируется как утверждение об отсутствии статистически значимых различий или эффектов;5
Что такое eventual consistency и в каких Big Data системах она используется?;Eventual consistency - модель согласованности, где обновления eventually распространяются на все узлы, но не гарантируется немедленная консистентность. Используется в Cassandra, DynamoDB, где доступность важнее строгой консистентности.;Тип согласованности в распределенных системах когда данные обновляются не сразу.;2
Для чего нужна гипотеза о равенстве средних;Гипотеза о равенстве средних позволяет статистически проверить различия между средними значениями групп;Сравнение средних значений;3
Что такое Quantum Machine Learning и какие преимущества оно обещает?;Применение квантовых вычислений для ML алгоритмов. Обещает экспоненциальное ускорение для optimization problems, quantum feature spaces, обработки больших данных.;Использование квантовых технологий в машинном обучении для будущего ускорения вычислений.;2
Что такое MapReduce и из каких этапов состоит?;Модель программирования для обработки больших данных. Состоит из Map (фильтрация и сортировка) и Reduce (агрегация результатов).;Алгоритм с этапами преобразования и агрегации данных для распределенной обработки.;3
Как внедрение компьютерное зрение влияет на процессы в организациях?;Компьютерное зрение применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;4
Критерии качества кластеризации;Silhouette score, Davies-Bouldin index, Calinski-Harabasz index - метрики оценки кластеров;Метрики для оценки кластеризации;2
В чем различия между R и Python для анализа данных?;R - специализирован для статистики и визуализации, богатые статистические пакеты. Python - универсальный, лучше для ML и production систем. R удобнее для исследований, Python - для промышленной разработки.;R силен в статистическом анализе и графиках, Python - в машинном обучении и интеграции с production. R для исследователей, Python для инженеров. Оба имеют богатые библиотеки для data science.;5
Что такое data mining и какие задачи оно решает?;Data mining используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Data mining применяется в бизнесе и иногда в науке для анализа данных.;3
Как нейронные сети помогает в анализе больших объемов данных?;Нейронные сети используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Используется для прогнозов и анализа информации.;3
Понятия репликации и шардинга;Репликация - копирование данных для отказоустойчивости, шардинг - горизонтальное разделение;Способы распределения данных;2
Какие риски связаны с использованием NLP в критически важных системах?;Nlp используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Nlp нужно только программистам.;2
Какие риски связаны с применением распределённые вычисления?;Распределённые вычисления используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Технологии позволяют улучшать качество аналитики, находить закономерности и предсказывать события.;4
Метрики качества для компьютерного зрения;"Accuracy, Precision, Recall для классификации; mAP, IoU для детекции объектов; Dice coefficient для сегментации изображений";Разные показатели точности для разных задач анализа изображений;2
Что делает алгоритм k-ближайших соседей (kNN)?;"kNN классифицирует объект на основе классов его ближайших соседей в пространстве признаков.,""kNN смотрит";какие точки ближе всего и решает по ним.;4
Что такое регуляризация в машинном обучении?;Метод предотвращения переобучения путем добавления штрафа за сложность модели к функции потерь.;Метод улучшения модели путем добавления дополнительных ограничений.;3
Как компьютерное зрение применяется для автоматизации рутинных процессов?;Компьютерное зрение используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;4
Что такое data lake и чем он отличается от data warehouse?;Data lake хранит сырые данные в любом формате, data warehouse - структурированные и обработанные данные по заданной схеме. Data lake для exploration, data warehouse для отчетности.;Data lake хранит сырые данные разных форматов, data warehouse - обработанные структурированные данные. Lake для исследований, warehouse для бизнес-отчетов.;5
Как организовать A/B тестирование для ML моделей в продакшене?;Canary deployments, постепенный rollout, monitoring ключевых метрик, статистические тесты для значимости, учет network effects и long-term impact.;Постепенное внедрение на часть пользователей, мониторинг метрик, статистическая проверка значимости результатов. Учитывать длительность теста и внешние факторы.;4
Достоинства и недостатки деревьев решений;"Достоинства: интерпретируемость, не требуют нормализации; недостатки: склонность к переобучению, нестабильность";Деревья решений имеют достоинства интерпретируемости и недостатки переобучения;5
Что такое кросс-валидация и зачем она нужна?;Метод оценки модели путем многократного разбиения данных на тренировочную и тестовую выборки. Нужна для более надежной оценки обобщающей способности и настройки гиперпараметров.;Многократное разбиение данных для проверки модели. Обеспечивает надежную оценку качества и помогает в подборе параметров.;4
Что представляет собой алгоритм k-means?;K-means — это метод кластеризации, основанный на минимизации суммы квадратов расстояний между точками и центрами кластеров. Итеративно пересчитывает центры кластеров до сходимости.;K-means делит данные на кластеры, где каждый объект принадлежит ближайшему центру.;4
Как работает технология Data Virtualization и какие проблемы она решает?;Предоставляет unified view данных без физического перемещения. Решает проблемы data silos, уменьшает latency доступа, упрощает data governance в распределенных системах.;Создает виртуальный слой доступа к данным из разных источников без копирования. Решает проблемы изолированных данных, ускоряет доступ и упрощает управление данными.;5
Что такое Feature Store;Feature Store — это централизованное хранилище для управления, версионирования и обслуживания признаков машинного обучения в production средах.;Место где хранятся и управляются фичи для моделей;3
Что такое дисперсия данных и что она показывает?;Дисперсия — это мера разброса данных относительно среднего значения. Вычисляется как среднее квадратов отклонений: D = ?(xi - ?)^2 / n.;Дисперсия показывает, насколько сильно значения отклоняются от среднего. Чем больше дисперсия, тем выше разброс.;5
Как обеспечить воспроизводимость экспериментов в ML и data science?;Version control для кода и данных, фиксация seed значений, контейнеризация (Docker), detailed logging, MLflow для отслеживания экспериментов.;Версионирование кода и данных, фиксация random seeds, использование Docker для среды выполнения, детальное логирование и инструменты типа MLflow для отслеживания экспериментов и параметров.;5
Какие риски связаны с применением in-memory обработка?;In-memory обработка используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;In-memory обработка нужно только программистам, обычным компаниям оно бесполезно.;2
Что такое статистическая гипотеза? Какие виды гипотез вы знаете?;Статистическая гипотеза - это предположение о свойствах генеральной совокупности, проверяемое статистическими методами. Виды: нулевая (об отсутствии эффекта) и альтернативная (о наличии эффекта);Утверждения для статистической проверки;3
Как in-memory обработка применяется в современных компаниях?;Технологии in-memory обработка позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;In-memory обработка применяется в некоторых компаниях для анализа данных.;3
В чем разница между supervised и unsupervised learning?;Supervised learning использует размеченные данные с метками, unsupervised работает с данными без меток.;Supervised использует данные с правильными ответами, unsupervised ищет закономерности в данных без меток.;4
Дайте определение социального графа. Перечислите его типы и свойства. К какому семейству больших графов он относится?;Социальный граф — это представление социальных взаимодействий между узлами (людьми, организациями). Характеризуется высокой кластеризацией, малой средней длиной пути, динамичностью и направленными рёбрами. Относится к семейству больших сложных сетей (complex networks).;Социальный граф — это просто набор узлов и рёбер без уточнения, кто эти узлы и как они связаны.;3
Порядок тестирования гипотезы о равенстве средних;Процесс включает формулировку гипотез, проверку условий, расчет статистики и принятие решения;Проверка гипотез о средних;2
Охарактеризуйте хранилища данных типа OLAP и OLTP. Назовите разницу.;OLTP (Online Transaction Processing) — системы для оперативной обработки транзакций характеризуются высокой скоростью записи и изменениями данных. OLAP (Online Analytical Processing) — системы аналитической обработки, оптимизированные для чтения и агрегации. Разница — в назначении и структуре: OLTP ориентирован на текущее состояние, OLAP — на анализ исторических данных.;OLTP используется для транзакций, OLAP — для отчетов. Разница в скорости и структуре.;4
Как модели прогнозирования используется в научных исследованиях?;Модели прогнозирования используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Модели прогнозирования — это что-то про компьютеры. Применяется редко.;2
Где применяется компьютерное зрение в промышленности и бизнесе?;Компьютерное зрение используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Компьютерное зрение применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;4
Что такое Delta Lake;Delta Lake — это open-source storage layer, который добавляет reliability, ACID транзакции и управление версиями к данным в data lakes поверх Parquet формата.;Надежный storage с транзакциями, версионированием и unified processing для data lakes;5
Что такое Synthetic Data Generation и когда его использование оправдано?;Создание искусственных данных сохраняющих статистические свойства реальных. Оправдано при недостатке данных, privacy concerns, testing систем, imbalance correction.;Создание искусственных данных для использования в машинном обучении вместо реальных.;2
Какие реальные примеры использования big data существуют?;Big data помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Это что?то связанное с данными, но используется редко.;2
Сравнительный анализ алгоритмов кластеризации;Алгоритмы кластеризации сравниваются по масштабируемости, чувствительности к шуму, способности находить кластеры сложной формы и вычислительной сложности;K-means быстрый но требует задания k, DBSCAN находит кластеры произвольной формы, иерархическая кластеризация дает дендрограмму но дорогая вычислительно;3
Стадии разработки систем ML;Полный процесс разработки систем машинного обучения включает сбор и подготовку данных, проектирование признаков, обучение моделей, валидацию результатов и развертывание в production-среде;Разработка ML систем включает несколько основных стадий от сбора данных до развертывания;5
Какие типы нейронных сетей используются в компьютерном зрении?;В компьютерном зрении применяются сверточные нейронные сети (CNN), автокодировщики, R-CNN для детекции объектов и U-Net для сегментации изображений;CNN и другие архитектуры для анализа изображений;3
Обучение с подкреплением и ансамбли;Обучение с подкреплением основано на взаимодействии со средой, ансамбли комбинируют несколько моделей;RL и ансамблевые методы;3
Что такое пайплайны, бенчмарки и SOTA;Пайплайны - автоматизированные процессы обработки данных, бенчмарки - эталоны сравнения, SOTA - лучшие достижения;Автоматизация процессов, сравнение методов, передовые решения;3
Принципы глубокого обучения в нейросетях;Глубокое обучение использует многослойные нейросети для автоматического извлечения признаков из данных различной природы;Глубокое обучение применяет многослойные сети для автоматического признаков;3
Что такое lambda architecture и из каких компонентов она состоит?;Архитектура для обработки Big Data, сочетающая batch и stream processing. Состоит из batch layer (обработка всех данных), speed layer (реaltime обработка) и serving layer (объединение результатов).;Сочетает пакетную и потоковую обработку. Batch для полных данных, speed для реального времени, serving для предоставления результатов.;4
Как проектировать систему для обработки данных в реальном времени с гарантией exactly-once?;Использовать фреймворки с поддержкой exactly-once (Flink, Kafka Streams), идемпотентные операции, transactional writes, checkpointing и watermarking для обработки late data.;Спроектировать систему чтобы данные обрабатывались ровно один раз.;2
Какие подходы использовать для feature selection в задачах с тысячами признаков?;Filter methods (correlation, mutual info), wrapper methods (recursive feature elimination), embedded methods (L1 regularization), domain knowledge. Начинать с фильтров для быстрого сокращения.;Методы фильтрации (корреляция, mutual information), методы обертки (recursive feature elimination) и встроенные методы (L1 регуляризация). Также использовать domain knowledge для отбора наиболее релевантных признаков.;5
Принцип работы SVM;Метод опорных векторов находит гиперплоскость с максимальным зазором для разделения классов в пространстве признаков;Решает задачу оптимизации для нахождения гиперплоскости w·x + b = 0 с максимальным margin, использует ядерные функции для отображения в пространство высшей размерности;4
Стадии разработки систем ML;Процесс разработки включает сбор данных, предобработку, проектирование признаков, обучение модели, валидацию, развертывание и мониторинг производительности;Полный цикл включает сбор и аннотацию данных, предобработку и feature engineering, выбор и обучение модели, валидацию и тестирование, развертывание в production и непрерывный мониторинг качества;5
Генеральная совокупность и выборка;Генеральная совокупность включает все объекты исследования, выборка является ее представительной частью;Полная совокупность и выборка;3
Назовите и поясните метрики качества для компьютерного зрения.;Используются метрики IoU = (S ? P) / (S ? P), mAP (mean Average Precision), Pixel Accuracy, Dice = 2|A ? B| / (|A| + |B|).;Метрики IoU и mAP — стандарт для оценки моделей детекции.;4
Стандарты жизненного цикла Big Data: CRISP?DM;CRISP-DM включает этапы бизнес-понимания, понимания данных, подготовки, моделирования, оценки и внедрения;Бизнес-понимание, данные, моделирование в CRISP-DM;4
Какие реальные примеры использования обработка потоковых данных существуют?;Технологии обработка потоковых данных позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Обработка потоковых данных применяется в финансах, медицине, рекламе и IT, помогает анализировать данные и строить модели.;4
Алгоритмы классификации;Основные алгоритмы включают логистическую регрессию, деревья решений, случайный лес, SVM и наивный байесовский классификатор;Методы для классификации;2
Какие методы использовать для детектирования аномалий в потоковых данных?;Statistical methods (moving average, z-score), ML approaches (isolation forest, autoencoders), time-series methods (STL decomposition). Важно учитывать задержку обработки и обновление модели.;Алгоритмы для обнаружения аномалий которые работают в реальном времени и могут адаптироваться.;3
Каков порядок обработки данных при тестировании гипотезы о равенстве, какие тесты должны быть пройдены, какие требования к данным выдвигаются?;Проверяется нормальность распределения (Shapiro–Wilk), гомогенность дисперсий (Levene), после чего применяют t-тест для независимых или парных выборок. Требования: независимость наблюдений, интервал/отношение шкалы.;Сначала проверяют нормальность и равенство дисперсий, затем применяют t-тест.;5
Какие реальные кейсы демонстрируют эффективность классификация данных?;Классификация данных используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;5
Какие компании активно используют машинное обучение и зачем?;Машинное обучение помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;4
Что такое большие данные и откуда они поступают?;Большие данные - огромные объемы структурированных и неструктурированных данных, которые невозможно обработать традиционными методами. Источники: соцсети, IoT устройства, транзакционные системы, сенсоры.;Это очень большие наборы данных, требующие специальных технологий обработки. Поступают из социальных сетей, умных устройств, банковских систем, датчиков.;5
Определение термина «большие данные»;Большие данные представляют собой огромные объемы разнородной информации, требующие специальных технологий обработки;Очень большие наборы данных;2
Виды неопределённости в анализе данных;Источники неопределенности включают ошибки измерений, sampling variability, model uncertainty и epistemic uncertainty due to limited knowledge;Разные типы ошибок и неточностей в данных и моделях;2
Какие навыки необходимы специалисту для работы с ETL-процессы?;Etl-процессы помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;4
Определение термина «большие данные»;Большие объемы разнородных данных, требующие специальных технологий обработки и хранения;Большие объемы, высокая скорость, разнообразие форматов данных;4
Основные вызовы больших данных;Основные вызовы больших данных включают объем (Volume), скорость (Velocity), разнообразие (Variety) и достоверность (Veracity) данных;Проблемы с большими данными;2
Что такое eventual consistency и в каких Big Data системах она используется?;Eventual consistency - модель согласованности, где обновления eventually распространяются на все узлы, но не гарантируется немедленная консистентность. Используется в Cassandra, DynamoDB, где доступность важнее строгой консистентности.;Это когда данные eventually становятся консистентными на всех узлах, но не сразу. Используется в NoSQL базах типа Cassandra где важна высокая доступность и производительность записи.;5
Почему технологии in-memory обработка стали критически важны?;In-memory обработка помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;In-memory обработка нужно только программистам, обычным компаниям оно бесполезно.;2
Достоинства и недостатки деревьев решений;Достоинства: интерпретируемость, работа с категориальными признаками, не требуют масштабирования. Недостатки: склонность к переобучению, нестабильность, чувствительность к шуму;Плюсы и минусы деревьев;2
Основные задачи Data Analysis;К основным задачам относятся описательная аналитика, диагностика проблем, прогнозирование и прескриптивная аналитика;Data Analysis включает различные типы аналитических задач;5
Что такое кросс-валидация?;Метод оценки модели, при котором данные разбиваются на k частей, модель обучается на k-1 частях и проверяется на оставшейся части, процесс повторяется k раз.;Это когда модель проверяют несколько раз чтобы убедиться что она хорошая.;2
Как нейронные сети помогает в анализе больших объемов данных?;Нейронные сети применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Нейронные сети применяется в бизнесе и иногда в науке для анализа данных.;3
Какие стратегии использовать для оптимизации производительности Spark при работе с большими данными?;Кэширование часто используемых DataFrame, правильное партиционирование данных, использование broadcast join для маленьких таблиц, настройка памяти исполнителей, выбор оптимального формата хранения.;Кэшировать данные которые используются многократно, правильно партиционировать по ключам joins, использовать broadcast join для небольших таблиц, настроить память executor'ов и использовать эффективные форматы типа Parquet.;5
Почему организации переходят на технологии системы логирования?;Системы логирования помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Системы логирования обеспечивает анализ потоковых данных, улучшает прогнозирование, помогает автоматизировать процессы и повышает точность аналитических моделей.;5
Что такое Big Data и каковы её основные характеристики?;Big Data — это технологии и методы обработки чрезвычайно больших объёмов данных, характеризующихся 5V: Volume, Velocity, Variety, Veracity, Value. Применяются в финансах, здравоохранении, промышленности.;Big Data — это совокупность методов и технологий обработки огромных объемов разнородных данных с учетом характеристик 5V.;5
Примеры использования гистограммы;Гистограммы применяются для анализа распределения яркости в обработке изображений, контроля качества в производстве через анализ распределения параметров продукции;"Обработка изображений: histogram equalization для улучшения контраста; контроль качества: анализ распределения размеров деталей для выявления отклонений";4
Разница между линейной и логистической регрессией;Линейная регрессия моделирует непрерывные количественные зависимости между переменными, тогда как логистическая регрессия предсказывает вероятности бинарной или мультиклассовой классификации с использованием сигмоидной функции;Линейная регрессия моделирует непрерывные зависимости, логистическая предсказывает вероятности классификации;5
Меры качества для языковых моделей;Perplexity, BLEU, ROUGE - основные метрики оценки качества языковых моделей и переводов;Perplexity для языковых моделей, BLEU для машинного перевода;3
Что такое Kubernetes?;Оркестратор контейнеров для автоматизации развертывания и управления приложениями.;Система для управления контейнерами, которая автоматизирует развертывание, масштабирование и отказоустойчивость контейнерных приложений в кластере.;4
Что такое word embeddings и какие модели используются для их создания?;Word embeddings - векторные представления слов, создаваемые моделями word2vec, GloVe, fastText, которые capture семантические и синтаксические отношения между словами;Векторные представления слов;2
Как data warehouses влияет на эффективность бизнеса?;Технологии data warehouses позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Data warehouses нужно только программистам, обычным компаниям оно бесполезно.;2
Как обеспечивается отказоустойчивость в Kafka;Через репликацию партиций на несколько брокеров. Одна реплика является лидером для чтения/записи, остальные — followers. При падении лидера одна из реплик становится новым лидером.;Отказоустойчивость достигается за счет репликации: каждая партиция имеет несколько реплик на разных брокерах, и при сбое одного брокера его реплики продолжают работать на других узлах.;3
Какие методы использовать для обработки временных рядов с пропущенными значениями?;Интерполяция (линейная, сплайн), forward/backward fill, статистические методы (скользящее среднее), ML методы (ARIMA, Prophet). Выбор зависит от природы пропусков и требований к точности.;Способы заполнения пропусков в данных с временными метками.;2
Какие методы использовать для балансировки классов в задачах классификации с сильным дисбалансом?;Oversampling (SMOTE), undersampling, изменение весов классов в функции потерь, использование алгоритмов устойчивых к дисбалансу, ансамблирование.;SMOTE, undersampling, взвешивание классов, устойчивые алгоритмы, ансамбли. Выбирать based on объема данных и важности редкого класса.;4
Что такое data governance в Big Data?;Управление доступностью, usability, integrity и security данных в организации;Управление данными;2
Принцип работы SVM;Метод опорных векторов находит гиперплоскость с максимальным зазором для разделения классов в пространстве признаков;SVM находит гиперплоскость с зазором;4
Где применяется предиктивная аналитика в промышленности и бизнесе?;Предиктивная аналитика помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Предиктивная аналитика применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;5
Когда использовать Spark вместо Pandas для обработки данных?;Spark когда данные не помещаются в память одного компьютера или нужна распределенная обработка. Pandas для данных, которые fit in memory и не требуют распределенных вычислений.;Spark быстрее для больших данных, Pandas проще в использовании.;2
В каких областях деятельности используются большие данные, привести примеры;Большие данные используются в финансах (обнаружение мошенничества), ритейле (рекомендательные системы), здравоохранении (персонализированная медицина), транспорте (оптимизация маршрутов) и социальных сетях.;Использование в финансах, ритейле, здравоохранении и транспорте;4
Что такое статистическая гипотеза;Статистическая гипотеза представляет собой формальное проверяемое предположение о свойствах генеральной совокупности или параметрах распределения, которое может быть подтверждено или опровергнуто с помощью статистических методов тестирования;Статистическая гипотеза это формальное предположение о свойствах данных для проверки;5
Какие инструменты используются для работы с data lakes?;Data lakes помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Data lakes нужно только программистам, обычным компаниям оно бесполезно.;2
Разновидности сложных сетей;Сложные сети можно классифицировать на однородные, масштабно-инвариантные, сети малого мира и иерархические структуры, каждая из которых обладает уникальными свойствами и характеристиками;Основные типы сетевых структур с различными свойствами связности и распределения;2
Как понимать «уровень статистической достоверности»? Это ли вероятность ошибки?;Уровень статистической достоверности (p-value) показывает вероятность того, что наблюдаемый эффект возник случайно. Чем меньше p-value, тем выше достоверность результата. Он не равен вероятности ошибки напрямую, но связан с ней через уровень значимости ?.;Это вероятность того, что результат получен случайно.;3
Что такое attention mechanism в нейронных сетях и где применяется?;Attention mechanism позволяет нейронной сети фокусироваться на важных частях входных данных, широко применяется в машинном переводе, обработке изображений и текста;Attention mechanism позволяет фокусироваться на важных частях входных данных;5
Какие реальные примеры использования системы логирования существуют?;Системы логирования помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Технологии системы логирования позволяют компаниям обрабатывать большие объёмы разнородных данных, выявлять сложные закономерности и принимать обоснованные решения.;5
Как машинное обучение помогает в анализе больших объемов данных?;Машинное обучение используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;5
Понятие корреляции, коэффициент корреляции Пирсона, Спирмена, Кендела.;Корреляция — статистическая мера связи между переменными. Коэффициент Пирсона измеряет линейную зависимость (r = cov(X,Y)/(?X?Y)), Спирмена — ранговую, Кендела — степень согласованности пар.;Корреляция — статистическая зависимость между величинами. Коэффициент Пирсона оценивает линейную зависимость, Спирмена — монотонную, Кендела — степень согласованности рангов.;4
Что такое метод опорных векторов (SVM)?;Метод опорных векторов — это алгоритм классификации, который ищет гиперплоскость, максимально разделяющую данные разных классов.;SVM — это метод, который разделяет данные на классы при помощи границы, называемой гиперплоскостью.;5
Как развивается направление предобработка данных в последние годы?;Технологии предобработка данных позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Предобработка данных применяется в некоторых компаниях для анализа данных.;3
Как мониторинг больших данных влияет на эффективность бизнеса?;Технологии мониторинг больших данных позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Мониторинг больших данных используется бизнесом для оптимизации процессов, анализа клиентов и прогнозирования.;4
Какие реальные кейсы демонстрируют эффективность классификация данных?;Классификация данных применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Это просто работа с таблицами. Не очень полезно.;2
Преобразование и очистка данных;Процесс преобразования включает нормализацию, кодирование категориальных переменных, обработку пропущенных значений и выбросов для улучшения качества данных;Очистка от шума, преобразование типов данных, работа с пропусками и аномалиями;3
Как оптимизировать data shuffling в распределенных вычислениях?;Minimize shuffling, use broadcast variables, optimize partitioning, use accumulators для агрегаций, filter early, use efficient serialization.;Минимизация shuffling'а, broadcast переменные, оптимизация партиционирования, аккумуляторы. Ранняя фильтрация и эффективная сериализация.;5
Какие навыки необходимы специалисту для работы с рекомендательные системы?;Рекомендательные системы используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Рекомендательные системы нужно только программистам.;2
Что такое Apache Kafka и для чего используется?;Распределенная потоковая платформа для обработки данных в реальном времени. Используется для построения data pipelines, event-driven архитектур, streaming приложений.;Инструмент для работы с потоками событий в реальном времени. Для сбора и обработки непрерывных данных.;3
Интегральные метрики качества;К интегральным метрикам относятся ROC-AUC, Precision-Recall AUC, F1-score и R?, которые агрегируют различные аспекты качества модели в единый показатель;Обобщенные показатели которые объединяют несколько аспектов производительности модели;2
Как проектировать data pipeline для обработки данных с разной latency требованиями?;Lambda architecture, multi-tier processing, priority queues, separate pipelines для real-time и batch, resource allocation based on SLA.;Архитектура поддерживающая разные требования к скорости обработки данных.;3
Какие навыки необходимы специалисту для работы с классификация данных?;Классификация данных применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;4
Какие основные инструменты используются для аналитики больших данных и их сравнение?;Hadoop (HDFS, MapReduce) для хранения и пакетной обработки, Spark для in-memory вычислений, Kafka для потоковой обработки, NoSQL БД для неструктурированных данных. Сравнение по производительности, масштабируемости, use cases.;Hadoop для batch processing больших объемов, Spark для быстрой обработки в памяти, Kafka для real-time потоков, Cassandra для NoSQL. Каждый инструмент оптимизирован под конкретные задачи и объемы данных.;5
Преимущества и недостатки непараметрических моделей;Непараметрические модели обладают гибкостью, но требуют значительных вычислительных ресурсов и объемов данных;Непараметрические модели гибкие но требуют много вычислительных ресурсов;5
Алгоритмы классификации;Основные алгоритмы включают логистическую регрессию, деревья решений, случайный лес, SVM и наивный байесовский классификатор;Logistic Regression, Decision Trees алгоритмы;3
В чем преимущества применения предиктивная аналитика по сравнению с традиционными методами?;Предиктивная аналитика применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;5
Что такое Feature Store и как он решает проблемы consistency между training и serving?;Централизованное хранилище признаков с гарантией идентичности фич при обучении и инференсе. Решает проблемы training-serving skew, обеспечивает версионирование и переиспользование фич.;Хранилище для управления ML признаками. Обеспечивает консистентность фич между тренировкой и продакшн, решая проблему расхождений в данных.;4
Как обрабатывать выбросы (outliers) в данных перед построением ML модели?;Анализировать природу выбросов: удалять если это ошибки измерения, использовать robust методы если это реальные значения, трансформировать данные, применять алгоритмы устойчивые к выбросам.;Убирать аномальные значения из данных перед обучением.;2
Что такое 'дерево решений'?;Дерево решений — это модель, которая представляет процесс принятия решений в виде иерархии правил, ведущих от корня к листьям.;Это алгоритм, в котором строится структура из узлов и ветвей, чтобы классифицировать данные.;4
Какие реальные примеры использования обработка потоковых данных существуют?;Обработка потоковых данных используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Это что?то связанное с данными, но используется редко.;2
Что такое обучение с учителем и как оценивается качество модели?;Обучение с учителем — это метод, при котором модель обучается на размеченных данных. Качество оценивается метриками: Accuracy, Precision, Recall, F1-score.;Обучение с учителем использует размеченные данные, качество оценивают по Accuracy, Precision и другим метрикам.;5
Почему организации переходят на технологии кластеризация данных?;Кластеризация данных помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Кластеризация данных обеспечивает анализ потоковых данных, улучшает прогнозирование, помогает автоматизировать процессы и повышает точность аналитических моделей.;5
Какие проблемы возникают при использовании обработка потоковых данных?;Технологии обработка потоковых данных позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Обработка потоковых данных обеспечивает анализ потоковых данных, улучшает прогнозирование, помогает автоматизировать процессы и повышает точность аналитических моделей.;5
Какие подходы использовать для оптимизации памяти в Python при обработке больших данных?;Использование генераторов, efficient data structures, memory mapping, chunk processing, удаление неиспользуемых объектов, использование специализированных библиотек.;Генераторы вместо списков, эффективные структуры данных, memory mapping, обработка чанками, удаление объектов. Специализированные библиотеки для работы с памятью.;5
Виды распределения данных и примеры;Распределения бывают разные.;Например, когда значения близки к среднему.;3
Что такое переобучение (overfitting)?;Ситуация, когда модель слишком точно подстраивается под тренировочные данные, включая их шум, теряя способность к обобщению на новых данных.;Модель демонстрирует высокую точность на обучающих данных, но плохо работает на новых, потому что выучила шум и частные случаи, а не общие закономерности.;5
Как оптимизировать хранение sparse данных в колоночных форматах?;Использование efficient encoding для sparse колонок, compression algorithms, отказ от хранения null значений, специализированные форматы для sparse матриц.;Эффективное кодирование sparse колонок, алгоритмы сжатия, исключение null значений. Специализированные форматы для разреженных данных.;5
Что такое дисперсия данных и что она показывает?;Дисперсия — это мера разброса данных относительно среднего значения. Вычисляется как среднее квадратов отклонений: D = ?(xi - ?)^2 / n.;Дисперсия показывает степень изменчивости данных относительно среднего.;4
Где применяется рекомендательные системы в промышленности и бизнесе?;Рекомендательные системы помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Помогает работать с данными и строить модели.;3
Как кластеризация данных влияет на эффективность бизнеса?;Технологии кластеризация данных позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Кластеризация данных применяется в некоторых компаниях для анализа данных.;3
Свойства описательных статистик;Меры центральной тенденции, меры изменчивости и показатели формы распределения данных;Средние значения, разброс данных и форма распределения;3
В чем разница между batch processing и stream processing?;Batch processing обрабатывает данные пачками с задержкой, stream processing обрабатывает данные в реальном времени по мере поступления.;Batch для данных которые накопились, stream для непрерывных данных. Разные подходы для разных требований к задержке.;4
Назовите характеристики качества данных.;К характеристикам качества данных относятся полнота, точность, актуальность, непротиворечивость, целостность и доступность.;Характеристики качества: точность, полнота, непротиворечивость.;4
Что такое Zero-shot и Few-shot learning в современных LLM и как они работают?;Способность моделей выполнять задачи без явного обучения (zero-shot) или с немногими примерами (few-shot). Работает через prompting и использование знаний полученных при претренинге.;Модели решают новые задачи без дополнительного обучения (zero-shot) или с 1-5 примерами (few-shot). Основано на способности больших языковых моделей обобщать знания из претренинга.;5
Какие реальные примеры использования кластеризация данных существуют?;Технологии кластеризация данных позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Кластеризация данных применяется в некоторых компаниях для анализа данных.;3
Как обрабатывать пропущенные значения в данных перед обучением модели?;Зависит от природы пропусков: удаление строк если мало пропусков, импутация средним/медианой для числовых, модой для категориальных, либо использование алгоритмов, поддерживающих пропуски.;Заполнить пропуски средним для чисел и модой для категорий. Или удалить строки с пропусками если их немного.;3
Как бороться с переобучением в глубоких нейронных сетях?;Dropout, batch normalization, early stopping, регуляризация L1/L2, data augmentation, уменьшение сложности сети, увеличение данных.;Dropout, batch norm, early stopping. Увеличить данные через augmentation или собрать больше. Упростить архитектуру если сеть слишком глубокая.;4
Что такое data product в data mesh?;Самодостаточный набор данных с гарантиями качества и интерфейсами для потребления;Данные как продукт;2
Понятия репликации и шардинга;Репликация - копирование данных для отказоустойчивости, шардинг - горизонтальное разделение;Репликация обеспечивает доступность, шардинг - масштабируемость;4
Какие проблемы возникают при использовании мониторинг больших данных?;Технологии мониторинг больших данных позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Мониторинг больших данных широко применяется в промышленности, здравоохранении, финансах и государственных системах. Позволяет анализировать большие массивы данных, строить точные модели и улучшать эффективность процессов.;5
Что такое attention mechanism в нейронных сетях и где применяется?;Attention mechanism позволяет нейронной сети фокусироваться на важных частях входных данных, широко применяется в машинном переводе, обработке изображений и текста;Механизм внимания в нейросетях;2
Что такое нейронные сети с резкими связями (ResNet)?;Архитектура CNN с skip-connections для решения проблемы исчезающего градиента в глубоких сетях.;ResNet использует residual connections которые пропускают один или несколько слоев, позволяя градиентам проходить напрямую и enabling обучение очень глубоких сетей без degradation точности.;5
Что такое регуляризация в машинном обучении?;Метод предотвращения переобучения путем добавления штрафа за сложность модели к функции потерь.;Регуляризация добавляет штрафной член к функции потерь, который ограничивает рост весов модели, тем самым снижая ее сложность и предотвращая переобучение.;5
Принципы глубокого обучения в нейросетях;Глубокое обучение использует многослойные нейронные сети для автоматического извлечения признаков из данных, CNN специализируются на обработке изображений с помощью сверточных слоев;Нейросети с большим количеством слоев для сложных задач анализа данных;2
Что такое feature engineering?;Процесс создания и отбора признаков для улучшения качества моделей машинного обучения.;Feature engineering включает создание, преобразование и отбор признаков на основе предметной области для повышения эффективности и интерпретируемости моделей машинного обучения.;5
Что понимают под переобучением модели?;Переобучение — это ситуация, когда модель слишком точно подстраивается под обучающую выборку, теряя способность обобщать знания на новые данные.;Модель работает хорошо только на обучающих данных.;3
Какие навыки необходимы специалисту для работы с data mining?;Data mining используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Data mining применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;4
Когда использовать линейные, а когда нелинейные модели?;"Линейные - при линейных зависимостях, нелинейные - при сложных паттернах; выбор через анализ остатков";Выбор между линейными и нелинейными моделями;4
Меры качества для языковых моделей;Основные меры качества включают перплексию для оценки модели, BLEU для машинного перевода, ROUGE для суммаризации и метрики точности;Метрики качества: perplexity, BLEU score, ROUGE для языковых моделей;4
Где применяется модели прогнозирования в промышленности и бизнесе?;Модели прогнозирования используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;4
Что такое переобучение модели?;Переобучение — это ситуация, когда модель слишком точно подстраивается под обучающие данные и теряет способность обобщать закономерности. Основные признаки — высокая точность на обучающей выборке и низкая на тестовой.;Переобучение — это когда модель плохо обучилась.;2
Что такое retention period;Retention period — это время, в течение котором сообщения хранятся в Kafka до удаления. Может задаваться по времени или по размеру данных.;Retention policy определяет продолжительность хранения сообщений в партициях топика до их удаления, что позволяет управлять использованием дискового пространства и соответствовать требованиям compliance.;4
Перечислить стадии разработки систем машинного обучения;Сбор и обработка данных, обучение модели.;Нужно собрать данные и обучить модель.;4
Охарактеризовать конструкции языка R.;Конструкции языка R включают присваивание (<-), условные выражения (if, else), циклы (for, while), функции (function()), и обращения к элементам вектора с помощью [].;В R есть циклы и условия, можно писать скрипты.;3
Где применяется анализ данных в промышленности и бизнесе?;Анализ данных используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Это просто работа с таблицами. Не очень полезно.;2
Шаги построения дендрограммы;Построение дендрограммы включает вычисление матрицы расстояний, применение агломеративного алгоритма кластеризации и визуализацию иерархической структуры слияния кластеров;Процесс создания древовидной диаграммы для отображения результатов иерархической кластеризации данных;2
Как хранилища данных влияет на эффективность бизнеса?;Технологии хранилища данных позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Хранилища данных применяется в некоторых компаниях для анализа данных.;3
Охарактеризовать конструкции языка R;Язык R предоставляет векторы для атомарных данных, матрицы для двумерных массивов, списки для гетерогенных коллекций, фреймы данных для табличной организации и факторы для категориальных переменных;Векторы, матрицы, списки, фреймы в R;3
Что такое Apache Spark SQL?;Модуль Spark для работы со структурированными данными с использованием SQL-подобного синтаксиса.;Инструмент для запросов к данным в экосистеме Spark.;2
Что такое статистическая гипотеза;Статистическая гипотеза представляет собой формальное проверяемое предположение о свойствах генеральной совокупности или параметрах распределения, которое может быть подтверждено или опровергнуто с помощью статистических методов тестирования;Формальное предположение о параметрах распределения, подвергаемое статистической проверке;4
Что такое data catalog?;Централизованный реестр метаданных для обнаружения и понимания данных;Каталог содержащий метаданные о всех данных в организации для их поиска и понимания;5
Какие реальные примеры использования масштабируемые системы существуют?;Технологии масштабируемые системы позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Масштабируемые системы применяется в некоторых компаниях для анализа данных.;3
Data Mining vs. Machine Learning — в чём отличия?;Data Mining фокусируется на обнаружении паттернов в данных, а Machine Learning - на построении прогнозных моделей;DM - поиск паттернов, ML - прогнозирование;3
Характерные черты безмасштабных сетей;Безмасштабные сети имеют степенное распределение степеней узлов, содержат хабы и демонстрируют устойчивость к случайным отказам но уязвимы к целевым атакам;Характеризуются степенным законом распределения P(k) ~ k^(-?) где 2<?<3, содержат немного highly connected хабов и много слабо связанных узлов, обладают свойством robustness against random failures но sensitive to targeted attacks on hubs, демонстрируют small-world эффект с короткими средними путями;5
Что такое data product в data mesh?;Самодостаточный набор данных с гарантиями качества и интерфейсами для потребления;Продукт на основе данных;3
Какие навыки необходимы специалисту для работы с рекомендательные системы?;Рекомендательные системы используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Рекомендательные системы применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;4
Какие методы используются для обработки временных рядов?;Для временных рядов применяются ARIMA, экспоненциальное сглаживание, методы на основе машинного обучения (LSTM, Prophet) и анализ трендов/сезонности;Анализ последовательных данных во времени;2
Что такое gradient boosting?;Метод машинного обучения, где несколько слабых моделей (обычно деревья) последовательно обучаются, каждая новая модель исправляет ошибки предыдущих.;Это сложный алгоритм для предсказаний, который работает лучше чем простые методы.;2
В чем преимущества применения рекомендательные системы по сравнению с традиционными методами?;Рекомендательные системы применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Рекомендательные системы — это что-то про компьютеры. Применяется редко.;2
Почему организации переходят на технологии ETL-пайплайны?;Технологии ETL-пайплайны позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Etl-пайплайны широко применяется в промышленности, здравоохранении, финансах и государственных системах. Позволяет анализировать большие массивы данных, строить точные модели и улучшать эффективность процессов.;5
Что такое 'кластеризация'?;Кластеризация — это процесс разделения множества объектов на группы (кластеры) так, чтобы объекты внутри одной группы были похожи, а между группами — различались.;Это метод анализа, где данные делят на части по похожим свойствам.;4
Что такое Vector Database и для каких задач она оптимальна?;Специализированная БД для хранения и поиска векторных эмбеддингов. Оптимальна для semantic search, рекомендательных систем, similarity search в больших наборах данных.;База данных для работы с векторными представлениями. Идеальна для поиска похожих items, рекомендаций, семантического поиска где важны близость в векторном пространстве.;5
Что такое 'обучение с учителем' в машинном обучении?;Обучение с учителем — это метод, при котором модель обучается на размеченных данных, где каждому входному значению соответствует известный правильный ответ.;Обучение с учителем — это процесс, когда данные имеют правильные ответы, и модель учится их предсказывать.;5
Почему организации переходят на технологии кластеризация данных?;Технологии кластеризация данных позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Технологии кластеризация данных позволяют компаниям обрабатывать большие объёмы разнородных данных, выявлять сложные закономерности и принимать обоснованные решения.;5
Факторы, влияющие на коэффициент корреляции;На корреляцию влияют выбросы, нелинейность связи, гетерогенность данных, размер выборки и наличие скрытых переменных;Факторы воздействия на корреляцию;4
Параметрическая модель статистического обучения;Параметрическая модель предполагает фиксированное число параметров и определенную функциональную форму зависимости между переменными в статистическом анализе;Модели с ограниченным количеством параметров и заданной структурой для анализа данных и построения прогнозов;2
Опишите процесс ETL и его этапы.;ETL (Extract, Transform, Load) — это процесс извлечения данных из источников, их преобразования в нужный формат и загрузки в целевое хранилище. Основные этапы: Extract, Transform, Load.;ETL — это загрузка данных из источников.;3
Где применяется ETL-процессы в промышленности и бизнесе?;Etl-процессы помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Etl-процессы применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;5
Данные, информация, знания – в чем отличия?;Данные — это необработанные факты и измерения. Информация — это данные, прошедшие интерпретацию. Знания — это результат анализа информации, ведущий к принятию решений. Пример: данные — цифры продаж, информация — динамика продаж, знание — вывод о сезонности спроса.;Данные, информация и знания — это одно и то же, просто разные слова.;2
Принципы глубокого обучения в нейросетях;Глубокое обучение основано на использовании нейронных сетей с множеством скрытых слоев, которые позволяют автоматически извлекать иерархические признаки из данных. Сверточные нейронные сети (CNN) специально разработаны для обработки изображений через применение сверточных фильтров и операций пулинга;Многослойные нейронные сети обеспечивают автоматическое извлечение признаков разного уровня абстракции, а CNN оптимизированы для работы с пространственными данными через сверточные операции;5
Как data warehouses применяется в современных компаниях?;Data warehouses используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Data warehouses широко применяется в промышленности, здравоохранении, финансах и государственных системах. Позволяет анализировать большие массивы данных, строить точные модели и улучшать эффективность процессов.;5
Мотивация происхождения NoSQL.;NoSQL возник как ответ на ограниченность реляционных баз в масштабируемости и гибкости. Цель — работа с неструктурированными и распределёнными данными, высокая производительность и горизонтальное масштабирование.;NoSQL создан для повышения масштабируемости и отказа от жёстких схем SQL.;4
Структуры и типы данных в R;Основные структуры включают векторы, матрицы, списки, фреймы данных и факторы для различных типов данных;Разные структуры хранения данных в R;3
Обучение с подкреплением и ансамбли;Обучение с подкреплением основано на взаимодействии агента со средой для максимизации награды, а ансамбли объединяют несколько моделей для улучшения прогнозирования;RL и ансамблевые методы имеют разные подходы;3
Назовите и поясните меры качества для языковых моделей.;Меры: Perplexity = exp(-1/N * ? log P(w_i)), BLEU (оценка совпадений n-грамм с эталоном), ROUGE (recall на уровне фраз), METEOR (комбинация точности и полноты).;BLEU — метрика для сравнения текстов.;3
Метрики качества для моделей регрессии;Основные метрики включают RMSE, MAE, MAPE и R? для оценки точности регрессионных моделей и их предсказательной способности;Показатели точности предсказаний и качества подгонки модели;4
Принципы и инструменты аналитики Big Data;Аналитика больших данных основана на принципах распределенной обработки, использования специализированных фреймворков и облачных технологий для работы с большими объемами информации;"Принципы: горизонтальное масштабирование, отказоустойчивость, параллельная обработка; инструменты: Hadoop ecosystem, Spark, Kafka, облачные платформы";4
В чем разница между параметрами и гиперпараметрами модели?;Параметры настраиваются автоматически в процессе обучения на данных (веса модели). Гиперпараметры задаются до обучения и управляют самим процессом обучения (скорость обучения, глубина дерева).;Параметры настраиваются моделью на данных, а гиперпараметры задаются до обучения и влияют на то, как модель учится.;4
Что такое рекомендательные системы и какие задачи оно решает?;Рекомендательные системы используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Рекомендательные системы применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;4
Обучение с учителем и без учителя. Приведите примеры методов.;Supervised learning использует размеченные данные, примеры: линейная регрессия, логистическая регрессия, SVM. Unsupervised learning использует неразмеченные данные, примеры: k-means, PCA, иерархическая кластеризация.;Supervised — это когда есть метки, unsupervised — когда их нет.;4
Как нейронные сети применяется для автоматизации рутинных процессов?;Нейронные сети используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Нейронные сети — это что-то про компьютеры. Применяется редко.;2
NoSQL классификация хранилищ;NoSQL базы данных классифицируются на документные, хранилища ключ-значение, колоночные и графовые в зависимости от модели данных и способа организации хранения;Документные БД хранят JSON-документы, key-value пары, колоночные семейства и графовые структуры с узлами и связями;3
Какие признаки создавать для временных рядов при feature engineering?;Лаги, скользящие статистики (mean, std), временные характеристики (час, день недели), фичи из Fourier transform, difference.;Лаги, скользящие средние, время дня, день недели, праздничные дни. Статистики за последние периоды и сезонные паттерны.;4
Обучение с подкреплением и ансамбли — основные разновидности и принципы;Обучение с подкреплением включает Q-learning и политические градиенты, ансамбли используют бэггинг, бустинг и стэкинг для улучшения предсказательной способности моделей;Обучение с подкреплением включает Q-learning, ансамбли используют бэггинг и бустинг;5
Сколько данных лучше взять для обучения — побольше или поменьше?;"Количество данных для обучения должно быть достаточным для генерализации модели. Однако избыточные данные при низком качестве не повышают точность. Оптимальный объем зависит от сложности задачи и модели.,""Для обучения лучше взять как можно больше данных, чем больше";тем лучше.;2
Опишите основные компоненты Hadoop.;Hadoop состоит из HDFS (Hadoop Distributed File System) для хранения данных и MapReduce для их параллельной обработки. Также включает компоненты YARN и Common для управления ресурсами и библиотек общего назначения.;Hadoop включает HDFS для хранения и MapReduce для анализа данных.;3
Меры изменчивости;К мерам изменчивости относятся дисперсия, стандартное отклонение, размах и межквартильный размах;Меры изменчивости описывают разброс значений;4
Как тестируются независимые и парные выборки?;"Независимые: t-test, Mann-Whitney; парные: paired t-test, Wilcoxon signed-rank test";Разные статистические тесты для типов выборок;4
Какие методы использовать для оптимизации JOIN операций в распределенных системах?;Broadcast join для маленьких таблиц, sort-merge join для отсортированных данных, hash join для больших таблиц, bucketing для предварительного разделения, использование статистик для выбора стратегии.;Способы ускорения операций соединения таблиц в распределенных системах.;2
Что такое word embeddings и какие модели используются для их создания?;Word embeddings - векторные представления слов, создаваемые моделями word2vec, GloVe, fastText, которые capture семантические и синтаксические отношения между словами;Модели для создания семантических представлений слов;4
Что такое data versioning?;Контроль версий для наборов данных и их метаданных;Система управления версиями для данных аналогично Git для кода;5
Алгоритмы классификации;Основные алгоритмы включают логистическую регрессию, деревья решений, случайный лес, метод опорных векторов и наивный байесовский классификатор;Logistic Regression, Decision Trees, Random Forest, SVM, k-NN, Naive Bayes - каждый с разными принципами работы;3
Какие методы борьбы с переобучением вы знаете?;Регуляризация L1/L2, dropout, early stopping, увеличение данных, упрощение модели, кросс-валидация, augmentation данных.;Регуляризация, увеличение тренировочных данных, упрощение модели, ранняя остановка обучения.;4
Охарактеризуйте хранилища OLAP и OLTP;OLTP системы оптимизированы для операционных транзакций, OLAP для аналитических запросов и отчетности;OLTP системы для транзакций, OLAP для аналитических запросов;5
Как предиктивная аналитика используется в научных исследованиях?;Предиктивная аналитика применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;5
Понятие корреляции, коэффициент корреляции Пирсона, Спирмена, Кендела.;Корреляция — статистическая мера связи между переменными. Коэффициент Пирсона измеряет линейную зависимость (r = cov(X,Y)/(?X?Y)), Спирмена — ранговую, Кендела — степень согласованности пар.;Корреляция описывает силу и направление связи между случайными переменными. Пирсон используется для линейных связей (r = cov(X,Y)/(?X?Y)), Спирмен — для ранговых зависимостей, Кендел — для оценки согласованности пар рангов.;5
Что такое transfer learning и в каких задачах он применяется?;Transfer learning - использование предобученных моделей для решения новых задач, применяется когда мало размеченных данных, особенно в компьютерном зрении и NLP;Перенос знаний между задачами машинного обучения;3
Что такое Apache HBase?;Распределенная column-oriented NoSQL база данных, построенная поверх HDFS для random read/write доступа к большим данным.;Еще одна база данных для Hadoop.;2
Виды связи между переменными при корреляции;"Положительная, отрицательная, нелинейная, ложная корреляция; сила связи от -1 до +1";Положительная и отрицательная корреляция;3
Что такое Apache Flink?;Фреймворк для распределенной обработки потоковых и пакетных данных с низкой задержкой.;Flink - это фреймворк для stateful вычислений над потоками данных с exactly-once семантикой, низкой задержкой и высокой пропускной способностью. Поддерживает как stream, так и batch обработку.;5
Как работает метод главных компонент (PCA) для снижения размерности?;PCA находит новые ортогональные оси, которые максимизируют дисперсию данных, проецируя их в пространство меньшей размерности с сохранением максимальной информации;Метод уменьшения количества признаков;2
Перечислите шкалы измерений. Приведите примеры их использования;Номинальная (пол, цвет), порядковая (уровень образования), интервальная (температура), относительная (вес, доход);Шкалы измерений с примерами;4
Что такое ROC-кривая?;ROC-кривая — это график зависимости True Positive Rate от False Positive Rate, используемый для оценки качества бинарного классификатора.;ROC — это метрика качества модели.;2
Факторы, влияющие на коэффициент корреляции;На коэффициент корреляции влияют выбросы, нелинейность связи, размер выборки, гетерогенность данных и наличие скрытых переменных;Выбросы, нелинейность и размер данных влияют на корреляцию;3
Какие метрики использовать для оценки несбалансированной бинарной классификации?;Precision, Recall, F1-score, ROC-AUC, PR-AUC. Accuracy не подходит, так как может быть обманчиво высоким при дисбалансе классов.;Метрики которые учитывают оба класса, не только общую точность.;2
Как кластеризация данных применяется в современных компаниях?;Кластеризация данных используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Кластеризация данных обеспечивает анализ потоковых данных, улучшает прогнозирование, помогает автоматизировать процессы и повышает точность аналитических моделей.;5
Как тестируются независимые и парные выборки?;"Независимые: t-test, Mann-Whitney; парные: paired t-test, Wilcoxon signed-rank test";Тесты для разных выборок;2
Сколько данных лучше взять для обучения: побольше или поменьше?;Объем данных для обучения должен быть достаточным для репрезентативности, но важнее качество данных. Для сложных моделей требуется больше данных, но необходим баланс с вычислительными ресурсами.;Зависит от задачи;2
Что такое переобучение (overfitting) и как его предотвратить?;Модель слишком точно подстраивается под тренировочные данные и плохо работает на новых. Методы предотвращения: регуляризация, кросс-валидация, упрощение модели, увеличение данных.;Модель работает идеально на тренировочных данных но плохо на тестовых. Решение: регуляризация, валидация, сбор больше данных, упрощение модели.;4
Как организовать feature engineering для NLP задач с большими текстовыми данными?;TF-IDF, word embeddings (Word2Vec, GloVe), contextual embeddings (BERT), character-level features, topic modeling (LDA), syntactic features (POS tagging).;Способы преобразования текста в признаки для машинного обучения.;2
Что такое data drift?;Изменение распределения входных данных со временем, ухудшающее качество модели.;Изменение характеристик входных данных с течением времени, из-за которого модель начинает работать хуже.;3
Что такое переобучение (overfitting) и как его предотвратить?;Модель слишком точно подстраивается под тренировочные данные и плохо работает на новых. Методы предотвращения: регуляризация, кросс-валидация, упрощение модели, увеличение данных.;Когда модель запоминает шум в данных вместо общих закономерностей. Борьба: регуляризация, validation set, упрощение модели, сбор больше данных, dropout для нейросетей.;5
Что означает термин 'переподгонка' (overfitting)?;Переподгонка — это ситуация, когда модель слишком хорошо запоминает обучающую выборку, теряя способность обобщать на новых данных.;Переподгонка — это когда модель слишком точно подстроена под данные.;4
Что такое feature engineering?;Процесс создания и отбора признаков для улучшения качества моделей машинного обучения.;Подготовка данных для машинного обучения через создание признаков.;3
Что такое ETL-процессы и какие задачи оно решает?;Etl-процессы применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Etl-процессы применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;5
Как обеспечить консистентность данных в распределенной системе при сетевых разделах?;Использовать consensus алгоритмы (Raft, Paxos), кворумные операции, конфликтующее разрешение на основе временных меток или векторов версий, eventual consistency с механизмами согласования.;Способы поддержания целостности данных при проблемах с сетью в распределенных системах.;2
Назовите и поясните метрики качества для компьютерного зрения.;Используются метрики IoU = (S ? P) / (S ? P), mAP (mean Average Precision), Pixel Accuracy, Dice = 2|A ? B| / (|A| + |B|).;mAP — это какая-то точность для фото.;2
Виды неопределённости в анализе данных;Источники неопределенности включают ошибки измерений, sampling variability, model uncertainty и epistemic uncertainty due to limited knowledge;Aleatoric uncertainty (неустранимый шум в данных), epistemic uncertainty (ограниченность знаний о системе), ошибки измерения, смещения выборки, неопределенность спецификации модели;5
Какие интегральные метрики качества вы знаете?;ROC-AUC, Precision-Recall AUC, F1-score, R? - метрики, агрегирующие различные аспекты качества моделей;Обобщенные метрики оценки;2
Наивный байесовский алгоритм;Наивный байесовский классификатор основан на теореме Байеса и предполагает условную независимость признаков при заданном классе для упрощения вычислений апостериорных вероятностей;"Основан на формуле Байеса с ""наивным"" предположением о независимости признаков";4
Какие инструменты используются для работы с in-memory обработка?;Технологии in-memory обработка позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Технологии in-memory обработка позволяют компаниям обрабатывать большие объёмы разнородных данных, выявлять сложные закономерности и принимать обоснованные решения.;5
Какие реальные кейсы демонстрируют эффективность ETL-процессы?;Etl-процессы помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Etl-процессы применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;5
Что такое learning rate в градиентном спуске?;Гиперпараметр, определяющий размер шага на каждой итерации градиентного спуска. Слишком высокий learning rate может привести к расходимости, слишком низкий - к медленной сходимости или застреванию в локальных минимумах.;Настройка которая влияет на скорость обучения нейронной сети.;3
Обучение с учителем и без учителя;"С учителем: классификация и регрессия с размеченными данными; без учителя: кластеризация и анализ без меток";"С учителем: алгоритмы с известными ответами; без учителя: поиск закономерностей";4
Как работает механизм shuffle в Spark?;Перераспределение данных между партициями при операциях типа groupBy или join. Включает сортировку, хэширование и сетевую передачу данных между узлами.;Механизм перераспределения данных между узлами при операциях требующих группировки или соединения данных.;4
Разница между линейной и логистической регрессией;Линейная регрессия предсказывает непрерывные числовые значения, тогда как логистическая регрессия предсказывает вероятности бинарной или мультиклассовой классификации с использованием сигмоидной функции активации;Линейная регрессия предсказывает непрерывные значения, логистическая - вероятности классификации;5
Что такое Feature Store и как он решает проблемы consistency между training и serving?;Централизованное хранилище признаков с гарантией идентичности фич при обучении и инференсе. Решает проблемы training-serving skew, обеспечивает версионирование и переиспользование фич.;Компонент MLOps для централизованного управления признаками. Гарантирует одинаковые данные для обучения и инференса моделей.;3
Примеры задач с большими графов;Социальные сети, рекомендательные системы, биоинформатика, транспортные сети, веб-графы;Большие графы используются в социальных сетях и рекомендациях;5
Что такое data replication в распределенных системах?;Создание копий данных на разных узлах для обеспечения отказоустойчивости и доступности;Резервное копирование в распределенных системах;2
Как кластеризация применяется для автоматизации рутинных процессов?;Кластеризация применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Кластеризация нужно только программистам.;2
Что такое Apache Spark и в чем его преимущество перед Hadoop MapReduce?;Это фреймворк для распределенной обработки больших данных. Ключевое преимущество — выполнение операций в оперативной памяти (in-memory), что значительно ускоряет итерационные алгоритмы и интерактивную аналитику по сравнению с дисковыми операциями MapReduce.;Spark быстрее MapReduce, потому что работает с данными в памяти, а не постоянно записывает их на диск. Это ускоряет машинное обучение и аналитику.;4
Что такое Data Mesh;Data Mesh — это децентрализованная архитектура управления данными, где данные организованы по доменам с владельцами и стандартизированными интерфейсами.;Децентрализованный подход к управлению данными по бизнес-доменам;4
В чем разница между SQL и NoSQL базами данных?;SQL базы реляционные, с жесткой схемой, используют SQL для запросов. NoSQL - нереляционные, с гибкой схемой, горизонтально масштабируемые.;SQL - это реляционные базы, а NoSQL - нереляционные. У них разный подход к хранению данных.;3
Какие компании активно используют классификация данных и зачем?;Классификация данных используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Используется для прогнозов и анализа информации.;3
Стандарты жизненного цикла Big Data: CRISP?DM;CRISP-DM включает этапы бизнес-понимания, понимания данных, подготовки, моделирования, оценки и внедрения;CRISP-DM включает этапы от бизнес-понимания до внедрения;5
Генеральная совокупность и выборка;Генеральная совокупность включает все объекты исследования, выборка является ее представительной частью;Генеральная совокупность это все объекты исследования;5
Какие компании активно используют обработка данных и зачем?;Обработка данных применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;5
Что означает дисперсия выборки?;Дисперсия выборки — это мера разброса значений относительно среднего. Вычисляется как среднее квадратов отклонений от выборочного среднего.;Дисперсия показывает, насколько значения отличаются от среднего.;5
Почему технологии in-memory обработка стали критически важны?;In-memory обработка помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;In-memory обработка обеспечивает анализ потоковых данных, улучшает прогнозирование, помогает автоматизировать процессы и повышает точность аналитических моделей.;5
Основные вызовы больших данных;Volume, Velocity, Variety, Veracity - основные характеристики и challenges больших данных;Volume (объем), Velocity (скорость), Variety (разнообразие), Veracity (достоверность);4
Что такое confusion matrix?;Таблица для оценки классификации, показывает true/false positive/negative предсказания модели.;Confusion matrix (матрица ошибок) - это таблица 2x2, которая показывает соотношение между фактическими и предсказанными классами: True Positive, False Positive, True Negative и False Negative, позволяя оценить различные метрики качества классификации.;5
Что такое регрессионный анализ какие задачи DM можно проводить с его помощью?,;"""Регрессионный анализ — метод моделирования зависимости переменной Y от одной или нескольких переменных X. Применяется для прогнозирования, оценки влияния факторов и аппроксимации зависимостей.";Регрессия ищет зависимость между данными и предсказывает.;2
Что такое Apache Flink?;Фреймворк для распределенной обработки потоковых и пакетных данных с низкой задержкой.;Инструмент для работы с данными в реальном времени из Apache экосистемы.;2
Как оптимизировать data shuffling в распределенных вычислениях?;Minimize shuffling, use broadcast variables, optimize partitioning, use accumulators для агрегаций, filter early, use efficient serialization.;Оптимизация shuffling в кластере.;2
С какими проблемами сталкиваются при применении обработка данных, и как их решают?;Обработка данных помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Помогает работать с данными и строить модели.;3
Что такое пайплайны, бенчмарки и SOTA, как и для чего используются?;Пайплайны автоматизируют процессы обработки данных, бенчмарки устанавливают эталоны сравнения, SOTA (State-of-the-Art) представляет передовые методы в области;Инструменты в анализе данных;2
Как модели прогнозирования помогает в анализе больших объемов данных?;Модели прогнозирования помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Это просто работа с таблицами. Не очень полезно.;2
Какие компании активно используют предиктивная аналитика и зачем?;Предиктивная аналитика используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Предиктивная аналитика применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;4
Охарактеризовать конструкции языка R;Есть переменные, циклы, условия и таблицы.;R используют для анализа данных и статистики.;4
Какие методы балансировки классов в несбалансированных данных?;Для балансировки классов используются oversampling (SMOTE), undersampling, взвешивание классов и генеративные модели для создания синтетических примеров;Для балансировки используются oversampling и undersampling;5
Принципы глубокого обучения в нейросетях;Глубокое обучение использует многослойные нейронные сети для автоматического извлечения признаков из данных, CNN специализируются на обработке изображений с помощью сверточных слоев;Многослойные нейронные сети для автоматического обучения признакам, CNN для анализа визуальных данных;5
Что понимается под термином 'recall'?;Recall — это доля правильно предсказанных положительных объектов среди всех реально положительных объектов.;Recall — это точность модели.;2
Какие инструменты используются для работы с ETL-пайплайны?;Etl-пайплайны используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Эти технологии помогают работать с информацией и делать прогнозы.;3
В чем преимущества применения data mining по сравнению с традиционными методами?;Data mining используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Data mining применяется в бизнесе и иногда в науке для анализа данных.;3
Дайте сравнительный анализ алгоритмов кластеризации.;Алгоритмы делятся на иерархические (агломеративные, дивизивные), разбиения (k-means, k-medoids), плотностные (DBSCAN), вероятностные (EM), графовые (Louvain). Отличаются подходами к определению расстояния и критериям объединения.;Сравнение алгоритмов кластеризации: иерархические, плотностные и вероятностные методы различаются по способу определения расстояний.;5
Какие реальные примеры использования распределённые вычисления существуют?;Технологии распределённые вычисления позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Эти технологии помогают работать с информацией и делать прогнозы.;3
Для чего нужны гипотезы в анализе данных;Для формулировки проверяемых утверждений и статистической проверки научных предположений;Для статистической проверки теорий и принятия решений;3
Как работает механизм Adaptive Query Execution в Spark 3.0 и какие проблемы он решает?;AQE динамически переоптимизирует план запроса во время выполнения на основе реальной статистики данных. Решает проблемы ошибочных оценок размера данных, неоптимальных join стратегий и партиционирования.;AQE перестраивает план запроса на лету используя актуальную статистику. Исправляет неправильные оценки размера таблиц, выбирает лучшие стратегии join'ов и перебалансирует партиции для ускорения выполнения.;5
Какие типы join существуют в Spark и когда их использовать?;Inner join, left outer, right outer, full outer, cross join. Выбор зависит от требуемого результата и наличия данных в обеих таблицах.;Способы соединения данных из разных таблиц в Spark.;2
Как анализ данных применяется для автоматизации рутинных процессов?;Анализ данных применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Анализ данных применяется в бизнесе и иногда в науке для анализа данных.;3
Поясните алгоритм работы кластеризатора k-means.;Алгоритм k-means: 1) выбираются k центров кластеров 2) объекты распределяются по ближайшему центру  3) центры пересчитываются как средние координаты точек кластера 4) шаги повторяются до стабилизации центров. Цель — минимизация внутрикластерной дисперсии.;K-means использует центры кластеров и распределяет объекты по ним.;3
Дайте сравнительный анализ алгоритмов кластеризации.;Алгоритмы делятся на иерархические (агломеративные, дивизивные), разбиения (k-means, k-medoids), плотностные (DBSCAN), вероятностные (EM), графовые (Louvain). Отличаются подходами к определению расстояния и критериям объединения.;Алгоритмы кластеризации — это алгоритмы сортировки.;2
Метрики качества для моделей регрессии;Для оценки регрессионных моделей используются RMSE, MAE, MAPE и R? для измерения точности предсказаний;RMSE, MAE, R? метрики;3
Что такое grid search?;Метод подбора гиперпараметров через exhaustive search по заранее заданной сетке значений.;Метод перебора параметров модели. Тестирует разные комбинации гиперпараметров.;3
Как выбрать между L1 и L2 регуляризацией для линейной модели?;L1 (Lasso) лучше когда нужен отбор признаков и интерпретируемость, L2 (Ridge) когда важна стабильность и все признаки потенциально полезны. L1 обнуляет неважные веса, L2 только уменьшает их.;Оба метода помогают от переобучения. Можно попробовать оба и выбрать лучший.;2
Что такое R-squared?;Статистическая мера, показывающая долю дисперсии зависимой переменной, объясненную моделью.;Коэффициент детерминации. Показывает долю дисперсии, которую модель объясняет. Чем ближе к 1, тем лучше.;4
Как организовать мониторинг качества данных в реальном времени?;Потоковая проверка метрик качества (completeness, accuracy, consistency), автоматические алерты при отклонениях, dashboard для визуализации, интеграция с data lineage для отслеживания проблем.;Непрерывный контроль качества данных, автоматические оповещения о проблемах, визуализация состояния данных.;3
Как оценивается качество рекомендательных систем?;Для оценки рекомендательных систем используются Precision@K, Recall@K, NDCG, MAP и метрики разнообразия рекомендаций;Метрики оценки эффективности рекомендательных алгоритмов;4
Каковы закономерности динамики сложных сетей и законы распространения информации в них.;Закономерности включают рост и предпочтительное присоединение, эволюцию степени узлов, каскадные эффекты и диффузионные процессы по законам SIR и SI моделей.;Информация распространяется по связям, узлы могут передавать данные дальше.;2
Как масштабируемые системы влияет на эффективность бизнеса?;Масштабируемые системы помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Масштабируемые системы почти нигде не применяется. Это просто большие таблицы.;2
Какие проблемы возникают при использовании предобработка данных?;Предобработка данных помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Предобработка данных применяется в финансах, медицине, рекламе и IT, помогает анализировать данные и строить модели.;4
Какие проблемы возникают при использовании in-memory обработка?;Технологии in-memory обработка позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;In-memory обработка применяется в некоторых компаниях для анализа данных.;3
Алгоритмы выделения сообществ;Алгоритмы Louvain, Girvan-Newman, Label Propagation используются для обнаружения сообществ в сложных сетях на основе модульности и связности;Louvain применяет итеративную оптимизацию модульности, Girvan-Newman использует betweenness centrality для разделения графа, Label Propagation распространяет метки между соседними узлами;5
Какие метрики использовать для оценки несбалансированной бинарной классификации?;Precision, Recall, F1-score, ROC-AUC, PR-AUC. Accuracy не подходит, так как может быть обманчиво высоким при дисбалансе классов.;Для несбалансированных данных лучше использовать F1-score, precision-recall curve, ROC-AUC. Accuracy не информативен, так как модель может просто предсказывать мажоритарный класс. Важно смотреть на метрики для миноритарного класса.;5
Что такое data mesh архитектура?;Децентрализованный подход к управлению данными с domain-oriented ownership;Децентрализованный подход к данным с ответственностью по доменам;4
Как развитие компьютерное зрение влияет на будущее цифровых технологий?;Компьютерное зрение используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Это просто работа с таблицами. Не очень полезно.;2
Почему организации переходят на технологии data lakes?;Data lakes помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Технологии data lakes позволяют компаниям обрабатывать большие объёмы разнородных данных, выявлять сложные закономерности и принимать обоснованные решения.;5
Как внедрение большие данные влияет на процессы в организациях?;Большие данные используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Помогает работать с данными и строить модели.;3
Какие реальные примеры использования предобработка данных существуют?;Предобработка данных помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Технологии позволяют улучшать качество аналитики, находить закономерности и предсказывать события.;4
Где применяется большие данные в промышленности и бизнесе?;Большие данные используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Большие данные применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;5
Использование гистограммы для обработки фото;Гистограммы яркости широко применяются в обработке изображений для анализа тонального диапазона, коррекции контраста, выполнения операций выравнивания гистограммы и улучшения общего качества визуального контента;Гистограммы позволяют анализировать распределение тонов и выполнять коррекцию качества изображений;4
Данные, информация, знания – в чем отличия?;Данные — это необработанные факты и измерения. Информация — это данные, прошедшие интерпретацию. Знания — это результат анализа информации, ведущий к принятию решений. Пример: данные — цифры продаж, информация — динамика продаж, знание — вывод о сезонности спроса.;Данные — это факты, информация — обработанные данные, знания — выводы на основе информации.;4
Как развитие предиктивная аналитика влияет на будущее цифровых технологий?;Предиктивная аналитика применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Помогает работать с данными и строить модели.;3
Охарактеризовать конструкции языка R.;Конструкции языка R включают присваивание (<-), условные выражения (if, else), циклы (for, while), функции (function()), и обращения к элементам вектора с помощью [].;В R можно писать только простые команды, конструкции отсутствуют.;2
Структуры и типы данных в R;Основные структуры включают векторы, матрицы, списки, фреймы данных и факторы для различных типов данных;Типы данных в языке R;2
Что такое статистическое обучение;Статистическое обучение объединяет методы статистики и машинного обучения для построения прогнозных моделей;Методы статистики для обучения моделей;3
Какие этапы включает проект, основанный на использовании модели прогнозирования?;Модели прогнозирования применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;5
Какие показатели характеризуют качество данных?;Полнота, точность, непротиворечивость, актуальность, достоверность, уникальность, целостность, своевременность.;Хорошие данные без ошибок и пропусков.;2
Какие типы join существуют в Spark и когда их использовать?;Inner join, left outer, right outer, full outer, cross join. Выбор зависит от требуемого результата и наличия данных в обеих таблицах.;Разные виды соединения таблиц: внутреннее, левое, правое, полное внешнее. Для разных сценариев объединения данных.;3
Что такое Graph Neural Networks и для каких задач они превосходят традиционные подходы?;Нейросети для графовых данных, учитывающие связи между объектами. Превосходят в задачах с relational структурами: рекомендательные системы, drug discovery, social network analysis.;Нейросети для работы с графами. Эффективны когда данные имеют сложные связи: социальные сети, молекулярные структуры, рекомендации based on связей.;4
Как большие данные используется в научных исследованиях?;Большие данные применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Помогает работать с данными и строить модели.;3
Как масштабируемые системы применяется в современных компаниях?;Технологии масштабируемые системы позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Масштабируемые системы применяется в некоторых компаниях для анализа данных.;3
Какие алгоритмы машинного обучения относятся к обучению с учителем?;Линейная регрессия, логистическая регрессия, SVM, деревья решений, случайный лес, градиентный бустинг, k-NN, нейронные сети. Все используют размеченные данные для обучения.;Алгоритмы для задач с известными ответами: регрессия, классификация. Включают линейные модели, деревья, SVM, нейросети.;4
Что означает термин 'кластеризация'?;Кластеризация — это метод анализа данных, при котором объекты объединяются в группы (кластеры) на основе схожести признаков без использования заранее известных меток.;Кластеризация объединяет объекты, похожие по признакам.;4
Определение термина «большие данные»;Большие данные представляют собой огромные объемы разнородной информации, требующие специальных технологий обработки;Очень большие наборы данных;2
Как развивается направление мониторинг больших данных в последние годы?;Мониторинг больших данных помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Технологии позволяют улучшать качество аналитики, находить закономерности и предсказывать события.;4
Характерные черты безмасштабных сетей и связь с сетями тесного мира;Безмасштабные сети имеют степенное распределение степеней, наличие хабов, устойчивость к случайным отказам. Связаны с сетями тесного мира через высокую кластеризацию и короткие пути;Особенности сетевых структур;2
Как принято формулировать нулевую гипотезу;Нулевая гипотеза формулируется как утверждение об отсутствии статистически значимого эффекта или различий;Утверждение об отсутствии значимых различий;3
Какие риски связаны с использованием большие данные в критически важных системах?;Большие данные используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Помогает работать с данными и строить модели.;3
Data Mining vs. Machine Learning – в чем отличия?;Data Mining (DM) — это процесс извлечения закономерностей и знаний из больших массивов данных, тогда как Machine Learning (ML) — это совокупность алгоритмов, позволяющих системе обучаться на данных и делать прогнозы. DM шире по смыслу и включает ML как инструмент.;DM используется для анализа больших данных, а ML для построения обучающихся моделей ML является частью DM.;5
Измерение качества модели анализа данных;Качество моделей оценивается с помощью метрик accuracy, precision, recall, F1-score для классификации и RMSE, MAE, R? для регрессии;"Classification: accuracy, precision, recall, F1-score, ROC-AUC; Regression: RMSE, MAE, MAPE, R-squared; Clustering: Silhouette score, Davies-Bouldin";4
В чём суть алгоритмов нахождения квадратичной ошибки?;Минимизация суммы квадратов разностей между предсказанными и фактическими значениями для нахождения оптимальных параметров модели;Минимизация ошибок;2
Что такое reinforcement learning и где применяется?;Reinforcement learning - обучение с подкреплением, где агент учится через взаимодействие со средой, применяется в робототехнике, играх и рекомендательных системах;Обучение с подкреплением для задач принятия решений;4
Что такое DataOps;DataOps — это методология управления данными, которая объединяет DevOps практики с процессами работы с данными для ускорения и повышения качества аналитики.;DataOps применяет принципы DevOps к данным: автоматизацию, мониторинг и CI/CD для data pipeline;5
Какие навыки необходимы специалисту для работы с ETL-процессы?;Etl-процессы помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Etl-процессы применяется в бизнесе и иногда в науке для анализа данных.;3
Какие риски связаны с использованием рекомендательные системы в критически важных системах?;Рекомендательные системы применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;5
Что представляет собой 'обучение без учителя'?;Обучение без учителя — это метод, при котором данные не имеют заранее известных меток, и алгоритм должен самостоятельно выявлять структуры и зависимости.;Это обучение, где нет учителя, и модель учится по примерам.;3
Что такое нормализация данных?;Нормализация — это преобразование данных в единую шкалу, чтобы устранить различия в масштабе признаков. Пример: приведение значений к диапазону [0,1].;Это изменение данных.;2
Что означает термин 'переподгонка' (overfitting)?;Переподгонка — это ситуация, когда модель слишком хорошо запоминает обучающую выборку, теряя способность обобщать на новых данных.;Это когда модель не обучается вообще.;2
Каковы факторы, влияющие на коэффициент корреляции?;Коэффициент корреляции зависит от линейности данных, наличия выбросов, дисперсии, размера выборки и точности измерений.;На коэффициент корреляции влияют линейность взаимосвязи, уровень вариативности переменных, наличие аномальных наблюдений, погрешности измерений и размер выборки.;5
Что такое Data Catalog;Data Catalog — это централизованный реестр метаданных, который обеспечивает discoverability, понимание и управление данными в организации.;Единая точка доступа к метаданным с поиском, lineage и governance;5
Сравнительная характеристика R и Python;R - для статистики и визуализации, Python - универсальный с библиотеками для ML;Оба для программирования, можно анализировать данные в каждом;2
Что такое Synthetic Data Generation и когда его использование оправдано?;Создание искусственных данных сохраняющих статистические свойства реальных. Оправдано при недостатке данных, privacy concerns, testing систем, imbalance correction.;Генерация искусственных данных для ML. Используется когда реальных данных недостаточно или они конфиденциальны, для тестирования и улучшения моделей.;3
Основные компоненты Kafka;Producer: отправляет сообщения. Consumer: читает сообщений. Broker: сервер Kafka. Topic: категория/канал сообщений. Partition: часть топика. ZooKeeper: координация кластера.;Ключевые компоненты Kafka: producers (создают сообщения), consumers (обрабатывают сообщения), brokers (серверы Kafka, хранящие данные), topics (логические каналы сообщений), partitions (единицы параллелизма внутри топиков), ZooKeeper (координация кластера, выбор лидера, хранение конфигурации).;5
Что такое DBSCAN?;Алгоритм кластеризации на основе плотности, способный находить кластеры произвольной формы и выбросы.;Метод кластеризации, который группирует точки по плотности распределения. Может находить кластеры разной формы и помечать шумовые точки. Не требует задания числа кластеров заранее.;5
Перечислить стадии разработки систем машинного обучения.;Стадии разработки систем машинного обучения: сбор данных, очистка и подготовка, выделение признаков, выбор модели, обучение, оценка качества, внедрение и мониторинг.;Разработка систем машинного обучения состоит из написания кода и проверки результатов, стадий нет.;2
Что такое MapReduce?;Модель программирования для обработки больших объемов данных в распределенных кластерах, состоящая из этапов Map (фильтрация и сортировка) и Reduce (агрегация результатов).;Архитектура обработки данных где сначала данные маппятся (преобразуются), затем редьюсятся (агрегируются). Используется в Hadoop для распределенных вычислений.;4
Обучение с учителем и без учителя. Приведите примеры методов.;Supervised learning использует размеченные данные, примеры: линейная регрессия, логистическая регрессия, SVM. Unsupervised learning использует неразмеченные данные, примеры: k-means, PCA, иерархическая кластеризация.;Обучение без учителя — это нейросети, а с учителем — деревья решений.;3
Какие основные инструменты и технологии используются для работы с data mining?;Data mining помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Используется для прогнозов и анализа информации.;3
Критерии качества кластеризации;К критериям качества относятся Silhouette score, Davies-Bouldin index и Calinski-Harabasz index;Для оценки кластеризации используются различные критерии качества;5
Дайте определение социального графа, его типы и свойства. К какому семейству больших графов он относится?;Социальный граф представляет собой сетевую структуру взаимоотношений между людьми или организациями, включает направленные и ненаправленные, взвешенные и невзвешенные типы, обладает свойствами малого мира и кластеризации, относится к семейству масштабно-инвариантных графов;Сеть связей между людьми в социальных системах и сообществах;2
Что включает в себя модель 8V для Big Data?;Volume, Velocity, Variety, Veracity, Value, Variability, Visualization, Validity. Эта модель охватывает технические и бизнес-аспекты больших данных от сбора до извлечения ценности.;Расширенный список характеристик больших данных до восьми пунктов.;2
Как работает Delta Lake и какие проблемы ACID он решает в data lakes?;Открытый формат хранения поверх data lakes с ACID транзакциями, schema enforcement, time travel. Решает проблемы consistency, изоляции и надежности в традиционных data lakes.;Технология для data lakes с ACID гарантиями. Решает проблемы консистентности данных, конкурентных записей и управления схемами в распределенных системах.;4
Где применяется модели прогнозирования в промышленности и бизнесе?;Модели прогнозирования используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Модели прогнозирования применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;5
Что такое MLOps и как он отличается от традиционного DevOps?;Практики для автоматизации жизненного цикла ML моделей включая эксперименты, deployment, мониторинг. Отличается необходимостью управления данными, моделями, экспериментированием и дрейфом.;DevOps для машинного обучения с дополнительными компонентами: управление данными, эксперименты, мониторинг моделей. Отличается focus на данных и ML специфичных процессах.;4
Где применяется большие данные в промышленности и бизнесе?;Большие данные помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Помогает работать с данными и строить модели.;3
Какие методы использовать для обработки данных с пропущенными временными метками?;Интерполяция временных меток, использование соседних значений, создание uniform timeline, обработка как отдельной категории, импутация на основе паттернов.;Обработка пропусков во времени.;2
Как NLP помогает в анализе больших объемов данных?;Nlp помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;5
Что такое data lineage?;Отслеживание происхождения данных и их преобразований от источника до потребителя;Отслеживание данных;2
Принципы глубокого обучения в нейросетях;Глубокое обучение использует многослойные нейронные сети для автоматического извлечения признаков из данных, CNN специализируются на обработке изображений;Нейросети с многими слоями для сложных задач машинного обучения;2
Какие способы визуализации корреляции были изучены в курсе Big Data?;Основные способы: корреляционная матрица, тепловая карта (heatmap), диаграмма рассеяния (scatter plot), графики зависимости и парные диаграммы (pairplot).;Графики и таблицы.;2
Что такое Apache Kafka и для каких задач он используется?;Распределенная потоковая платформа для обработки данных в реальном времени. Используется для построения data pipelines, event-driven архитектур, streaming приложений.;Платформа для потоковой обработки событий в реальном времени. Применяется для data pipelines, микросервисов, обработки логов, IoT данных.;5
Сколько данных лучше для обучения;Объем данных для обучения моделей машинного обучения должен быть достаточным для обеспечения репрезентативности выборки при обязательном условии обеспечения высокого качества данных и их релевантности решаемой задаче;Необходимо иметь достаточно большой объем данных для обучения эффективных моделей;2
Охарактеризовать конструкции языка R;Конструкции включают векторы, списки, матрицы, data frames, функции управления потоком и функциональное программирование;Основные конструкции языка программирования R;4
Какие интегральные метрики качества вы знаете?;ROC-AUC, Precision-Recall AUC, F1-score, R? - метрики, агрегирующие различные аспекты качества моделей;ROC-AUC, F1-score, R?;3
Порядок тестирования гипотезы о равенстве средних;Процесс включает формулировку гипотез, проверку условий, расчет статистики и принятие решения;Тестирование гипотезы включает формулировку и проверку статистических условий;5
Какие риски связаны с использованием data mining в критически важных системах?;Data mining используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;4
Какие компании активно используют предиктивная аналитика и зачем?;Предиктивная аналитика используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Предиктивная аналитика применяется в бизнесе и иногда в науке для анализа данных.;3
Что понимают под переобучением модели?;Переобучение — это ситуация, когда модель слишком точно подстраивается под обучающую выборку, теряя способность обобщать знания на новые данные.;Это ошибка модели.;2
Стадии разработки систем ML;Полный процесс разработки систем машинного обучения включает сбор и подготовку данных, проектирование признаков, обучение моделей, валидацию результатов и развертывание в production-среде;Процесс создания ML моделей состоит из нескольких последовательных этапов разработки;4
Как data warehouses применяется в современных компаниях?;Data warehouses помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Эти технологии помогают работать с информацией и делать прогнозы.;3
Какие основные инструменты и технологии используются для работы с большие данные?;Большие данные используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;5
Что такое машинное обучение?;Машинное обучение — это раздел искусственного интеллекта, изучающий методы построения алгоритмов, способных самостоятельно выявлять закономерности в данных и принимать решения без явного программирования.;Это процесс, при котором программа учится на данных, чтобы лучше предсказывать результаты.;4
Что такое Apache Superset?;BI платформа с открытым кодом для визуализации и исследования данных через веб-интерфейс.;BI инструмент для визуализации данных. Позволяет строить дашборды, выполнять ad-hoc анализ и поддерживает множество баз данных.;5
Где применяется машинное обучение в промышленности и бизнесе?;Машинное обучение используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;5
Какие риски связаны с использованием нейронные сети в критически важных системах?;Нейронные сети помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Нейронные сети — это что-то про компьютеры. Применяется редко.;2
С какими проблемами сталкиваются при применении data mining, и как их решают?;Data mining применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;5
Что такое пайплайны, бенчмарки и SOTA;Пайплайны автоматизируют процессы, бенчмарки устанавливают стандарты сравнения, SOTA представляет передовые методы;Пайплайны автоматизируют процессы обработки данных, бенчмарки для сравнения;5
Стандартизация и нормализация переменных: зачем нужны?;Стандартизация и нормализация обеспечивают сопоставимость признаков, улучшают сходимость алгоритмов и повышают точность моделей машинного обучения;Чтобы алгоритмы лучше работали с данными;3
Что такое Apache Spark RDD и чем он отличается от DataFrame?;RDD - низкоуровневая распределенная коллекция объектов, DataFrame - распределенная коллекция данных с именованными колонками и оптимизацией через Catalyst.;RDD и DataFrame - разные API в Spark для работы с данными, DataFrame более высокоуровневый.;3
Какие этапы включает проект, основанный на использовании рекомендательные системы?;Рекомендательные системы помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Помогает работать с данными и строить модели.;3
Стандарты жизненного цикла Big Data: CRISP?DM;CRISP-DM представляет собой стандартизированный процесс, включающий 6 этапов: бизнес-понимание, понимание данных, подготовка данных, моделирование, оценка и внедрение;Методология для проектов анализа данных;2
В чем преимущества применения большие данные по сравнению с традиционными методами?;Большие данные применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Большие данные применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;5
Как нейронные сети помогает в анализе больших объемов данных?;Нейронные сети используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;5
Что означает термин 'кластеризация'?;Кластеризация — это метод анализа данных, при котором объекты объединяются в группы (кластеры) на основе схожести признаков без использования заранее известных меток.;Кластеризация — это сортировка данных.;2
Обучение с учителем и без учителя;"С учителем: классификация и регрессия с размеченными данными; без учителя: кластеризация и анализ без меток";С учителем есть правильные ответы, без учителя их нет;3
Какие инструменты используются для работы с мониторинг больших данных?;Технологии мониторинг больших данных позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Мониторинг больших данных используется бизнесом для оптимизации процессов, анализа клиентов и прогнозирования.;4
Что такое Apache Hadoop?;Фреймворк для распределенной обработки больших данных, состоящий из HDFS (распределенная файловая система) и MapReduce (модель программирования).;Это платформа для работы с большими данными, которая использует HDFS для хранения и MapReduce для обработки информации в распределенном кластере.;4
Принципы глубокого обучения в нейросетях;Глубокое обучение использует многослойные нейросети для автоматического извлечения признаков, CNN специализированы для изображений;Глубокое обучение использует многослойные нейросети для извлечения признаков;5
Как глубокое обучение применяется для автоматизации рутинных процессов?;Глубокое обучение применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Используется для прогнозов и анализа информации.;3
Как понимать «уровень статистической достоверности»?;Это вероятность ошибки.;Это число, показывающее насколько результат можно считать правильным.;3
Какие этапы включает проект, основанный на использовании нейронные сети?;Нейронные сети помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;4
Какие бывают виды регрессионного анализа? Поясните логистическую регрессию и SVM;Виды регрессии включают линейную, полиномиальную, логистическую и др. Логистическая регрессия предсказывает вероятности бинарной классификации, а SVM находит оптимальную разделяющую гиперплоскость;Логистическая регрессия предскажает вероятности классификации, SVM находит разделяющую гиперплоскость;5
Основные задачи Data Analysis;К основным задачам относятся описательная аналитика, диагностика проблем, прогнозирование и прескриптивная аналитика;Задачи анализа данных;2
Какие компании активно используют нейронные сети и зачем?;Нейронные сети используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Нейронные сети применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;5
Какие подходы использовать для обработки hierarchical данных в SQL?;Recursive CTEs, hierarchical queries, nested sets model, adjacency list, materialized paths, использование специализированных расширений.;Рекурсивные запросы, nested sets, adjacency list. Методы работы с иерархическими данными в SQL.;4
Когда использовать Spark вместо Pandas для обработки данных?;Spark когда данные не помещаются в память одного компьютера или нужна распределенная обработка. Pandas для данных, которые fit in memory и не требуют распределенных вычислений.;Spark используют для больших данных в кластере, Pandas - для небольших данных на одной машине. Если данные не влазят в память, нужно использовать Spark.;4
В чем преимущества применения рекомендательные системы по сравнению с традиционными методами?;Рекомендательные системы помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Рекомендательные системы применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;5
Охарактеризовать конструкции языка R;Язык R предоставляет векторы для атомарных данных, матрицы для двумерных массивов, списки для гетерогенных коллекций, фреймы данных для табличной организации и факторы для категориальных переменных;R предоставляет векторы, матрицы, списки и фреймы данных;5
Как мониторинг больших данных влияет на эффективность бизнеса?;Мониторинг больших данных помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Мониторинг больших данных применяется в некоторых компаниях для анализа данных.;3
Что такое Spark и чем он отличается от Hadoop?;Apache Spark — это платформа для распределенных вычислений, быстрее Hadoop MapReduce за счёт работы в памяти (in-memory). Поддерживает потоковую обработку данных и имеет библиотеки для SQL и машинного обучения.;Spark — это инструмент для анализа данных, работает быстрее Hadoop.;4
Какие навыки необходимы специалисту для работы с нейронные сети?;Нейронные сети помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;4
Что такое Apache Kafka и для чего используется?;Распределенная потоковая платформа для обработки данных в реальном времени. Используется для построения data pipelines, event-driven архитектур, streaming приложений.;Kafka - система для обработки потоковых данных. Используется для передачи сообщений между системами, обработки событий в реальном времени, data integration.;5
Опишите шаги построения дендрограммы.;Шаги: 1) вычисление матрицы расстояний 2) объединение наиболее близких объектов 3) пересчёт расстояний между новыми кластерами 4) повторение до объединения всех объектов. Результат — иерархическая структура кластеров.;Дендрограмма строится из данных автоматически.;2
Какие риски связаны с применением хранилища данных?;Технологии хранилища данных позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Эти технологии помогают работать с информацией и делать прогнозы.;3
Где применяется анализ данных в промышленности и бизнесе?;Анализ данных используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Помогает работать с данными и строить модели.;3
Как кластеризация данных применяется в современных компаниях?;Кластеризация данных помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Кластеризация данных применяется в финансах, медицине, рекламе и IT, помогает анализировать данные и строить модели.;4
Мотивация происхождения NoSQL.;NoSQL возник как ответ на ограниченность реляционных баз в масштабируемости и гибкости. Цель — работа с неструктурированными и распределёнными данными, высокая производительность и горизонтальное масштабирование.;NoSQL — это система для работы с числами.;2
Принципы глубокого обучения в нейросетях. Преимущества сверточных сетей.;Глубокое обучение использует многослойные нейронные сети (MLP, CNN, RNN) для автоматического извлечения признаков. CNN эффективны в задачах CV благодаря сверткам (convolution) и pooling. Формула свертки: y = ?(x*w).;Глубокое обучение использует много слоев, CNN хорошо обрабатывают изображения.;5
Критерии качества кластеризации;К критериям качества относятся Silhouette score, Davies-Bouldin index и Calinski-Harabasz index;Метрики для оценки кластеризации;4
Стандарты жизненного цикла Big Data: CRISP?DM;CRISP-DM включает этапы бизнес-понимания, понимания данных, подготовки, моделирования, оценки и внедрения;Стандарт для проектов данных;2
Стадии разработки систем ML;Полный процесс разработки систем машинного обучения включает сбор и подготовку данных, проектирование признаков, обучение моделей, валидацию результатов и развертывание в production-среде;Ключевые шаги разработки ML приложений от сбора данных до промышленной эксплуатации;3
Типы деревьев решений и индексы;Основные типы деревьев решений включают CART и C4.5, использующие индексы Джини, энтропию и gain ratio для выбора разделяющих признаков;CART использует индекс Джини для классификации, C4.5 применяет информационный выигрыш на основе энтропии;3
Сколько данных лучше взять для обучения: побольше или поменьше?;Зависит от сложности задачи: для сложных моделей нужно больше данных, но важнее качество и репрезентативность;Нужно достаточно данных;2
Как предобработка данных влияет на эффективность бизнеса?;Предобработка данных используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Это что?то связанное с данными, но используется редко.;2
Мотивация происхождения NoSQL;NoSQL базы данных возникли из-за необходимости обработки больших объемов неструктурированных данных, горизонтального масштабирования и обеспечения высокой производительности при работе с распределенными системами;Потребность в масштабируемости и работе с неструктурированными данными;4
Шкалы измерений, примеры;Номинальная, порядковая, интервальная, относительная;Номинальная (пол, цвет), порядковая (уровень образования), интервальная (температура в °C), относительная (вес, доход) с абсолютным нулем;5
Что такое checkpointing в распределенных системах?;Сохранение состояния системы в устойчивое хранилище для восстановления после сбоев;Механизм восстановления после сбоев;2
Как работает алгоритм Diffusion Models в генеративном AI?;Постепенное добавление шума к данным с последующим обучению обратному процессу восстановления. Создает высококачественные изображения через итеративное уточнение.;Модель которая учится генерировать данные через процесс добавления и удаления шума. Используется для создания реалистичных изображений и другого контента.;3
Как внедрение классификация данных влияет на процессы в организациях?;Классификация данных используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Классификация данных применяется в бизнесе и иногда в науке для анализа данных.;3
Что такое линейная регрессия?;Линейная регрессия — это статистический метод, описывающий зависимость между независимыми переменными X и зависимой переменной Y в виде линейной функции Y = ?0 + ?1X + ?.;Линейная регрессия — метод, который строит прямую, описывающую зависимость между переменными.;5
Охарактеризовать конструкции языка R;R — это программа.;R — язык для чего-то с таблицами.;2
Шаги построения дендрограммы;Построение дендрограммы включает вычисление матрицы расстояний между объектами, применение агломеративного алгоритма кластеризации с выбором меры связи и визуализацию иерархической структуры слияния кластеров;Создание матрицы расстояний, итеративное объединение, визуализация дендрограммы;4
Что такое R-squared?;Статистическая мера, показывающая долю дисперсии зависимой переменной, объясненную моделью.;Показатель точности модели.;2
Параметрическая модель статистического обучения;Параметрическая модель предполагает фиксированное число параметров и определенную функциональную форму зависимости между переменными в статистическом анализе;Параметрические модели с ограниченным числом параметров и заданной функциональной формой;4
Что понимается под термином 'Data Mining'?;Data Mining — это процесс извлечения ранее неизвестных, практически полезных и интерпретируемых знаний из больших объемов данных.;Data Mining — это процесс поиска знаний и закономерностей в больших объемах информации.;5
Почему организации переходят на технологии мониторинг больших данных?;Технологии мониторинг больших данных позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Мониторинг больших данных почти нигде не применяется. Это просто большие таблицы.;2
Что такое k-fold cross validation?;Метод валидации, при котором данные разбиваются на k равных частей, модель обучается на k-1 частях и тестируется на оставшейся.;Техника валидации с разбиением данных на k фолдов. Каждый фолд по очереди становится тестовой выборкой, остальные - тренировочными.;4
Что такое checkpointing в распределенных системах?;Сохранение состояния системы в устойчивое хранилище для восстановления после сбоев;Создание точек сохранения состояния;3
Суть алгоритмов связных компонент и покрывающего дерева;Связные компоненты находят группы связанных узлов, покрывающее дерево - минимальный набор рёбер, соединяющий все узлов;Алгоритмы находят связные компоненты и покрывающие деревья;5
Как рекомендуется разделять данные для обучения моделей?;60-80% тренировочные, 10-20% валидационные, 10-20% тестовые. Для кросс-валидации - k-fold разбиение. Зависит от объема данных.;Делить данные на части для обучения и проверки.;2
Когда использовать линейные, а когда нелинейные модели;Линейные - когда связь линейная, нелинейные - для сложных зависимостей. Проверять через визуализацию и тесты;Линейные модели применяются когда зависимость приблизительно линейна и интерпретируемость важна. Нелинейные (деревья, нейросети) когда связи сложные. Критерий выбора - анализ остатков, кросс-валидация и природа данных;5
Какие методы использовать для детектирования аномалий в потоковых данных?;Statistical methods (moving average, z-score), ML approaches (isolation forest, autoencoders), time-series methods (STL decomposition). Важно учитывать задержку обработки и обновление модели.;Статистические методы, ML алгоритмы и методы для временных рядов. Важно чтобы методы работали в реальном времени и адаптировались к изменениям.;4
Что такое переобучение (overfitting)?;Ситуация, когда модель слишком точно подстраивается под тренировочные данные, включая их шум, теряя способность к обобщению на новых данных.;Модель работает хорошо только на тех данных, на которых училась, и становится неэффективной для других данных.;3
Как внедрение глубокое обучение влияет на процессы в организациях?;Глубокое обучение используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Глубокое обучение применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;5
Что такое обучение без учителя и для чего оно используется?;Обучение без учителя применяется, когда нет размеченных данных. Основные задачи: кластеризация и снижение размерности.;Это обучение без преподавателя.;2
Какие подходы к детекции аномалий в больших данных?;Методы детекции аномалий включают статистические подходы, методы на основе кластеризации, изолирующие леса и нейросетевые подходы для выявления выбросов;Подходы включают статистические методы и изолирующие леса;5
Что такое пайплайны, бенчмарки и SOTA;Пайплайны автоматизируют процессы, бенчмарки устанавливают стандарты сравнения, SOTA представляет передовые методы;Инструменты и стандарты в ML;2
Зачем нужны рекуррентные нейросети?;Рекуррентные нейросети (RNN) используются для работы с последовательными данными — текст, временные ряды, речь. Основная идея — наличие памяти о предыдущих состояниях. Формула: h_t = f(Wx_t + Uh_{t-1}).;RNN работают с последовательными входами и учитывают контекст предыдущих значений.;3
В каких сферах применяются большие данные и каковы примеры их использования?;Большие данные используются в медицине (анализ медицинских изображений), ритейле (персонализированные рекомендации), финансах (fraud detection), транспорте (оптимизация маршрутов), IoT (умные города).;В разных отраслях: медицина, торговля, финансы. Для анализа данных и прогнозирования.;3
Что такое attention mechanism?;Механизм, позволяющий модели фокусироваться на relevant частях входных данных.;Способ улучшения нейросетей чтобы они лучше понимали данные.;2
Что такое 'валидация модели'?;Валидация — это процесс проверки качества обученной модели на независимых данных, не участвовавших в обучении.;Это процесс проверки синтаксиса данных.;2
Что такое retention period;Retention period — это время, в течение котором сообщения хранятся в Kafka до удаления. Может задаваться по времени или по размеру данных.;Это сколько времени сообщения хранятся в Kafka.;2
Где применяется рекомендательные системы в промышленности и бизнесе?;Рекомендательные системы используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Рекомендательные системы применяется в бизнесе и иногда в науке для анализа данных.;3
Шаги построения дендрограммы;Построение дендрограммы включает вычисление матрицы расстояний, применение агломеративного алгоритма кластеризации и визуализацию иерархической структуры слияния кластеров;Основные этапы: матрица расстояний, агломеративная кластеризация, визуализация дендрограммы;4
Как специалисты анализируют данные в рамках in-memory обработка?;In-memory обработка помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;In-memory обработка применяется в некоторых компаниях для анализа данных.;3
В чем преимущества применения большие данные по сравнению с традиционными методами?;Большие данные применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Помогает работать с данными и строить модели.;3
Boxplot и его интерпретация, связь с другими элементами анализа;"Boxplot показывает медиану, квартили, выбросы; связан с описательной статистикой и проверкой распределений";График для распределения;2
Перечислите основные задачи анализа сетей на графах;Основные задачи включают обнаружение сообществ, вычисление центральности узлов, поиск кратчайших путей, анализ связности и выявление влиятельных узлов в сетевых структурах;Задачи для работы с сетевыми графами и анализа взаимосвязей между различными объектами в системе;2
Что такое Data Mining и какие задачи он решает?;Data Mining — интеллектуальный анализ данных, направленный на выявление скрытых закономерностей. Основные задачи: классификация, кластеризация, ассоциативные правила, прогнозирование.;Data Mining — это анализ таблиц и данных.;3
Какие проблемы возникают при использовании хранилища данных?;Хранилища данных используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Технологии позволяют улучшать качество аналитики, находить закономерности и предсказывать события.;4
Принципы и инструменты аналитики Big Data;Аналитика больших данных основана на принципах распределенной обработки, использования специализированных фреймворков Hadoop и Spark, NoSQL баз данных и облачных технологий;Принципы включают распределенную обработку с Hadoop и Spark;4
Что такое MLOps и как он отличается от традиционного DevOps?;Практики для автоматизации жизненного цикла ML моделей включая эксперименты, deployment, мониторинг. Отличается необходимостью управления данными, моделями, экспериментированием и дрейфом.;Методология для развертывания и управления ML моделями в продакшн.;2
Алгоритмы выделения сообществ;Алгоритмы Louvain, Girvan-Newman, Label Propagation используются для обнаружения сообществ в сложных сетях на основе модульности и связности;Методы для нахождения групп узлов в сетях, которые тесно связаны между собой;2
Что такое Apache Iceberg?;Открытый табличный формат для больших данных с ACID транзакциями и версионированием.;Формат таблиц для data lakes, поддерживающий транзакции, версионирование и эволюцию схемы. Улучшает надежность и управление данными.;4
Какие навыки необходимы специалисту для работы с NLP?;Nlp применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;5
Что такое Apache Cassandra?;Распределенная NoSQL база данных с высокой доступностью и масштабируемостью, использующая модель column-family.;Распределенная NoSQL БД с линейной масштабируемостью и отказоустойчивостью. Использует модель column-oriented и не имеет единой точки отказа.;5
Измерение качества модели анализа данных;Качество моделей анализа данных оценивается с помощью метрик accuracy, precision, recall, F1-score для классификации и RMSE, MAE, R? для регрессионных моделей;Метрики качества включают accuracy, precision, recall для классификации;4
Что такое 'кластеризация'?;Кластеризация — это процесс разделения множества объектов на группы (кластеры) так, чтобы объекты внутри одной группы были похожи, а между группами — различались.;Кластеризация — это группировка объектов по признакам, чтобы похожие были в одном кластере.;5
Поясните алгоритм работы кластеризатора k-means.;Алгоритм k-means: 1) выбираются k центров кластеров 2) объекты распределяются по ближайшему центру 3) центры пересчитываются как средние координаты точек кластера 4) шаги повторяются до стабилизации центров. Цель — минимизация внутрикластерной дисперсии.;K-means — это метод деления данных на случайные группы.;2
Алгоритмы классификации;Основные алгоритмы включают логистическую регрессию, деревья решений, случайный лес, SVM и наивный байесовский классификатор;Алгоритмы: Logistic Regression, Decision Trees, SVM;4
Характерные черты безмасштабных сетей;Степенное распределение степеней, наличие хабов, устойчивость к случайным отказам, уязвимость к targeted attacks;Черты безмасштабных сетевых структур;4
Примеры задач с большими графов;Социальные сети, рекомендательные системы, биоинформатика, транспортные сети, веб-графы;Соцсети, рекомендации, биоинформатика;3
Дайте сравнительный анализ алгоритмов кластеризации.;Алгоритмы делятся на иерархические (агломеративные, дивизивные), разбиения (k-means, k-medoids), плотностные (DBSCAN), вероятностные (EM), графовые (Louvain). Отличаются подходами к определению расстояния и критериям объединения.;Разные алгоритмы кластеризации используют разные подходы — иерархические и плотностные.;4
Примеры задач с большими графами;Большие графы используются в социальных сетях для анализа сообществ, в рекомендательных системах и биоинформатике для изучения белковых взаимодействий;Social network analysis (community detection, influence maximization), recommendation systems (graph-based collaborative filtering), biological networks (protein-protein interactions), web graph analysis (PageRank);4
Как реализовать инкрементальную обработку данных в ETL пайплайнах?;Использовать Change Data Capture (CDC), watermarking для потоковых данных, инкрементальные snapshot'ы, обработку только дельт изменений вместо полных данных.;Обработка только новых данных вместо всех каждый раз.;2
Какие компании активно используют классификация данных и зачем?;Классификация данных применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Классификация данных применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;4
Примеры задач с большими графами;Большие графы применяются в социальных сетях, рекомендательных системах и биоинформатике для анализа сложных связей;Большие графы применяются в социальных сетях, рекомендательных системах для анализа связей;5
Что такое нормализация данных?;Нормализация — это преобразование данных в единую шкалу, чтобы устранить различия в масштабе признаков. Пример: приведение значений к диапазону [0,1].;Нормализация делает признаки сопоставимыми, чтобы модели работали корректно.;5
Что такое data compression в Big Data?;Уменьшение размера данных для экономии места и ускорения передачи;Сжатие данных для уменьшения занимаемого места и ускорения передачи по сети;5
Какие методы использовать для оптимизации JOIN операций в распределенных системах?;Broadcast join для маленьких таблиц, sort-merge join для отсортированных данных, hash join для больших таблиц, bucketing для предварительного разделения, использование статистик для выбора стратегии.;Разные алгоритмы join'ов для разных размеров таблиц и распределения данных, предварительная организация данных для ускорения соединений.;3
Какие реальные кейсы демонстрируют эффективность модели прогнозирования?;Модели прогнозирования используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Помогает работать с данными и строить модели.;3
NoSQL. Классификация NoSQL-хранилищ (типы). Их особенности. Примеры распределенных хранилищ.;Типы NoSQL: документо-ориентированные (MongoDB), ключ-значение (Redis), графовые (Neo4j), колонночные (Cassandra). Особенности — отсутствие фиксированной схемы, горизонтальное масштабирование, высокая доступность.;NoSQL — это облачные таблицы Excel.;2
С какими проблемами сталкиваются при применении предиктивная аналитика, и как их решают?;Предиктивная аналитика помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Предиктивная аналитика применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;5
Факторы, влияющие на коэффициент корреляции;На коэффициент корреляции влияют выбросы, нелинейность связи, размер выборки, гетерогенность данных и наличие скрытых переменных;Элементы, изменяющие корреляцию;2
Как развивается направление data warehouses в последние годы?;Технологии data warehouses позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Data warehouses используется бизнесом для оптимизации процессов, анализа клиентов и прогнозирования.;4
Свойства описательных статистик;Меры центральной тенденции, изменчивости и формы распределения данных;Свойства описательных статистик;4
Как глубокое обучение используется в научных исследованиях?;Глубокое обучение используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;5
Структуры и типы данных в R;Основные структуры данных в R включают векторы для атомарных данных, матрицы для двумерных массивов, списки для разнотипных коллекций, фреймы данных для таблиц и факторы для категориальных переменных;Данные в R бывают разные;2
Какие этапы включает разработка систем машинного обучения?;Сбор данных, подготовка и очистка, feature engineering, выбор модели, обучение, валидация, тестирование, развертывание, мониторинг.;Создание и настройка ML модели с данными.;2
Как проектировать систему для обработки данных в реальном времени с гарантией exactly-once?;Использовать фреймворки с поддержкой exactly-once (Flink, Kafka Streams), идемпотентные операции, transactional writes, checkpointing и watermarking для обработки late data.;Выбирать системы с native поддержкой exactly-once семантики like Flink. Использовать идемпотентные операции, transactional writes, checkpointing и правильно настраивать watermark для обработки задержанных данных.;5
Что такое data lineage?;Отслеживание происхождения данных и их преобразований от источника до потребителя;История преобразований данных;3
Интегральные метрики качества;К интегральным метрикам относятся ROC-AUC, Precision-Recall AUC, F1-score и R?, которые агрегируют различные аспекты качества модели в единый показатель;ROC-AUC измеряет способность модели разделять классы across всех порогов классификации, Precision-Recall AUC??? для несбалансированных данных, F1-score балансирует precision и recall, R? показывает долю дисперсии объясненную моделью регрессии;5
Принципы и инструменты аналитики. Задачи и компетенции аналитиков Big Data;Принципы включают data-driven подход, итеративность, автоматизацию. Инструменты: Hadoop, Spark, NoSQL. Задачи: анализ паттернов, прогнозирование. Компетенции: статистика, программирование, доменные знания;Аналитика больших данных;2
Как развивается направление хранилища данных в последние годы?;Хранилища данных используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Технологии позволяют улучшать качество аналитики, находить закономерности и предсказывать события.;4
Меры качества для языковых моделей;Основные меры качества включают перплексию для оценки модели, BLEU для машинного перевода, ROUGE для суммаризации и метрики точности;Показатели для оценки эффективности и качества работы языковых моделей в NLP задачах;2
Что такое word embeddings и какие модели используются для их создания?;Word embeddings - векторные представления слов, создаваемые моделями word2vec, GloVe, fastText, которые capture семантические и синтаксические отношения между словами;Числовые представления слов в NLP;3
Архитектура хранилищ данных;Современная архитектура хранилищ данных включает многоуровневую структуру с уровнями приема, обработки, хранения и анализа информации, использующую ETL-процессы, data lakes и специализированные витрины данных для различных бизнес-потребностей;Архитектура хранилищ данных включает многоуровневую структуру с ETL-процессами и data lakes;5
Какие методы использовать для обнаружения concept drift в ML моделях?;Statistical tests (KS test, PSI), monitoring performance metrics, drift detection algorithms (ADWIN, DDM), анализ распределения предсказаний и фактических значений.;Статистические тесты (KS, PSI), мониторинг метрик качества, специализированные алгоритмы обнаружения дрейфа (ADWIN), анализ изменений в распределении входных данных и предсказаний модели.;5
Что такое feature engineering и какие методы используются?;Feature engineering - процесс создания и отбора признаков, включающий кодирование категориальных переменных, создаение полиномиальных features и отбор признаков;Проектирование и отбор признаков для улучшения моделей;4
Что такое sharding в базах данных?;Горизонтальное разделение данных на основе ключа sharding для распределения нагрузки;Способ масштабирования баз данных;2
В чем преимущества применения большие данные по сравнению с традиционными методами?;Большие данные используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Большие данные применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;5
Что такое Neuromorphic Computing и как оно применяется в AI?;Архитектура вычислений имитирующая работу человеческого мозга. Применяется для энергоэффективного AI, real-time обработки сенсорных данных, edge computing.;Новый тип вычислений для искусственного интеллекта основанный на принципах работы мозга.;2
Свойства описательных статистик;Меры центральной тенденции, изменчивости и формы распределения данных;Меры центра, разброса и формы;3
Какие методы использовать для обработки данных с пропущенными временными метками?;Интерполяция временных меток, использование соседних значений, создание uniform timeline, обработка как отдельной категории, импутация на основе паттернов.;Способы восстановления пропущенных временных меток в данных.;3
Что такое consumer groups;Consumer group — это группа потребителей, которые совместно обрабатывают сообщения из топика. Каждое сообщение доставляется только одному потребителю в группе.;Группы консьюмеров обеспечивают масштабируемость и отказоустойчивость: консьюмеры в группе распределяют между собой партиции топика для параллельной обработки, и при выходе одного консьюмера из строя его партиции перераспределяются между оставшимися.;4
«Меры изменчивости»: что к ним относится?;Дисперсия, стандартное отклонение, размах, межквартильный размах, среднее абсолютное отклонение;Меры изменчивости данных;4
Как выбрать стратегию индексации для оптимизации запросов в колоночных хранилищах?;Использовать zone maps для min/max значений, bloom filters для членства, inverted indexes для категориальных данных. Выбор зависит от типа запросов и распределения данных.;Методы индексации для ускорения запросов.;2
Фундаментальное свойство статистического обучения;Фундаментальным свойством является компромисс между смещением и дисперсией (bias-variance tradeoff), который определяет способность модели к обобщению на новых данных;Фундаментальное свойство - компромисс между смещением и дисперсией;5
Сколько данных оптимально использовать для обучения моделей?;Зависит от сложности задачи: для простых моделей достаточно тысяч примеров, для глубокого обучения - миллионы. Важен баланс между объемом и качеством разметки.;Больше данных обычно лучше для обучения.;2
Разница описательных и предсказательных задач;Описательные анализируют текущие данные, предсказательные строят прогнозы на будущее;Описательные анализируют существующие данные, предсказательные строят прогнозы;5
Где применяется кластеризация в промышленности и бизнесе?;Кластеризация применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;5
Как работает принцип векторных и матричных вычислений в R?;Векторизация позволяет применять операции ко всем элементам без циклов. Элементы обрабатываются параллельно, что ускоряет вычисления. Матричные операции используют линейную алгебру.;Операции применяются ко всем элементам вектора/матрицы одновременно без явных циклов. Это ускоряет вычисления и упрощает код. Например, vector * 2 умножает все элементы.;5
В чем преимущества применения большие данные по сравнению с традиционными методами?;Большие данные используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Это просто работа с таблицами. Не очень полезно.;2
Структуры и типы данных в R;Основные структуры данных в R включают векторы, матрицы, списки, data frames и factors, каждая с определенными свойствами и методами обработки;Разные способы хранения и организации данных в языке R;2
Что такое data mesh архитектура?;Децентрализованный подход к управлению данными с domain-oriented ownership;Новая архитектура для данных;3
Метрики качества для моделей регрессии;Основные метрики включают RMSE, MAE, MAPE и R? для оценки точности регрессионных моделей и их предсказательной способности;Разные показатели для измерения ошибок предсказания в регрессии;2
Какие реальные примеры использования мониторинг больших данных существуют?;Технологии мониторинг больших данных позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Мониторинг больших данных нужно только программистам, обычным компаниям оно бесполезно.;2
Понятие регрессии;Моделирование связи между переменными для прогнозирования;Метод для предсказания чисел;2
Какие реальные примеры использования обработка потоковых данных существуют?;Обработка потоковых данных используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Обработка потоковых данных обеспечивает анализ потоковых данных, улучшает прогнозирование, помогает автоматизировать процессы и повышает точность аналитических моделей.;5
Какие методы обработки пропущенных значений в данных вы знаете?;Для обработки пропущенных значений используются удаление строк, импутация средним/медианой, предсказание с помощью моделей и интерполяция, выбор метода зависит от природы пропусков и объема данных;Способы работы с отсутствующими данными;2
Что такое HDFS и как обеспечивается отказоустойчивость?;Распределенная файловая система Hadoop. Отказоустойчивость обеспечивается репликацией данных на несколько узлов (по умолчанию 3 копии) и rack-aware размещением.;HDFS - файловая система для хранения больших данных. Репликация на разные узлы обеспечивает отказоустойчивость - при падении узла данные доступны с других.;5
Что такое SHAP values?;Метод объяснения предсказаний ML моделей на основе теории игр, показывающий вклад каждого признака.;Метод интерпретации моделей ML. Показывает как каждый признак влияет на предсказание для отдельного наблюдения.;4
Перечислить типы языка R, привести примеры.;Основные типы данных R: numeric (числовой, пример 3.14), integer (целый, пример 10L), character (строка, пример 'data'), logical (логический, пример TRUE), complex (комплексное число, пример 2+3i).;Типы данных в R — это числа, строки и функции, больше ничего нет.;2
Как предобработка данных применяется в современных компаниях?;Технологии предобработка данных позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Технологии позволяют улучшать качество аналитики, находить закономерности и предсказывать события.;4
Как рекомендуется разделять данные для обучения моделей?;60-80% тренировочные, 10-20% валидационные, 10-20% тестовые. Для кросс-валидации - k-fold разбиение. Зависит от объема данных.;Большую часть на обучение, остальное на проверку и тестирование. Обычно 70/30 или 80/20.;3
Основные задачи Data Analysis;Описательная аналитика, диагностика, прогнозирование, рекомендации - основные направления анализа;Анализ данных для извлечения информации;2
Какие проблемы возникают при использовании распределённые вычисления?;Распределённые вычисления помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Распределённые вычисления применяется в финансах, медицине, рекламе и IT, помогает анализировать данные и строить модели.;4
Понятие регрессии;Моделирование связи между переменными для прогнозирования;Метод анализа зависимости между переменными, позволяющий строить прогнозные модели и оценивать влияние факторов на целевую переменную;5
Меры качества для языковых моделей;Основные метрики включают перплексию для оценки модели, BLEU для перевода и ROUGE для суммаризации текстов;Метрики для оценки языковых моделей;2
Что такое Data Lake и в чем его преимущества перед Data Warehouse?;Data Lake — это хранилище, где данные сохраняются в исходном виде. Преимущества: гибкость, возможность работы с сырыми и разнородными данными, масштабируемость. Data Warehouse хранит структурированные данные.;Data Lake — это база, где хранятся разные данные.;3
Что такое Delta Lake;Delta Lake — это open-source storage layer, который добавляет reliability, ACID транзакции и управление версиями к данным в data lakes поверх Parquet формата.;Улучшенный data lake;2
Обучение с подкреплением и ансамбли;Обучение с подкреплением основано на взаимодействии со средой, ансамбли комбинируют несколько моделей;Разные методы машинного обучения;4
Как анализ данных используется в научных исследованиях?;Анализ данных помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;5
Перечислить стадии разработки систем машинного обучения;Сначала данные, потом модель.;Главное обучить что-то и проверить.;3
Что такое Apache HBase?;Распределенная column-oriented NoSQL база данных, построенная поверх HDFS для random read/write доступа к большим данным.;NoSQL база в экосистеме Hadoop. Для быстрого доступа к большим данным.;3
Как обеспечить консистентность данных в распределенной системе при сетевых разделах?;Использовать consensus алгоритмы (Raft, Paxos), кворумные операции, конфликтующее разрешение на основе временных меток или векторов версий, eventual consistency с механизмами согласования.;Специальные протоколы для поддержания согласованности при сетевых сбоях, механизмы разрешения конфликтов данных.;3
Принцип массивных вычислений в R;Векторизованные операции в R позволяют эффективно обрабатывать большие объемы данных без использования циклов через применение оптимизированных встроенных функций и операций;Эффективная обработка больших массивов данных с помощью векторизованных операций в R;4
Какие навыки необходимы специалисту для работы с data mining?;Data mining помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Помогает работать с данными и строить модели.;3
Какие навыки необходимы специалисту для работы с большие данные?;Большие данные используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Большие данные нужно только программистам.;2
В чем преимущества применения нейронные сети по сравнению с традиционными методами?;Нейронные сети используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Это просто работа с таблицами. Не очень полезно.;2
Опишите шаги построения дендрограммы.;Шаги: 1) вычисление матрицы расстояний 2) объединение наиболее близких объектов 3) пересчёт расстояний между новыми кластерами  4) повторение до объединения всех объектов. Результат — иерархическая структура кластеров.;Для построения дендрограммы нужно рассчитать расстояния и соединить объекты.;3
Что такое обучение с учителем и как оценивается качество модели?;Обучение с учителем — это метод, при котором модель обучается на размеченных данных. Качество оценивается метриками: Accuracy, Precision, Recall, F1-score.;Обучение с учителем — когда известны правильные ответы, качество модели измеряется метриками.;4
Data Mining vs. Machine Learning — в чём отличия?;Data Mining фокусируется на обнаружении паттернов в данных, а Machine Learning - на построении прогнозных моделей;Разные цели анализа;2
Как предиктивная аналитика применяется для автоматизации рутинных процессов?;Предиктивная аналитика используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;4
Назовите характеристики качества данных;Полнота, точность, непротиворечивость, актуальность, достоверность, релевантность данных;Свойства хороших данных;2
Что такое кросс-валидация и зачем она нужна?;Метод оценки модели путем многократного разбиения данных на тренировочную и тестовую выборки. Нужна для более надежной оценки обобщающей способности и настройки гиперпараметров.;Способ проверки модели на разных частях данных для оценки ее реальной производительности.;3
Принцип работы SVM;Метод опорных векторов находит гиперплоскость с максимальным зазором для разделения классов в пространстве признаков;Алгоритм для классификации который ищет оптимальную границу между классами;2
Где применяется анализ данных в промышленности и бизнесе?;Анализ данных применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Анализ данных применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;4
Какие основные инструменты и технологии используются для работы с NLP?;Nlp применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Используется для прогнозов и анализа информации.;3
Как глубокое обучение используется в научных исследованиях?;Глубокое обучение помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Глубокое обучение применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;4
Какие методы использовать для обработки категориальных переменных с большим количеством уникальных значений?;Target encoding, frequency encoding, embedding layers для нейросетей, grouping редких категорий, hash encoding. Избегать one-hot encoding при большом cardinality.;"Target encoding, frequency encoding, embedding слои в нейросетях, группировка редких категорий в ""other"", hashing trick. One-hot encoding не подходит при тысячах уникальных значений.";5
Почему организации переходят на технологии обработка потоковых данных?;Технологии обработка потоковых данных позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Это что?то связанное с данными, но используется редко.;2
Что такое Apache Kafka?;Распределенная потоковая платформа обмена сообщениями для обработки потоков данных в реальном времени.;Это технология для обмена данными между разными программами и сервисами.;2
Метрики качества для моделей регрессии;Для оценки регрессионных моделей используются RMSE, MAE, MAPE и R? для измерения точности предсказаний;Для регрессии используются RMSE, MAE, MAPE и R?;5
Нормальное распределение;Нормальное распределение характеризуется симметричной колоколообразной формой и определенными параметрами центра и dispersion;Нормальное распределение имеет симметричную колоколообразную форму;5
Что такое dropout в нейросетях?;Метод регуляризации, при котором случайно выбранные нейроны игнорируются во время обучения для предотвращения переобучения.;Способ улучшения нейросетей через отключение элементов.;2
Что такое пайплайны, бенчмарки и SOTA;Пайплайны автоматизируют процессы, бенчмарки устанавливают стандарты сравнения, SOTA представляет передовые методы;Пайплайны для автоматизации, бенчмарки для сравнения;4
Способы графического представления данных;Гистограммы, диаграммы рассеяния, box plots, линейные графики. Выбор зависит от типа данных и цели;Гистограммы для распределения, scatter plot для связи переменных, линейные графики для трендов;3
Почему организации переходят на технологии кластеризация данных?;Технологии кластеризация данных позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Это что?то связанное с данными, но используется редко.;2
Обучение с подкреплением и ансамбли;Обучение с подкреплением основано на взаимодействии агента со средой для максимизации награды, а ансамбли объединяют несколько моделей для улучшения прогнозирования;Обучение с подкреплением основано на MDP где агент учится через trial-and-error, ансамбли используют комбинацию слабых learners (Random Forest, Gradient Boosting) для уменьшения переобучения и улучшения обобщения;5
Как специалисты анализируют данные в рамках масштабируемые системы?;Технологии масштабируемые системы позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Масштабируемые системы применяется в некоторых компаниях для анализа данных.;3
Что такое consumer groups;Consumer group — это группа потребителей, которые совместно обрабатывают сообщения из топика. Каждое сообщение доставляется только одному потребителю в группе.;Группы консьюмеров позволяют масштабировать обработку сообщений: каждый консьюмер в группе обрабатывает определенное подмножество партиций топика.;3
Какие подходы к детекции аномалий в больших данных?;Методы детекции аномалий включают статистические подходы, методы на основе кластеризации, изолирующие леса и нейросетевые подходы для выявления выбросов;Обнаружение выбросов в данных;2
Data Mining vs. Machine Learning — в чём отличия?;Data Mining ориентирован на обнаружение скрытых паттернов и закономерностей в существующих данных, тогда как Machine Learning сосредоточен на построении алгоритмов, способных обучаться и делать прогнозы на новых данных;Data Mining ориентирован на обнаружение паттернов, Machine Learning на построение прогнозных моделей;5
Процесс познания (от гипотезы к функции);Процесс включает формулировку гипотезы, сбор и подготовку данных, построение модели, валидацию результатов и создание прогнозной функции для практического применения;Этапы: гипотеза ? данные ? модель ? функция;3
Какие подходы использовать для оптимизации памяти в Python при обработке больших данных?;Использование генераторов, efficient data structures, memory mapping, chunk processing, удаление неиспользуемых объектов, использование специализированных библиотек.;Генераторы, оптимизированные структуры, memory mapping, чанковая обработка. Снижение потребления памяти в Python.;4
Шаги построения дендрограммы;Построение дендрограммы включает вычисление матрицы расстояний между объектами, применение агломеративного алгоритма кластеризации и визуализацию иерархической структуры;1) Вычисление матрицы попарных расстояний 2) Выбор linkage criterion (single, complete, average) 3) Итеративное объединение ближайших кластеров 4) Визуализация дендрограммы где высота отражает расстояние слияния кластеров;5
Что такое нейронные сети с резкими связями (ResNet)?;Архитектура CNN с skip-connections для решения проблемы исчезающего градиента в глубоких сетях.;Тип нейросетей где есть прямые связи между дальними слоями. Помогает обучать глубокие сети.;3
Опишите процесс ETL и его этапы.;ETL (Extract, Transform, Load) — это процесс извлечения данных из источников, их преобразования в нужный формат и загрузки в целевое хранилище. Основные этапы: Extract, Transform, Load.;ETL — это процесс работы с данными, где их извлекают, меняют и сохраняют.;4
Назовите характеристики качества данных.;К характеристикам качества данных относятся полнота, точность, актуальность, непротиворечивость, целостность и доступность.;К качеству данных относятся их количество и размер базы.;2
Перечислите шкалы измерений. Приведите примеры их использования;Номинальная (пол, цвет), порядковая (уровень образования), интервальная (температура), относительная (вес, доход);Типы шкал измерений;2
Свойства эластичности и надёжности сложных сетей;Эластичность - устойчивость к нагрузкам, надежность - отказоустойчивость. Зависит от структуры сети;Эластичность - способность сети масштабироваться и выдерживать пиковые нагрузки. Надежность - сохранение связности при отказах узлов. Зависит от наличия хабов и избыточности связей;5
Что такое Apache Spark и в чем его преимущество перед Hadoop MapReduce?;Это фреймворк для распределенной обработки больших данных. Ключевое преимущество — выполнение операций в оперативной памяти (in-memory), что значительно ускоряет итерационные алгоритмы и интерактивную аналитику по сравнению с дисковыми операциями MapReduce.;Это такая программа для работы с большими данными. Она лучше других, потому что ее все используют и у нее много функций.;2
Архитектура хранилищ данных.;Классическая архитектура хранилища включает уровни: источник данных, ETL-процесс (Extract, Transform, Load), слой хранения (Data Warehouse), слой аналитики (OLAP-кубы, BI-инструменты). Возможны схемы: звезда, снежинка, галактика.;Архитектура хранилища данных состоит из ETL-процессов, уровня хранения и уровня анализа, с возможными схемами звезда и снежинка.;5
Назовите и поясните меры качества для языковых моделей.;Меры: Perplexity = exp(-1/N * ? log P(w_i)), BLEU (оценка совпадений n-грамм с эталоном), ROUGE (recall на уровне фраз), METEOR (комбинация точности и полноты).;Перплексия и BLEU оценивают текстовые модели.;4
Что такое word2vec?;Алгоритм для создания векторных представлений слов на основе их контекста.;Способ представления текстов в виде чисел для обработки компьютером.;2
Охарактеризовать конструкции языка R;R поддерживает переменные, функции, циклы, условия, векторы, списки и датафреймы. Это язык, ориентированный на статистику и анализ данных.;В R есть переменные, функции, циклы и структуры данных вроде векторов и таблиц. Он удобен для анализа данных.;5
Что такое нормализация данных?;"Нормализация данных — это процесс приведения признаков к единому масштабу для повышения точности и стабильности алгоритмов.,""Нормализация — это изменение данных";чтобы они стали равными.;3
Какие основные характеристики и вызовы больших данных (4V, 8V)?;4V: Volume (объем), Velocity (скорость), Variety (разнообразие), Veracity (достоверность). 8V добавляют: Value, Variability, Visualization, Validity.;Характеристики больших данных: размер, скорость поступления, разные форматы. Вызовы в обработке и хранении.;3
Дайте определение социального графа, его типы и свойства. К какому семейству больших графов он относится?;Социальный граф представляет собой сетевую структуру взаимоотношений между людьми или организациями, включает направленные и ненаправленные, взвешенные и невзвешенные типы, обладает свойствами малого мира и кластеризации, относится к семейству масштабно-инвариантных графов;Социальный граф как сетевая структура взаимоотношений с типами и свойствами масштабно-инвариантных сетей;4
Что такое DataOps;DataOps — это методология управления данными, которая объединяет DevOps практики с процессами работы с данными для ускорения и повышения качества аналитики.;DataOps использует автоматизацию для пайплайнов данных;3
Принцип работы RandomForest;Ансамбль деревьев, бэггинг, случайный выбор признаков;Создает ансамбль деревьев на бутстрэп-выборках со случайным выбором признаков, уменьшает variance;4
Какие реальные примеры использования распределённые вычисления существуют?;Технологии распределённые вычисления позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Распределённые вычисления применяется в финансах, медицине, рекламе и IT, помогает анализировать данные и строить модели.;4
Мотивация происхождения NoSQL;NoSQL базы данных возникли из-за необходимости обработки больших объемов неструктурированных данных, горизонтального масштабирования и обеспечения высокой производительности при работе с распределенными системами;Потребность в новых типах баз данных;2
Что такое Graph Neural Networks и для каких задач они превосходят традиционные подходы?;Нейросети для графовых данных, учитывающие связи между объектами. Превосходят в задачах с relational структурами: рекомендательные системы, drug discovery, social network analysis.;GNN обрабатывают графы учитывая связи между узлами. Лучше традиционных методов в задачах где важны отношения: рекомендации, химические соединения, анализ сетей.;5
Что такое SMOTE?;Метод синтеза новых примеров для балансировки несбалансированных наборов данных.;Алгоритм для борьбы с несбалансированностью данных через создание искусственных примеров миноритарного класса на основе k ближайших соседей.;4
Что такое ROC-кривая?;ROC-кривая — это график зависимости True Positive Rate от False Positive Rate, используемый для оценки качества бинарного классификатора.;ROC-кривая показывает, как изменяются показатели TPR и FPR при разных порогах классификации.;5
Какие методы использовать для обработки данных с высокой cardinality в feature engineering?;Target encoding, hashing trick, frequency encoding, embedding learning, categorical embedding с нейросетями, grouping редких категорий.;Target encoding, hashing, frequency encoding, embedding слои. Группировка редких значений. Избегать one-hot при высокой cardinality.;5
Что такое Zero-shot и Few-shot learning в современных LLM и как они работают?;Способность моделей выполнять задачи без явного обучения (zero-shot) или с немногими примерами (few-shot). Работает через prompting и использование знаний полученных при претренинге.;Методы когда модели работают на новых задачах без специального обучения.;2
Boxplot и его интерпретация, связь с другими элементами анализа;Boxplot визуализирует распределение данных через медиану, квартили и выбросы, тесно связан с описательной статистикой и используется для сравнения распределений и выявления аномалий в наборах данных;Boxplot визуализирует распределение данных через медиану и квартили, связан с описательной статистикой;5
Какие основные инструменты и технологии используются для работы с NLP?;Nlp помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;5
Что такое Feature Store;Feature Store — это централизованное хранилище для управления, версионирования и обслуживания признаков машинного обучения в production средах.;Централизованный каталог признаков с версионированием, обеспечивающий согласованность между обучением и inference;5
Как выбрать стратегию индексации для оптимизации запросов в колоночных хранилищах?;Использовать zone maps для min/max значений, bloom filters для членства, inverted indexes для категориальных данных. Выбор зависит от типа запросов и распределения данных.;Zone maps, bloom filters и inverted indexes в зависимости от типов запросов и данных. Балансировать выгоду и overhead.;4
Как предобработка данных применяется в современных компаниях?;Предобработка данных помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Технологии позволяют улучшать качество аналитики, находить закономерности и предсказывать события.;4
Назовите и поясните меры качества для языковых моделей.;Меры: Perplexity = exp(-1/N * ? log P(w_i)), BLEU (оценка совпадений n-грамм с эталоном), ROUGE (recall на уровне фраз), METEOR (комбинация точности и полноты).;BLEU — это что-то про качество модели.;2
Как специалисты анализируют данные в рамках обработка потоковых данных?;Технологии обработка потоковых данных позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Технологии позволяют улучшать качество аналитики, находить закономерности и предсказывать события.;4
Какие методы использовать для балансировки классов в задачах классификации с сильным дисбалансом?;Oversampling (SMOTE), undersampling, изменение весов классов в функции потерь, использование алгоритмов устойчивых к дисбалансу, ансамблирование.;Способы работы с данными где один класс сильно преобладает.;2
Где применяется большие данные в промышленности и бизнесе?;Большие данные помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Большие данные нужно только программистам.;2
В чем преимущества применения модели прогнозирования по сравнению с традиционными методами?;Модели прогнозирования используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;5
Определение термина «большие данные»;Большие данные представляют собой огромные объемы разнородной информации, требующие специальных технологий обработки;Большие данные это огромные объемы разнородной информации;5
Как организовать data lineage в сложных ETL пайплайнах?;Automated lineage tracking, metadata management, data provenance recording, impact analysis capabilities, integration с orchestration tools, visualization dependencies.;Отслеживание данных в ETL процессах.;2
Что такое convolutional neural network (CNN)?;Архитектура нейросетей для обработки изображений с использованием сверточных слоев.;Тип искусственного интеллекта для работы с картинками и фотографиями.;2
В чем преимущества применения нейронные сети по сравнению с традиционными методами?;Нейронные сети помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Используется для прогнозов и анализа информации.;3
Какие стратегии использовать для backup и recovery больших datasets?;Incremental backups, snapshotting, geographic replication, versioned storage, automated recovery procedures, regular testing восстановления.;Подходы к резервному копированию и восстановлению больших объемов данных.;3
Что такое k-fold cross validation?;Метод валидации, при котором данные разбиваются на k равных частей, модель обучается на k-1 частях и тестируется на оставшейся.;Способ проверки модели на разных частях данных. Делит данные на k частей и многократно тестирует модель.;3
Что такое MongoDB?;Документо-ориентированная NoSQL база данных с гибкой JSON-подобной схемой документов.;База данных для хранения документов.;2
Дайте определение социального графа, его типы и свойства;Социальный граф - сеть взаимоотношений между людьми, включает directed/undirected, weighted/unweighted, обладает small-world property;Социальный граф с типами и свойствами;4
Какие подходы использовать для real-time агрегации потоковых данных?;Tumbling windows, sliding windows, session windows, incremental aggregation, использование stateful processing, оптимизация с помощью approximate algorithms.;Tumbling и sliding windows, session windows, инкрементальная агрегация. Stateful обработка и approximate алгоритмы для оптимизации.;5
Где применяется нейронные сети в промышленности и бизнесе?;Нейронные сети используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Нейронные сети применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;4
Что такое топик в Kafka;Топик — это логический канал или категория, в которую производители публикуют сообщения и из которой потребители читают сообщения. Сообщения в топике упорядочены.;Это канал для сообщений в Kafka.;2
Какие навыки необходимы специалисту для работы с анализ данных?;Анализ данных помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Анализ данных применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;4
Зачем нужно уменьшение размерностей?;Уменьшение размерностей позволяет снизить вычислительную сложность, устранить мультиколлинеарность и улучшить интерпретируемость моделей;Для упрощения данных и моделей;3
Какие интегральные метрики качества вы знаете?;ROC-AUC, Precision-Recall AUC, F1-score, R? - метрики, агрегирующие различные аспекты качества моделей;Интегральные метрики качества моделей;4
Что такое data warehouse?;Централизованное хранилище интегрированных данных из различных источников, оптимизированное для анализа и отчетности, с поддержкой исторических данных и структурированной схемой.;Централизованное хранилище для анализа данных. Собирает информацию из разных систем, преобразует в удобный формат и поддерживает сложные запросы.;4
Основные инструменты аналитики больших данных, провести сравнительную характеристику.;К основным инструментам аналитики больших данных относятся Apache Hadoop, Spark, Flink, Hive, Pig, а также BI-платформы вроде Tableau и Power BI. Hadoop обеспечивает распределённое хранение (HDFS) и обработку, Spark — высокую скорость вычислений в оперативной памяти, Hive — SQL-подобный доступ к данным.;Для аналитики больших данных можно использовать Excel и SQL, они решают все задачи.;2
Какие риски связаны с применением хранилища данных?;Технологии хранилища данных позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Хранилища данных широко применяется в промышленности, здравоохранении, финансах и государственных системах. Позволяет анализировать большие массивы данных, строить точные модели и улучшать эффективность процессов.;5
Охарактеризовать конструкции языка R;Конструкции включают векторы, списки, матрицы, data frames, функции управления потоком и функциональное программирование;Элементы языка R;2
Где применяется компьютерное зрение в промышленности и бизнесе?;Компьютерное зрение используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Компьютерное зрение применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;4
Для чего нужна гипотеза о равенстве средних?;Гипотеза о равенстве средних используется для проверки различий между двумя выборками. Применяется t-тест (t = (x?1 - x?2) / s_p?(1/n1 + 1/n2)).;Чтобы найти медиану.;2
Классификация методов Data Mining;Классификация, кластеризация, регрессия, ассоциативные правила, анализ последовательностей;Классификация (с учителем), кластеризация (без учителя), регрессия (прогноз численных значений), ассоциативные правила (шаблоны), анализ последовательностей (временные паттерны);4
Генеральная совокупность и выборка;Генеральная совокупность включает все объекты исследования, выборка является ее представительной частью;Совокупность объектов и выборка;4
Какие риски связаны с использованием машинное обучение в критически важных системах?;Машинное обучение применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;5
Какие навыки необходимы специалисту для работы с глубокое обучение?;Глубокое обучение используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Используется для прогнозов и анализа информации.;3
В чем преимущества применения рекомендательные системы по сравнению с традиционными методами?;Рекомендательные системы используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Используется для прогнозов и анализа информации.;3
Где применяется предиктивная аналитика в промышленности и бизнесе?;Предиктивная аналитика помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Предиктивная аналитика применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;5
Что такое Apache Kafka;Apache Kafka — это распределенная потоковая платформа для обработки потоков данных в реальном времени. Состоит из производителей, потребителей, брокеров и тем.;Kafka — это распределенная, отказоустойчивая платформа для потоковой обработки данных, которая работает по принципу публикации-подписки и обеспечивает высокую пропускную способность и низкую задержку.;3
В чем преимущества применения кластеризация по сравнению с традиционными методами?;Кластеризация применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Это просто работа с таблицами. Не очень полезно.;2
Что понимается под 'стандартизацией данных'?;Стандартизация — это преобразование признаков таким образом, чтобы их среднее значение было равно нулю, а стандартное отклонение — единице.;Это процесс сортировки данных по возрастанию.;2
Что такое машинное обучение и каковы его основные типы?;Машинное обучение — это раздел искусственного интеллекта, изучающий методы построения алгоритмов, способных обучаться на данных. Основные типы: обучение с учителем, без учителя и с подкреплением.;Машинное обучение — это когда программа учится распознавать данные без помощи человека.;2
Какие проблемы возникают при использовании ETL-пайплайны?;Etl-пайплайны помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Технологии ETL-пайплайны позволяют компаниям обрабатывать большие объёмы разнородных данных, выявлять сложные закономерности и принимать обоснованные решения.;5
Какие стратегии использовать для балансировки нагрузки в распределенных data processing системах?;Dynamic resource allocation, adaptive scheduling, data locality optimization, load-aware partitioning, auto-scaling based on metrics.;Методы равномерного распределения работы между узлами кластера.;2
Какие дополнительные V добавляют к расширенной модели Big Data?;Value (ценность данных), Variability (изменчивость), Visualization (визуализация), Validity (валидность данных). Эти характеристики дополняют основные 4V и подчеркивают бизнес-аспекты.;Еще четыре характеристики включая ценность и визуализацию данных.;2
Шаги построения дендрограммы;Построение дендрограммы включает вычисление матрицы расстояний между объектами, применение агломеративного алгоритма кластеризации и визуализацию иерархической структуры;Процесс создания древовидной диаграммы для иерархической кластеризации;2
В каких областях деятельности используются большие данные, привести примеры.;Большие данные применяются в маркетинге, финансах, медицине, промышленности, транспорте и государственном управлении. Примеры: прогнозирование спроса, анализ поведения клиентов, медицинская диагностика, предиктивное обслуживание оборудования.;Большие данные используются в финансах, медицине и промышленности, например для анализа и прогнозирования.;4
Что такое HDFS и как обеспечивается отказоустойчивость?;Распределенная файловая система Hadoop. Отказоустойчивость обеспечивается репликацией данных на несколько узлов (по умолчанию 3 копии) и rack-aware размещением.;Система хранения в Hadoop. Создает копии данных на разных машинах для надежности.;3
Что такое lambda architecture и из каких компонентов она состоит?;Архитектура для обработки Big Data, сочетающая batch и stream processing. Состоит из batch layer (обработка всех данных), speed layer (реaltime обработка) и serving layer (объединение результатов).;Архитектура с batch и stream слоями. Batch слой обрабатывает все данные, speed слой - последние данные, serving слой объединяет результаты для запросов.;5
Где применяется машинное обучение в промышленности и бизнесе?;Машинное обучение используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Машинное обучение применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;5
Примеры задач с большими графами;Большие графы используются в социальных сетях для анализа сообществ, в рекомендательных системах и биоинформатике для изучения белковых взаимодействий;Применение графовых моделей для решения реальных задач в различных областях;2
Какие метрики используются для оценки качества регрессионных моделей?;MSE, RMSE, MAE, R?, MAPE. Каждая метрика имеет свои преимущества: MSE чувствительна к выбросам, MAE более устойчива, R? показывает долю объясненной дисперсии.;Ошибки предсказания: среднеквадратичная, средняя абсолютная. R-квадрат для оценки объясненной дисперсии.;3
Как тестируются независимые и парные выборки?;Независимые выборки тестируются с помощью t-теста Стьюдента или U-критерия Манна-Уитни, а парные выборки - с использованием парного t-теста или критерия Вилкоксона;Независимые выборки тестируются t-тестом, парные - парным t-тестом и критерием Вилкоксона;4
Какие структуры данных используются в R и их примеры?;"Вектор (c(1,2,3)), матрица (matrix(1:6, nrow=2)), список (list(1, ""a"", TRUE)), data frame (data.frame(x=1:3, y=c(""a"",""b"",""c""))), фактор (factor(c(""A"",""B"",""A""))).";Разные способы организации данных в R.;2
Что такое пайплайны, бенчмарки и SOTA;Пайплайны - автоматизированные процессы обработки данных, бенчмарки - эталоны сравнения, SOTA - лучшие достижения;Пайплайны автоматизируют процессы, бенчмарки служат для сравнения, SOTA представляет лучшие методы;5
Факторы, влияющие на коэффициент корреляции;На корреляцию влияют выбросы, нелинейность связи, гетерогенность данных, размер выборки и наличие скрытых переменных;Что влияет на корреляцию;2
Что такое L1 и L2 регуляризация?;L1 (Lasso) добавляет штраф за абсолютные значения весов, L2 (Ridge) - за квадраты весов.;L1 регуляризация (Lasso) добавляет к функции потерь сумму абсолютных значений весов, что может обнулять некоторые веса, выполняя отбор признаков. L2 регуляризация (Ridge) добавляет сумму квадратов весов, уменьшая их величину без обнуления.;5
Какие навыки необходимы специалисту для работы с обработка данных?;Обработка данных применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Обработка данных — это что-то про компьютеры. Применяется редко.;2
Какие проблемы возникают при использовании big data?;Big data помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Big data нужно только программистам, обычным компаниям оно бесполезно.;2
Как глубокое обучение применяется для автоматизации рутинных процессов?;Глубокое обучение используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Глубокое обучение применяется в бизнесе и иногда в науке для анализа данных.;3
Понятие корреляции коэффициент корреляции Пирсона, Спирмена, Кендела.,;"""Корреляция — статистическая мера связи между переменными. Коэффициент Пирсона измеряет линейную зависимость (r = cov(X,Y)/(?X?Y)), Спирмена — ранговую, Кендела — степень согласованности пар.";Корреляция — это когда данные похожи. Пирсон и Спирмен просто разные способы посчитать схожесть.;2
Какие типы шкал измерения данных существуют в статистике?;Номинальная (категории без порядка), порядковая (категории с порядком), интервальная (числа с равными интервалами), относительная (числа с абсолютным нулем).;Категориальные и числовые шкалы с разными свойствами для измерения данных.;3
Что такое 'нормализация данных'?;Нормализация данных — это процесс приведения признаков к единому масштабу для корректной работы алгоритмов машинного обучения.;Это удаление лишних данных из таблицы.;2
Примеры задач с большими графами;Большие графы применяются в социальных сетях, рекомендательных системах и биоинформатике для анализа сложных связей;Графы в соцсетях и рекомендательных системах;3
Охарактеризовать конструкции языка R.;Конструкции языка R включают присваивание (<-), условные выражения (if, else), циклы (for, while), функции (function()), и обращения к элементам вектора с помощью [].;R поддерживает стандартные конструкции: условия, циклы, функции и обращения к элементам по индексам.;4
Что такое уровень значимости;Уровень значимости ? представляет собой вероятность совершить ошибку первого рода, то есть отвергнуть верную нулевую гипотезу в статистическом тестировании, обычно устанавливается на уровне 0.05 или 0.01;Вероятность ошибочного отклонения правильной нулевой гипотезы при статистической проверке;2
Требования ACID. CAP-теорема, BASE архитектура: как и к каким хранилищам данных эти понятия применяются.;ACID (Atomicity, Consistency, Isolation, Durability) — свойства транзакционных систем (OLTP). CAP-теорема утверждает невозможность одновременного обеспечения согласованности (C), доступности (A) и устойчивости к разделению (P). BASE (Basically Available, Soft-state, Eventually consistent) описывает принципы NoSQL систем.;ACID, CAP и BASE — это методы хранения файлов.;2
Мотивация происхождения NoSQL;NoSQL базы возникли из-за необходимости обработки неструктурированных данных и горизонтального масштабирования систем;Причины появления NoSQL;2
Охарактеризовать конструкции языка R.;Конструкции языка R включают присваивание (<-), условные выражения (if, else), циклы (for, while), функции (function()), и обращения к элементам вектора с помощью [].;R использует конструкции: <- для присваивания, if/else для условий, for/while для циклов, function() для определения функций.;5
Какие проблемы возникают при использовании мониторинг больших данных?;Мониторинг больших данных используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Технологии позволяют улучшать качество аналитики, находить закономерности и предсказывать события.;4
Что такое schema evolution в Big Data?;Возможность изменения схемы данных без потери совместимости с существующими данными;Механизм позволяющий изменять структуру данных сохраняя совместимость со старыми версиями;5
Что такое Apache Hive?;Система управления данными в Hadoop, предоставляющая SQL-подобный язык запросов (HiveQL) для обработки структурированных данных в распределенном хранилище HDFS, с преобразованием запросов в MapReduce или Tez jobs.;Какая-то система из экосистемы Hadoop для данных.;2
Меры изменчивости;Дисперсия, стандартное отклонение, размах, межквартильный размах - показатели разброса данных;Дисперсия, стандартное отклонение, размах описывают вариативность;3
Что такое уровень значимости;Уровень значимости ? представляет вероятность совершить ошибку первого рода - отвергнуть верную нулевую гипотезу, обычно устанавливается 0.05;Статистический параметр ?, определяющий вероятность отвергнуть нулевую гипотезу когда она верна, устанавливает порог для p-value при принятии статистических решений;5
Что такое grid search?;Метод подбора гиперпараметров через exhaustive search по заранее заданной сетке значений.;Алгоритм поиска оптимальных гиперпараметров. Проверяет все комбинации параметров из заданной сетки для нахождения лучших.;4
Характерные черты безмасштабных сетей, какова их связь с сетями тесного мира?;Безмасштабные сети имеют степенное распределение степеней вершин (P(k)~k^-?), содержат хабы. Сети тесного мира характеризуются малой длиной пути и высоким коэффициентом кластеризации. Обе модели встречаются в реальных системах.;Безмасштабные сети имеют узлы-лидеры, тесные миры — короткие пути.;2
Какие признаки создавать для временных рядов при feature engineering?;Лаги, скользящие статистики (mean, std), временные характеристики (час, день недели), фичи из Fourier transform, difference.;Лаги целевой переменной, скользящие средние и стандартные отклонения, сезонные фичи (час, день недели, месяц), признаки тренда, разности ряда. Также фичи из domain knowledge.;5
Какие навыки необходимы специалисту для работы с рекомендательные системы?;Рекомендательные системы используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Рекомендательные системы нужно только программистам.;2
Уровень статистической достоверности;Вероятность того, что результат не случаен. Не вероятность ошибки, а доверие к результату;Это точность вычислений;2
Шаги построения дендрограммы;Построение дендрограммы включает вычисление матрицы расстояний между объектами, применение агломеративного алгоритма кластеризации и визуализацию иерархической структуры;Создание матрицы расстояний, выбор меры близости между кластерами, итеративное объединение кластеров, визуализация дендрограммы с высотой representing расстояние слияния;4
Что такое ансамблевые методы?;Комбинация нескольких моделей для улучшения прогнозной способности и устойчивости.;Методы, которые объединяют несколько простых моделей в одну сильную. Bagging (как Random Forest) уменьшает дисперсию, Boosting (как Gradient Boosting) уменьшает смещение, а Stacking комбинирует разные типы моделей.;5
Что такое word2vec?;Алгоритм для создания векторных представлений слов на основе их контекста.;Word2vec - это группа моделей, которые обучают векторные представления слов таким образом, что семантически близкие слова имеют близкие векторы, используя либо skip-gram, либо CBOW архитектуры.;5
Понятие регрессии. Как используется этот вид анализа?;Регрессия — статистический метод, моделирующий зависимость целевой переменной Y от факторов X1, X2,..., Xn. Применяется для прогнозирования и анализа влияния факторов.;Регрессионный анализ ищет зависимость между признаками и результатом.;3
Мотивация происхождения NoSQL;NoSQL базы возникли из-за необходимости обработки неструктурированных данных и горизонтального масштабирования систем;Потребность в масштабируемости и гибкости;3
Что понимают под переобучением модели?;Переобучение — это ситуация, когда модель слишком точно подстраивается под обучающую выборку, теряя способность обобщать знания на новые данные.;Модель подстраивается под обучающие данные, и результаты на тесте хуже.;4
Как внедрение ETL-процессы влияет на процессы в организациях?;Etl-процессы применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;4
Интегральные метрики качества;К интегральным метрикам относятся ROC-AUC, Precision-Recall AUC, F1-score и R?, агрегирующие различные аспекты качества;Общие метрики оценки;2
Какие подходы использовать для обработки hierarchical данных в SQL?;Recursive CTEs, hierarchical queries, nested sets model, adjacency list, materialized paths, использование специализированных расширений.;Способы работы с древовидными структурами в реляционных БД.;3
Назовите критерии качества кластеризации и поясните их значение и когда они используются.;Критерии качества: внутрикластерная дисперсия (SSW), межкластерная дисперсия (SSB), индекс силуэта, индекс Дэвиса-Болдина, индекс Калински-Харабаса. Применяются для оценки плотности и разделимости кластеров.;Критерии качества — это гипотезы в анализе данных.;2
В каких пропорциях разделять данные перед обучением;70-80% обучение, 15-20% валидация, 15-20% тестирование. Зависит от объема данных;70% на обучение, 30% на тестирование. Иногда добавляют валидационную выборку;3
Что такое регрессионный анализ;Статистический метод моделирования зависимостей между переменными для прогнозирования численных значений;Анализ связей между переменными для построения прогнозных моделей;3
В чем преимущества применения NLP по сравнению с традиционными методами?;Nlp помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;5
Определение термина 'большие данные', источники получения больших данных.;Большие данные — это совокупность структурированных и неструктурированных данных значительного объема, скорости и разнообразия, требующих специализированных методов хранения и анализа. Источники: сенсоры IoT, социальные сети, логи систем, транзакционные данные, мультимедиа.;Большие данные — это все данные, которые есть в интернете. Источники — сайты и новости.;2
Что такое обработка данных и какие задачи оно решает?;Обработка данных помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Обработка данных применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;4
Где применяется большие данные в промышленности и бизнесе?;Большие данные применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;4
Свойства описательных статистик;Меры центральной тенденции, меры изменчивости и показатели формы распределения данных;Включают меры центральной тенденции, меры изменчивости и характеристики формы распределения;5
Что такое машинное обучение?;Машинное обучение — это раздел искусственного интеллекта, изучающий методы построения алгоритмов, способных самостоятельно выявлять закономерности в данных и принимать решения без явного программирования.;Это когда компьютер может учиться на примерах.;3
Классификация методов Data Mining;Классификация, кластеризация, регрессия, ассоциативные правила, анализ последовательностей;Методы для анализа данных: классификация, кластеризация;2
Как обеспечить воспроизводимость экспериментов в ML и data science?;Version control для кода и данных, фиксация seed значений, контейнеризация (Docker), detailed logging, MLflow для отслеживания экспериментов.;Версионирование кода и данных, фиксация случайных seed'ов, контейнеризация окружения, детальное логирование параметров и результатов экспериментов.;4
Где применяется машинное обучение в промышленности и бизнесе?;Машинное обучение применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Используется для прогнозов и анализа информации.;3
Требования ACID. CAP-теорема, BASE архитектура: как и к каким хранилищам данных эти понятия применяются.;ACID (Atomicity, Consistency, Isolation, Durability) — свойства транзакционных систем (OLTP). CAP-теорема утверждает невозможность одновременного обеспечения согласованности (C), доступности (A) и устойчивости к разделению (P). BASE (Basically Available, Soft-state, Eventually consistent) описывает принципы NoSQL систем.;ACID — это принципы транзакций, CAP — баланс между согласованностью и доступностью, BASE — концепция NoSQL, гарантирующая eventual consistency.;5
Какие навыки необходимы специалисту для работы с модели прогнозирования?;Модели прогнозирования используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Это просто работа с таблицами. Не очень полезно.;2
Какие методы feature selection используются в машинном обучении?;Методы отбора признаков включают фильтры (correlation), встроенные методы (L1-регуляризация) и методы-обертки (recursive feature elimination);Отбор наиболее значимых признаков;2
Как нейронные сети применяется для автоматизации рутинных процессов?;Нейронные сети помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;5
Критерии качества кластеризации;К критериям качества относятся Silhouette score, Davies-Bouldin index и Calinski-Harabasz index;Метрики оценки кластеров;2
Как выполняется преобразование данных и зачем нужна их очистка?;Преобразование включает нормализацию, агрегацию, обогащение. Очистка нужна для удаления шума, исправления ошибок, обработки пропусков для повышения качества моделей.;Данные преобразуют через масштабирование, агрегирование, создание признаков. Очистка удаляет аномалии, исправляет ошибки, обрабатывает пропуски для улучшения качества анализа.;5
Какие метрики используются для оценки моделей в задачах мультиклассовой классификации?;Для мультиклассовой классификации используются accuracy, macro/micro averaged precision/recall, F1-score и confusion matrix для детального анализа ошибок;Показатели для многоклассовой классификации;2
Метрики качества для моделей регрессии;Для оценки регрессионных моделей используются RMSE (среднеквадратичная ошибка), MAE (средняя абсолютная ошибка), MAPE (средняя абсолютная процентная ошибка) и R? (коэффициент детерминации), которые измеряют различные аспекты точности предсказаний;Различные показатели позволяют оценить, насколько хорошо регрессионная модель предсказывает числовые значения;2
Что такое YARN?;Компонент Hadoop для управления ресурсами кластера и планирования задач. Отделяет функции управления от модели обработки данных.;Менеджер ресурсов Hadoop. Отвечает за распределение памяти и CPU между задачами в кластере.;4
Что такое Apache Airflow?;Платформа для оркестрации и мониторинга рабочих процессов данных.;Apache Airflow - это open-source платформа для программирования, планирования и мониторинга рабочих процессов данных через направленные ациклические графы (DAGs), обеспечивающая надежное выполнение ETL процессов и пайплайнов данных.;5
Какие риски связаны с применением data warehouses?;Технологии data warehouses позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Data warehouses нужно только программистам, обычным компаниям оно бесполезно.;2
Что такое data drift?;Изменение распределения входных данных со временем, ухудшающее качество модели.;Data drift возникает когда статистические свойства входных данных модели меняются со временем, приводя к degradation производительности модели, что требует мониторинга и переобучения.;5
Как работает технология Data Virtualization и какие проблемы она решает?;Предоставляет unified view данных без физического перемещения. Решает проблемы data silos, уменьшает latency доступа, упрощает data governance в распределенных системах.;Способ работы с данными из разных мест без их перемещения.;2
Какие реальные примеры использования масштабируемые системы существуют?;Технологии масштабируемые системы позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Масштабируемые системы широко применяется в промышленности, здравоохранении, финансах и государственных системах. Позволяет анализировать большие массивы данных, строить точные модели и улучшать эффективность процессов.;5
Генеральная совокупность и выборка;Генеральная совокупность включает все объекты исследования, выборка является ее представительной частью;Совокупность объектов и выборка;4
Что такое большие данные и откуда они поступают?;Большие данные - огромные объемы структурированных и неструктурированных данных, которые невозможно обработать традиционными методами. Источники: соцсети, IoT устройства, транзакционные системы, сенсоры.;Много информации из разных мест.;2
Метрики качества для компьютерного зрения;"Accuracy, Precision, Recall, F1-score для классификации; mAP, IoU для детекции; Dice coefficient для сегментации";Метрики оценки в компьютерном зрении;4
Что такое Apache ZooKeeper?;Централизованный сервис для поддержания конфигурационной информации, именования, распределенной синхронизации и предоставления групповых сервисов в распределенных системах.;Инструмент для управления распределенными системами. Используется для координации сервисов.;3
Что такое MLOps;MLOps — это практика внедрения и поддержки ML моделей в production через автоматизацию, мониторинг и управление жизненным циклом моделей.;Набор практик для автоматизации развертывания, мониторинга и поддержки ML моделей в production;5
Как работает механизм Attention в трансформерах и почему он революционен для NLP?;Взвешенная агрегация информации из всех позиций последовательности. Революционен благодаря ability улавливать long-range зависимости и параллелизации в отличие от RNN.;Способ определения важности разных элементов в данных. Изменил NLP позволив лучше обрабатывать длинные тексты и сложные языковые зависимости.;3
Что такое DataOps;DataOps — это методология управления данными, которая объединяет DevOps практики с процессами работы с данными для ускорения и повышения качества аналитики.;Это подход к автоматизации процессов работы с данными с использованием практик DevOps;4
Что такое большие данные и какие задачи оно решает?;Большие данные используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;5
Что такое кросс-валидация?;Метод оценки модели, при котором данные разбиваются на k частей, модель обучается на k-1 частях и проверяется на оставшейся части, процесс повторяется k раз.;Кросс-валидация - это техника, при которой данные многократно разбиваются на обучающую и тестовую выборки, что позволяет получить более надежную оценку качества модели и уменьшить зависимость от конкретного разбиения данных.;5
Что такое Big Data и каковы её основные характеристики?;Big Data — это совокупность технологий и подходов, направленных на обработку больших объёмов данных, которые не поддаются традиционным методам анализа. Основные характеристики: Volume (объём), Velocity (скорость), Variety (разнообразие), Veracity (достоверность), Value (ценность).;Big Data — это большие объёмы данных, которые быстро создаются и обрабатываются с помощью современных технологий.;5
Требования ACID. CAP?теорема, BASE?архитектура;ACID - гарантии целостности транзакций, CAP - невозможность одновременно обеспечить согласованность, доступность и устойчивость к разделению;ACID (атомарность, согласованность, изоляция, долговечность) для транзакций. CAP-теорема: нельзя одновременно обеспечить согласованность, доступность и устойчивость к разделению;4
Что такое DBSCAN?;Алгоритм кластеризации на основе плотности, способный находить кластеры произвольной формы и выбросы.;Алгоритм кластеризации, работающий на основе плотности точек. Находит группы разной формы и выбросы без задания количества кластеров.;4
Мотивация происхождения NoSQL;Необходимость работы с неструктурированными данными и горизонтального масштабирования систем;Потребность в обработке неструктурированных данных и горизонтальном масштабировании;5
Как проектировать систему для обработки геопространственных данных в реальном времени?;Использовать специализированные БД (PostGIS), пространственные индексы (R-tree, Quad-tree), распределенные системы для масштабирования, streaming frameworks для real-time обработки.;Система для работы с данными о местоположениях в реальном времени.;2
Как работает метод главных компонент (PCA) для снижения размерности?;PCA находит новые ортогональные оси, которые максимизируют дисперсию данных, проецируя их в пространство меньшей размерности с сохранением максимальной информации;Нахождение главных компонент для сокращения размерности данных;4
Разница описательных и предсказательных задач;Описательные задачи анализируют существующие данные, предсказательные строят модели для прогнозирования;Разные типы задач анализа данных;4
Почему организации переходят на технологии предобработка данных?;Предобработка данных используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Предобработка данных нужно только программистам, обычным компаниям оно бесполезно.;2
Когда использовать Spark вместо Pandas для обработки данных?;Spark когда данные не помещаются в память одного компьютера или нужна распределенная обработка. Pandas для данных, которые fit in memory и не требуют распределенных вычислений.;Spark для очень больших данных, Pandas для обычных размеров. Выбор зависит от объема данных и доступных ресурсов.;3
Где применяется NLP в промышленности и бизнесе?;Nlp применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Nlp применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;5
Перечислить стадии разработки систем машинного обучения;Сделать модель.;Нужно что-то обучить.;2
Как работает алгоритм DBSCAN для кластеризации?;DBSCAN группирует точки в кластеры на основе плотности, выделяя core points, border points и noise, не требуя предварительного задания числа кластеров;Группировка данных на основе плотности распределения;4
Что такое DataOps;DataOps — это методология управления данными, которая объединяет DevOps практики с процессами работы с данными для ускорения и повышения качества аналитики.;Это про управление данными;2
Какие реальные кейсы демонстрируют эффективность машинное обучение?;Машинное обучение помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;5
Как проектировать data pipeline для обработки данных с разной latency требованиями?;Lambda architecture, multi-tier processing, priority queues, separate pipelines для real-time и batch, resource allocation based on SLA.;Пайплайн для данных с разной срочностью обработки.;2
Какие этапы включает проект, основанный на использовании анализ данных?;Анализ данных используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Анализ данных применяется в бизнесе и иногда в науке для анализа данных.;3
Какие этапы включает проект, основанный на использовании NLP?;Nlp применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;5
Как модели прогнозирования используется в научных исследованиях?;Модели прогнозирования используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Модели прогнозирования применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;5
Меры качества для языковых моделей;Perplexity, BLEU, ROUGE - основные метрики оценки качества языковых моделей и переводов;Perplexity оценивает модель, BLEU и ROUGE - качество генерации текста;4
Как оптимизировать запросы к данным с временными рядами для аналитических нагрузок?;Партиционирование по времени, индексы по временным меткам, материализованные представления для агрегатов, сжатие временных данных, использование специализированных TSDB.;Методы ускорения запросов к данным с временными метками.;2
Какие основные инструменты и технологии используются для работы с предиктивная аналитика?;Предиктивная аналитика применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Предиктивная аналитика применяется в бизнесе и иногда в науке для анализа данных.;3
Что такое sharding в базах данных?;Горизонтальное разделение данных на основе ключа sharding для распределения нагрузки;Разделение базы данных на меньшие части (shards) для распределения нагрузки по разным серверам;5
Обучение с учителем и без учителя. Приведите примеры методов.;Supervised learning использует размеченные данные, примеры: линейная регрессия, логистическая регрессия, SVM. Unsupervised learning использует неразмеченные данные, примеры: k-means, PCA, иерархическая кластеризация.;Обучение с учителем — это SVM, а без учителя — k-means.;5
Какие риски связаны с применением ETL-пайплайны?;Etl-пайплайны помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Etl-пайплайны обеспечивает анализ потоковых данных, улучшает прогнозирование, помогает автоматизировать процессы и повышает точность аналитических моделей.;5
Свойства описательных статистик;Меры центральной тенденции, изменчивости и формы распределения данных;Свойства включают меры центральной тенденции и изменчивости;5
Разница описательных и предсказательных задач;Описательные задачи анализируют существующие данные, предсказательные строят модели для прогнозирования;Описательные - что было, предсказательные - что будет;3
Как нейронные сети используется в научных исследованиях?;Нейронные сети помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Используется для прогнозов и анализа информации.;3
Основные задачи Data Analysis;К основным задачам относятся описательная аналитика, диагностика проблем, прогнозирование и прескриптивная аналитика;Разные типы аналитических задач;4
Как глубокое обучение помогает в анализе больших объемов данных?;Глубокое обучение применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;4
Какие компании активно используют NLP и зачем?;Nlp используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Помогает работать с данными и строить модели.;3
Как классификация данных используется в научных исследованиях?;Классификация данных применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Классификация данных применяется в бизнесе и иногда в науке для анализа данных.;3
Сравнительный анализ алгоритмов кластеризации;Алгоритмы кластеризации сравниваются по масштабируемости, чувствительности к шуму, способности находить кластеры сложной формы и вычислительной сложности;"K-means: линейная сложность, чувствительность к выбросам, сферические кластеры; DBSCAN: устойчивость к шуму, кластеры произвольной формы, не требует задания k; Hierarchical: O(n?) сложность, визуализация дендрограммы; Spectral: эффективен для невыпуклых кластеров";5
Основные задачи Data Analysis;Описательная аналитика, диагностика, прогнозирование, рекомендации - основные направления анализа;Описательная, диагностическая, предиктивная и прескриптивная аналитика;4
Что такое 'F1-мера'?;F1-мера — это гармоническое среднее между precision и recall, отражающее баланс между точностью и полнотой.;F1-мера — это показатель, объединяющий precision и recall в одно значение для оценки модели.;5
Какие риски связаны с применением data lakes?;Технологии data lakes позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Технологии позволяют улучшать качество аналитики, находить закономерности и предсказывать события.;4
Как организовать систему для ML feature serving в реальном времени?;Feature store с low-latency API, online/offline feature consistency, versioning, monitoring feature quality, scalable serving infrastructure.;Serving фич для ML в реальном времени.;2
Мотивация происхождения NoSQL;NoSQL базы данных возникли из-за необходимости обработки больших объемов неструктурированных данных, горизонтального масштабирования и обеспечения высокой производительности при работе с распределенными системами;Необходимость работы с большими данными и масштабируемостью;3
Нарисуйте (опишите) схему классификации методов машинного обучения;Классификация включает обучение с учителем, без учителя, с подкреплением и полу-контролируемое обучение;С учителем, без учителя, с подкреплением;3
Какие бывают виды регрессионного анализа?;"Линейная, полиномиальная, логистическая, ридж, лассо регрессия; каждая решает специфические задачи";Виды регрессионного анализа включают линейную и логистическую;5
Что такое обучение без учителя и для чего оно используется?;Обучение без учителя применяется, когда нет размеченных данных. Основные задачи: кластеризация и снижение размерности.;Обучение без учителя — это обучение без меток.;3
Суть алгоритмов связных компонент и покрывающего дерева;Связные компоненты находят группы связанных узлов, покрывающее дерево - минимальный набор рёбер, соединяющий все узлов;Алгоритмы анализа графовых структур;4
Какие типы шкал измерения данных существуют в статистике?;Номинальная (категории без порядка), порядковая (категории с порядком), интервальная (числа с равными интервалами), относительная (числа с абсолютным нулем).;Разные способы измерения и классификации данных.;2
Какие методы использовать для детектирования аномалий в потоковых данных?;Statistical methods (moving average, z-score), ML approaches (isolation forest, autoencoders), time-series methods (STL decomposition). Важно учитывать задержку обработки и обновление модели.;Методы основанные на статистике (скользящее среднее, z-score), машинное обучение (isolation forest, LSTM) и специализированные алгоритмы для временных рядов. Нужно выбирать методы с низкой latency для потоковой обработки.;5
Какие компании активно используют ETL-процессы и зачем?;Etl-процессы применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;5
Назовите меры центральной тенденции;Основные меры центральной тенденции включают среднее арифметическое, медиану и моду распределения;Меры центра: среднее, медиана, мода;4
Как проектировать систему для обработки данных в реальном времени с гарантией exactly-once?;Использовать фреймворки с поддержкой exactly-once (Flink, Kafka Streams), идемпотентные операции, transactional writes, checkpointing и watermarking для обработки late data.;Выбрать систему с exactly-once гарантиями, использовать checkpointing и идемпотентность.;3
Что такое регуляризация в машинном обучении?;Регуляризация — это метод предотвращения переобучения за счёт добавления штрафа за сложность модели в функцию потерь (например, L1, L2).;Регуляризация добавляет штраф за сложность модели, чтобы она не переобучалась.;4
Как обрабатывать пропущенные значения в данных перед обучением модели?;Зависит от природы пропусков: удаление строк если мало пропусков, импутация средним/медианой для числовых, модой для категориальных, либо использование алгоритмов, поддерживающих пропуски.;"Удалить строки если пропусков мало, иначе импутировать. Для чисел - среднее или медиана, для категорий - мода. Можно создать бинарный признак ""был ли пропуск"".";4
Что такое Data Mining и какие задачи он решает?;Data Mining — интеллектуальный анализ данных, направленный на выявление скрытых закономерностей. Основные задачи: классификация, кластеризация, ассоциативные правила, прогнозирование.;Data Mining — это поиск закономерностей в данных, включает классификацию, кластеризацию, прогнозирование.;5
Как специалисты анализируют данные в рамках системы логирования?;Системы логирования помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Системы логирования обеспечивает анализ потоковых данных, улучшает прогнозирование, помогает автоматизировать процессы и повышает точность аналитических моделей.;5
Стандартизация и нормализация переменных: зачем нужны?;Стандартизация и нормализация обеспечивают сопоставимость признаков, улучшают сходимость алгоритмов и повышают точность моделей машинного обучения;Для приведения данных к одному масштабу;2
Как специалисты анализируют данные в рамках предобработка данных?;Технологии предобработка данных позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Это что?то связанное с данными, но используется редко.;2
Data Mining vs. Machine Learning – в чем отличия?;Data Mining (DM) — это процесс извлечения закономерностей и знаний из больших массивов данных, тогда как Machine Learning (ML) — это совокупность алгоритмов, позволяющих системе обучаться на данных и делать прогнозы. DM шире по смыслу и включает ML как инструмент.;Data Mining — это статистическая обработка данных, а Machine Learning — это создание моделей, способных обучаться.;3
Типы деревьев решений и индексы;Основные типы алгоритмов деревьев решений включают CART и C4.5, которые используют различные индексы для разделения данных, такие как индекс Джини, энтропия и коэффициент gain ratio;Виды деревьев решений используют различные метрики для построения оптимальных моделей классификации;4
Какие подходы к детекции аномалий в больших данных?;Методы детекции аномалий включают статистические подходы, методы на основе кластеризации, изолирующие леса и нейросетевые подходы для выявления выбросов;Статистические и машинные методы для нахождения аномалий;3
Какие инструменты используются для работы с предобработка данных?;Предобработка данных используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Предобработка данных используется бизнесом для оптимизации процессов, анализа клиентов и прогнозирования.;4
Как внедрение NLP влияет на процессы в организациях?;Nlp применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;4
Основные вызовы больших данных;Ключевые вызовы включают объем (Volume), скорость (Velocity), разнообразие (Variety) и достоверность (Veracity) данных, требующие специальных подходов к обработке;Volume - экзабайты данных требующие распределенного хранения, Velocity - реальное время обработки потоковых данных, Variety - комбинация структурированных, полуструктурированных и неструктурированных форматов, Veracity - обеспечение качества и достоверности разнородных источников данных;5
Какие инструменты используются для работы с масштабируемые системы?;Масштабируемые системы используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Масштабируемые системы широко применяется в промышленности, здравоохранении, финансах и государственных системах. Позволяет анализировать большие массивы данных, строить точные модели и улучшать эффективность процессов.;5
Как мониторинг больших данных применяется в современных компаниях?;Мониторинг больших данных помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Технологии мониторинг больших данных позволяют компаниям обрабатывать большие объёмы разнородных данных, выявлять сложные закономерности и принимать обоснованные решения.;5
Какие основные инструменты и технологии используются для работы с data mining?;Data mining помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;4
Как глубокое обучение применяется для автоматизации рутинных процессов?;Глубокое обучение применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;5
Какие риски связаны с использованием рекомендательные системы в критически важных системах?;Рекомендательные системы помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Рекомендательные системы применяется в бизнесе и иногда в науке для анализа данных.;3
Какие подходы использовать для real-time агрегации потоковых данных?;Tumbling windows, sliding windows, session windows, incremental aggregation, использование stateful processing, оптимизация с помощью approximate algorithms.;Оконные агрегации (tumbling, sliding), инкрементальные вычисления. Stateful обработка потоков.;4
Какие метрики используются для оценки бинарной классификации?;Accuracy, Precision, Recall, F1-score, ROC-AUC, PR-AUC, Confusion Matrix. Выбор зависит от задачи и дисбаланса классов.;Accuracy, Precision, Recall, F1-score, ROC-AUC. Precision важна когда false positive дорого, Recall когда false critical.;5
Основные вызовы больших данных (4V, 8V).;Основные характеристики больших данных обозначаются как 4V: Volume (объем), Velocity (скорость), Variety (разнообразие), Veracity (достоверность). В расширенной модели 8V добавляются Value (ценность), Variability (изменчивость), Visualization (визуализация), Vulnerability (уязвимость).;Концепция 4V включает Volume, Velocity, Variety, Veracity. Дополнительно выделяют Value, Variability, Visualization, Vulnerability.;5
Что такое feature store?;Централизованное хранилище для управления и обслуживания признаков ML моделей.;Централизованный репозиторий для управления фичами машинного обучения, который обеспечивает повторное использование, консистентность и эффективное обслуживание фич для тренировки и продакшена.;4
Что такое YARN?;Компонент Hadoop для управления ресурсами кластера и планирования задач. Отделяет функции управления от модели обработки данных.;Система управления ресурсами в Hadoop. Распределяет вычислительные мощности между приложениями и отслеживает использование кластера.;5
Разновидности сложных сетей;Сложные сети можно классифицировать на однородные, масштабно-инвариантные, сети малого мира и иерархические структуры, каждая из которых обладает уникальными свойствами и характеристиками;Существуют различные разновидности сложных сетевых структур, которые отличаются своими свойствами и закономерностями организации;5
Преобразование и очистка данных;Процесс преобразования включает нормализацию, кодирование категориальных переменных, обработку пропущенных значений и выбросов для улучшения качества данных;Включает стандартизацию/нормализацию числовых признаков, кодирование категориальных переменных, импутацию пропущенных значений методами mean/median/mode, обнаружение и обработку выбросов с помощью IQR или z-score;5
Что представляет собой 'обучение без учителя'?;Обучение без учителя — это метод, при котором данные не имеют заранее известных меток, и алгоритм должен самостоятельно выявлять структуры и зависимости.;Это метод анализа, где нет правильных ответов, и нужно искать сходства.;4
Как организовать систему кэширования для ускорения аналитических запросов к большим данным?;Многоуровневое кэширование (in-memory, SSD, disk), инвалидация кэша на основе TTL или изменений данных, предварительная агрегация, использование распределенных кэшей (Redis, Memcached).;Многоуровневый кэш, стратегии обновления кэша, предварительные вычисления агрегатов, распределенные in-memory хранилища для ускорения запросов к большим данным.;4
Меры качества для языковых моделей;Основные метрики включают перплексию для оценки модели, BLEU для перевода и ROUGE для суммаризации текстов;Метрики оценки качества работы с текстом;4
Что такое Big Data и каковы её основные характеристики?;Big Data — это технологии и методы обработки чрезвычайно больших объёмов данных, характеризующихся 5V: Volume, Velocity, Variety, Veracity, Value. Применяются в финансах, здравоохранении, промышленности.;Это когда данных слишком много, и компьютеры не справляются.;2
Какие инструменты используются для работы с распределённые вычисления?;Технологии распределённые вычисления позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Распределённые вычисления нужно только программистам, обычным компаниям оно бесполезно.;2
Что такое MLOps?;Практики CI/CD для развертывания и мониторинга ML моделей в продакшене;Подход к управлению жизненным циклом ML моделей;4
Что такое data lineage?;Отслеживание происхождения данных и их преобразований от источника до потребителя;Отслеживание истории данных от источника до конечного использования;4
Какие реальные примеры использования кластеризация данных существуют?;Кластеризация данных помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Кластеризация данных нужно только программистам, обычным компаниям оно бесполезно.;2
В чем преимущества применения предиктивная аналитика по сравнению с традиционными методами?;Предиктивная аналитика применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Используется для прогнозов и анализа информации.;3
Что такое Data Governance;Data Governance — это система управления доступностью, usability, integrity и безопасностью данных в организации через политики, стандарты и процессы.;Управление качеством данных;2
Как хранилища данных применяется в современных компаниях?;Технологии хранилища данных позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Хранилища данных применяется в финансах, медицине, рекламе и IT, помогает анализировать данные и строить модели.;4
Как data warehouses применяется в современных компаниях?;Data warehouses используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Эти технологии помогают работать с информацией и делать прогнозы.;3
Генеральная совокупность и выборка;Генеральная совокупность включает все объекты исследования, выборка является ее представительной частью;Полная совокупность и выборка;3
Что такое нормализация данных?;Приведение данных к единому масштабу без искажения соотношений.;Нормализация данных - это процесс приведения числовых признаков к сопоставимому масштабу, обычно в диапазон [0,1] или с единичной дисперсией, чтобы избежать доминирования признаков с большими значениями.;5
Наивный байесовский алгоритм;Наивный байесовский классификатор основан на теореме Байеса и предполагает условную независимость признаков при заданном классе для упрощения вычислений;Простой вероятностный классификатор использующий теорему Байеса;2
Какие интегральные метрики качества вы знаете?;ROC-AUC, Precision-Recall AUC, F1-score, R? - метрики, агрегирующие различные аспекты качества моделей;Интегральные метрики включают ROC-AUC и F1-score;5
Что понимается под термином 'recall'?;Recall — это доля правильно предсказанных положительных объектов среди всех реально положительных объектов.;Recall — это насколько модель хорошо ищет данные.;3
Назовите виды связи между переменными при корреляции.;Связь может быть положительной, отрицательной и нулевой  сильной, средней или слабой по модулю коэффициента корреляции.;Есть положительная и отрицательная корреляция.;2
Для чего нужны гипотезы в анализе данных;Для формулировки проверяемых утверждений и статистической проверки научных предположений;Для формулировки проверяемых утверждений и статистической проверки предположений;5
Нормальное распределение;Нормальное распределение характеризуется симметричной колоколообразной формой, параметрами ? и ?, встречается во многих природных явлениях;Симметричное распределение с параметрами;3
Какие метрики используются для оценки качества регрессионных моделей?;MSE, RMSE, MAE, R?, MAPE. Каждая метрика имеет свои преимущества: MSE чувствительна к выбросам, MAE более устойчива, R? показывает долю объясненной дисперсии.;MSE, MAE, R-squared - основные метрики для регрессии. MSE учитывает большие ошибки, MAE более робастна, R? показывает качество объяснения данных.;4
Какие проблемы возникают при использовании масштабируемые системы?;Масштабируемые системы помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Технологии позволяют улучшать качество аналитики, находить закономерности и предсказывать события.;4
Какие методы использовать для detection outliers в многомерных данных?;Mahalanobis distance, isolation forest, local outlier factor, DBSCAN, PCA-based methods, autoencoders reconstruction error.;Обнаружение выбросов в многомерных данных.;2
Как глубокое обучение помогает в анализе больших объемов данных?;Глубокое обучение помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Глубокое обучение нужно только программистам.;2
Какие методы используются для обработки пропущенных значений в данных?;Удаление строк с пропусками, импутация средним/медианой, предсказание значений с помощью ML моделей, интерполяция для временных рядов, создание отдельной категории для пропусков.;Способы работы с отсутствующими данными в наборах.;2
Какие компании активно используют нейронные сети и зачем?;Нейронные сети используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Помогает работать с данными и строить модели.;3
Каковы условия остановки ветвления дерева?;Остановка при достижении максимальной глубины, минимального числа samples в узле, отсутствии улучшения качества или pure node;Условия по глубине и количеству samples;4
Архитектура хранилищ данных;Современная архитектура хранилищ данных включает многоуровневую структуру с уровнями приема, обработки, хранения и анализа информации, использующую ETL-процессы, data lakes и специализированные витрины данных для различных бизнес-потребностей;Как устроены системы хранения информации в компаниях и организациях для работы с большими объемами цифровых данных;2
Какие риски связаны с применением data warehouses?;Технологии data warehouses позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Это что?то связанное с данными, но используется редко.;2
Принципы глубокого обучения в нейросетях;Глубокое обучение использует многослойные нейронные сети для автоматического извлечения признаков из данных, CNN специализируются на обработке изображений;Глубокие сети учатся иерархическим представлениям данных, CNN эффективны для компьютерного зрения благодаря сверточным слоям;3
Какие структуры данных используются в R и их примеры?;"Вектор (c(1,2,3)), матрица (matrix(1:6, nrow=2)), список (list(1, ""a"", TRUE)), data frame (data.frame(x=1:3, y=c(""a"",""b"",""c""))), фактор (factor(c(""A"",""B"",""A""))).";Векторы, матрицы, data frames для табличных данных, списки для сложных структур. Примеры создания и использования каждой структуры.;4
Какие вы знаете интегральные метрики качества;"""Интегральные метрики: ROC-AUC (площадь под кривой зависимости TPR от FPR), PR-AUC (площадь под кривой Precision-Recall), LogLoss = -1/N * ?[y*log(p) + (1 - y)*log(1 - p)].";AUC — это формула для проверки модели.;2
Критерии качества кластеризации;Метрики оценки кластеризации включают Silhouette score, Davies-Bouldin index и Calinski-Harabasz index для измерения компактности и разделимости кластеров;Silhouette оценивает компактность кластеров, Davies-Bouldin измеряет разделимость, Calinski-Harabasz оценивает дисперсию;3
Какие риски связаны с применением хранилища данных?;Хранилища данных помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Технологии хранилища данных позволяют компаниям обрабатывать большие объёмы разнородных данных, выявлять сложные закономерности и принимать обоснованные решения.;5
Как мониторить качество ML модели в продакшене?;Отслеживать accuracy/precision/recall на отложенной выборке, мониторить data drift и concept drift, отслеживать бизнес-метрики.;Проверять точность модели на новых данных, следить за изменениями в данных. Переобучать модель если качество падает.;3
Какие основные инструменты и технологии используются для работы с большие данные?;Большие данные используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Помогает работать с данными и строить модели.;3
Какие риски связаны с применением in-memory обработка?;In-memory обработка используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;In-memory обработка обеспечивает анализ потоковых данных, улучшает прогнозирование, помогает автоматизировать процессы и повышает точность аналитических моделей.;5
Что такое batch normalization?;Техника ускорения обучения глубоких нейронных сетей путем нормализации входов каждого слоя к нулевому среднему и единичной дисперсии для каждого мини-батча, что решает проблему internal covariate shift.;Способ нормализации данных в нейронных сетях. Улучшает и ускоряет обучение.;3
Метрики качества для моделей регрессии;Для оценки регрессионных моделей применяются RMSE, MAE, MAPE и коэффициент детерминации R?;Для оценки моделей регрессии используются RMSE, MAE и R?;4
Какие основные конструкции языка R?;Векторы, матрицы, списки, data frames, факторы. Функции, управляющие конструкции (if, for, while). Пакеты для расширения функциональности. Векторизованные операции.;Элементы языка R для работы с данными.;2
Как бороться с переобучением в глубоких нейронных сетях?;Dropout, batch normalization, early stopping, регуляризация L1/L2, data augmentation, уменьшение сложности сети, увеличение данных.;Использовать методы регуляризации и больше данных для обучения.;2
Что такое ETL-процессы и какие задачи оно решает?;Etl-процессы используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Etl-процессы нужно только программистам.;2
Что такое data mesh архитектура?;Децентрализованный подход к управлению данными с domain-oriented ownership;Способ организации данных;2
Как работает принцип векторных и матричных вычислений в R?;Векторизация позволяет применять операции ко всем элементам без циклов. Элементы обрабатываются параллельно, что ускоряет вычисления. Матричные операции используют линейную алгебру.;Обработка массивов данных целиком вместо поэлементной обработки. Быстрее и удобнее для анализа.;3
Как реализовать инкрементальную обработку данных в ETL пайплайнах?;Использовать Change Data Capture (CDC), watermarking для потоковых данных, инкрементальные snapshot'ы, обработку только дельт изменений вместо полных данных.;CDC для отслеживания изменений, watermark для потоковой обработки, инкрементальные снимки данных, обработка только измененных записей. Важно обеспечить идемпотентность и консистентность при инкрементальных обновлениях.;5
Какие подходы использовать для real-time агрегации потоковых данных?;Tumbling windows, sliding windows, session windows, incremental aggregation, использование stateful processing, оптимизация с помощью approximate algorithms.;Агрегация потоковых данных.;2
Какие риски связаны с использованием анализ данных в критически важных системах?;Анализ данных используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Анализ данных — это что-то про компьютеры. Применяется редко.;2
Какие риски связаны с применением кластеризация данных?;Кластеризация данных помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Кластеризация данных применяется в финансах, медицине, рекламе и IT, помогает анализировать данные и строить модели.;4
Зачем нужны рекуррентные нейросети?;Рекуррентные нейросети (RNN) используются для работы с последовательными данными — текст, временные ряды, речь. Основная идея — наличие памяти о предыдущих состояниях. Формула: h_t = f(Wx_t + Uh_{t-1}).;RNN — это просто обычная нейросеть.;2
Какие реальные примеры использования кластеризация данных существуют?;Технологии кластеризация данных позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Кластеризация данных почти нигде не применяется. Это просто большие таблицы.;2
Какие основные конструкции языка R?;Векторы, матрицы, списки, data frames, факторы. Функции, управляющие конструкции (if, for, while). Пакеты для расширения функциональности. Векторизованные операции.;Типы данных и операции для статистического анализа. Функции и пакеты.;3
В каких областях деятельности используются большие данные, привести примеры;Используются в финансах (fraud detection), ритейле (recommendations), healthcare (personalized medicine), транспорте (route optimization);Применение в разных сферах;2
Перечислите и поясните с формулами и примерами метрики качества для бинарной классификации.;Основные метрики: Accuracy = (TP + TN) / (TP + FP + TN + FN), Precision = TP / (TP + FP), Recall = TP / (TP + FN), F1 = 2 * (Precision * Recall) / (Precision + Recall).;Метрики: Accuracy, Precision, Recall, F1 — вычисляются по TP, TN, FP, FN. Пример: F1 = 2*(P*R)/(P+R).;5
Что представляет собой 'обучение без учителя'?;Обучение без учителя — это метод, при котором данные не имеют заранее известных меток, и алгоритм должен самостоятельно выявлять структуры и зависимости.;Это метод, где случайным образом анализируют набор данных без цели.;2
Основные задачи Data Analysis;Описательная аналитика, диагностика, прогнозирование, прескриптивная аналитика для принятия решений;Data Analysis включает описательную и прогнозную аналитику;5
В чем разница между SQL и NoSQL базами данных?;SQL базы реляционные, с жесткой схемой, используют SQL для запросов. NoSQL - нереляционные, с гибкой схемой, горизонтально масштабируемые.;SQL использует таблицы и связи, NoSQL более гибкие и лучше масштабируются. Подходят для разных типов данных.;4
Как работает принцип векторных и матричных вычислений в R?;Векторизация позволяет применять операции ко всем элементам без циклов. Элементы обрабатываются параллельно, что ускоряет вычисления. Матричные операции используют линейную алгебру.;Вычисления над всеми элементами структур данных сразу, без циклов. Эффективно для больших данных и математических операций.;4
Как глубокое обучение помогает в анализе больших объемов данных?;Глубокое обучение помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Это просто работа с таблицами. Не очень полезно.;2
Какие основные инструменты и технологии используются для работы с нейронные сети?;Нейронные сети помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Это просто работа с таблицами. Не очень полезно.;2
Основные метрики больших графов;Ключевые метрики включают диаметр графа, плотность связей, коэффициент кластеризации и различные меры центральности;Основные показатели для анализа графовых структур;4
Какие проблемы возникают при использовании data lakes?;Data lakes используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Data lakes применяется в финансах, медицине, рекламе и IT, помогает анализировать данные и строить модели.;4
Как бороться с переобучением в глубоких нейронных сетях?;Dropout, batch normalization, early stopping, регуляризация L1/L2, data augmentation, уменьшение сложности сети, увеличение данных.;Добавить dropout, использовать early stopping, увеличить количество тренировочных данных.;3
Что такое K-means кластеризация?;Метод кластеризации, разделяющий данные на k кластеров на основе расстояния до центроидов.;K-means итеративно группирует данные в k кластеров, минимизируя суммарное квадратичное расстояние от точек до центроидов их кластеров, где k задается заранее.;5
Стандартизация и нормализация переменных: зачем нужны?;Стандартизация и нормализация обеспечивают сопоставимость признаков, улучшают сходимость алгоритмов и повышают точность моделей машинного обучения;Стандартизация и нормализация нужны для улучшения работы алгоритмов машинного обучения;5
Как выбрать между L1 и L2 регуляризацией для линейной модели?;L1 (Lasso) лучше когда нужен отбор признаков и интерпретируемость, L2 (Ridge) когда важна стабильность и все признаки потенциально полезны. L1 обнуляет неважные веса, L2 только уменьшает их.;L1 используют для отбора признаков, так как он обнуляет некоторые веса. L2 применяют когда хотят уменьшить влияние всех признаков без полного исключения.;4
Что такое convolutional neural network (CNN)?;Архитектура нейросетей для обработки изображений с использованием сверточных слоев.;Специализированная архитектура нейронных сетей для работы с изображениями, которая применяет свертки для обнаружения локальных паттернов и постепенного уменьшения пространственной размерности.;4
Boxplot и его интерпретация, связь с другими элементами анализа;"Boxplot показывает медиану, квартили, выбросы; связан с описательной статистикой и проверкой распределений";Boxplot показывает медиану и квартили распределения;5
Что такое k-fold cross validation?;Метод валидации, при котором данные разбиваются на k равных частей, модель обучается на k-1 частях и тестируется на оставшейся.;Метод оценки модели когда данные делят на k частей. k раз обучают на k-1 частях и тестируют на одной, затем усредняют результаты для надежной оценки.;5
Меры качества для языковых моделей;Основные метрики включают перплексию для оценки модели, BLEU для перевода и ROUGE для суммаризации текстов;Для оценки языковых моделей используются различные метрики качества;5
Как специалисты анализируют данные в рамках ETL-пайплайны?;Etl-пайплайны используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Это что?то связанное с данными, но используется редко.;2
Как работает Federated Learning и в каких сценариях он наиболее эффективен?;Обучение моделей на децентрализованных данных без их передачи на сервер. Эффективен для privacy-sensitive сценариев: healthcare, мобильные устройства, где данные нельзя централизовать.;Модель обучается локально на устройствах, только градиенты агрегируются на сервере. Идеально для сценариев с конфиденциальными данными: медицинские records, персональные данные на телефонах.;5
Что такое Apache Iceberg?;Открытый табличный формат для больших данных с ACID транзакциями и версионированием.;Современный формат для хранения таблиц в data lakes с поддержкой транзакций и версий данных.;3
Нарисуйте схему классификации методов машинного обучения.;Методы ML классифицируются на обучение с учителем, без учителя и с подкреплением. Также выделяют подтипы — классификация, регрессия, кластеризация, ассоциативные правила, ансамблевые методы.;Существует обучение с учителем и без него.;3
Что такое A/B тестирование?;Статистический метод сравнения двух версий для определения лучшей на основе метрик.;A/B тестирование - это рандомизированный эксперимент, где две группы пользователей видят разные версии продукта, и статистически значимые различия в их поведении определяют лучшую версию.;5
Что такое Data Mesh архитектура и как она решает проблемы централизованных data lakes?;Децентрализованный подход, где данные управляются domain-командами как продукты. Решает проблемы монолитных data lakes: bottlenecks, низкое качество данных, сложность масштабирования.;Современный подход к организации данных в больших компаниях.;2
Как организовать систему кэширования для ускорения аналитических запросов к большим данным?;Многоуровневое кэширование (in-memory, SSD, disk), инвалидация кэша на основе TTL или изменений данных, предварительная агрегация, использование распределенных кэшей (Redis, Memcached).;Система кэширования для быстрого доступа к данным.;2
Как работает технология Data Virtualization и какие проблемы она решает?;Предоставляет unified view данных без физического перемещения. Решает проблемы data silos, уменьшает latency доступа, упрощает data governance в распределенных системах.;Технология доступа к данным из разных источников через единый интерфейс. Упрощает работу с распределенными и разнородными данными.;3
Что такое data versioning?;Контроль версий для наборов данных и их метаданных;Отслеживание изменений в данных во времени;4
Как оценивается качество рекомендательных систем?;Для оценки рекомендательных систем используются Precision@K, Recall@K, NDCG, MAP и метрики разнообразия рекомендаций;Для оценки используются Precision@K, Recall@K и NDCG;5
Основные задачи Data Analysis;К основным задачам относятся описательная аналитика, диагностика проблем, прогнозирование и прескриптивная аналитика;Задачи анализа данных;2
Примеры задач с большими графами;Большие графы применяются в социальных сетях, рекомендательных системах и биоинформатике для анализа сложных связей;Графы в социальных сетях;2
Что такое consumer groups;Consumer group — это группа потребителей, которые совместно обрабатывают сообщения из топика. Каждое сообщение доставляется только одному потребителю в группе.;Это группа получателей, которые вместе читают сообщения.;2
Data Mining vs. Machine Learning — в чём отличия?;Data Mining фокусируется на обнаружении паттернов в данных, а Machine Learning - на построении прогнозных моделей;Data Mining фокусируется на паттернах, Machine Learning на прогнозировании;5
Какие метрики используются для оценки бинарной классификации?;Accuracy, Precision, Recall, F1-score, ROC-AUC, PR-AUC, Confusion Matrix. Выбор зависит от задачи и дисбаланса классов.;Accuracy, Precision, Recall, F1. Для несбалансированных данных лучше использовать Precision-Recall и F1-score.;4
Для чего нужны индексы Gain и Gini? В чём суть индекса Gini.;Индексы Gain и Gini используются в деревьях решений для выбора оптимального признака при разбиении узлов. Индекс Gini измеряет неоднородность данных и стремится к нулю для чистых узлов.;Индексы Gain и Gini используются для выбора признаков в деревьях, Gini измеряет неоднородность;5
Какие знаете алгоритмы классификации;Основные алгоритмы классификации включают логистическую регрессию, метод опорных векторов, деревья решений, случайный лес, наивный байесовский классификатор и k-ближайших соседей;Алгоритмы: логистическая регрессия, SVM, деревья решений, случайный лес для задач классификации;4
Структуры и типы данных в R;Векторы, матрицы, списки, фреймы данных, факторы - основные структуры хранения данных;Векторы, матрицы, списки, data.frame для работы с данными;3
Как рекомендуется разделять данные для обучения моделей?;60-80% тренировочные, 10-20% валидационные, 10-20% тестовые. Для кросс-валидации - k-fold разбиение. Зависит от объема данных.;Train 70-80%, validation 10-15%, test 10-15%. Или кросс-валидация при недостатке данных. Сохранять баланс классов в выборках.;4
Как работает технология MapReduce в экосистеме Hadoop?;MapReduce разделяет обработку данных на этапы Map (разбиение и фильтрация) и Reduce (агрегация), позволяя распределенно обрабатывать большие объемы информации на кластерах;Распределенная обработка через Map и Reduce этапы;4
Сравнительная характеристика R и Python.;R — это специализированный язык для статистики и визуализации, Python — универсальный язык с библиотеками для анализа данных (NumPy, pandas, scikit-learn). R более мощен для статистических тестов, Python — для интеграции и масштабируемых решений.;R и Python — одинаковые языки, только Python новее.;2
Что такое ROC-кривая?;ROC-кривая — это график зависимости True Positive Rate от False Positive Rate, используемый для оценки качества бинарного классификатора.;ROC-кривая строится по значениям истинно положительных и ложноположительных срабатываний.;4
Что такое PostgreSQL?;Реляционная СУБД с открытым исходным кодом, поддерживающая расширенные типы данных и SQL стандарты.;Мощная реляционная БД с открытым кодом. Поддерживает сложные типы данных, транзакции и имеет высокую производительность.;4
Принципы глубокого обучения в нейросетях;Глубокое обучение использует многослойные нейросети для автоматического извлечения признаков из данных различной природы;Глубокое обучение основано на многослойных нейросетях для автоматического извлечения признаков из данных;5
Что такое Synthetic Data Generation и когда его использование оправдано?;Создание искусственных данных сохраняющих статистические свойства реальных. Оправдано при недостатке данных, privacy concerns, testing систем, imbalance correction.;Генерация искусственных данных похожих на реальные. Используется когда мало данных, для защиты приватности, тестирования, балансировки наборов данных.;5
Как предобработка данных применяется в современных компаниях?;Предобработка данных используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Предобработка данных нужно только программистам, обычным компаниям оно бесполезно.;2
Почему организации переходят на технологии системы логирования?;Технологии системы логирования позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Системы логирования обеспечивает анализ потоковых данных, улучшает прогнозирование, помогает автоматизировать процессы и повышает точность аналитических моделей.;5
Что такое Data Lake и чем он отличается от Data Warehouse?;Data Lake — это централизованное хранилище, где данные сохраняются в исходном виде. Data Warehouse — структурированное хранилище для анализа. Главное отличие — степень структурированности данных.;Data Lake хранит неструктурированные данные, а Warehouse — структурированные для аналитики.;3
Достоинства и недостатки деревьев решений;Достоинства: интерпретируемость, работа с категориальными признаками, не требуют масштабирования. Недостатки: склонность к переобучению, нестабильность, чувствительность к шуму;Интерпретируемость vs переобучение;3
Какие типы данных существуют в языке R?;Numeric, integer, character, logical, complex. Специальные: NA для пропусков, NULL, factors для категориальных данных. Векторы базовых типов.;Основные: numeric, integer, character, logical. Специальные: factor, NA, NULL, NaN. Каждый тип имеет свои особенности хранения и обработки.;5
Как компьютерное зрение помогает в анализе больших объемов данных?;Компьютерное зрение применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Это просто работа с таблицами. Не очень полезно.;2
Характерные черты безмасштабных сетей, какова их связь с сетями тесного мира?;Безмасштабные сети имеют степенное распределение степеней вершин (P(k)~k^-?), содержат хабы. Сети тесного мира характеризуются малой длиной пути и высоким коэффициентом кластеризации. Обе модели встречаются в реальных системах.;Безмасштабные сети состоят из узлов с разной степенью связи, тесный мир имеет короткие расстояния между вершинами.;3
Перечислите шкалы измерений. Приведите примеры их использования;Номинальная (пол, цвет), порядковая (уровень образования), интервальная (температура), относительная (вес, доход);Шкалы измерений включают номинальную, порядковую, интервальную и относительную;5
Работа кластеризатора k-means;Итеративный алгоритм с центроидами, минимизация внутрикластерного расстояния;Выбирает k центров, назначает точки, пересчитывает центры;3
Как организовать мониторинг производительности распределенных data processing jobs?;Metrics collection (throughput, latency, resource usage), distributed tracing, alerting on anomalies, dashboard visualization, correlation с business metrics.;Сбор метрик производительности, distributed tracing, алертинг при аномалиях, визуализация на дашбордах. Корреляция с бизнес-метриками.;5
Виды распределения данных и примеры;Основные виды распределений: нормальное (рост людей), равномерное (бросок кости), экспоненциальное (время между событиями), биномиальное (успехи в испытаниях);Различные типы распределений данных с примерами;4
Шаги построения дендрограммы;Построение дендрограммы включает вычисление матрицы расстояний между объектами, применение агломеративного алгоритма кластеризации и визуализацию иерархической структуры;Расчет попарных расстояний, последовательное объединение ближайших кластеров, построение дерева слияний;3
Как глубокое обучение помогает в анализе больших объемов данных?;Глубокое обучение помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Глубокое обучение применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;4
Что такое dropout в нейросетях?;Метод регуляризации, при котором случайно выбранные нейроны игнорируются во время обучения для предотвращения переобучения.;Техника когда случайные нейроны временно отключаются во время обучения. Помогает сети стать более robust и предотвращает переобучение.;5
Меры изменчивости;Дисперсия, стандартное отклонение, размах, межквартильный размах - показатели разброса данных;Дисперсия, стандартное отклонение, размах и межквартильный размах;4
Какие основные инструменты и технологии используются для работы с нейронные сети?;Нейронные сети используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Используется для прогнозов и анализа информации.;3
Как анализ данных применяется для автоматизации рутинных процессов?;Анализ данных применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;4
Какие подходы использовать для обработки полуструктурированных данных (JSON, XML) в Big Data системах?;Использование форматов с schema evolution (Avro, Parquet), извлечение полей в отдельные колонки, хранение в native формате с индексацией, использование специализированных функций для querying.;Эффективные форматы хранения, извлечение полей, индексация, специальные операторы для запросов. Балансировать между гибкостью и производительностью при работе с JSON/XML.;4
Какие проблемы возникают при использовании ETL-пайплайны?;Etl-пайплайны помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Технологии позволяют улучшать качество аналитики, находить закономерности и предсказывать события.;4
Как работает технология MapReduce в экосистеме Hadoop?;MapReduce разделяет обработку данных на этапы Map (разбиение и фильтрация) и Reduce (агрегация), позволяя распределенно обрабатывать большие объемы информации на кластерах;Двухэтапная модель обработки больших данных;3
Что такое random forest?;Ансамблевый метод, строящий множество решающих деревьев на случайных подвыборках данных и признаков.;Ансамбль деревьев решений. Каждое дерево обучается на случайной выборке данных и признаков, затем результаты усредняются.;4
Перечислите и поясните с формулами и примерами метрики качества для бинарной классификации.;Основные метрики: Accuracy = (TP + TN) / (TP + FP + TN + FN), Precision = TP / (TP + FP), Recall = TP / (TP + FN), F1 = 2 * (Precision * Recall) / (Precision + Recall).;F1 — это формула для проверки модели.;2
Какие инструменты используются для работы с масштабируемые системы?;Масштабируемые системы используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Масштабируемые системы нужно только программистам, обычным компаниям оно бесполезно.;2
Работа кластеризатора k-means;Итеративный алгоритм с центроидами, минимизация внутрикластерного расстояния;1) Инициализация k центроидов 2) Назначение точек ближайшим центрам 3) Пересчет центроидов 4) Повтор до стабилизации - минимизация WCSS;5
Какие проблемы возникают при использовании хранилища данных?;Технологии хранилища данных позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Эти технологии помогают работать с информацией и делать прогнозы.;3
Как развивается направление системы логирования в последние годы?;Технологии системы логирования позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Системы логирования нужно только программистам, обычным компаниям оно бесполезно.;2
Что такое регрессионный анализ;Статистический метод моделирования зависимостей между переменными для прогнозирования численных значений;Метод анализа данных для моделирования зависимостей между переменными и построения прогнозов;5
Стандарты жизненного цикла Big Data: CRISP?DM;CRISP-DM представляет собой стандартизированный процесс, включающий 6 этапов: бизнес-понимание, понимание данных, подготовка данных, моделирование, оценка и внедрение;CRISP-DM включает этапы бизнес-понимания, подготовки данных и моделирования;5
Какие реальные кейсы демонстрируют эффективность анализ данных?;Анализ данных помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;4
Что такое ARIMA модель?;Модель для прогнозирования временных рядов, учитывающая автокорреляцию и дифференцирование.;Метод прогнозирования временных рядов, который учитывает прошлые значения и тенденции для предсказания будущего.;3
Как выбрать между колоночным и строчным хранением данных для аналитических нагрузок?;Колоночное хранилище лучше для аналитических запросов с агрегациями по немногим колонкам, строчное - для OLTP с операциями над целыми строками. Использовать колоночные форматы (Parquet, ORC) для data warehousing.;Для аналитики лучше колоночное хранение, для OLTP - строчное. Зависит от типа запросов.;3
Как развитие рекомендательные системы влияет на будущее цифровых технологий?;Рекомендательные системы помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Используется для прогнозов и анализа информации.;3
Зачем нужны рекуррентные нейросети;Для обработки последовательных данных: текст, речь, временные ряды. Сохраняют контекст;Для работы с последовательностями;2
Порядок тестирования гипотезы о равенстве средних;Процесс включает формулировку гипотез, проверку условий, расчет статистики и принятие решения;Проверка гипотез включает несколько последовательных этапов;4
Что такое Quantum Machine Learning и какие преимущества оно обещает?;Применение квантовых вычислений для ML алгоритмов. Обещает экспоненциальное ускорение для optimization problems, quantum feature spaces, обработки больших данных.;ML на квантовых компьютерах. Обещает значительное ускорение для сложных вычислений, новых подходов к feature engineering, решения оптимизационных задач.;4
Как ETL-пайплайны влияет на эффективность бизнеса?;Etl-пайплайны помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Etl-пайплайны применяется в финансах, медицине, рекламе и IT, помогает анализировать данные и строить модели.;4
Какие бывают виды регрессионного анализа? Поясните логистическую регрессию и SVM;Виды регрессии включают линейную, полиномиальную, логистическую и др. Логистическая регрессия предсказывает вероятности бинарной классификации, а SVM находит оптимальную разделяющую гиперплоскость;Линейная и логистическая регрессия для разных типов задач;3
Какие реальные примеры использования обработка потоковых данных существуют?;Обработка потоковых данных помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Обработка потоковых данных используется бизнесом для оптимизации процессов, анализа клиентов и прогнозирования.;4
Структуры и типы данных в R;Основные структуры данных в R включают векторы для атомарных данных, матрицы для двумерных массивов, списки для разнотипных коллекций, фреймы данных для таблиц и факторы для категориальных переменных;Векторы, матрицы и другие структуры в R;3
Как распределённые вычисления влияет на эффективность бизнеса?;Технологии распределённые вычисления позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Технологии распределённые вычисления позволяют компаниям обрабатывать большие объёмы разнородных данных, выявлять сложные закономерности и принимать обоснованные решения.;5
Измерение качества модели анализа данных;Качество моделей оценивается с помощью метрик accuracy, precision, recall, F1-score для классификации и RMSE, MAE, R? для регрессии;"Для классификации: точность, полнота, F-мера; для регрессии: среднеквадратичная ошибка, коэффициент детерминации";3
Какие риски связаны с применением распределённые вычисления?;Распределённые вычисления помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Распределённые вычисления используется бизнесом для оптимизации процессов, анализа клиентов и прогнозирования.;4
В каких пропорциях рекомендуют разделять данные перед обучением и на какие части?;Обычно данные делятся на три части: обучающую 70%, валидационную 15% и тестовую 15%. Это обеспечивает корректную оценку модели без переобучения.;Рекомендуемое разделение: 70% обучающие, 15% валидация, 15% тестовые.;5
Шкалы измерений, примеры;Номинальная, порядковая, интервальная, относительная;Номинальная (цвета), порядковая (оценки), интервальная (температура);3
Какие навыки необходимы специалисту для работы с обработка данных?;Обработка данных применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Используется для прогнозов и анализа информации.;3
Как оптимизировать запросы к данным с временными рядами для аналитических нагрузок?;Партиционирование по времени, индексы по временным меткам, материализованные представления для агрегатов, сжатие временных данных, использование специализированных TSDB.;Партиционирование по времени, временные индексы, предварительные агрегаты, сжатие данных, использование TSDB для эффективной работы с временными рядами.;4
Что такое обучение без учителя и для чего оно используется?;Обучение без учителя применяется, когда нет размеченных данных. Основные задачи: кластеризация и снижение размерности.;Обучение без учителя — когда нет правильных ответов, используется для группировки данных.;4
В чем разница между SQL и NoSQL базами данных?;SQL базы реляционные, с жесткой схемой, используют SQL для запросов. NoSQL - нереляционные, с гибкой схемой, горизонтально масштабируемые.;Это разные системы хранения информации. NoSQL более современные и быстрые.;2
Как выбрать между различными алгоритмами кластеризации для конкретной задачи?;Анализировать форму кластеров (K-means для spherical, DBSCAN для произвольных), наличие шума (DBSCAN robust к выбросам), знание числа кластеров (K-means требует k), размер данных.;K-means для сферических кластеров когда известно их число, DBSCAN для произвольных форм и данных с шумом, hierarchical для иерархической структуры. Оценивать форму данных и требования к результату.;4
Как хранилища данных влияет на эффективность бизнеса?;Хранилища данных помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Хранилища данных используется бизнесом для оптимизации процессов, анализа клиентов и прогнозирования.;4
Что такое регрессионный анализ какие задачи DM можно проводить с его помощью?,;"""Регрессионный анализ — метод моделирования зависимости переменной Y от одной или нескольких переменных X. Применяется для прогнозирования, оценки влияния факторов и аппроксимации зависимостей.";Регрессионный анализ ищет зависимость между переменными и помогает делать прогнозы по данным.;3
Основные вызовы больших данных;Ключевые вызовы включают объем (Volume), скорость (Velocity), разнообразие (Variety) и достоверность (Veracity) данных, требующие специальных подходов к обработке;Проблемы связанные с обработкой очень больших и сложных наборов данных;2
Виды распределения данных и примеры;Есть нормальное и равномерное распределение.;Примеры — рост людей или случайные числа.;4
Виды столбчатых диаграмм и их интерпретация;"Столбчатые диаграммы включают вертикальные, горизонтальные, сгруппированные и stacked; интерпретируются через сравнение величин категорий";Типы столбчатых графиков;2
Что такое attention mechanism?;Механизм, позволяющий модели фокусироваться на relevant частях входных данных.;Attention mechanism позволяет нейронным сетям динамически взвешивать важность разных частей входной последовательности при генерации каждой части выходной последовательности, значительно улучшая качество в задачах типа машинного перевода.;5
Что такое sharding в базах данных?;Горизонтальное разделение данных на основе ключа sharding для распределения нагрузки;Разделение данных между разными серверами;3
NoSQL классификация хранилищ;NoSQL базы данных классифицируются на документные хранилища, хранилища ключ-значение, колоночные базы данных и графовые базы данных в зависимости от модели данных и способа организации хранения информации;Основные категории нереляционных баз данных по типам структур хранения;2
Какие особенности архитектуры потоковой обработки данных?;Архитектура потоковой обработки включает ingestion слои (Kafka), processing (Spark Streaming, Flink) и sink слои для хранения, обеспечивая обработку в реальном времени;Обработка данных в реальном времени;2
В чем преимущества применения ETL-процессы по сравнению с традиционными методами?;Etl-процессы применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Etl-процессы применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;5
Что такое Apache NiFi?;Система для автоматизации потоков данных между различными источниками и приемниками с визуальным интерфейсом.;Инструмент для создания потоков данных. Перемещает данные между источниками с гарантированной доставкой.;3
Какие риски связаны с использованием data mining в критически важных системах?;Data mining помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;4
Как выбрать оптимальную стратегию партиционирования данных в распределенной системе?;Выбор зависит от паттернов доступа: партиционирование по диапазону для range queries, по хэшу для равномерного распределения, по списку для категориальных данных. Учитывать размер партиций и частоту запросов.;Выбирать тип партиционирования в зависимости от запросов и характеристик данных для равномерного распределения нагрузки.;3
Какие дополнительные V добавляют к расширенной модели Big Data?;Value (ценность данных), Variability (изменчивость), Visualization (визуализация), Validity (валидность данных). Эти характеристики дополняют основные 4V и подчеркивают бизнес-аспекты.;Value - бизнес-ценность, Variability - изменения в данных, Visualization - визуализация, Validity - правильность данных.;4
Какие дополнительные V добавляют к расширенной модели Big Data?;Value (ценность данных), Variability (изменчивость), Visualization (визуализация), Validity (валидность данных). Эти характеристики дополняют основные 4V и подчеркивают бизнес-аспекты.;Value - полезность данных для бизнеса, Variability - изменчивость потоков, Visualization - представление данных, Validity - корректность и соответствие требованиям.;5
Какие признаки создавать для временных рядов при feature engineering?;Лаги, скользящие статистики (mean, std), временные характеристики (час, день недели), фичи из Fourier transform, difference.;Взять прошлые значения и разные статистики из истории.;2
Какие реальные кейсы демонстрируют эффективность рекомендательные системы?;Рекомендательные системы используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;5
Обучение с подкреплением и ансамбли;Обучение с подкреплением основано на взаимодействии агента со средой для максимизации награды, а ансамбли объединяют несколько моделей для улучшения прогнозирования;Reinforcement learning использует марковские процессы принятия решений, ансамбли применяют bagging, boosting и stacking для агрегации предсказаний;4
Измерение качества модели анализа данных;Качество моделей анализа данных оценивается с помощью метрик accuracy, precision, recall, F1-score для классификации и RMSE, MAE, R? для регрессионных моделей;Модели можно оценивать разными способами;2
Мотивация происхождения NoSQL;NoSQL базы данных возникли из-за необходимости обработки больших объемов неструктурированных данных, горизонтального масштабирования и обеспечения высокой производительности при работе с распределенными системами;NoSQL возникли из-за необходимости обработки больших объемов неструктурированных данных и горизонтального масштабирования;5
Виды столбчатых диаграмм и их интерпретация;"Столбчатые диаграммы включают вертикальные, горизонтальные, сгруппированные и stacked; интерпретируются через сравнение величин категорий";Вертикальные, горизонтальные, сгруппированные;3
Для чего нужна гипотеза о равенстве средних?;Гипотеза о равенстве средних используется для проверки различий между двумя выборками. Применяется t-тест (t = (x?1 - x?2) / s_p?(1/n1 + 1/n2)).;Для проверки равенства средних двух выборок.;4
Как принято формулировать нулевую гипотезу?;Как утверждение об отсутствии эффекта, различий или связи между переменными;Утверждение об отсутствии различий;3
Алгоритмы классификации;Основные алгоритмы включают логистическую регрессию, деревья решений, случайный лес, SVM и наивный байесовский классификатор;Основные алгоритмы включают логистическую регрессию, деревья решений и SVM;5
Как оптимизировать memory usage в Spark при работе с wide transformations?;Увеличение памяти исполнителей, использование off-heap memory, оптимизация serialization, уменьшение размера данных перед shuffling, использование broadcast variables.;Настройка памяти, off-heap, сериализация. Оптимизация данных для wide transformations в Spark.;4
Шкалы измерений, примеры;Номинальная, порядковая, интервальная, относительная;Есть разные шкалы для разных данных;2
Какие подходы использовать для feature selection в задачах с тысячами признаков?;Filter methods (correlation, mutual info), wrapper methods (recursive feature elimination), embedded methods (L1 regularization), domain knowledge. Начинать с фильтров для быстрого сокращения.;Фильтры для быстрого отбора, wrapper методы для точного выбора, embedded методы которые встроены в алгоритмы. Комбинировать статистические подходы с domain knowledge.;4
Перечислить стадии разработки систем машинного обучения;Этапы включают сбор данных, их очистку, выбор признаков, построение и обучение модели, проверку качества и внедрение.;Сначала собирают данные, очищают их, обучают модель и проверяют результат.;5
Когда использовать линейные, а когда нелинейные модели?;"Линейные - при линейных зависимостях, нелинейные - при сложных паттернах; выбор через анализ остатков";Критерии выбора моделей;2
Что такое K-means кластеризация?;Метод кластеризации, разделяющий данные на k кластеров на основе расстояния до центроидов.;Алгоритм кластеризации, который делит данные на заданное число кластеров, находя центры кластеров и назначая точки ближайшему центру.;4
Нормальное распределение;Нормальное распределение характеризуется симметричной колоколообразной формой, параметрами ? и ?, встречается во многих природных явлениях;Нормальное распределение имеет колоколообразную форму с параметрами ? и ?;5
Как внедрение ETL-процессы влияет на процессы в организациях?;Etl-процессы применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Это просто работа с таблицами. Не очень полезно.;2
Что такое регуляризация в машинном обучении?;Регуляризация — это метод предотвращения переобучения за счёт добавления штрафа за сложность модели в функцию потерь (например, L1, L2).;Регуляризация — это когда уменьшают данные.;2
Требования ACID. CAP?теорема, BASE?архитектура;ACID - гарантии целостности транзакций, CAP - невозможность одновременно обеспечить согласованность, доступность и устойчивость к разделению;ACID обеспечивает надежность транзакций, CAP показывает компромиссы в распределенных системах;3
В каких областях деятельности используются большие данные, привести примеры;Используются в финансах (fraud detection), ритейле (recommendations), healthcare (personalized medicine), транспорте (route optimization);Примеры использования в различных отраслях;4
Как реализовать инкрементальную обработку данных в ETL пайплайнах?;Использовать Change Data Capture (CDC), watermarking для потоковых данных, инкрементальные snapshot'ы, обработку только дельт изменений вместо полных данных.;Обрабатывать только измененные данные через CDC и инкрементальные подходы вместо полной перезагрузки.;3
Что такое collaborative filtering?;Метод рекомендательных систем, основанный на поведении и предпочтениях пользователей.;Collaborative filtering строит рекомендации на основе схожести пользователей или items, используя либо user-based подход (похожие пользователи), либо item-based подход (похожие товары).;5
В чем преимущества применения модели прогнозирования по сравнению с традиционными методами?;Модели прогнозирования применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;5
Что такое большие данные и какие задачи оно решает?;Большие данные применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Большие данные применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;5
Работа кластеризатора k-means;Итеративный алгоритм с центроидами, минимизация внутрикластерного расстояния;Итеративно обновляет центроиды и перераспределяет точки до сходимости, минимизируя сумму квадратов расстояний;4
Какие риски связаны с применением хранилища данных?;Хранилища данных помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Хранилища данных используется для обработки информации и улучшения решений.;3
Основные задачи Data Analysis;К основным задачам относятся описательная аналитика, диагностика проблем, прогнозирование и прескриптивная аналитика;Описательная и прогнозная аналитика;3
Как специалисты анализируют данные в рамках in-memory обработка?;In-memory обработка используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;In-memory обработка обеспечивает анализ потоковых данных, улучшает прогнозирование, помогает автоматизировать процессы и повышает точность аналитических моделей.;5
Что такое 'оценка точности модели'?;Оценка точности модели — это процесс измерения доли правильных предсказаний модели относительно всех предсказаний.;Оценка точности модели — это вычисление доли правильных ответов от общего числа предсказаний.;5
Что такое 4V в Big Data и объясните каждую характеристику?;Volume (объем данных), Velocity (скорость генерации и обработки), Variety (разнообразие форматов), Veracity (достоверность и качество данных). Эти характеристики определяют сложности работы с большими данными.;Volume - размер данных, Velocity - скорость, Variety - типы данных, Veracity - качество. Основные вызовы Big Data.;4
Метрики качества для моделей регрессии;Для оценки регрессионных моделей используются RMSE, MAE, MAPE и R? для измерения точности предсказаний;Метрики: RMSE, MAE, MAPE, R?;4
Обучение с подкреплением и ансамбли;Обучение с подкреплением основано на взаимодействии агента со средой для максимизации награды, а ансамбли объединяют несколько моделей для улучшения прогнозирования;RL решает задачи последовательного принятия решений, ансамбли снижают variance и bias через комбинацию моделей;3
Что такое анализ данных и какие задачи оно решает?;Анализ данных используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Используется для прогнозов и анализа информации.;3
Что такое collaborative filtering?;Метод рекомендательных систем, основанный на поведении и предпочтениях пользователей.;Метод построения рекомендаций на основе анализа поведения группы пользователей.;3
Что такое 'функция активации' в нейросети?;Функция активации определяет, будет ли нейрон активирован, и вносит нелинейность в модель.;Функция активации помогает модели обучаться нелинейным зависимостям.;4
В чем разница между batch processing и stream processing?;Batch processing обрабатывает данные пачками с задержкой, stream processing обрабатывает данные в реальном времени по мере поступления.;Batch - обработка накопленных данных, stream - обработка в реальном времени. Batch имеет большую задержку, stream - низкую задержку.;5
Что понимается под признаковым пространством (feature space)?;Признаковое пространство — это многомерное пространство, где каждая ось соответствует отдельному признаку, а каждая точка — объекту с набором характеристик.;Пространство — это место, где лежат данные.;2
Какие знаете алгоритмы классификации;Основные алгоритмы классификации включают логистическую регрессию, метод опорных векторов, деревья решений, случайный лес, наивный байесовский классификатор и k-ближайших соседей;Логистическая регрессия, SVM, деревья решений, случайный лес и другие алгоритмы для классификации данных;3
Как принято формулировать нулевую гипотезу?;Нулевая гипотеза (H0) утверждает отсутствие различий или эффектов: H0: ?1 = ?2. Альтернативная H1 утверждает обратное. Проверяется через статистический критерий (например, t-тест).;Нулевая гипотеза — это гипотеза о равенстве параметров, например H0: ?1 = ?2.;5
Что такое data compression в Big Data?;Уменьшение размера данных для экономии места и ускорения передачи;Сокращение размера данных;3
Для чего нужны ключи сообщений в Kafka;Ключи сообщений определяют, в какую партицию топика будет записано сообщение. Сообщения с одинаковым ключом попадают в одну партицию, сохраняя порядок.;Ключи сообщений обеспечивают семантику упорядочивания: хэш ключа определяет целевую партицию, гарантируя, что все сообщения с одинаковым ключом обрабатываются в порядке отправки и одним консьюмером.;4
Что такое Data Mesh архитектура и как она решает проблемы централизованных data lakes?;Децентрализованный подход, где данные управляются domain-командами как продукты. Решает проблемы монолитных data lakes: bottlenecks, низкое качество данных, сложность масштабирования.;Децентрализованное управление данными через domain teams. Решает проблемы масштабируемости и качества в традиционных data lakes через распределенную ответственность.;4
Что такое attention mechanism в нейронных сетях и где применяется?;Attention mechanism позволяет нейронной сети фокусироваться на важных частях входных данных, широко применяется в машинном переводе, обработке изображений и текста;Фокусировка на значимых элементах данных;3
Назовите и поясните метрики качества для компьютерного зрения.;Используются метрики IoU = (S ? P) / (S ? P), mAP (mean Average Precision), Pixel Accuracy, Dice = 2|A ? B| / (|A| + |B|).;IoU и mAP измеряют качество распознавания объектов, Dice — схожесть масок.;5
Какие реальные кейсы демонстрируют эффективность модели прогнозирования?;Модели прогнозирования помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Помогает работать с данными и строить модели.;3
Перечислите основные задачи анализа сетей на графах;Основные задачи включают обнаружение сообществ, вычисление центральности узлов, поиск кратчайших путей, анализ связности и выявление влиятельных узлов в сетевых структурах;Анализ сообществ, расчет центральности, поиск путей и определение ключевых узлов в сложных сетях;3
Что такое convolutional neural network (CNN)?;Архитектура нейросетей для обработки изображений с использованием сверточных слоев.;CNN использует сверточные слои для автоматического извлечения признаков из изображений через фильтры, пулинговые слои для уменьшения размерности и полносвязные слои для классификации.;5
Как обеспечивается отказоустойчивость в Kafka;Через репликацию партиций на несколько брокеров. Одна реплика является лидером для чтения/записи, остальные — followers. При падении лидера одна из реплик становится новым лидером.;Данные копируются на несколько серверов.;2
Векторы, матрицы, фреймы в R;Векторы хранят однотипные данные, матрицы - двумерные массивы, фреймы - таблицы с разными типами колонок;Векторы, матрицы и фреймы данных;3
Что понимается под термином 'recall'?;"Recall — это доля правильно предсказанных положительных объектов среди всех реально положительных объектов.,""Recall — это показатель полноты, отражающий";сколько из всех положительных примеров модель нашла.;5
Что такое XGBoost?;Библиотека для градиентного бустинга с оптимизацией производительности и регуляризацией.;Алгоритм машинного обучения для табличных данных.;2
Как оптимизировать хранение sparse данных в колоночных форматах?;Использование efficient encoding для sparse колонок, compression algorithms, отказ от хранения null значений, специализированные форматы для sparse матриц.;Хранение sparse данных в колонках.;2
Какие методы использовать для обработки временных рядов с пропущенными значениями?;Интерполяция (линейная, сплайн), forward/backward fill, статистические методы (скользящее среднее), ML методы (ARIMA, Prophet). Выбор зависит от природы пропусков и требований к точности.;Интерполяция, заполнение соседними значениями, скользящие статистики, прогнозные модели. Учитывать характер пропусков и требования к данным при выборе метода импутации.;4
Какие компании активно используют анализ данных и зачем?;Анализ данных помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;4
Какие гарантии доставки предоставляет Kafka;At most once: сообщения могут быть потеряны. At least once: сообщения могут быть доставлены повторно. Exactly once: каждое сообщение доставляется ровно один раз.;Kafka предоставляет три уровня семантики доставки: at-most-once (сообщения могут быть потеряны при сбоях), at-least-once (гарантирует доставку, но возможны дубликаты) и exactly-once (исключает как потери, так и дублирование через транзакционные механизмы).;4
С какими проблемами сталкиваются при применении компьютерное зрение, и как их решают?;Компьютерное зрение помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;4
Что такое Hadoop и каковы его основные компоненты?;Hadoop — это фреймворк для распределенной обработки больших данных. Основные компоненты: HDFS (файловая система), YARN (планировщик ресурсов), MapReduce (модель вычислений).;Hadoop — это система для обработки больших данных, включает HDFS, YARN и MapReduce.;5
Какие инструменты используются для работы с масштабируемые системы?;Масштабируемые системы помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Масштабируемые системы нужно только программистам, обычным компаниям оно бесполезно.;2
Как ETL-пайплайны влияет на эффективность бизнеса?;Etl-пайплайны используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Etl-пайплайны обеспечивает анализ потоковых данных, улучшает прогнозирование, помогает автоматизировать процессы и повышает точность аналитических моделей.;5
Что такое Edge AI и какие вызовы оно решает по сравнению с cloud AI?;Выполнение AI моделей на edge устройствах вместо облака. Решает проблемы latency, bandwidth, privacy, offline работы в IoT, мобильных и embedded системах.;AI на периферийных устройствах. Преимущества: низкая задержка, экономия bandwidth, конфиденциальность данных, работа без подключения к облаку.;4
Как глубокое обучение помогает в анализе больших объемов данных?;Глубокое обучение используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Используется для прогнозов и анализа информации.;3
Какие навыки необходимы специалисту для работы с предиктивная аналитика?;Предиктивная аналитика применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Предиктивная аналитика применяется в бизнесе и иногда в науке для анализа данных.;3
Что такое data mining и какие задачи оно решает?;Data mining используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;5
Разница между линейной и логистической регрессией;Линейная регрессия моделирует непрерывные количественные зависимости между переменными, тогда как логистическая регрессия предсказывает вероятности бинарной или мультиклассовой классификации с использованием сигмоидной функции;Два статистических метода для разных типов задач анализа данных;2
Что такое регрессионный анализ;Статистический метод моделирования зависимостей между переменными для прогнозирования численных значений;Моделирование зависимостей между признаками и целевой переменной для прогнозирования;4
Какие методы обработки пропущенных значений в данных вы знаете?;Для обработки пропущенных значений используются удаление строк, импутация средним/медианой, предсказание с помощью моделей и интерполяция, выбор метода зависит от природы пропусков и объема данных;Для обработки пропусков используются удаление строк и импутация средним значением;5
Что такое TF-IDF?;Статистическая мера важности слова в документе относительно коллекции документов.;Метод оценки важности слов в тексте, учитывающий как частоту слова в документе, так и редкость слова во всей коллекции документов.;4
Какие реальные примеры использования in-memory обработка существуют?;In-memory обработка помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;In-memory обработка используется для обработки информации и улучшения решений.;3
Виды распределения данных и примеры;Репликация, шардинг, партиционирование. Примеры: Master-Slave, горизонтальное разделение;Репликация (копирование для отказоустойчивости), шардинг (горизонтальное разделение), партиционирование (вертикальное разделение). Пример: Master-Slave репликация;4
Что такое Apache Beam?;Унифицированная модель для определения пайплайнов обработки данных, работающая с разными рантаймами.;Библиотека для работы с большими данными в Python и Java.;2
Как нейронные сети используется в научных исследованиях?;Нейронные сети помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Нейронные сети применяется в бизнесе и иногда в науке для анализа данных.;3
Какие подходы использовать для оптимизации запросов в колоночных базах данных?;Predicate pushdown, column pruning, использование статистик для планирования запросов, оптимизация формата хранения, сжатие данных, правильное партиционирование.;Методы ускорения запросов через фильтрацию на чтении, выбор колонок и оптимизацию хранения данных.;3
Как мониторинг больших данных применяется в современных компаниях?;Технологии мониторинг больших данных позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Мониторинг больших данных широко применяется в промышленности, здравоохранении, финансах и государственных системах. Позволяет анализировать большие массивы данных, строить точные модели и улучшать эффективность процессов.;5
Генеральная совокупность и выборка;Совокупность - все объекты исследования, выборка - часть совокупности для анализа;Генеральная совокупность и репрезентативная выборка из нее;5
Как специалисты анализируют данные в рамках кластеризация данных?;Кластеризация данных используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Технологии кластеризация данных позволяют компаниям обрабатывать большие объёмы разнородных данных, выявлять сложные закономерности и принимать обоснованные решения.;5
Принципы и инструменты аналитики. Задачи и компетенции аналитиков Big Data;Принципы включают data-driven подход, итеративность, автоматизацию. Инструменты: Hadoop, Spark, NoSQL. Задачи: анализ паттернов, прогнозирование. Компетенции: статистика, программирование, доменные знания;Data-driven подход, инструменты Hadoop/Spark, компетенции аналитиков;4
Основные вызовы больших данных (4V, 8V).;Основные характеристики больших данных обозначаются как 4V: Volume (объем), Velocity (скорость), Variety (разнообразие), Veracity (достоверность). В расширенной модели 8V добавляются Value (ценность), Variability (изменчивость), Visualization (визуализация), Vulnerability (уязвимость).;Основные характеристики — объем, скорость, разнообразие и достоверность.;4
Как развитие классификация данных влияет на будущее цифровых технологий?;Классификация данных применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;5
Как обеспечить консистентность данных в распределенной системе при сетевых разделах?;Использовать consensus алгоритмы (Raft, Paxos), кворумные операции, конфликтующее разрешение на основе временных меток или векторов версий, eventual consistency с механизмами согласования.;Алгоритмы консенсуса типа Raft/Paxos, операции с кворумом, разрешение конфликтов через временные метки или vector clocks, eventual consistency с синхронизацией при восстановлении связи.;5
Как работает градиентный бустинг и чем отличается от случайного леса?;Градиентный бустинг последовательно строит деревья, каждое следующее исправляет ошибки предыдущего, тогда как случайный лес строит деревья независимо и усредняет результат;Различия в принципах построения ансамблей деревьев;4
Что такое нормализация данных?;Приведение данных к единому масштабу без искажения соотношений.;Подготовка данных для работы в системе.;2
"Понятие корреляции; коэффициенты Пирсона, Спирмена, Кендалла";"Корреляция - мера линейной связи; Пирсон для нормальных данных, Спирмен для рангов, Кендалл для порядковых данных";Корреляция измеряется коэффициентами Пирсона и Спирмена;5
Как организовать мониторинг производительности распределенных data processing jobs?;Metrics collection (throughput, latency, resource usage), distributed tracing, alerting on anomalies, dashboard visualization, correlation с business metrics.;Мониторинг производительности задач в кластере.;2
Использование гистограммы для обработки фото;Гистограммы яркости используются для анализа тонального диапазона изображений, коррекции контраста и выполнения операций по улучшению качества;В компьютерном зрении гистограммы используются для анализа распределения яркости, выполнения histogram equalization для улучшения контраста, оценки качества экспозиции и автоматической коррекции цветового баланса изображений;5
Что такое Data Fabric;Data Fabric — это архитектурный подход, обеспечивающий единый, согласованный слой доступа к данным across разнородных источников через метаданные и семантическую интеграцию.;Архитектура для унифицированного доступа к распределенным данным через метаданные;4
Что такое lambda architecture и из каких компонентов она состоит?;Архитектура для обработки Big Data, сочетающая batch и stream processing. Состоит из batch layer (обработка всех данных), speed layer (реaltime обработка) и serving layer (объединение результатов).;Архитектура с тремя слоями: пакетная обработка, потоковая обработка и слой обслуживания запросов.;3
Что такое Apache Spark и в чем его преимущества перед Hadoop?;Распределенный фреймворк для обработки данных с in-memory вычислениями. Преимущества: выше скорость за счет работы в памяти, богатый API, поддержка streaming и ML.;Распределенная обработка данных с использованием памяти. Преимущества: скорость, универсальность, встроенные инструменты для разных задач анализа.;4
Какие бывают виды регрессионного анализа?;"Линейная, полиномиальная, логистическая, ридж, лассо регрессия; каждая решает специфические задачи";Разные типы регрессии;2
Типы языка R, примеры;Вектор, матрица, список, фрейм данных, фактор;Вектор c(1,2,3), матрица matrix(), список list();3
NoSQL классификация хранилищ;NoSQL базы данных классифицируются на документные хранилища, хранилища ключ-значение, колоночные базы данных и графовые базы данных в зависимости от модели данных и способа организации хранения информации;Классификация NoSQL по моделям данных: документы, пары, колонки, графы;4
Мотивация происхождения NoSQL;Необходимость работы с неструктурированными данными и горизонтального масштабирования систем;Обработка больших объемов неструктурированных данных и масштабируемость;4
Какие основные инструменты и технологии используются для работы с глубокое обучение?;Глубокое обучение используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Используется для прогнозов и анализа информации.;3
Как развивается направление big data в последние годы?;Big data используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Технологии позволяют улучшать качество аналитики, находить закономерности и предсказывать события.;4
Закономерности динамики сложных сетей;Предпочтительное присоединение, рост по степенному закону, small-world эффект, кластеризация;Закономерности сетевого роста;2
Архитектура хранилищ данных;Современная архитектура хранилищ данных включает многоуровневую структуру с уровнями приема, обработки, хранения и анализа информации, использующую ETL-процессы, data lakes и специализированные витрины данных для различных бизнес-потребностей;Структура систем хранения с этапами загрузки, преобразования и организации данных для дальнейшего использования в аналитике;3
Какие методы использовать для обработки временных рядов с пропущенными значениями?;Интерполяция (линейная, сплайн), forward/backward fill, статистические методы (скользящее среднее), ML методы (ARIMA, Prophet). Выбор зависит от природы пропусков и требований к точности.;Заполнение пропусков через интерполяцию, соседние значения или прогнозные модели в зависимости от ситуации.;3
Что такое уровень значимости;Уровень значимости ? представляет вероятность совершить ошибку первого рода - отвергнуть верную нулевую гипотезу, обычно устанавливается 0.05;Статистический порог для принятия решения об отклонении нулевой гипотезы, обычно 5% или 1%;3
Что такое пайплайны бенчмарки и SOTA, как и для чего они используются?;"Пайплайн — последовательность шагов обработки данных и обучения модели. Бенчмарк — набор стандартных задач и метрик для сравнения моделей. SOTA (State Of The Art) — лучшие результаты на этих задачах.,""Пайплайн — процесс работы модели, бенчмарк — способ проверки";SOTA — лучший результат.;4
Что такое 'F1-мера'?;F1-мера — это гармоническое среднее между precision и recall, отражающее баланс между точностью и полнотой.;F1 — это процент правильных ответов.;2
Что такое Data Mesh архитектура и как она решает проблемы централизованных data lakes?;Децентрализованный подход, где данные управляются domain-командами как продукты. Решает проблемы монолитных data lakes: bottlenecks, низкое качество данных, сложность масштабирования.;Новая архитектура для данных с распределенным управлением. Решает проблемы больших централизованных data lakes через domain-ориентированный подход.;3
Свойства эластичности и надёжности сложных сетей;"Эластичность - устойчивость к нагрузкам, надежность - отказоустойчивость; зависят от структуры и связности сети";Устойчивость к нагрузкам и отказам;3
Сравнительный анализ алгоритмов кластеризации;Алгоритмы кластеризации сравниваются по масштабируемости, чувствительности к шуму, способности находить кластеры сложной формы и вычислительной сложности;Оценка алгоритмов по масштабируемости и способности находить разные формы кластеров;5
Метрики качества для компьютерного зрения;"Accuracy, Precision, Recall, F1-score для классификации; mAP, IoU для детекции; Dice coefficient для сегментации";Метрики для компьютерного зрения включают Accuracy и mAP;5
Основные метрики больших графов;Диаметр, плотность, кластеризация, центральность - ключевые метрики сетевого анализа;Показатели для анализа сетей;2
Как обработка данных помогает в анализе больших объемов данных?;Обработка данных помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Обработка данных — это что-то про компьютеры. Применяется редко.;2
Что такое точность (accuracy) в машинном обучении?;Точность — это метрика, определяющая долю правильных предсказаний от общего числа наблюдений: Accuracy = (TP + TN) / (TP + TN + FP + FN).;Точность — это качество модели.;2
Какие инструменты используются для работы с обработка потоковых данных?;Обработка потоковых данных помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Обработка потоковых данных широко применяется в промышленности, здравоохранении, финансах и государственных системах. Позволяет анализировать большие массивы данных, строить точные модели и улучшать эффективность процессов.;5
Какие реальные примеры использования data warehouses существуют?;Технологии data warehouses позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Data warehouses почти нигде не применяется. Это просто большие таблицы.;2
Зачем нужны рекуррентные нейросети;Для обработки последовательных данных: текст, речь, временные ряды. Сохраняют контекст;Специализированы для последовательностей (текст, аудио, временные ряды), сохраняют состояние между шагами;4
Как развитие data mining влияет на будущее цифровых технологий?;Data mining используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Это просто работа с таблицами. Не очень полезно.;2
Как кластеризация данных применяется в современных компаниях?;Технологии кластеризация данных позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Технологии кластеризация данных позволяют компаниям обрабатывать большие объёмы разнородных данных, выявлять сложные закономерности и принимать обоснованные решения.;5
Что такое пайплайны, бенчмарки и SOTA;Пайплайны - автоматизированные процессы обработки данных, бенчмарки - эталоны сравнения, SOTA - лучшие достижения;Пайплайны автоматизируют workflow, бенчмарки устанавливают стандарты, SOTA - state-of-the-art;4
Охарактеризовать конструкции языка R;Конструкции включают векторы, списки, матрицы, data frames, функции управления потоком и функциональное программирование;Конструкции языка R включают векторы, списки и data frames;5
Дайте определение социального графа. Перечислите его типы и свойства. К какому семейству больших графов он относится?;Социальный граф — это представление социальных взаимодействий между узлами (людьми, организациями). Характеризуется высокой кластеризацией, малой средней длиной пути, динамичностью и направленными рёбрами. Относится к семейству больших сложных сетей (complex networks).;Социальный граф — это граф, который используют для изучения компьютеров в сети.;2
Примеры задач с большими графами;Большие графы применяются для анализа социальных сетей (обнаружение сообществ, измерение влияния), в рекомендательных системах (коллаборативная фильтрация), биоинформатике (изучение взаимодействий белков) и веб-аналитике (ранжирование страниц);Социальные сети, рекомендательные системы и научные исследования активно используют графовые модели для анализа связей;3
Какие риски связаны с использованием нейронные сети в критически важных системах?;Нейронные сети используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Нейронные сети нужно только программистам.;2
Какие реальные примеры использования хранилища данных существуют?;Хранилища данных используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Хранилища данных широко применяется в промышленности, здравоохранении, финансах и государственных системах. Позволяет анализировать большие массивы данных, строить точные модели и улучшать эффективность процессов.;5
Что такое ELT процесс?;Процесс загрузки данных перед их преобразованием в целевой системе.;ELT (Extract, Load, Transform) отличается от ETL тем, что данные сначала загружаются в целевую систему в сыром виде, а преобразования выполняются уже внутри целевой системы, что лучше подходит для облачных хранилищ данных.;5
Охарактеризуйте хранилища OLAP и OLTP;OLTP системы оптимизированы для операционных транзакций, OLAP для аналитических запросов и отчетности;OLTP и OLAP системы;2
Как оптимизировать запросы к данным с временными рядами для аналитических нагрузок?;Партиционирование по времени, индексы по временным меткам, материализованные представления для агрегатов, сжатие временных данных, использование специализированных TSDB.;Партиционирование по времени для быстрой фильтрации, индексы по timestamp'ам, материализованные views для предварительных агрегатов, эффективное сжатие, специализированные базы временных рядов для оптимизации запросов.;5
Что такое recall и precision?;Precision - точность предсказаний, recall - полнота охвата реальных позитивных случаев.;Показатели для проверки точности алгоритмов машинного обучения.;2
Что такое feature engineering и какие методы он включает?;Создание и преобразование признаков для улучшения качества ML моделей: кодирование категориальных переменных, масштабирование, создание полиномиальных признаков, извлечение признаков из дат и текстов.;Подготовка данных для обучения моделей.;2
Какие методы использовать для detection data drift в production ML systems?;Statistical tests (KS, PSI), monitoring prediction distributions, concept drift detection algorithms, feature distribution monitoring, performance metrics tracking.;Методы обнаружения изменений в данных и поведении ML моделей в продакшене.;3
Обучение с подкреплением и ансамбли;Обучение с подкреплением основано на взаимодействии со средой, ансамбли комбинируют несколько моделей;Два подхода в машинном обучении;2
Что такое машинное обучение?;Машинное обучение — это раздел искусственного интеллекта, изучающий методы построения алгоритмов, способных самостоятельно выявлять закономерности в данных и принимать решения без явного программирования.;Машинное обучение — это область, где алгоритмы учатся находить закономерности и принимать решения без прямого вмешательства человека.;5
Как организовать мониторинг производительности распределенных data processing jobs?;Metrics collection (throughput, latency, resource usage), distributed tracing, alerting on anomalies, dashboard visualization, correlation с business metrics.;Система мониторинга для распределенных задач обработки данных.;3
Что такое feature engineering и какие методы он включает?;Создание и преобразование признаков для улучшения качества ML моделей: кодирование категориальных переменных, масштабирование, создание полиномиальных признаков, извлечение признаков из дат и текстов.;Подготовка признаков для ML: кодирование категорий, нормализация, создание новых переменных. Важный этап для улучшения моделей.;4
Какие инструменты используются для работы с масштабируемые системы?;Масштабируемые системы помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Масштабируемые системы нужно только программистам, обычным компаниям оно бесполезно.;2
Основные компоненты Kafka;Producer: отправляет сообщения. Consumer: читает сообщения. Broker: сервер Kafka. Topic: категория/канал сообщений. Partition: часть топика. ZooKeeper: координация кластера.;В Kafka есть отправители, получатели и серверы.;2
Что такое dbt (data build tool)?;Инструмент для трансформации данных в хранилищах через SQL с тестированием и документацией.;dbt позволяет инженерам данных преобразовывать данные в хранилищах с помощью SQL, обеспечивая версионирование, тестирование, документацию и автоматизацию пайплайнов данных.;5
Охарактеризуйте хранилища OLAP и OLTP;"OLTP для операционных транзакций, OLAP для аналитических запросов; разная оптимизация";OLTP оптимизированы для записи, OLAP для чтения и анализа;4
Где применяется машинное обучение в промышленности и бизнесе?;Машинное обучение используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Это просто работа с таблицами. Не очень полезно.;2
Что такое batch normalization?;Техника ускорения обучения глубоких нейронных сетей путем нормализации входов каждого слоя к нулевому среднему и единичной дисперсии для каждого мини-батча, что решает проблему internal covariate shift.;Техника нормализации данных между слоями нейросети. Применяется к каждому батчу и помогает стабилизировать обучение глубоких сетей.;4
Что такое 'градиентное исчезновение'?;Градиентное исчезновение — это ситуация, когда градиенты становятся слишком малыми, что замедляет или останавливает обучение нейросети.;Это ошибка при обучении нейросети.;2
Что такое Data Fabric;Data Fabric — это архитектурный подход, обеспечивающий единый, согласованный слой доступа к данным across разнородных источников через метаданные и семантическую интеграцию.;Виртуальный слой доступа к данным с автоматическим discovery и оркестрацией;5
В чём суть алгоритмов нахождения квадратичной ошибки?;Алгоритмы нахождения квадратичной ошибки минимизируют сумму квадратов разностей между предсказанными и фактическими значениями для определения оптимальных параметров модели;Минимизация квадратичной ошибки для настройки моделей;3
Обучение с подкреплением и ансамбли;"RL - обучение через взаимодействие со средой; ансамбли - комбинация нескольких моделей";Обучение с подкреплением и ансамблевые методы как различные подходы;5
Преимущества и недостатки непараметрических моделей;Непараметрические модели гибки и не требуют предположений о распределении данных, но могут требовать больших объемов данных и вычислительных ресурсов;"Преимущества: не требуют априорных предположений о данных, могут аппроксимировать сложные функции; недостатки: требуют больших объемов данных для обучения, вычислительно затратны, склонны к переобучению, сложны для интерпретации";5
Что такое статистическое обучение;Статистическое обучение объединяет методы статистики и машинного обучения для построения прогнозных моделей;Использование статистических методов для обучения;4
Дайте сравнительный анализ алгоритмов кластеризации.;Алгоритмы делятся на иерархические (агломеративные, дивизивные), разбиения (k-means, k-medoids), плотностные (DBSCAN), вероятностные (EM), графовые (Louvain). Отличаются подходами к определению расстояния и критериям объединения.;Кластеризация бывает только методом k-means.;3
Алгоритмы выделения сообществ;Алгоритмы Louvain, Girvan-Newman, Label Propagation используются для обнаружения сообществ в сложных сетях на основе модульности и связности;Louvain оптимизирует модульность, Girvan-Newman удаляет ребра с высокой betweenness centrality;3
Где применяется NLP в промышленности и бизнесе?;Nlp используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;5
Что такое Data Governance;Data Governance — это система управления доступностью, usability, integrity и безопасностью данных в организации через политики, стандарты и процессы.;Система управления данными в компании;3
Нормальное распределение;Симметричное распределение с заданными математическим ожиданием и дисперсией, встречается в природе;Симметричное распределение с математическим ожиданием и дисперсией;5
Что такое feature importance?;Методы оценки важности признаков для прогнозов модели.;Показатели того, насколько каждый признак важен для работы модели машинного обучения.;3
Виды распределения данных и примеры;Основные виды распределений: нормальное (рост людей), равномерное (бросок кости), экспоненциальное (время между событиями), биномиальное (успехи в испытаниях);Виды распределений: нормальное, равномерное, экспоненциальное с примерами;5
Какие стратегии использовать для управления памятью в Spark при работе с большими датасетами?;Настройка memory fractions, использование off-heap memory, сериализация данных, кэширование с правильными уровнями хранения, мониторинг GC, разделение памяти между execution и storage.;Настройка памяти Spark, использование off-heap, оптимизация сериализации и кэширования для работы с большими данными.;3
Какие реальные примеры использования мониторинг больших данных существуют?;Мониторинг больших данных используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Мониторинг больших данных широко применяется в промышленности, здравоохранении, финансах и государственных системах. Позволяет анализировать большие массивы данных, строить точные модели и улучшать эффективность процессов.;5
В чем разница между горизонтальным и вертикальным масштабированием в контексте Big Data?;Горизонтальное масштабирование - добавление новых узлов в кластер, вертикальное - увеличение ресурсов существующих серверов. Big Data системы предпочитают горизонтальное масштабирование как более экономичное и отказоустойчивое.;Два способа увеличения мощности системы. Big Data предпочитает один из них.;2
Какие компании активно используют классификация данных и зачем?;Классификация данных используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;4
Критерии качества кластеризации;Метрики оценки кластеризации включают Silhouette score, Davies-Bouldin index и Calinski-Harabasz index для измерения компактности и разделимости кластеров;Silhouette score вычисляет среднюю схожесть объектов с своим кластером относительно других кластеров, Davies-Bouldin index измеряет среднее отношение внутрикластерных расстояний к межкластерным, Calinski-Harabasz оценивает отношение дисперсии между кластерами к дисперсии внутри кластеров;5
Какие реальные кейсы демонстрируют эффективность рекомендательные системы?;Рекомендательные системы применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Рекомендательные системы — это что-то про компьютеры. Применяется редко.;2
Как работает механизм shuffle в Spark?;Перераспределение данных между партициями при операциях типа groupBy или join. Включает сортировку, хэширование и сетевую передачу данных между узлами.;Shuffle происходит когда данные нужно перераспределить между исполнителями. Включает передачу данных по сети и репартиционирование для операций агрегации.;5
Data Mining vs. Machine Learning — в чём отличия?;Data Mining ориентирован на обнаружение скрытых паттернов и закономерностей в существующих данных, тогда как Machine Learning сосредоточен на построении алгоритмов, способных обучаться и делать прогнозы на новых данных;Data Mining ищет закономерности в исторических данных, Machine Learning создает модели для будущих предсказаний;3
Основные метрики больших графов;Диаметр, плотность, кластеризация, центральность - ключевые метрики сетевого анализа;Диаметр, плотность, коэффициент кластеризации, меры центральности;5
Разница между линейной и логистической регрессией;Линейная регрессия предсказывает непрерывные значения, логистическая - вероятности бинарной классификации;Линейная для регрессии, логистическая для классификации;4
Что такое статистическая гипотеза;Статистическая гипотеза представляет собой проверяемое предположение о свойствах генеральной совокупности, которое может быть подтверждено или опровергнуто с помощью статистических тестов;Формальное предположение о параметрах распределения или характере данных которое подвергается статистической проверке с определением уровня значимости;4
Что такое feature importance?;Методы оценки важности признаков для прогнозов модели.;Рейтинг переменных по их полезности для алгоритма.;2
Что такое SHAP values?;Метод объяснения предсказаний ML моделей на основе теории игр, показывающий вклад каждого признака.;Метод анализа важности переменных в модели.;2
В чем преимущества применения предиктивная аналитика по сравнению с традиционными методами?;Предиктивная аналитика применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;4
Как организовать систему для ML feature serving в реальном времени?;Feature store с low-latency API, online/offline feature consistency, versioning, monitoring feature quality, scalable serving infrastructure.;Feature store с низкой задержкой, согласованность данных, версионирование. Надежная инфраструктура для обслуживания фич.;4
Как развитие предиктивная аналитика влияет на будущее цифровых технологий?;Предиктивная аналитика применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;5
Векторы, матрицы, фреймы и факторы в R;Векторы - атомарные данные, матрицы - 2D массивы, фреймы - таблицы, факторы - категориальные переменные;В R есть векторы, матрицы, фреймы и факторы;5
Какие стратегии использовать для управления памятью в Spark при работе с большими датасетами?;Настройка memory fractions, использование off-heap memory, сериализация данных, кэширование с правильными уровнями хранения, мониторинг GC, разделение памяти между execution и storage.;Методы управления памятью в Spark для больших объемов данных.;2
Какие алгоритмы лежат в основе методов выделения сообществ? Дайте общее описание шагов выполнения этих алгоритмов.;Алгоритмы выделения сообществ включают методы модульности (Лувен, Ньюман-Гирван), спектральные методы и итерационные подходы. Основные шаги: построение графа, вычисление меры модульности Q, итеративное объединение или разбиение узлов до оптимума Q.;Алгоритмы выделения сообществ ищут самые длинные пути в графе.;2
Какие основные конструкции языка R?;Векторы, матрицы, списки, data frames, факторы. Функции, управляющие конструкции (if, for, while). Пакеты для расширения функциональности. Векторизованные операции.;Структуры данных: векторы, матрицы, data frames. Управляющие конструкции и функции. Векторизация операций.;4
Что такое переобучение (overfitting)?;Ситуация, когда модель слишком точно подстраивается под тренировочные данные, включая их шум, теряя способность к обобщению на новых данных.;Это проблема, когда алгоритм показывает плохие результаты из-за неправильных данных или слабого компьютера.;2
Что такое Neuromorphic Computing и как оно применяется в AI?;Архитектура вычислений имитирующая работу человеческого мозга. Применяется для энергоэффективного AI, real-time обработки сенсорных данных, edge computing.;Вычисления на основе нейроморфных чипов имитирующих мозг. Используется для эффективного AI на устройствах, обработки потоковых данных, low-power нейросетей.;5
Что такое метод опорных векторов (SVM)?;Метод опорных векторов — это алгоритм классификации, который ищет гиперплоскость, максимально разделяющую данные разных классов.;SVM — это способ разделить данные с помощью линии или плоскости.;3
Параметрическая модель статистического обучения;Модель с фиксированным числом параметров, заданная функциональной формой и распределением ошибок;Модель с фиксированной параметризацией и предположениями о распределении;4
Что такое Delta Lake;Delta Lake — это open-source storage layer, который добавляет reliability, ACID транзакции и управление версиями к данным в data lakes поверх Parquet формата.;Хранилище с транзакциями для data lake;3
Какие риски связаны с использованием модели прогнозирования в критически важных системах?;Модели прогнозирования помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Это просто работа с таблицами. Не очень полезно.;2
Порядок тестирования гипотезы о равенстве средних;Формулировка гипотез, проверка условий, расчет статистики, сравнение с критическим значением;Проверка различий между группами;2
Данные, информация, знания — в чём отличия?;Данные - сырые факты, информация - структурированные данные, знания - проверенные закономерности;Данные ? информация ? знания;3
Какие бывают виды регрессионного анализа? Поясните логистическую регрессию и SVM;Виды регрессии включают линейную, полиномиальную, логистическую и др. Логистическая регрессия предсказывает вероятности бинарной классификации, а SVM находит оптимальную разделяющую гиперплоскость;Логистическая регрессия для классификации, SVM для нахождения разделяющей границы;4
Использование гистограммы для обработки фото;Гистограммы яркости широко применяются в обработке изображений для анализа тонального диапазона, коррекции контраста, выполнения операций выравнивания гистограммы и улучшения общего качества визуального контента;В обработке фото гистограммы используются для анализа яркости и коррекции качества изображений;5
Что такое обработка данных и какие задачи оно решает?;Обработка данных помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Это просто работа с таблицами. Не очень полезно.;2
Примеры задач, решаемых с помощью больших графов;Большие графы применяются для анализа социальных сетей, рекомендательных систем, биоинформатики (белковые взаимодействия), транспортных сетей и веб-графов (PageRank);Анализ социальных сетей, рекомендательных систем и биоинформатики;4
Понятие регрессии;Моделирование связи между переменными для прогнозирования;Анализ зависимости целевой переменной от признаков для прогноза;3
Какие риски связаны с применением in-memory обработка?;In-memory обработка используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;In-memory обработка применяется в финансах, медицине, рекламе и IT, помогает анализировать данные и строить модели.;4
Какие этапы включает проект, основанный на использовании большие данные?;Большие данные используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Большие данные применяется в бизнесе и иногда в науке для анализа данных.;3
Что такое 'кластеризация'?;Кластеризация — это процесс разделения множества объектов на группы (кластеры) так, чтобы объекты внутри одной группы были похожи, а между группами — различались.;Это сортировка данных по алфавиту.;2
Что такое checkpointing в распределенных системах?;Сохранение состояния системы в устойчивое хранилище для восстановления после сбоев;Сохранение промежуточного состояния системы для возможности восстановления;4
Что такое Neuromorphic Computing и как оно применяется в AI?;Архитектура вычислений имитирующая работу человеческого мозга. Применяется для энергоэффективного AI, real-time обработки сенсорных данных, edge computing.;Вычислительная архитектура вдохновленная мозгом. Используется для создания более эффективных и быстрых AI систем особенно на edge устройствах.;3
Назовите виды связи между переменными при корреляции.;Связь может быть положительной, отрицательной и нулевой  сильной, средней или слабой по модулю коэффициента корреляции.;Связь бывает положительной, отрицательной или нулевой, в зависимости от направления зависимости.;3
Как рекомендательные системы помогает в анализе больших объемов данных?;Рекомендательные системы применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Помогает работать с данными и строить модели.;3
Примеры задач, решаемых с помощью больших графов;Графы — это таблицы.;Их применяют для чего-то в интернете.;2
Как мониторинг больших данных влияет на эффективность бизнеса?;Мониторинг больших данных помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Мониторинг больших данных используется бизнесом для оптимизации процессов, анализа клиентов и прогнозирования.;4
Какие инструменты используются для работы с ETL-пайплайны?;Etl-пайплайны используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Etl-пайплайны широко применяется в промышленности, здравоохранении, финансах и государственных системах. Позволяет анализировать большие массивы данных, строить точные модели и улучшать эффективность процессов.;5
Какие проблемы возникают при использовании кластеризация данных?;Технологии кластеризация данных позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Кластеризация данных обеспечивает анализ потоковых данных, улучшает прогнозирование, помогает автоматизировать процессы и повышает точность аналитических моделей.;5
Какие типы нейронных сетей используются в компьютерном зрении?;В компьютерном зрении применяются сверточные нейронные сети (CNN), автокодировщики, R-CNN для детекции объектов и U-Net для сегментации изображений;Сверточные сети и специализированные архитектуры для CV;4
Какие методы используются для обработки пропущенных значений в данных?;Удаление строк с пропусками, импутация средним/медианой, предсказание значений с помощью ML моделей, интерполяция для временных рядов, создание отдельной категории для пропусков.;Удаление или заполнение пропусков в зависимости от их количества и важности. Использование статистических методов и ML для восстановления значений.;4
Метрики качества для моделей регрессии;Для оценки регрессионных моделей используются RMSE, MAE, MAPE и R? для измерения точности предсказаний;Метрики для регрессии;2
Когда использовать градиентный бустинг вместо случайного леса?;Бустинг когда важна максимальная точность и есть время на тонкую настройку, случайный лес когда нужна robustness и скорость обучения.;Бустинг если нужна максимальная точность и есть время на настройку. Random Forest если важна стабильность, интерпретируемость и скорость обучения. Бустинг может переобучаться на шуме.;4
Какие навыки необходимы специалисту для работы с кластеризация?;Кластеризация помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Помогает работать с данными и строить модели.;3
Какие основные инструменты и технологии используются для работы с большие данные?;Большие данные используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;4
Что такое метод опорных векторов (SVM)?;Метод опорных векторов — это алгоритм классификации, который ищет гиперплоскость, максимально разделяющую данные разных классов.;Метод SVM строит линию, разделяющую данные.;4
Что такое attention mechanism в нейронных сетях и где применяется?;Attention mechanism позволяет нейронной сети фокусироваться на важных частях входных данных, широко применяется в машинном переводе, обработке изображений и текста;Механизм для выделения важных признаков в данных;4
Фундаментальное свойство статистического обучения;Компромисс между смещением и дисперсией (bias-variance tradeoff) - ключевое свойство, определяющее обобщающую способность моделей;Фундаментальное свойство это компромисс между смещением и дисперсией;5
Как классификация данных применяется для автоматизации рутинных процессов?;Классификация данных используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;5
Что такое гиперпараметры модели?;Гиперпараметры — это параметры, значения которых задаются до обучения модели и влияют на её архитектуру и процесс обучения, например скорость обучения или количество слоёв.;Это характеристики модели.;2
Как организовать A/B тестирование для ML моделей в продакшене?;Canary deployments, постепенный rollout, monitoring ключевых метрик, статистические тесты для значимости, учет network effects и long-term impact.;Постепенное развертывание модели на части трафика, мониторинг бизнес-метрик, статистические тесты для определения значимости изменений. Важно тестировать достаточно долго и учитывать сезонность.;5
Нормальное распределение;Симметричное распределение с заданными математическим ожиданием и дисперсией, встречается в природе;Симметричное распределение с параметрами ? и ?;3
Что такое data quality monitoring?;Непрерывный мониторинг качества данных по метрикам completeness, accuracy, consistency;Постоянный контроль качества данных через автоматические проверки и метрики;5
Назовите критерии качества кластеризации и поясните их значение и когда они используются.;Критерии качества: внутрикластерная дисперсия (SSW), межкластерная дисперсия (SSB), индекс силуэта, индекс Дэвиса-Болдина, индекс Калински-Харабаса. Применяются для оценки плотности и разделимости кластеров.;Критерии — это просто количество кластеров и их центров.;3
В чем разница между batch processing и stream processing?;Batch processing обрабатывает данные пачками с задержкой, stream processing обрабатывает данные в реальном времени по мере поступления.;Batch медленнее, stream быстрее. Выбор зависит от требований к скорости.;2
Что представляет собой метод k-means?;k-means — это алгоритм кластеризации, основанный на минимизации расстояний между объектами и центрами кластеров.;k-means — алгоритм, который делит данные на кластеры по принципу минимального расстояния до центра.;5
Что такое feature store?;Централизованное хранилище для управления и обслуживания признаков ML моделей;Система для хранения и обслуживания фич для обучения и инференса ML моделей;5
Принципы глубокого обучения в нейросетях;Глубокое обучение основано на использовании нейронных сетей с множеством скрытых слоев, которые позволяют автоматически извлекать иерархические признаки из данных. Сверточные нейронные сети (CNN) специально разработаны для обработки изображений через применение сверточных фильтров и операций пулинга;Глубокие нейросети автоматически обучаются иерархическим представлениям данных, а сверточные сети эффективно обрабатывают изображения с помощью специализированных слоев;4
Разница описательных и предсказательных задач;Описательные анализируют текущие данные, предсказательные строят прогнозы на будущее;Описательные - что произошло, предсказательные - что произойдет;3
Как кластеризация используется в научных исследованиях?;Кластеризация используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;4
Критерии качества кластеризации;К критериям качества относятся Silhouette score, Davies-Bouldin index и Calinski-Harabasz index;Для оценки кластеризации используются различные критерии качества;5
Дайте определение социального графа. Перечислите его типы и свойства. К какому семейству больших графов он относится?;Социальный граф — это представление социальных взаимодействий между узлами (людьми, организациями). Характеризуется высокой кластеризацией, малой средней длиной пути, динамичностью и направленными рёбрами. Относится к семейству больших сложных сетей (complex networks).;Социальный граф — это модель связей между пользователями. Обычно он ориентированный, отражает дружбу, подписки и взаимодействия.;5
Примеры задач, решаемых с помощью больших графов.;Большие графы применяются для анализа социальных сетей, поиска путей в транспортных системах, моделирования связей в биоинформатике, рекомендаций и кибербезопасности.;Большие графы применяются в анализе соцсетей, транспортных сетей, рекомендациях и безопасности.;5
Почему технологии ETL-пайплайны стали критически важны?;Etl-пайплайны используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Etl-пайплайны применяется в некоторых компаниях для анализа данных.;3
Data Mining vs. Machine Learning — в чём отличия?;Data Mining ориентирован на обнаружение скрытых паттернов и закономерностей в существующих данных, тогда как Machine Learning сосредоточен на построении алгоритмов, способных обучаться и делать прогнозы на новых данных;Data Mining для анализа существующих данных, Machine Learning для построения прогнозных моделей;4
Основные метрики больших графов;Диаметр, плотность, кластеризация, центральность - ключевые метрики сетевого анализа;Диаметр, плотность, коэффициент кластеризации, центральность;3
Что такое 'градиентный спуск'?;Градиентный спуск — это алгоритм оптимизации, который минимизирует функцию потерь, изменяя параметры модели в направлении антиградиента.;Градиентный спуск — это уменьшение ошибки путём итераций без формул.;3
Принципы глубокого обучения в нейросетях;Глубокое обучение использует многослойные нейронные сети для автоматического извлечения признаков из данных, CNN специализируются на обработке изображений;Основано на многослойных перцептронах с нелинейными функциями активации, обучение через backpropagation и gradient descent, CNN используют сверточные слои для обнаружения локальных паттернов и pooling слои для инвариантности к трансформациям;5
Какие гарантии доставки предоставляет Kafka;At most once: сообщения могут быть потеряны. At least once: сообщения могут быть доставлены повторно. Exactly once: каждое сообщение доставляется ровно один раз.;Kafka поддерживает три семантики доставки: at-most-once (возможна потеря), at-least-once (возможны дубли) и exactly-once (гарантированно один раз).;3
Какие основные инструменты и технологии используются для работы с рекомендательные системы?;Рекомендательные системы применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;4
Что такое линейная регрессия?;Линейная регрессия — это статистический метод, описывающий зависимость между независимыми переменными X и зависимой переменной Y в виде линейной функции Y = ?0 + ?1X + ?.;Модель линейной регрессии ищет линейную зависимость между X и Y.;4
Какие компании активно используют машинное обучение и зачем?;Машинное обучение используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;4
Принцип работы SVM;Метод опорных векторов находит гиперплоскость с максимальным зазором для разделения классов в пространстве признаков;SVM ищет границу между классами;3
Обучение с подкреплением и ансамбли;Обучение с подкреплением основано на взаимодействии агента со средой для максимизации награды, а ансамбли объединяют несколько моделей для улучшения прогнозирования;Два разных подхода в машинном обучении для решения различных типов задач;2
Какие этапы включает проект, основанный на использовании классификация данных?;Классификация данных помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Классификация данных нужно только программистам.;2
Что такое Data Mining и какие задачи он решает?;Data Mining — интеллектуальный анализ данных, направленный на выявление скрытых закономерностей. Основные задачи: классификация, кластеризация, ассоциативные правила, прогнозирование.;Data Mining — это программа для поиска информации.;2
Дайте определение социального графа. Перечислите его типы и свойства. К какому семейству больших графов он относится?;Социальный граф — это представление социальных взаимодействий между узлами (людьми, организациями). Характеризуется высокой кластеризацией, малой средней длиной пути, динамичностью и направленными рёбрами. Относится к семейству больших сложных сетей (complex networks).;Социальный граф — это граф, где вершины — люди, а рёбра — их связи. У него могут быть группы и связи, но без указания на типы и свойства.;4
Что такое нейронная сеть и где она применяется?;Нейронная сеть — это вычислительная модель, имитирующая работу нейронов мозга, применяемая для распознавания образов, прогнозирования и обработки естественного языка.;Нейронные сети используются для прогнозов и распознавания, похожи на человеческий мозг.;3
Какие основные характеристики и вызовы больших данных (4V, 8V)?;4V: Volume (объем), Velocity (скорость), Variety (разнообразие), Veracity (достоверность). 8V добавляют: Value, Variability, Visualization, Validity.;Свойства больших данных и связанные с ними проблемы.;2
Какие риски связаны с применением распределённые вычисления?;Технологии распределённые вычисления позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Распределённые вычисления почти нигде не применяется. Это просто большие таблицы.;2
Что такое обучение с учителем и как оценивается качество модели?;Обучение с учителем — это метод, при котором модель обучается на размеченных данных. Качество оценивается метриками: Accuracy, Precision, Recall, F1-score.;Модель обучается с примерами правильных ответов.;3
Какие риски связаны с использованием классификация данных в критически важных системах?;Классификация данных применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Используется для прогнозов и анализа информации.;3
Виды столбчатых диаграмм и их интерпретация;Столбчатые диаграммы включают вертикальные, горизонтальные, сгруппированные и составные типы, которые интерпретируются через сравнение высот столбцов для анализа категориальных данных;Вертикальные и горизонтальные столбчатые диаграммы для визуализации данных;3
Что такое Apache NiFi?;Система для автоматизации потоков данных между различными источниками и приемниками с визуальым интерфейсом.;Система для автоматизации потоков данных. Визуальное проектирование пайплайнов, гарантированная доставка и мониторинг в реальном времени.;4
Какие проблемы возникают при использовании data warehouses?;Data warehouses используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Эти технологии помогают работать с информацией и делать прогнозы.;3
Критерии качества кластеризации;Silhouette score, Davies-Bouldin index, Calinski-Harabasz index - метрики оценки кластеров;Silhouette score, Davies-Bouldin index, Calinski-Harabasz index;5
Суть алгоритмов связных компонент и покрывающего дерева;Алгоритм связных компонент находит группы связанных узлов в графе, а алгоритм покрывающего дерева находит минимальный набор рёбер, соединяющий все вершины;Поиск компонент связности и минимальных остовных деревьев;3
Как работает квантование в ML моделей и какие преимущества она дает для продакшн систем?;Сокращение точности весов модели (с FP32 до INT8). Уменьшает размер модели и ускоряет инференс с минимальной потерей качества. Критично для edge devices и high-load систем.;Метод сжатия ML моделей через уменьшение точности вычислений. Ускоряет инференс и уменьшает требования к памяти.;3
Какие риски связаны с использованием ETL-процессы в критически важных системах?;Etl-процессы помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Etl-процессы — это что-то про компьютеры. Применяется редко.;2
Какие риски связаны с использованием NLP в критически важных системах?;Nlp применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;5
Как характеристика Velocity влияет на выбор архитектуры обработки данных?;Высокая Velocity требует streaming архитектур (Kafka, Flink, Spark Streaming) вместо batch processing, так как данные должны обрабатываться в реальном времени с минимальной задержкой.;Большая скорость данных требует streaming решений вместо batch. Нужны системы реального времени для быстрой обработки.;4
Перечислите разновидности сложных сетей, назовите их характеристики.;Разновидности: случайные графы (Эрдёша–Реньи), безмасштабные сети (Барбаши–Альберт), сети тесного мира (Уоттса–Строгаца), ориентированные и взвешенные сети.;Сложные сети включают: случайные графы (Эрдёша–Реньи, равномерное распределение связей), безмасштабные сети (Барбаши–Альберт, P(k)~k^-?), сети тесного мира (Уоттс–Строгац, высокая кластеризация и малое среднее расстояние). Эти классы описывают разные топологические свойства реальных систем.;5
Понятия репликации и шардинга для хранилищ данных.;"Репликация — копирование данных между узлами для повышения отказоустойчивости. Шардинг — горизонтальное разделение данных на сегменты (shards) для масштабирования. Используются в NoSQL и распределённых СУБД.,""Репликация — это перезапуск базы";шардинг — её сжатие.;2
Какие методы борьбы с переобучением вы знаете?;Регуляризация L1/L2, dropout, early stopping, увеличение данных, упрощение модели, кросс-валидация, augmentation данных.;Добавление регуляризации, использование больше данных для обучения, проверка на валидационной выборке.;3
Основные компоненты Kafka;Producer: отправляет сообщения. Consumer: читает сообщений. Broker: сервер Kafka. Topic: категория/канал сообщений. Partition: часть топика. ZooKeeper: координация кластера.;Архитектура Kafka состоит из продюсеров (публикуют сообщения), консьюмеров (подписываются на топики), брокеров (хранят данные), топиков (логические группы сообщений), партиций (обеспечивают параллелизм) и ZooKeeper для координации кластера и хранения метаданных.;4
В чем разница между batch processing и stream processing?;Batch processing обрабатывает данные пачками с задержкой, stream processing обрабатывает данные в реальном времени по мере поступления.;Batch - обработка накопленных данных пачками (например, ночью), stream - обработка в реальном времени. Batch проще, stream быстрее но сложнее.;4
Каковы закономерности динамики сложных сетей и законы распространения информации в них.;Закономерности включают рост и предпочтительное присоединение, эволюцию степени узлов, каскадные эффекты и диффузионные процессы по законам SIR и SI моделей.;Динамика сетей определяется механизмами роста (предпочтительное присоединение) и процессами распространения информации, описываемыми моделями SI и SIR.;4
Что такое Apache Hadoop?;Фреймворк для распределенной обработки больших данных, состоящий из HDFS (распределенная файловая система) и MapReduce (модель программирования).;Apache Hadoop - это открытый фреймворк для распределенной обработки больших данных, который включает HDFS для надежного хранения данных across кластера и MapReduce для параллельной обработки этих данных.;5
Как оптимизировать производительность запросов к partitioned данным?;Partition pruning, predicate pushdown, statistics usage, optimal partition size, partition key selection based on query patterns.;Partition pruning для исключения партиций, predicate pushdown, использование статистик. Оптимальный размер партиций и выбор ключа.;5
Как организовать A/B тестирование для ML моделей в продакшене?;Canary deployments, постепенный rollout, monitoring ключевых метрик, статистические тесты для значимости, учет network effects и long-term impact.;Сравнивать новую модель со старой на части трафика.;2
Что такое MLOps;MLOps — это практика внедрения и поддержки ML моделей в production через автоматизацию, мониторинг и управление жизненным циклом моделей.;DevOps для машинного обучения;2
Принцип работы SVM;Метод опорных векторов находит гиперплоскость с максимальным зазором для разделения классов в пространстве признаков;SVM максимизирует margin между классами используя опорные вектора, может применять kernel trick для нелинейного разделения;3
Что представляет собой 'обучение без учителя'?;Обучение без учителя — это метод, при котором данные не имеют заранее известных меток, и алгоритм должен самостоятельно выявлять структуры и зависимости.;Обучение без учителя — это когда данные не размечены и нужно находить кластеры или группы.;5
Что такое 4V в Big Data и объясните каждую характеристику?;Volume (объем данных), Velocity (скорость генерации и обработки), Variety (разнообразие форматов), Veracity (достоверность и качество данных). Эти характеристики определяют сложности работы с большими данными.;Volume - огромные объемы данных, Velocity - высокая скорость поступления, Variety - разные форматы данных, Veracity - надежность и качество информации.;5
Интегральные метрики качества;К интегральным метрикам относятся ROC-AUC, Precision-Recall AUC, F1-score и R?, агрегирующие различные аспекты качества;Интегральные метрики: ROC-AUC, F1-score, R?;4
Охарактеризовать конструкции языка R;Конструкции включают векторы, списки, матрицы, data frames, функции управления потоком и функциональное программирование;Структуры данных и функции в R;3
Как оптимизировать производительность запросов к partitioned данным?;Partition pruning, predicate pushdown, statistics usage, optimal partition size, partition key selection based on query patterns.;Partition pruning, predicate pushdown, статистики. Выбор размера и ключа партиционирования.;4
Какие основные инструменты и технологии используются для работы с большие данные?;Большие данные используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;5
Какие проблемы возникают при использовании кластеризация данных?;Технологии кластеризация данных позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Кластеризация данных нужно только программистам, обычным компаниям оно бесполезно.;2
Как обеспечивается отказоустойчивость в Kafka;Через репликацию партиций на несколько брокеров. Одна реплика является лидером для чтения/записи, остальные — followers. При падении лидера одна из реплик становится новым лидером.;Отказоустойчивость в Kafka обеспечивается механизмом репликации на уровне партиций: каждая партиция имеет несколько реплик (ISR - In-Sync Replicas), распределенных по разным брокерам. Лидер обрабатывает все операции чтения/записи, а при его отказе контроллер автоматически promotes одну из синхронизированных реплик в лидеры, обеспечивая непрерывность service.;5
Что такое 'нормализация данных'?;"Нормализация данных — это процесс приведения признаков к единому масштабу для корректной работы алгоритмов машинного обучения.,""Нормализация — это когда данные уменьшают до одного диапазона";например от 0 до 1.;4
Что такое Feature Store и как он решает проблемы consistency между training и serving?;Централизованное хранилище признаков с гарантией идентичности фич при обучении и инференсе. Решает проблемы training-serving skew, обеспечивает версионирование и переиспользование фич.;Система для управления признаками ML моделей. Гарантирует что одни и те же фичи используются при обучении и предсказании, предотвращая расхождения и улучшая качество моделей.;5
Что такое Apache Kafka;Apache Kafka — это распределенная потоковая платформа для обработки потоков данных в реальном времени. Состоит из производителей, потребителей, брокеров и тем.;Kafka представляет собой распределенную систему обмена сообщениями, построенную на принципах журналирования commit log. Она обеспечивает горизонтальную масштабируемость, отказоустойчивость и гарантированную доставку сообщений.;4
Какие реальные кейсы демонстрируют эффективность анализ данных?;Анализ данных применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;5
Какие проблемы возникают при использовании масштабируемые системы?;Масштабируемые системы помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Это что?то связанное с данными, но используется редко.;2
Что такое Apache NiFi?;Система для автоматизации потоков данных между различными источниками и приемниками с визуальным интерфейсом.;Система для перемещения данных между разными источниками.;2
Какие этапы включает проект, основанный на использовании модели прогнозирования?;Модели прогнозирования помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Помогает работать с данными и строить модели.;3
Что такое переобучение модели?;Переобучение — это ситуация, когда модель слишком точно подстраивается под обучающие данные и теряет способность обобщать закономерности. Основные признаки — высокая точность на обучающей выборке и низкая на тестовой.;Переобучение — это когда модель обучается слишком хорошо на обучающих данных, но теряет способность работать на тестовых.;4
Как предобработка данных влияет на эффективность бизнеса?;Предобработка данных помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Предобработка данных применяется в финансах, медицине, рекламе и IT, помогает анализировать данные и строить модели.;4
Как работает механизм Attention в трансформерах и почему он революционен для NLP?;Взвешенная агрегация информации из всех позиций последовательности. Революционен благодаря ability улавливать long-range зависимости и параллелизации в отличие от RNN.;Attention вычисляет веса для каждого слова в последовательности. Позволяет обрабатывать длинные тексты и улавливать сложные зависимости, при этом легко параллелится на GPU.;5
Какие стратегии использовать для миграции данных между разными системами хранения?;Инкрементальная миграция, dual write during transition, проверка консистентности, откат на предыдущую версию, мониторинг производительности, постепенное переключение трафика.;Постепенная миграция, запись в обе системы during перехода, проверка целостности данных, возможность отката, мониторинг и постепенное переключение нагрузки.;4
Что такое XGBoost?;Библиотека для градиентного бустинга с оптимизацией производительности и регуляризацией.;Популярный алгоритм бустинга. Работает быстро и дает точные предсказания для табличных данных.;3
Какие подходы использовать для обработки hierarchical данных в SQL?;Recursive CTEs, hierarchical queries, nested sets model, adjacency list, materialized paths, использование специализированных расширений.;Рекурсивные CTE, иерархические запросы, nested sets. Модели для работы с древовидными структурами в SQL.;5
Что означает 'precision' в классификации?;Precision — это доля правильно предсказанных положительных примеров среди всех предсказанных как положительные.;Precision — это доля всех правильных ответов.;2
В чём суть алгоритмов нахождения квадратичной ошибки?;Минимизация суммы квадратов разностей между предсказанными и фактическими значениями для нахождения оптимальных параметров модели;Минимизация квадратичной ошибки;4
Архитектура хранилищ данных;Архитектура включает уровни сбора, обработки, хранения и анализа данных с использованием ETL-процессов, data lakes и витрин данных;Уровни сбора, хранения и анализа данных;3
Примеры задач, решаемых с помощью больших графов.;Большие графы применяются для анализа социальных сетей, поиска путей в транспортных системах, моделирования связей в биоинформатике, рекомендаций и кибербезопасности.;В больших данных тоже есть графы.;2
Как специалисты анализируют данные в рамках системы логирования?;Технологии системы логирования позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Технологии позволяют улучшать качество аналитики, находить закономерности и предсказывать события.;4
Что такое TF-IDF?;Статистическая мера важности слова в документе относительно коллекции документов.;Способ анализа текстов для нахождения ключевых слов.;2
Определение термина «большие данные»;Большие данные представляют собой огромные объемы разнородной информации, требующие специальных технологий обработки;Большие объемы разнородных данных;3
Что такое data product в data mesh?;Самодостаточный набор данных с гарантиями качества и интерфейсами для потребления;Независимый продукт данных с гарантированным качеством и стандартными интерфейсами;5
Какие реальные кейсы демонстрируют эффективность нейронные сети?;Нейронные сети применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Нейронные сети применяется в бизнесе и иногда в науке для анализа данных.;3
Как проектировать систему для обработки данных в реальном времени с гарантией exactly-once?;Использовать фреймворки с поддержкой exactly-once (Flink, Kafka Streams), идемпотентные операции, transactional writes, checkpointing и watermarking для обработки late data.;Использовать Flink или Kafka Streams, настраивать checkpointing, применять идемпотентные операции и управлять состоянием для гарантии однократной обработки.;4
Что такое нормализация данных?;Приведение данных к единому масштабу без искажения соотношений.;Процесс масштабирования числовых признаков к определенному диапазону для улучшения сходимости алгоритмов и сравнения признаков.;4
В чем разница между данными, информацией и знаниями?;Данные - сырые факты, информация - обработанные данные с контекстом, знания - информация + понимание и опыт для принятия решений.;Данные - это сырье, информация - обработанные данные, знания - то что используется для действий.;3
Параметрическая модель статистического обучения;Параметрическая модель имеет фиксированное число параметров и предполагает определенную функциональную форму зависимости;Модели с заданной структурой параметров;3
Что такое 'градиентное исчезновение'?;Градиентное исчезновение — это ситуация, когда градиенты становятся слишком малыми, что замедляет или останавливает обучение нейросети.;Это проблема при обучении, когда сеть перестаёт учиться.;3
Примеры задач, решаемых с помощью больших графов;Большие графы применяются для анализа социальных сетей, рекомендательных систем, биоинформатики (белковые взаимодействия), транспортных сетей и веб-графов (PageRank);Соцсети, рекомендации, биоинформатика;3
Как глубокое обучение применяется для автоматизации рутинных процессов?;Глубокое обучение помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Используется для прогнозов и анализа информации.;3
Что такое 'нормализация данных'?;"Нормализация данных — это процесс приведения признаков к единому масштабу для корректной работы алгоритмов машинного обучения.,""Нормализация данных — это процесс приведения признаков к одному масштабу";чтобы улучшить обучение модели.;5
Что такое крос-валидация по временным рядам?;Специальные методы валидации для временных рядов, сохраняющие временной порядок данных.;Проверка моделей на данных с временными метками.;2
Что такое data governance в Big Data?;Управление доступностью, usability, integrity и security данных в организации;Управление качеством и безопасностью данных в организации;4
Что такое data serialization в Big Data?;Преобразование объектов в формат для передачи по сети или хранения;Процесс преобразования структур данных в формат пригодный для передачи или хранения;5
