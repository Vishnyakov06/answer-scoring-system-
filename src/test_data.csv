Вопрос;Эталонный ответ преподавателя;Ответ студента;Оценка
Как большие данные помогает в анализе больших объемов данных?;Большие данные используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;5
Какие методы используются для обработки временных рядов?;Для временных рядов применяются ARIMA, экспоненциальное сглаживание, методы на основе машинного обучения (LSTM, Prophet) и анализ трендов/сезонности;Статистические и ML подходы для временных данных;3
Мотивация происхождения NoSQL;NoSQL базы возникли из-за необходимости обработки неструктурированных данных и горизонтального масштабирования систем;NoSQL базы данных появились для обработки больших объемов данных;5
Примеры задач, решаемых с помощью больших графов;Большие графы применяются для анализа социальных сетей, рекомендательных систем, биоинформатики (белковые взаимодействия), транспортных сетей и веб-графов (PageRank);Применение графов в анализе;2
Что такое статистическая гипотеза? Какие виды гипотез вы знаете?;Статистическая гипотеза - это предположение о свойствах генеральной совокупности, проверяемое статистическими методами. Виды: нулевая (об отсутствии эффекта) и альтернативная (о наличии эффекта);Предположения о данных;2
Архитектура хранилищ данных.;Классическая архитектура хранилища включает уровни: источник данных, ETL-процесс (Extract, Transform, Load), слой хранения (Data Warehouse), слой аналитики (OLAP-кубы, BI-инструменты). Возможны схемы: звезда, снежинка, галактика.;Архитектура хранилища — это просто база данных и отчеты.;3
Какие основные конструкции языка R?;Векторы, матрицы, списки, data frames, факторы. Функции, управляющие конструкции (if, for, while). Пакеты для расширения функциональности. Векторизованные операции.;Основные структуры: векторы, матрицы, списки, data frames. Управление: условия, циклы, функции. Векторизованные вычисления и пакеты для анализа.;5
Какие риски связаны с применением ETL-пайплайны?;Технологии ETL-пайплайны позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Etl-пайплайны почти нигде не применяется. Это просто большие таблицы.;2
Как работает алгоритм DBSCAN для кластеризации?;DBSCAN группирует точки в кластеры на основе плотности, выделяя core points, border points и noise, не требуя предварительного задания числа кластеров;Алгоритм на основе плотности точек;3
Какие подходы использовать для обработки полуструктурированных данных (JSON, XML) в Big Data системах?;Использование форматов с schema evolution (Avro, Parquet), извлечение полей в отдельные колонки, хранение в native формате с индексацией, использование специализированных функций для querying.;Методы обработки данных в форматах JSON и XML в Big Data.;2
Какие основные инструменты и технологии используются для работы с глубокое обучение?;Глубокое обучение помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;5
Что такое метод главных компонент (PCA)?;Метод снижения размерности данных через проецирование на ортогональные компоненты с максимальной дисперсией.;Алгоритм для уменьшения количества признаков путем набора новых компонент, которые сохраняют максимальную дисперсию исходных данных.;4
Что такое data serialization в Big Data?;Преобразование объектов в формат для передачи по сети или хранения;Способ подготовки данных;2
Что такое Data Lake?;Хранилище неструктурированных и полуструктурированных данных в исходном формате.;Большое хранилище информации в компании.;2
Как развивается направление масштабируемые системы в последние годы?;Технологии масштабируемые системы позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Масштабируемые системы нужно только программистам, обычным компаниям оно бесполезно.;2
Принцип работы RandomForest;Ансамбль деревьев, бэггинг, случайный выбор признаков;Строит много деревьев на разных данных и усредняет результат;3
Что такое 'оценка точности модели'?;Оценка точности модели — это процесс измерения доли правильных предсказаний модели относительно всех предсказаний.;Это просто насколько хорошо модель работает.;3
Почему технологии кластеризация данных стали критически важны?;Кластеризация данных помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Технологии позволяют улучшать качество аналитики, находить закономерности и предсказывать события.;4
Какие навыки необходимы специалисту для работы с нейронные сети?;Нейронные сети помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Нейронные сети — это что-то про компьютеры. Применяется редко.;2
Какие методы используются для обработки пропущенных значений в данных?;Удаление строк с пропусками, импутация средним/медианой, предсказание значений с помощью ML моделей, интерполяция для временных рядов, создание отдельной категории для пропусков.;Заполнение пропусков средними значениями или удаление строк с недостающими данными перед анализом.;3
Понятие регрессии. Как используется этот вид анализа?;Регрессия — статистический метод, моделирующий зависимость целевой переменной Y от факторов X1, X2,..., Xn. Применяется для прогнозирования и анализа влияния факторов.;Регрессионный анализ используется для построения моделей вида Y = a0 + a1X1 + ... + anXn, позволяющих предсказывать значения Y и оценивать влияние факторов.;4
Что такое Vector Database и для каких задач она оптимальна?;Специализированная БД для хранения и поиска векторных эмбеддингов. Оптимальна для semantic search, рекомендательных систем, similarity search в больших наборах данных.;БД для векторных эмбеддингов с эффективным поиском ближайших соседей. Используется в рекомендательных системах, поиске по смыслу, кластеризации.;4
В чем преимущества применения рекомендательные системы по сравнению с традиционными методами?;Рекомендательные системы помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Рекомендательные системы применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;4
Какие реальные примеры использования ETL-пайплайны существуют?;Технологии ETL-пайплайны позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Etl-пайплайны применяется в некоторых компаниях для анализа данных.;3
Что включает в себя модель 8V для Big Data?;Volume, Velocity, Variety, Veracity, Value, Variability, Visualization, Validity. Эта модель охватывает технические и бизнес-аспекты больших данных от сбора до извлечения ценности.;Volume, Velocity, Variety, Veracity плюс Value, Variability, Visualization, Validity. Полный набор характеристик больших данных.;4
Как внедрение data mining влияет на процессы в организациях?;Data mining применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Data mining — это что-то про компьютеры. Применяется редко.;2
Какие риски связаны с использованием нейронные сети в критически важных системах?;Нейронные сети помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Помогает работать с данными и строить модели.;3
Как выбрать между реляционной и документной БД для хранения сложных структур?;Реляционная для строгой схемы и сложных запросов, документная для гибкой схемы и иерархических данных. Выбор зависит от требований к целостности и запросам.;Реляционная БД для строгих схем и сложных JOIN, документная для гибких структур и простых запросов. Учитывать требования к данным и запросам.;5
Какие реальные кейсы демонстрируют эффективность классификация данных?;Классификация данных помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Классификация данных применяется в бизнесе и иногда в науке для анализа данных.;3
Алгоритмы классификации;Основные алгоритмы включают логистическую регрессию, деревья решений, случайный лес, метод опорных векторов и наивный байесовский классификатор;Logistic Regression (линейная модель для вероятностей), Decision Trees (иерархическое разбиение пространства), Random Forest (ансамбль деревьев), SVM (максимизация зазора), Naive Bayes (вероятностная модель с предположением независимости);5
Нормальное распределение;Симметричное распределение с заданными математическим ожиданием и дисперсией, встречается в природе;Симметричное распределение с параметрами среднего и стандартного отклонения;4
Генеральная совокупность и выборка;Генеральная совокупность включает все объекты исследования, выборка является ее представительной частью;Генеральная совокупность это все объекты исследования;5
Основные вызовы больших данных (4V, 8V).;Основные характеристики больших данных обозначаются как 4V: Volume (объем), Velocity (скорость), Variety (разнообразие), Veracity (достоверность). В расширенной модели 8V добавляются Value (ценность), Variability (изменчивость), Visualization (визуализация), Vulnerability (уязвимость).;4V — это объем, скорость, значение и величина. Остальные характеристики не имеют значения.;2
Почему организации переходят на технологии масштабируемые системы?;Масштабируемые системы используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Масштабируемые системы используется бизнесом для оптимизации процессов, анализа клиентов и прогнозирования.;4
Что такое TF-IDF?;Статистическая мера важности слова в документе относительно коллекции документов.;TF-IDF (Term Frequency-Inverse Document Frequency) вычисляет вес термина как произведение частоты термина в документе (TF) на обратную частоту документа (IDF), показывая значимость слова в контексте коллекции.;5
Принципы глубокого обучения в нейросетях;Глубокое обучение основано на использовании нейронных сетей с множеством скрытых слоев, которые позволяют автоматически извлекать иерархические признаки из данных. Сверточные нейронные сети (CNN) специально разработаны для обработки изображений через применение сверточных фильтров и операций пулинга;Нейросети с большим количеством слоев способны решать сложные задачи машинного обучения путем постепенного извлечения признаков;2
Какие риски связаны с применением in-memory обработка?;Технологии in-memory обработка позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Эти технологии помогают работать с информацией и делать прогнозы.;3
Перечислить стадии разработки систем машинного обучения.;Стадии разработки систем машинного обучения: сбор данных, очистка и подготовка, выделение признаков, выбор модели, обучение, оценка качества, внедрение и мониторинг.;Основные этапы — сбор и обучение модели.;3
Как data mining помогает в анализе больших объемов данных?;Data mining используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;4
Принципы и инструменты аналитики Big Data;Аналитика больших данных основана на принципах распределенной обработки, использования специализированных фреймворков и облачных технологий для работы с большими объемами информации;"Основные принципы: распределенная обработка, горизонтальное масштабирование, отказоустойчивость; ключевые инструменты: Hadoop (HDFS, MapReduce), Spark для in-memory обработки, Kafka для потоковых данных, NoSQL базы (Cassandra, MongoDB), облачные платформы (AWS, GCP)";5
Процесс познания (от гипотезы к функции);Процесс включает формулировку гипотезы, сбор данных, построение модели, валидацию и создание прогнозной функции;От гипотезы через данные к функции;4
Почему технологии распределённые вычисления стали критически важны?;Распределённые вычисления используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Распределённые вычисления обеспечивает анализ потоковых данных, улучшает прогнозирование, помогает автоматизировать процессы и повышает точность аналитических моделей.;5
Что означает термин 'обучение с подкреплением'?;Обучение с подкреплением — это тип обучения, при котором агент взаимодействует со средой, получая вознаграждение за правильные действия.;Это метод, где данные поступают из среды, но без учителя.;3
Какие методы использовать для обработки данных с высокой cardinality в feature engineering?;Target encoding, hashing trick, frequency encoding, embedding learning, categorical embedding с нейросетями, grouping редких категорий.;Специальные методы кодирования для признаков с большим числом уникальных значений.;3
Что такое random forest?;Ансамблевый метод, строящий множество решающих деревьев на случайных подвыборках данных и признаков.;Алгоритм который строит множество деревьев на bootstrap выборках. Усредняет их предсказания для уменьшения переобучения и повышения точности.;5
«Меры изменчивости»: что к ним относится?;Дисперсия, стандартное отклонение, размах, межквартильный размах, среднее абсолютное отклонение;К мерам изменчивости относятся дисперсия и стандартное отклонение;5
Разница между линейной и логистической регрессией;Линейная регрессия предсказывает непрерывные числовые значения, тогда как логистическая регрессия предсказывает вероятности бинарной или мультиклассовой классификации с использованием сигмоидной функции активации;Линейная для чисел, логистическая для категорий;3
Какие методы используются для снижения размерности данных?;PCA (метод главных компонент), t-SNE, UMAP, autoencoders, feature selection. Уменьшают количество признаков сохраняя важную информацию.;PCA, t-SNE, отбор признаков. Методы для уменьшения числа переменных while сохраняя структуру данных.;4
Что такое feature engineering и какие методы используются?;Feature engineering - процесс создания и отбора признаков, включающий кодирование категориальных переменных, создание полиномиальных features и отбор наиболее значимых признаков;Методы подготовки признаков для машинного обучения;3
Каковы условия остановки ветвления дерева?;Условия остановки включают достижение максимальной глубины, минимального числа образцов в узле, отсутствие улучшения качества разбиения или достижение чистого узла.;Когда дерево перестает расти;2
Почему технологии мониторинг больших данных стали критически важны?;Мониторинг больших данных помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Мониторинг больших данных применяется в некоторых компаниях для анализа данных.;3
Где применяется классификация данных в промышленности и бизнесе?;Классификация данных используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Классификация данных нужно только программистам.;2
Какие риски связаны с использованием нейронные сети в критически важных системах?;Нейронные сети используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;5
Что такое GraphQL?;Язык запросов для API, позволяющий клиентам запрашивать только нужные данные.;GraphQL - это язык запросов и среда выполнения для API, который позволяет клиентам точно определять структуру требуемых данных в одном запросе, избегая over-fetching и under-fetching.;5
Что такое feature engineering и какие методы он включает?;Создание и преобразование признаков для улучшения качества ML моделей: кодирование категориальных переменных, масштабирование, создание полиномиальных признаков, извлечение признаков из дат и текстов.;Преобразование исходных данных в информативные признаки: one-hot encoding, scaling, создание новых фич на основе доменных знаний, работа с временными рядами и текстами.;5
Назовите, поясните и подкрепите формулами метрики качества для моделей регрессии.;Основные метрики: MAE = (1/n)*?|y - ?|, MSE = (1/n)*?(y - ?)^2, RMSE = sqrt(MSE), R^2 = 1 - ?(y - ?)^2 / ?(y - y?)^2.;MAE, MSE, RMSE и R2 оценивают отклонение предсказаний от реальных значений.;5
Сколько данных лучше взять для обучения: побольше или поменьше?;Объем данных для обучения должен быть достаточным для репрезентативности, но важнее качество данных. Для сложных моделей требуется больше данных, но необходим баланс с вычислительными ресурсами.;Объем данных должен быть достаточным для репрезентативности при обеспечении качества;5
Что такое Kubernetes?;Оркестратор контейнеров для автоматизации развертывания и управления приложениями.;Kubernetes - это open-source платформа для оркестрации контейнеризированных приложений, обеспечивающая автоматическое развертывание, масштабирование, healing и управление контейнерами в кластере.;5
Какие проблемы возникают при использовании кластеризация данных?;Кластеризация данных используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Кластеризация данных широко применяется в промышленности, здравоохранении, финансах и государственных системах. Позволяет анализировать большие массивы данных, строить точные модели и улучшать эффективность процессов.;5
Что такое Apache NiFi?;Система для автоматизации потоков данных между различными источниками и приемниками с визуальным интерфейсом.;Инструмент для построения data flows между системами. Визуальный интерфейс для проектирования потоков данных, мониторинга и управления routing, transformation.;5
Data Mining vs. Machine Learning – в чем отличия?;Data Mining (DM) — это процесс извлечения закономерностей и знаний из больших массивов данных, тогда как Machine Learning (ML) — это совокупность алгоритмов, позволяющих системе обучаться на данных и делать прогнозы. DM шире по смыслу и включает ML как инструмент.;Data Mining — это поиск закономерностей, а Machine Learning — метод автоматизации анализа данных, они связаны, но не тождественны.;4
Типы языка R, примеры;Вектор, матрица, список, фрейм данных, фактор;Есть разные типы для хранения данных;2
Дайте определение социального графа, его типы и свойства. К какому семейству больших графов он относится?;Социальный граф представляет собой сетевую структуру взаимоотношений между людьми или организациями, включает направленные и ненаправленные, взвешенные и невзвешенные типы, обладает свойствами малого мира и кластеризации, относится к семейству масштабно-инвариантных графов;Социальный граф - сетевая структура взаимоотношений, относится к масштабно-инвариантным графам;5
Обучение с учителем и без учителя;Обучение с учителем использует размеченные данные с известными ответами, а без учителя обнаруживает скрытые структуры в данных без меток;Два основных подхода в машинном обучении с различными принципами работы и областями применения;2
Примеры использования гистограммы;Гистограммы применяются для анализа распределения яркости в обработке изображений, контроля качества в производстве через анализ распределения параметров продукции;В обработке изображений и контроле качества;3
Какие риски связаны с использованием рекомендательные системы в критически важных системах?;Рекомендательные системы применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Рекомендательные системы применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;5
Как выбрать между различными алгоритмами кластеризации для конкретной задачи?;Анализировать форму кластеров (K-means для spherical, DBSCAN для произвольных), наличие шума (DBSCAN robust к выбросам), знание числа кластеров (K-means требует k), размер данных.;Выбирать based on формы кластеров: K-means для сферических, DBSCAN для произвольных форм и выбросов. Учитывать нужно ли заранее число кластеров, наличие шума в данных и масштабируемость алгоритма на большие объемы.;5
Какие методы используются для обработки временных рядов?;Для временных рядов применяются ARIMA, экспоненциальное сглаживание, методы на основе машинного обучения (LSTM, Prophet) и анализ трендов/сезонности;Для временных рядов применяются ARIMA и LSTM;5
Какие подходы использовать для обработки графовых данных в распределенных системах?;Специализированные графовые базы (Neo4j), графовые обработчики (GraphX), алгоритмы для распределенных графов (Pregel), оптимизация хранения графовых структур, partitioning по вершинам или ребрам.;Методы работы с данными имеющими сложные связи в распределенных системах.;2
Что такое MapReduce и из каких этапов состоит?;Модель программирования для обработки больших данных. Состоит из Map (фильтрация и сортировка) и Reduce (агрегация результатов).;Два этапа: Map преобразует данные, Reduce агрегирует результаты. Основа обработки в Hadoop.;4
Суть алгоритмов связных компонент и покрывающего дерева;Алгоритм связных компонент находит группы связанных узлов в графе, а алгоритм покрывающего дерева находит минимальный набор рёбер, соединяющий все вершины;Алгоритмы находят связные компоненты и покрывающие деревья в графах;5
Что такое ROC-кривая?;ROC-кривая — это график зависимости True Positive Rate от False Positive Rate, используемый для оценки качества бинарного классификатора.;ROC — это график точности модели.;3
Какие показатели характеризуют качество данных?;Полнота, точность, непротиворечивость, актуальность, достоверность, уникальность, целостность, своевременность.;Полнота, точность, согласованность, актуальность. Основные метрики качества данных для анализа.;4
Что такое MLOps?;Практики CI/CD для развертывания и мониторинга ML моделей в продакшене;Управление ML моделями;2
Какие методы обработки естественного языка используются в аналитике больших данных?;В NLP для больших данных применяются word2vec, BERT, TF-IDF, обработка n-грамм и методы тематического моделирования для извлечения смысла из текстовых данных;В NLP применяются word2vec, BERT и TF-IDF для анализа текстовых данных;5
Что такое grid search?;Метод подбора гиперпараметров через exhaustive search по заранее заданной сетке значений.;Способ настройки параметров алгоритма.;2
Что такое exactly-once semantics в stream processing?;Гарантия что каждое сообщение будет обработано ровно один раз без дублирования или потерь;Семантика гарантирующая что каждое событие будет обработано ровно один раз в потоковой обработке;5
Как развитие ETL-процессы влияет на будущее цифровых технологий?;Etl-процессы используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;5
Какие проблемы возникают при использовании обработка потоковых данных?;Обработка потоковых данных используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Обработка потоковых данных применяется в финансах, медицине, рекламе и IT, помогает анализировать данные и строить модели.;4
Для чего нужны партиции в Kafka;Партиции позволяют масштабировать обработку сообщений параллельно, распределяя нагрузку между несколькими потребителями. Каждая партиция гарантирует порядок сообщений.;Партиции в Kafka служат для горизонтального масштабирования топиков: распределения данных по разным брокерам, обеспечения параллелизма обработки (каждая партиция потребляется одним консьюмером в группе) и гарантии порядка сообщений в пределах одной партиции при увеличении общей пропускной способности системы.;5
Какие проблемы возникают при использовании кластеризация данных?;Кластеризация данных используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Кластеризация данных используется для обработки информации и улучшения решений.;3
Что такое Apache HBase?;Распределенная column-oriented NoSQL база данных, построенная поверх HDFS для random read/write доступа к большим данным.;База данных поверх HDFS для оперативного доступа. Column-oriented хранилище с поддержкой больших объемов.;4
Как специалисты анализируют данные в рамках in-memory обработка?;In-memory обработка помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;In-memory обработка используется бизнесом для оптимизации процессов, анализа клиентов и прогнозирования.;4
Преимущества CNN и их задач;"CNN эффективны для распознавания образов, обнаружения объектов, сегментации; преимущества - локальная связность, параметризация";Преимущества сверточных нейросетей;4
Что такое корреляция в анализе данных?;Корреляция — это статистическая мера взаимосвязи между двумя переменными. Она показывает направление и силу связи, выражается коэффициентом r в диапазоне от -1 до +1.;Это когда две величины как-то связаны.;3
Обучение с учителем и без учителя;Обучение с учителем использует размеченные данные, а без учителя обнаруживает скрытые структуры в данных без меток;С учителем используются размеченные данные для обучения;4
Нарисуйте (опишите) схему классификации методов машинного обучения;Классификация включает обучение с учителем, без учителя, с подкреплением и полу-контролируемое обучение;Схема методов ML;2
Как внедрение компьютерное зрение влияет на процессы в организациях?;Компьютерное зрение применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Используется для прогнозов и анализа информации.;3
Где применяется анализ данных в промышленности и бизнесе?;Анализ данных используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Анализ данных применяется в бизнесе и иногда в науке для анализа данных.;3
Порядок тестирования гипотезы о равенстве средних;Формулировка гипотез, проверка условий, расчет статистики, сравнение с критическим значением;Формулировка гипотез, проверка условий, расчет статистики, сравнение с критическим значением;5
Архитектура хранилищ данных;Архитектура включает уровни сбора, обработки, хранения и анализа данных с использованием ETL-процессов, data lakes и витрин данных;ETL-процессы и data lakes в архитектуре;4
Почему технологии предобработка данных стали критически важны?;Технологии предобработка данных позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Предобработка данных применяется в финансах, медицине, рекламе и IT, помогает анализировать данные и строить модели.;4
Как работает Delta Lake и какие проблемы ACID он решает в data lakes?;Открытый формат хранения поверх data lakes с ACID транзакциями, schema enforcement, time travel. Решает проблемы consistency, изоляции и надежности в традиционных data lakes.;Формат для data lakes с поддержкой ACID транзакций, управления схемами, версионированием данных. Решает проблемы качества и надежности в больших данных lakes.;5
Когда использовать Graph Database вместо реляционной для хранения данных?;Graph DB лучше когда данные имеют сложные связи и запросы ориентированы на отношения (социальные сети, рекомендации, fraud detection). Реляционные - для структурированных данных с простыми связями.;Graph databases эффективны для данных с богатыми связями где важны отношения между сущностями. Реляционные лучше для структурированных данных с предсказуемыми запросами.;5
Как работает алгоритм DBSCAN для кластеризации?;DBSCAN группирует точки в кластеры на основе плотности, выделяя core points, border points и noise, не требуя предварительного задания числа кластеров;DBSCAN группирует точки в кластеры на основе плотности;5
Шаги построения дендрограммы;Построение дендрограммы включает вычисление матрицы расстояний между объектами, применение агломеративного алгоритма кластеризации с выбором меры связи и визуализацию иерархической структуры слияния кластеров;Расчет попарных расстояний, последовательное объединение кластеров, построение дерева;3
Принцип работы RandomForest;Ансамбль деревьев, бэггинг, случайный выбор признаков;Применяет бэггинг: строит множество деревьев на случайных подвыборках данных и признаков, затем агрегирует предсказания, что снижает переобучение;5
Как выбрать оптимальную стратегию партиционирования данных в распределенной системе?;Выбор зависит от паттернов доступа: партиционирование по диапазону для range queries, по хэшу для равномерного распределения, по списку для категориальных данных. Учитывать размер партиций и частоту запросов.;Разные способы разделения данных для распределенных систем.;2
Нормальное распределение;Симметричное распределение с заданными математическим ожиданием и дисперсией, встречается в природе;Колоколообразное распределение;2
Метрики качества для моделей регрессии;Основные метрики включают RMSE, MAE, MAPE и R? для оценки точности регрессионных моделей и их предсказательной способности;Показатели для оценки того насколько хорошо регрессионная модель предсказывает числовые значения;2
Как машинное обучение применяется для автоматизации рутинных процессов?;Машинное обучение применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;5
Какие методы использовать для обработки данных с пропущенными временными метками?;Интерполяция временных меток, использование соседних значений, создание uniform timeline, обработка как отдельной категории, импутация на основе паттернов.;Интерполяция временных меток, заполнение соседними значениями, создание равномерной шкалы времени. Учитывать природу пропусков.;5
Понятия репликации и шардинга;Репликация - копирование данных для отказоустойчивости, шардинг - горизонтальное разделение;Репликация создает копии, шардинг делит данные между серверами;3
Алгоритмы выделения сообществ;Основные алгоритмы для обнаружения сообществ в сложных сетях включают метод Louvain, алгоритм Girvan-Newman и метод распространения меток, которые используют различные подходы к выявлению групп тесно связанных узлов;Алгоритмы для нахождения сообществ основаны на анализе связности и модульности сетевых структур;3
Как развитие модели прогнозирования влияет на будущее цифровых технологий?;Модели прогнозирования помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Помогает работать с данными и строить модели.;3
Что такое машинное обучение и какие задачи оно решает?;Машинное обучение используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;5
Как проектировать data pipeline для обработки данных с разной latency требованиями?;Lambda architecture, multi-tier processing, priority queues, separate pipelines для real-time и batch, resource allocation based on SLA.;Раздельная обработка для разных требований к задержке, приоритезация, распределение ресурсов. Баланс между real-time и batch.;4
Свойства эластичности и надёжности сложных сетей;Эластичность - устойчивость к нагрузкам, надежность - отказоустойчивость. Зависит от структуры сети;Сети бывают прочные и ненадежные;2
Что такое статистическое обучение;Статистическое обучение объединяет методы статистики и машинного обучения для построения прогнозных моделей;Статистика и машинное обучение;2
Что означает дисперсия выборки?;Дисперсия выборки — это мера разброса значений относительно среднего. Вычисляется как среднее квадратов отклонений от выборочного среднего.;Это показатель разброса данных.;4
Что такое feature store?;Централизованное хранилище для управления и обслуживания признаков ML моделей.;База данных для хранения и управления признаками, используемыми в моделях машинного обучения.;3
Критерии качества кластеризации;К критериям качества относятся Silhouette score, Davies-Bouldin index и Calinski-Harabasz index;Показатели качества кластеризации;3
Что такое CAP-теорема и как она применяется в Big Data системах?;CAP-теорема утверждает, что распределенная система может гарантировать только два из трех свойств: Consistency (консистентность), Availability (доступность), Partition Tolerance (устойчивость к разделению). В Big Data обычно жертвуют строгой консистентностью ради доступности и partition tolerance.;Важная теорема про распределенные системы и их ограничения.;2
С какими проблемами сталкиваются при применении модели прогнозирования, и как их решают?;Модели прогнозирования помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;5
Какие методы использовать для detection outliers в многомерных данных?;Mahalanobis distance, isolation forest, local outlier factor, DBSCAN, PCA-based methods, autoencoders reconstruction error.;Алгоритмы поиска аномалий в данных с множеством признаков.;3
Виды распределения данных и примеры;Основные виды распределений: нормальное (рост людей), равномерное (бросок кости), экспоненциальное (время между событиями), биномиальное (успехи в испытаниях);Нормальное, равномерное, экспоненциальное распределения;3
Сравнительный анализ алгоритмов кластеризации;Алгоритмы кластеризации сравниваются по масштабируемости, устойчивости к шуму и вычислительной эффективности;Алгоритмы сравниваются по масштабируемости и устойчивости;4
Алгоритмы классификации;Основные алгоритмы включают логистическую регрессию, деревья решений, случайный лес, метод опорных векторов и наивный байесовский классификатор;Популярные методы для задач классификации в машинном обучении;2
Data Mining vs. Machine Learning – в чем отличия?;Data Mining (DM) — это процесс извлечения закономерностей и знаний из больших массивов данных, тогда как Machine Learning (ML) — это совокупность алгоритмов, позволяющих системе обучаться на данных и делать прогнозы. DM шире по смыслу и включает ML как инструмент.;Data Mining и Machine Learning — это одно и то же, просто разные термины.;2
Сравнительная характеристика R и Python;R - для статистики и визуализации, Python - универсальный с библиотеками для ML;R обладает богатыми статистическими пакетами и визуализацией (ggplot2), Python имеет унифицированный стек библиотек (pandas, scikit-learn) и лучше для production;5
Что такое обработка данных и какие задачи оно решает?;Обработка данных применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;5
Что такое Apache Kafka?;Распределенная потоковая платформа обмена сообщениями для обработки потоков данных в реальном времени.;Это система для обработки потоковых данных в реальном времени, которая использует модель публикации-подписки и обеспечивает надежную передачу сообщений между системами.;4
Как развивается направление in-memory обработка в последние годы?;In-memory обработка используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;In-memory обработка широко применяется в промышленности, здравоохранении, финансах и государственных системах. Позволяет анализировать большие массивы данных, строить точные модели и улучшать эффективность процессов.;5
Какие особенности архитектуры потоковой обработки данных?;Архитектура потоковой обработки включает ingestion слои (Kafka), processing (Spark Streaming, Flink) и sink слои для хранения, обеспечивая обработку в реальном времени;Архитектура включает ingestion, processing и sink слои для потоковой обработки;5
Что такое Data Fabric;Data Fabric — это архитектурный подход, обеспечивающий единый, согласованный слой доступа к данным across разнородных источников через метаданные и семантическую интеграцию.;Слой для доступа к данным;2
Что такое Data Governance;Data Governance — это система управления доступностью, usability, integrity и безопасностью данных в организации через политики, стандарты и процессы.;Framework для управления качеством и безопасностью данных;4
Как ETL-пайплайны применяется в современных компаниях?;Технологии ETL-пайплайны позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Технологии позволяют улучшать качество аналитики, находить закономерности и предсказывать события.;4
Нарисуйте схему классификации методов машинного обучения.;Методы ML классифицируются на обучение с учителем, без учителя и с подкреплением. Также выделяют подтипы — классификация, регрессия, кластеризация, ассоциативные правила, ансамблевые методы.;Методы ML — это способ построения деревьев решений.;2
Как работает квантование в ML моделей и какие преимущества она дает для продакшн систем?;Сокращение точности весов модели (с FP32 до INT8). Уменьшает размер модели и ускоряет инференс с минимальной потерей качества. Критично для edge devices и high-load систем.;Способ оптимизации ML моделей для продакшн использования.;2
Что такое p-value в статистике?;Вероятность получить наблюдаемые или более экстремальные результаты при условии, что нулевая гипотеза верна.;Это значение, которое показывает точность расчетов в статистике.;2
Назовите меры центральной тенденции;Основные меры центральной тенденции включают среднее арифметическое, медиану и моду распределения;К мерам центральной тенденции относятся среднее, медиана и мода;5
Как работает Delta Lake и какие проблемы ACID он решает в data lakes?;Открытый формат хранения поверх data lakes с ACID транзакциями, schema enforcement, time travel. Решает проблемы consistency, изоляции и надежности в традиционных data lakes.;Решение для обеспечения надежности данных в data lakes.;2
Типы деревьев решений и индексы;Основные типы деревьев решений включают CART и C4.5, использующие индексы Джини, энтропию и gain ratio для выбора разделяющих признаков;CART строит бинарные деревья регрессии и классификации с индексом Джини, C4.5 создает деревья с дискретизацией непрерывных признаков и использует gain ratio для нормализации информационного выигрыша;5
Какие стратегии использовать для обработки данных с changing schema в data lakes?;Schema evolution, schema on read, использование форматов с backward compatibility, metadata management, data validation pipelines.;Методы работы с изменяющимися схемами в data lakes.;3
Что такое 'валидация модели'?;Валидация — это процесс проверки качества обученной модели на независимых данных, не участвовавших в обучении.;Валидация — это тестирование модели на другой части выборки.;4
Какие типы данных используются в Big Data и чем они отличаются?;"В Big Data выделяют структурированные, неструктурированные и полуструктурированные данные. Структурированные хранятся в таблицах, неструктурированные — это тексты, изображения, видео; полуструктурированные — JSON, XML.";Данные — это информация разных видов, например файлы и таблицы.;2
Что такое feature engineering?;Процесс создания и отбора признаков для улучшения качества моделей машинного обучения.;Работа с данными перед обучением моделей.;2
Каков порядок обработки данных при тестировании гипотезы о равенстве;"какие тесты должны быть пройдены, какие требования к данным выдвигаются?,""Проверяется нормальность распределения (Shapiro–Wilk), гомогенность дисперсий (Levene), после чего применяют t-тест для независимых или парных выборок. Требования: независимость наблюдений, интервал/отношение шкалы.";Перед тестом нужно проверить нормальность и гомогенность данных.;4
Что такое K-means кластеризация?;Метод кластеризации, разделяющий данные на k кластеров на основе расстояния до центроидов.;Алгоритм для нахождения групп в данных.;2
Как понимать «уровень статистической достоверности»? Это ли вероятность ошибки?;Уровень статистической достоверности (p-value) показывает вероятность того, что наблюдаемый эффект возник случайно. Чем меньше p-value, тем выше достоверность результата. Он не равен вероятности ошибки напрямую, но связан с ней через уровень значимости ?.;p-value — это вероятность случайного результата. Чем меньше, тем надежнее вывод.;4
Как работает механизм Attention в трансформерах и почему он революционен для NLP?;Взвешенная агрегация информации из всех позиций последовательности. Революционен благодаря ability улавливать long-range зависимости и параллелизации в отличие от RNN.;Важный компонент в современных NLP моделях который улучшил обработку текста.;2
Охарактеризуйте хранилища данных типа OLAP и OLTP. Назовите разницу.;OLTP (Online Transaction Processing) — системы для оперативной обработки транзакций характеризуются высокой скоростью записи и изменениями данных. OLAP (Online Analytical Processing) — системы аналитической обработки, оптимизированные для чтения и агрегации. Разница — в назначении и структуре: OLTP ориентирован на текущее состояние, OLAP — на анализ исторических данных.;OLAP и OLTP — это базы данных, у них разные функции.;3
Что такое transfer learning и в каких задачах он применяется?;Transfer learning - использование предобученных моделей для решения новых задач, применяется когда мало размеченных данных, особенно в компьютерном зрении и NLP;Transfer learning - использование предобученных моделей для новых задач;5
Какие бывают виды регрессионного анализа?;"Линейная, полиномиальная, логистическая, ридж, лассо регрессия; каждая решает специфические задачи";Основные виды регрессионного анализа;4
Как классификация данных используется в научных исследованиях?;Классификация данных помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;4
Для чего нужны гипотезы в анализе данных;Для формулировки проверяемых утверждений и статистической проверки научных предположений;Для формализации предположений и их статистической верификации;4
Что такое Data Warehouse;Data Warehouse — это централизованное хранилище интегрированных данных из различных источников, оптимизированное для аналитики и отчетности.;Центральное хранилище данных для отчетов;3
Какие риски связаны с применением системы логирования?;Системы логирования помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Системы логирования используется для обработки информации и улучшения решений.;3
В чем разница между параметрами и гиперпараметрами модели?;Параметры настраиваются автоматически в процессе обучения на данных (веса модели). Гиперпараметры задаются до обучения и управляют самим процессом обучения (скорость обучения, глубина дерева).;Параметры — это внутренние переменные, которые модель настраивает сама в процессе тренировки. Гиперпараметры — это внешние конфигурации, которые задаются аналитиком и управляют процессом обучения, например, скорость обучения или сложность модели.;5
Как обработка данных применяется для автоматизации рутинных процессов?;Обработка данных используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;4
Как специалисты анализируют данные в рамках big data?;Big data используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Big data нужно только программистам, обычным компаниям оно бесполезно.;2
Сколько данных лучше для обучения;Объем данных для обучения должен быть достаточным для репрезентативности, но важнее качество данных и их соответствие решаемой задаче;Оптимальный объем данных зависит от сложности задачи, используемого алгоритма и требуемой точности, при этом критически важны репрезентативность и качество данных;5
Какие проблемы возникают при использовании in-memory обработка?;In-memory обработка помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;In-memory обработка применяется в финансах, медицине, рекламе и IT, помогает анализировать данные и строить модели.;4
Каким образом выполняется преобразование данных, почему нужна очистка данных?;Преобразование данных выполняется для приведения данных к единому формату и структуры. Очистка необходима для устранения пропусков, дубликатов и ошибок, повышая достоверность анализа.;Очистка нужна, чтобы убрать ошибки, преобразование — чтобы изменить формат.;3
Перечислите основные метрики больших графов;Основные метрики больших графов включают диаметр, плотность, коэффициент кластеризации, центральность по степени, посредничеству и близости;Ключевые показатели для характеристики свойств и структуры крупных сетевых графов в анализе;2
Разновидности сложных сетей;Сети можно классифицировать на однородные, масштабно-инвариантные, малого мира и иерархические в зависимости от их структурных свойств;Разные типы сетей с различными характеристиками связности и распределения степеней;2
Структуры и типы данных в R;Основные структуры включают векторы, матрицы, списки, фреймы данных и факторы для различных типов данных;Язык R поддерживает различные структуры данных для анализа;5
Как big data применяется в современных компаниях?;Big data помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Технологии big data позволяют компаниям обрабатывать большие объёмы разнородных данных, выявлять сложные закономерности и принимать обоснованные решения.;5
Как работает технология MapReduce в экосистеме Hadoop?;MapReduce разделяет обработку данных на этапы Map (разбиение и фильтрация) и Reduce (агрегация), позволяя распределенно обрабатывать большие объемы информации на кластерах;MapReduce разделяет обработку на этапы Map и Reduce для распределенных вычислений;5
Как внедрение компьютерное зрение влияет на процессы в организациях?;Компьютерное зрение помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Помогает работать с данными и строить модели.;3
Что такое Apache Spark и в чем его преимущества перед Hadoop?;Распределенный фреймворк для обработки данных с in-memory вычислениями. Преимущества: выше скорость за счет работы в памяти, богатый API, поддержка streaming и ML.;Инструмент для обработки данных который работает быстрее старых систем.;2
Что такое Docker контейнер?;Легковесная изолированная среда для запуска приложений со всеми зависимостями.;Изолированная среда для запуска приложений, которая содержит все необходимое для их работы и обеспечивает консистентность на разных системах.;4
Какие реальные кейсы демонстрируют эффективность глубокое обучение?;Глубокое обучение используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;4
Data Mining vs. Machine Learning — в чём отличия?;Data Mining фокусируется на обнаружении паттернов в существующих данных, тогда как Machine Learning ориентирован на построение моделей для прогнозирования на новых данных;Data Mining для анализа данных, Machine Learning для построения моделей;4
Интегральные метрики качества;К интегральным метрикам относятся ROC-AUC, Precision-Recall AUC, F1-score и R?, агрегирующие различные аспекты качества;ROC-AUC, F1-score метрики;3
Зачем нужна мера близости в кластеризации? Достоинства графовых алгоритмов;Мера близости определяет схожесть объектов для группировки. Графовые алгоритмы эффективны для работы с разреженными данными и выявления сложных структур;Метрики для определения расстояний между точками;2
Какие стратегии использовать для миграции данных между разными системами хранения?;Инкрементальная миграция, dual write during transition, проверка консистентности, откат на предыдущую версию, мониторинг производительности, постепенное переключение трафика.;План переноса данных из одной системы в другую с минимальным простоем.;2
Как развивается направление ETL-пайплайны в последние годы?;Технологии ETL-пайплайны позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Etl-пайплайны используется для обработки информации и улучшения решений.;3
Какие навыки необходимы специалисту для работы с рекомендательные системы?;Рекомендательные системы используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Используется для прогнозов и анализа информации.;3
Как выбрать оптимальную стратегию партиционирования данных в распределенной системе?;Выбор зависит от паттернов доступа: партиционирование по диапазону для range queries, по хэшу для равномерного распределения, по списку для категориальных данных. Учитывать размер партиций и частоту запросов.;Анализировать типы запросов: range partitioning для диапазонных запросов, hash partitioning для равномерной нагрузки, list partitioning для категориальных данных. Важно избегать data skew и выбирать размер партиций для баланса между параллелизмом и overhead'ом.;5
Какие проблемы возникают при использовании data warehouses?;Data warehouses помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Data warehouses обеспечивает анализ потоковых данных, улучшает прогнозирование, помогает автоматизировать процессы и повышает точность аналитических моделей.;5
Как внедрение нейронные сети влияет на процессы в организациях?;Нейронные сети используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Помогает работать с данными и строить модели.;3
В чем разница между supervised и unsupervised learning?;Supervised learning использует размеченные данные с метками, unsupervised работает с данными без меток.;Supervised learning требует размеченных данных для обучения с учителем, тогда как unsupervised learning самостоятельно находит паттерны в данных без заранее известных ответов.;5
Как кластеризация помогает в анализе больших объемов данных?;Кластеризация используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Это просто работа с таблицами. Не очень полезно.;2
Какие риски связаны с применением предобработка данных?;Предобработка данных помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Предобработка данных используется для обработки информации и улучшения решений.;3
Как выбрать стратегию индексации для оптимизации запросов в колоночных хранилищах?;Использовать zone maps для min/max значений, bloom filters для членства, inverted indexes для категориальных данных. Выбор зависит от типа запросов и распределения данных.;Разные типы индексов для разных сценариев запросов в колоночных БД.;3
Перечислите основные метрики больших графов;Основные метрики больших графов включают диаметр, плотность, коэффициент кластеризации, центральность по степени, посредничеству и близости;Диаметр графа, плотность связей, коэффициенты кластеризации и различные меры центральности узлов;3
Какие типы машинного обучения существуют?;Существует три типа машинного обучения: с учителем, без учителя и с подкреплением. Первый использует размеченные данные, второй — неразмеченные, третий — обучение через взаимодействие с средой.;Это обучение машин на данных.;2
С какими проблемами сталкиваются при применении машинное обучение, и как их решают?;Машинное обучение применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Машинное обучение нужно только программистам.;2
Примеры задач с большими графами;Большие графы используются в социальных сетях для анализа сообществ, в рекомендательных системах и биоинформатике для изучения белковых взаимодействий;Анализ социальных сетей, рекомендации и биологические исследования;4
В чем разница между SQL и NoSQL базами данных?;SQL базы реляционные, с жесткой схемой, используют SQL для запросов. NoSQL - нереляционные, с гибкой схемой, горизонтально масштабируемые.;SQL базы данных имеют строгую схему и используют таблицы со связями, тогда как NoSQL базы предлагают гибкие схемы, горизонтальное масштабирование и могут хранить данные в виде документов, графов или ключ-значение.;5
Какие основные инструменты и технологии используются для работы с глубокое обучение?;Глубокое обучение используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;4
Шаги построения дендрограммы;Построение дендрограммы включает вычисление матрицы расстояний между объектами, применение агломеративного алгоритма кластеризации с выбором меры связи и визуализацию иерархической структуры слияния кластеров;Процесс создания древовидной диаграммы для визуализации иерархической кластеризации;2
Какие реальные кейсы демонстрируют эффективность компьютерное зрение?;Компьютерное зрение помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Компьютерное зрение применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;4
Основные задачи Data Analysis;К основным задачам относятся описательная аналитика, диагностика проблем, прогнозирование и прескриптивная аналитика;Описательная и прогнозная аналитика;3
Какие навыки необходимы специалисту для работы с обработка данных?;Обработка данных применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Обработка данных применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;5
Что такое нормализация данных и зачем она нужна?;Нормализация данных — это процесс приведения числовых признаков к общему масштабу, чтобы исключить влияние разницы в единицах измерения на обучение модели. Применяется методы Min-Max, Z-score, логарифмирование.;Нормализация — это когда убирают ошибки в данных.;2
Что такое random forest?;Ансамблевый метод, строящий множество решающих деревьев на случайных подвыборках данных и признаков.;Метод машинного обучения на основе деревьев.;2
Основные задачи Data Analysis;К основным задачам относятся описательная аналитика, диагностика проблем, прогнозирование и прескриптивная аналитика;Data Analysis включает различные типы аналитических задач;5
Что понимается под термином 'recall'?;Recall — это доля правильно предсказанных положительных объектов среди всех реально положительных объектов.;Recall — это мера полноты модели.;4
Как развитие предиктивная аналитика влияет на будущее цифровых технологий?;Предиктивная аналитика применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;4
Что такое гиперпараметры модели?;Гиперпараметры — это параметры, значения которых задаются до обучения модели и влияют на её архитектуру и процесс обучения, например скорость обучения или количество слоёв.;Это параметры, которые настраивают перед обучением модели.;4
Что такое машинное обучение и каковы его основные типы?;Машинное обучение — это раздел искусственного интеллекта, изучающий методы построения алгоритмов, способных обучаться на данных. Основные типы: обучение с учителем, без учителя и с подкреплением.;Машинное обучение делится на обучение с учителем и без, но в целом это когда модель учится на данных.;3
Что такое data product в data mesh?;Самодостаточный набор данных с гарантиями качества и интерфейсами для потребления;Автономный набор данных с определенными интерфейсами;4
Какие методы использовать для обработки данных с пропущенными временными метками?;Интерполяция временных меток, использование соседних значений, создание uniform timeline, обработка как отдельной категории, импутация на основе паттернов.;Интерполяция timestamp'ов, заполнение соседними значениями. Методы обработки пропущенных временных меток.;4
Процесс познания (от гипотезы к функции);Процесс включает формулировку гипотезы, сбор данных, построение модели, валидацию и создание прогнозной функции;От идеи к модели;2
Перечислите разновидности сложных сетей, назовите их характеристики.;Разновидности: случайные графы (Эрдёша–Реньи), безмасштабные сети (Барбаши–Альберт), сети тесного мира (Уоттса–Строгаца), ориентированные и взвешенные сети.;Есть разные типы сетей, например, случайные и социальные.;2
Как работает квантование в ML моделях и какие преимущества она дает для продакшн систем?;Сокращение точности весов модели (с FP32 до INT8). Уменьшает размер модели и ускоряет инференс с минимальной потерей качества. Критично для edge devices и high-load систем.;Уменьшение битности весов модели. Сокращает размер и ускоряет работу модели с небольшим снижением точности. Важно для продакшн где важна скорость и эффективность.;4
Основные вызовы больших данных;Основные вызовы включают объем, скорость поступления, разнообразие форматов и достоверность данных;Volume, velocity, variety и veracity данных;3
Что такое статистическая гипотеза? Какие виды гипотез вы знаете?;Статистическая гипотеза — это предположение о параметрах генеральной совокупности. Различают нулевую гипотезу H0 и альтернативную H1. Пример: H0: ?1 = ?2, H1: ?1 ? ?2.;Гипотеза — это догадка, которая проверяется статистикой.;3
Как модели прогнозирования помогает в анализе больших объемов данных?;Модели прогнозирования применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Используется для прогнозов и анализа информации.;3
Какие риски связаны с использованием обработка данных в критически важных системах?;Обработка данных применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;5
Метрики качества для моделей регрессии;Для оценки регрессионных моделей применяются RMSE, MAE, MAPE и коэффициент детерминации R?;Метрики RMSE, MAE для регрессии;2
Как работает квантование в ML моделях и какие преимущества она дает для продакшн систем?;Сокращение точности весов модели (с FP32 до INT8). Уменьшает размер модели и ускоряет инференс с минимальной потерей качества. Критично для edge devices и high-load систем.;Снижение точности чисел в модели (например, до 8 бит). Уменьшает размер модели в 4 раза и ускоряет предсказания. Особенно полезно для мобильных устройств и высоконагруженных API.;5
Что такое дисперсия данных и что она показывает?;Дисперсия — это мера разброса данных относительно среднего значения. Вычисляется как среднее квадратов отклонений: D = ?(xi - ?)^2 / n.;Это показатель среднего значения данных.;2
Основные задачи Data Analysis;Описательная аналитика, диагностика, прогнозирование, прескриптивная аналитика для принятия решений;Основные направления анализа данных;4
Когда использовать линейные, а когда нелинейные модели;Линейные - когда связь линейная, нелинейные - для сложных зависимостей. Проверять через визуализацию и тесты;Линейные модели для прямых зависимостей, нелинейные когда кривые. Смотреть на графики;3
Сколько данных оптимально использовать для обучения моделей?;Зависит от сложности задачи: для простых моделей достаточно тысяч примеров, для глубокого обучения - миллионы. Важен баланс между объемом и качеством разметки.;Нужно достаточно данных для обучения, но не слишком много. Зависит от задачи и алгоритма.;3
Каким образом выполняется преобразование данных;"""Преобразование данных выполняется для приведения данных к единому формату и структуры. Очистка необходима для устранения пропусков, дубликатов и ошибок, повышая достоверность анализа.";Очистка и преобразование нужны для корректной структуры и устранения ошибок.;4
Что такое ETL-процессы и какие задачи оно решает?;Etl-процессы применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Etl-процессы применяется в бизнесе и иногда в науке для анализа данных.;3
Дайте определение социального графа, его типы и свойства;Социальный граф - сеть взаимоотношений между людьми, включает directed/undirected, weighted/unweighted, обладает small-world property;Граф социальных связей;2
Дайте определение социального графа, его типы и свойства;Социальный граф - сеть взаимоотношений между людьми, включает directed/undirected, weighted/unweighted, обладает small-world property;Типы социальных графов и их свойства;3
Что такое крос-валидация по временным рядам?;Специальные методы валидации для временных рядов, сохраняющие временной порядок данных.;Time series cross-validation использует скользящее окно или расширяющееся окно для тренировки и тестирования, сохраняя временную структуру данных и предотвращая data leakage из будущего в прошлое.;5
Какие проблемы возникают при использовании распределённые вычисления?;Технологии распределённые вычисления позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Эти технологии помогают работать с информацией и делать прогнозы.;3
Определение термина «большие данные»;Большие объемы разнородных данных, требующие специальных технологий обработки и хранения;Большие объемы разнородных данных, требующие специальных технологий;5
Как работает технология In-Memory Computing в современных СУБД?;Хранение и обработка данных в оперативной памяти вместо диска. Обеспечивает sub-millisecond latency для transactional и analytical workloads.;Хранение данных в памяти для быстрого доступа. Значительно ускоряет выполнение запросов и транзакций по сравнению с дисковыми системами.;3
Какие методы использовать для detection data drift в production ML systems?;Statistical tests (KS, PSI), monitoring prediction distributions, concept drift detection algorithms, feature distribution monitoring, performance metrics tracking.;Статистические тесты, мониторинг распределений предсказаний, алгоритмы детектирования дрейфа. Отслеживание распределений фич и метрик качества.;5
Как обработка данных применяется для автоматизации рутинных процессов?;Обработка данных применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Помогает работать с данными и строить модели.;3
Порядок тестирования гипотезы о равенстве средних;Процесс включает формулировку гипотез, проверку условий, расчет статистики и принятие решения;Этапы проверки гипотез о средних значениях;3
Что такое Feature Store и как он решает проблемы consistency между training и serving?;Централизованное хранилище признаков с гарантией идентичности фич при обучении и инференсе. Решает проблемы training-serving skew, обеспечивает версионирование и переиспользование фич.;Система для хранения признаков ML моделей обеспечивающая согласованность данных.;2
Типы деревьев решений и индексы;Основные типы алгоритмов деревьев решений включают CART и C4.5, которые используют различные индексы для разделения данных, такие как индекс Джини, энтропия и коэффициент gain ratio;Деревья решений и различные индексы для оценки качества разделения данных на классы;2
Как data mining применяется для автоматизации рутинных процессов?;Data mining помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Data mining применяется в бизнесе и иногда в науке для анализа данных.;3
Какие методы использовать для оптимизации JOIN операций в распределенных системах?;Broadcast join для маленьких таблиц, sort-merge join для отсортированных данных, hash join для больших таблиц, bucketing для предварительного разделения, использование статистик для выбора стратегии.;Broadcast join для небольших таблиц, sort-merge и hash join для больших, bucketing для оптимизации, использование статистик данных для выбора оптимального алгоритма join'а.;4
Что понимается под термином 'Data Mining'?;Data Mining — это процесс извлечения ранее неизвестных, практически полезных и интерпретируемых знаний из больших объемов данных.;Это что-то вроде обработки данных, когда ищут закономерности, но без особых методов.;3
Какие стратегии использовать для оптимизации производительности Spark при работе с большими данными?;Кэширование часто используемых DataFrame, правильное партиционирование данных, использование broadcast join для маленьких таблиц, настройка памяти исполнителей, выбор оптимального формата хранения.;Кэширование данных, оптимизация партиционирования, настройка памяти, использование эффективных форматов хранения и правильная организация joins.;4
Что такое Apache Iceberg;Apache Iceberg — это open-source table format для аналитических datasets, обеспечивающий ACID семантику, hidden partitioning и schema evolution поверх cloud object stores.;Формат таблиц с ACID транзакциями и эволюцией схемы;4
Как оптимизировать производительность запросов к partitioned данным?;Partition pruning, predicate pushdown, statistics usage, optimal partition size, partition key selection based on query patterns.;Методы ускорения запросов к партиционированным данным через исключение партиций и оптимизацию.;3
Нарисуйте схему классификации методов машинного обучения.;Методы ML классифицируются на обучение с учителем, без учителя и с подкреплением. Также выделяют подтипы — классификация, регрессия, кластеризация, ассоциативные правила, ансамблевые методы.;Machine learning бывает supervised, unsupervised и reinforcement.;4
Какие стратегии использовать для балансировки нагрузки в распределенных data processing системах?;Dynamic resource allocation, adaptive scheduling, data locality optimization, load-aware partitioning, auto-scaling based on metrics.;Балансировка ресурсов, оптимизация расположения данных и автоматическое масштабирование в зависимости от нагрузки.;3
Когда использовать линейные, а когда нелинейные модели?;"Линейные - при линейных зависимостях, нелинейные - при сложных паттернах; выбор через анализ остатков";Для простых и сложных зависимостей;3
Принцип работы SVM;Метод опорных векторов находит гиперплоскость с максимальным зазором для разделения классов в пространстве признаков;SVM находит гиперплоскость с максимальным зазором между классами;5
Параметрическая модель статистического обучения;Параметрическая модель имеет фиксированное число параметров и предполагает определенную функциональную форму зависимости;Параметрические модели предполагают фиксированное количество параметров для обучения;5
Каковы закономерности динамики сложных сетей и законы распространения информации в них.;Закономерности включают рост и предпочтительное присоединение, эволюцию степени узлов, каскадные эффекты и диффузионные процессы по законам SIR и SI моделей.;Динамика сетей подчиняется законам роста (механизм preferential attachment), изменениям структуры со временем и диффузии информации, описываемой моделями SI, SIR, SIS. Распространение может быть эпидемическим, каскадным или стохастическим.;5
Понятия репликации и шардинга;Репликация - копирование данных для отказоустойчивости, шардинг - горизонтальное разделение;Репликация для отказоустойчивости, шардинг для горизонтального масштабирования;5
Сколько данных оптимально использовать для обучения моделей?;Зависит от сложности задачи: для простых моделей достаточно тысяч примеров, для глубокого обучения - миллионы. Важен баланс между объемом и качеством разметки.;Объем зависит от сложности модели: простые алгоритмы - тысячи примеров, нейросети - миллионы. Важно качество разметки и репрезентативность данных.;5
Какие проблемы возникают при использовании распределённые вычисления?;Технологии распределённые вычисления позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Распределённые вычисления почти нигде не применяется. Это просто большие таблицы.;2
Почему организации переходят на технологии data warehouses?;Технологии data warehouses позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Технологии data warehouses позволяют компаниям обрабатывать большие объёмы разнородных данных, выявлять сложные закономерности и принимать обоснованные решения.;5
Зачем нужны рекуррентные нейросети;Для обработки последовательных данных: текст, речь, временные ряды. Сохраняют контекст;Предназначены для обработки последовательностей с памятью о предыдущих состояниях. Применяются в NLP (машинный перевод), анализе временных рядов, распознавании речи благодаря способности улавливать временные зависимости;5
Какие этапы включает проект, основанный на использовании модели прогнозирования?;Модели прогнозирования помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Помогает работать с данными и строить модели.;3
Когда использовать Spark вместо Pandas для обработки данных?;Spark когда данные не помещаются в память одного компьютера или нужна распределенная обработка. Pandas для данных, которые fit in memory и не требуют распределенных вычислений.;Spark необходим когда работаешь с большими данными, которые не помещаются в память одной машины, или когда нужна горизонтальная масштабируемость. Pandas подходит для данных размером до нескольких GB на одной машине.;5
Перечислите и поясните с формулами и примерами метрики качества для бинарной классификации.;Основные метрики: Accuracy = (TP + TN) / (TP + FP + TN + FN), Precision = TP / (TP + FP), Recall = TP / (TP + FN), F1 = 2 * (Precision * Recall) / (Precision + Recall).;Accuracy и Precision считаются по TP и TN.;3
Мотивация происхождения NoSQL;NoSQL базы возникли из-за необходимости обработки неструктурированных данных и горизонтального масштабирования систем;Необходимость работы с большими данными;4
Что такое Data Scientist и какие навыки ему необходимы?;Data Scientist — это специалист, который сочетает навыки программирования, статистики и предметной области. Он занимается анализом данных, построением моделей и интерпретацией результатов.;Data Scientist должен уметь программировать и анализировать данные.;4
Как оптимизировать запросы к данным с временными рядами для аналитических нагрузок?;Партиционирование по времени, индексы по временным меткам, материализованные представления для агрегатов, сжатие временных данных, использование специализированных TSDB.;Организация данных по времени, индексы для временных меток, предвычисление агрегатов для ускорения запросов к временным рядам.;3
Определение термина 'большие данные', источники получения больших данных.;Большие данные — это совокупность структурированных и неструктурированных данных значительного объема, скорости и разнообразия, требующих специализированных методов хранения и анализа. Источники: сенсоры IoT, социальные сети, логи систем, транзакционные данные, мультимедиа.;Большие данные — это большие объемы информации, получаемые из разных источников.;3
Какие проблемы возникают при использовании системы логирования?;Технологии системы логирования позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Системы логирования используется бизнесом для оптимизации процессов, анализа клиентов и прогнозирования.;4
Что такое 'обучающая выборка'?;Обучающая выборка — это часть данных, используемая для настройки параметров модели.;Это данные для проверки модели.;2
Как масштабируемые системы влияет на эффективность бизнеса?;Масштабируемые системы помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Технологии позволяют улучшать качество аналитики, находить закономерности и предсказывать события.;4
Требования ACID. CAP-теорема, BASE архитектура: как и к каким хранилищам данных эти понятия применяются.;ACID (Atomicity, Consistency, Isolation, Durability) — свойства транзакционных систем (OLTP). CAP-теорема утверждает невозможность одновременного обеспечения согласованности (C), доступности (A) и устойчивости к разделению (P). BASE (Basically Available, Soft-state, Eventually consistent) описывает принципы NoSQL систем.;ACID — это принципы SQL, BASE — принципы Big Data, CAP — это формула связи.;3
Как предиктивная аналитика применяется для автоматизации рутинных процессов?;Предиктивная аналитика применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;5
Что такое feature store?;Централизованное хранилище для управления и обслуживания признаков ML моделей;Система для ML;2
Как организовать feature engineering для NLP задач с большими текстовыми данными?;TF-IDF, word embeddings (Word2Vec, GloVe), contextual embeddings (BERT), character-level features, topic modeling (LDA), syntactic features (POS tagging).;TF-IDF для весов слов, word embeddings (Word2Vec, FastText), контекстные эмбеддинги (BERT), признаки на уровне символов, тематическое моделирование, синтаксические особенности. Важно учитывать вычислительную сложность и качество представлений.;5
Разница между линейной и логистической регрессией;Линейная регрессия предсказывает непрерывные значения, логистическая - вероятности бинарной классификации;Линейная регрессия для непрерывных значений, логистическая для классификации;5
С какими проблемами сталкиваются при применении ETL-процессы, и как их решают?;Etl-процессы помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;5
Что означает дисперсия выборки?;Дисперсия выборки — это мера разброса значений относительно среднего. Вычисляется как среднее квадратов отклонений от выборочного среднего.;Это про средние данные.;2
Структуры и типы данных в языке R, привести примеры.;В R присутствуют структуры данных: vector, matrix, data.frame, list, factor. Примеры: vector(c(1,2,3)), matrix(1:9, nrow=3), data.frame(x=1:3, y=c('a','b','c')).;В R все данные хранятся в таблицах, других структур нет.;2
Что такое data lake и чем он отличается от data warehouse?;Data lake хранит сырые данные в любом формате, data warehouse - структурированные и обработанные данные по заданной схеме. Data lake для exploration, data warehouse для отчетности.;Два типа хранилищ данных с разными подходами к организации информации.;2
Что такое обучение с учителем и как оценивается качество модели?;Обучение с учителем — это метод, при котором модель обучается на размеченных данных. Качество оценивается метриками: Accuracy, Precision, Recall, F1-score.;Это обучение, когда преподаватель объясняет машине.;2
Почему организации переходят на технологии хранилища данных?;Хранилища данных помогает компаниям анализировать пользовательское поведение, выявлять закономерности и строить точные модели. Применяется в цифровых сервисах, рекламе и смарт?системах.;Хранилища данных используется бизнесом для оптимизации процессов, анализа клиентов и прогнозирования.;4
Как специалисты анализируют данные в рамках обработка потоковых данных?;Обработка потоковых данных используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Обработка потоковых данных почти нигде не применяется. Это просто большие таблицы.;2
Что такое трансформер (Transformer) в NLP?;Архитектура нейросетей на основе механизма внимания, исключающая рекуррентные и сверточные слои для обработки последовательностей.;Алгоритм для обработки естественного языка, который использует внимание к словам.;3
Нарисуйте (опишите) схему классификации методов машинного обучения;Классификация включает обучение с учителем, без учителя, с подкреплением и полу-контролируемое обучение;Классификация методов включает обучение с учителем и без учителя;5
Как работает Federated Learning и в каких сценариях он наиболее эффективен?;Обучение моделей на децентрализованных данных без их передачи на сервер. Эффективен для privacy-sensitive сценариев: healthcare, мобильные устройства, где данные нельзя централизовать.;Метод обучения ML моделей без сбора данных в одном месте.;2
Преимущества и недостатки непараметрических моделей;Непараметрические модели гибки и не требуют предположений о распределении данных, но могут требовать больших объемов данных и вычислительных ресурсов;"Плюсы: адаптивность к сложным зависимостям; минусы: риск переобучения, высокие вычислительные затраты";3
Виды связи между переменными при корреляции;Связи бывают положительные, отрицательные и нулевые. При положительной связи увеличение одной переменной сопровождается ростом другой, при отрицательной — снижением. Отсутствие связи указывает на независимость переменных.;При корреляции одна переменная растёт вместе с другой или наоборот, уменьшается. Если изменений нет, значит, связи нет.;5
Что такое data versioning?;Контроль версий для наборов данных и их метаданных;Управление версиями данных;3
Разница между линейной и логистической регрессией;Линейная регрессия предсказывает непрерывные значения, логистическая - вероятности бинарной классификации;Для чисел и для классификации;3
Как оптимизировать data shuffling в распределенных вычислениях?;Minimize shuffling, use broadcast variables, optimize partitioning, use accumulators для агрегаций, filter early, use efficient serialization.;Сокращение shuffling'а, broadcast, оптимизация партиций. Методы уменьшения сетевого обмена в кластере.;4
Обучение с подкреплением и ансамбли;"RL - обучение через взаимодействие со средой; ансамбли - комбинация нескольких моделей";Два разных подхода в ML;2
Разница описательных и предсказательных задач;Описательные задачи анализируют существующие данные, предсказательные строят модели для прогнозирования;Описательные задачи focused на анализе исторических данных;5
Что такое federated learning?;Подход когда модель обучается на децентрализованных данных без их централизации;Новый способ обучения ИИ;2
Какие способы визуализации корреляции были изучены в курсе Big Data?;Основные способы: корреляционная матрица, тепловая карта (heatmap), диаграмма рассеяния (scatter plot), графики зависимости и парные диаграммы (pairplot).;Корреляция визуализируется при помощи матрицы корреляций, heatmap, scatter plot, а также pairplot в библиотеках Python (seaborn, matplotlib).;4
Уровень статистической достоверности;Вероятность того, что результат не случаен. Не вероятность ошибки, а доверие к результату;Уровень доверия к результату исследования. 95% означает высокую уверенность, но не вероятность ошибки;4
Обучение с подкреплением и ансамбли;"RL - обучение через взаимодействие со средой; ансамбли - комбинация нескольких моделей";RL через trial-and-error, ансамбли через агрегацию моделей;4
Что такое gradient boosting?;Метод машинного обучения, где несколько слабых моделей (обычно деревья) последовательно обучаются, каждая новая модель исправляет ошибки предыдущих.;Это метод, когда последовательно строятся деревья, где каждое следующее дерево учится на ошибках предыдущих, постепенно улучшая качество модели.;4
Разновидности сложных сетей;Однородные, масштабно-инвариантные, малого мира, иерархические, случайные сети;Типы сетевых структур;2
Как развитие большие данные влияет на будущее цифровых технологий?;Большие данные используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Большие данные применяется в финансах, медицине, рекламе и производстве. Используется для анализа данных, построения моделей и прогнозирования.;4
Как развитие глубокое обучение влияет на будущее цифровых технологий?;Глубокое обучение используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Глубокое обучение применяется в бизнесе и иногда в науке для анализа данных.;3
Какие этапы включает проект, основанный на использовании рекомендательные системы?;Рекомендательные системы используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Рекомендательные системы нужно только программистам.;2
Что такое нормализация данных и зачем она нужна?;Нормализация данных — это процесс приведения числовых признаков к общему масштабу, чтобы исключить влияние разницы в единицах измерения на обучение модели. Применяется методы Min-Max, Z-score, логарифмирование.;Это процесс, при котором данные делаются равными по размеру, чтобы обучение было проще.;3
Как внедрение анализ данных влияет на процессы в организациях?;Анализ данных используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;4
Что такое data partitioning в Big Data?;Разделение данных на меньшие части для распределенной обработки и хранения, что улучшает производительность и управляемость;Метод разделения больших данных на части для параллельной обработки в распределенных системах;4
Какие риски связаны с применением ETL-пайплайны?;Etl-пайплайны используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Технологии позволяют улучшать качество аналитики, находить закономерности и предсказывать события.;4
Архитектура хранилищ данных;Архитектура включает уровни сбора, обработки, хранения и анализа данных с использованием ETL-процессов, data lakes и витрин данных;Структура хранения данных;2
Виды связи между переменными при корреляции.;Корреляция отражает степень и направление линейной связи между двумя переменными. Связи могут быть положительные, отрицательные или нулевые. Для оценки используется коэффициент корреляции Пирсона или Спирмена.;Корреляция — это зависимость между переменными, выражаемая коэффициентом, например, Пирсона.;5
Как кластеризация используется в научных исследованиях?;Кластеризация помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Используется компаниями для анализа клиентов, предсказания событий и оптимизации процессов.;5
В чем преимущества применения глубокое обучение по сравнению с традиционными методами?;Глубокое обучение используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Помогает работать с данными и строить модели.;3
Как обработка данных помогает в анализе больших объемов данных?;Обработка данных применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Позволяет находить закономерности, улучшать точность решений и автоматизировать процессы в разных сферах.;4
Что такое Apache Parquet?;Колоночный формат хранения данных с эффективным сжатием и кодированием.;Формат файлов для хранения структурированных данных, который хранит данные по колонкам а не по строкам, что улучшает производительность аналитических запросов и сжатие.;4
Какие методы использовать для детектирования аномалий в потоковых данных?;Statistical methods (moving average, z-score), ML approaches (isolation forest, autoencoders), time-series methods (STL decomposition). Важно учитывать задержку обработки и обновление модели.;Методы для поиска отклонений в данных которые приходят постоянно.;2
Какие риски связаны с применением мониторинг больших данных?;Мониторинг больших данных используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Мониторинг больших данных используется бизнесом для оптимизации процессов, анализа клиентов и прогнозирования.;4
Что такое XGBoost?;Библиотека для градиентного бустинга с оптимизацией производительности и регуляризацией.;Эффективная реализация gradient boosting. Быстрая, с регуляризацией и хорошей работой с разными типами данных. Часто побеждает в соревнованиях.;4
Что такое трансформер (Transformer) в NLP?;Архитектура нейросетей на основе механизма внимания, исключающая рекуррентные и сверточные слои для обработки последовательностей.;Модель для обработки текста, которая использует механизм внимания чтобы понимать контекст слов в предложении. Хорошо работает для переводов и анализа текстов.;5
Как ETL-пайплайны влияет на эффективность бизнеса?;Etl-пайплайны используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Etl-пайплайны используется для обработки информации и улучшения решений.;3
Почему технологии кластеризация данных стали критически важны?;Технологии кластеризация данных позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Эти технологии помогают работать с информацией и делать прогнозы.;3
Что такое Apache Iceberg?;Открытый табличный формат для больших данных с ACID транзакциями и версионированием.;Способ хранения данных в больших системах типа Hadoop.;2
Какие стратегии использовать для балансировки нагрузки в распределенных data processing системах?;Dynamic resource allocation, adaptive scheduling, data locality optimization, load-aware partitioning, auto-scaling based on metrics.;Динамическое распределение ресурсов, оптимизация расположения данных, интеллектуальное планирование задач и автоматическое масштабирование кластера.;4
Что такое data lake и чем он отличается от data warehouse?;Data lake хранит сырые данные в любом формате, data warehouse - структурированные и обработанные данные по заданной схеме. Data lake для exploration, data warehouse для отчетности.;Data lake - сырые данные любого типа, data warehouse - очищенные структурированные данные. Разные цели использования и подходы к хранению.;4
Что такое Data Lake?;Хранилище неструктурированных и полуструктурированных данных в исходном формате.;Место для хранения больших данных разных типов перед их обработкой.;3
Какие стратегии использовать для балансировки нагрузки в распределенных data processing системах?;Dynamic resource allocation, adaptive scheduling, data locality optimization, load-aware partitioning, auto-scaling based on metrics.;Динамическое распределение ресурсов, адаптивное планирование задач, оптимизация data locality, балансировка партиций и автоматическое масштабирование на основе метрик нагрузки.;5
Какие инструменты используются для работы с data warehouses?;Data warehouses используется для обработки больших объёмов информации, оптимизации бизнес?процессов и повышения качества аналитики. Сферы применения: финансы, медицина, промышленность, телекоммуникации.;Data warehouses применяется в финансах, медицине, рекламе и IT, помогает анализировать данные и строить модели.;4
Какие этапы включает разработка систем машинного обучения?;Сбор данных, подготовка и очистка, feature engineering, выбор модели, обучение, валидация, тестирование, развертывание, мониторинг.;Подготовка данных, создание признаков, обучение модели, оценка качества, внедрение в production.;4
Как выбрать оптимальную стратегию партиционирования данных в распределенной системе?;Выбор зависит от паттернов доступа: партиционирование по диапазону для range queries, по хэшу для равномерного распределения, по списку для категориальных данных. Учитывать размер партиций и частоту запросов.;Выбирать стратегию на основе типов запросов: range, hash или list partitioning. Учитывать распределение данных чтобы избежать перекоса и оптимизировать размер партиций.;4
Что такое data partitioning в Big Data?;Разделение данных на меньшие части для распределенной обработки и хранения, что улучшает производительность и управляемость;Способ работы с большими данными;2
Как работает алгоритм DBSCAN для кластеризации?;DBSCAN группирует точки в кластеры на основе плотности, выделяя core points, border points и noise, не требуя предварительного задания числа кластеров;Кластеризация по плотности;2
Разновидности сложных сетей;Однородные, масштабно-инвариантные, малого мира, иерархические, случайные сети;Классификация сложных сетей;4
Свойства эластичности и надежности сложных сетей.;Эластичность описывает способность сети сохранять функции при удалении вершин, надежность — устойчивость к отказам и атакам. Безмасштабные сети устойчивы к случайным сбоям, но уязвимы к целевым атакам.;Эластичность — способность сети оставаться работоспособной после сбоев, надежность — вероятность сохранения связности.;3
Что такое 'регрессия' в машинном обучении?;Регрессия — это метод моделирования зависимости между зависимой переменной и одной или несколькими независимыми переменными.;Регрессия — это просто анализ данных без формул.;2
Как организовать versioning для ML моделей в production?;Model registry, version metadata, A/B testing инфраструктура, rollback capabilities, dependency tracking, reproducibility guarantees.;Registry моделей, метаданные версий, A/B тесты. Отслеживание зависимостей и воспроизводимость.;4
Что такое большие данные и откуда они поступают?;Большие данные - огромные объемы структурированных и неструктурированных данных, которые невозможно обработать традиционными методами. Источники: соцсети, IoT устройства, транзакционные системы, сенсоры.;Большие объемы данных из разных источников: интернет, устройства, бизнес-системы. Требуют распределенной обработки.;4
Какие реальные кейсы демонстрируют эффективность машинное обучение?;Машинное обучение помогает обрабатывать большие массивы информации, выявлять скрытые паттерны, повышать точность прогнозов и снижать затраты. Используется в умных городах, здравоохранении, кибербезопасности.;Это просто работа с таблицами. Не очень полезно.;2
Что такое ETL процесс?;Процесс извлечения данных из источников, их преобразования в нужный формат и загрузки в целевую систему.;ETL (Extract, Transform, Load) - это процесс извлечения данных из различных источников, их преобразования (очистка, агрегация, обогащение) и загрузки в целевую систему хранения или витрину данных для дальнейшего анализа.;5
Что такое уровень значимости;"как он определяется, как влияет на решение о принятии гипотезы?,""Уровень значимости ? — вероятность ошибки первого рода (отклонение H0 при её истинности). Обычно ? = 0.05. Если p < ?, H0 отклоняется. Чем меньше ?, тем строже критерий.";Уровень значимости — это насколько уверены в данных.;3
Алгоритмы выделения сообществ;Основные алгоритмы для обнаружения сообществ в сложных сетях включают метод Louvain, алгоритм Girvan-Newman и метод распространения меток, которые используют различные подходы к выявлению групп тесно связанных узлов;Методы поиска групп узлов в сетевых структурах с высокой плотностью внутренних связей;2
Какие этапы включает разработка систем машинного обучения?;Сбор данных, подготовка и очистка, feature engineering, выбор модели, обучение, валидация, тестирование, развертывание, мониторинг.;Обработка данных, обучение модели, проверка точности, использование в реальной системе.;3
Для чего нужны партиции в Kafka;Партиции позволяют масштабировать обработку сообщений параллельно, распределяя нагрузку между несколькими потребителями. Каждая партиция гарантирует порядок сообщений.;Партиции обеспечивают горизонтальное масштабирование топиков, позволяя распределять данные по разным брокерам и обрабатывать их параллельно разными консьюмерами, сохраняя при этом порядок сообщений в пределах одной партиции.;4
В каких пропорциях рекомендуют разделять данные перед обучением и на какие части?;Обычно данные делятся на три части: обучающую 70%, валидационную 15% и тестовую 15%. Это обеспечивает корректную оценку модели без переобучения.;Разделяют на обучающую и тестовую выборки, примерно пополам.;3
Меры изменчивости;К мерам изменчивости относятся дисперсия, стандартное отклонение, размах и межквартильный размах;Меры изменчивости включают различные показатели разброса данных;5
Что понимается под 'стандартизацией данных'?;Стандартизация — это преобразование признаков таким образом, чтобы их среднее значение было равно нулю, а стандартное отклонение — единице.;Это когда данные делают одинаковыми для модели.;3
Что такое ARIMA модель?;Модель для прогнозирования временных рядов, учитывающая автокорреляцию и дифференцирование.;Статистическая модель для прогноза временных рядов, которая включает компоненты авторегрессии, дифференцирования и скользящего среднего для работы с нестационарными данными.;4
Что такое SMOTE?;Метод синтеза новых примеров для балансировки несбалансированных наборов данных.;Техника подготовки данных для машинного обучения когда классов мало.;2
Как развивается направление ETL-пайплайны в последние годы?;Технологии ETL-пайплайны позволяют работать с данными высокой скорости, разнообразия и объёма. Это улучшает прогнозирование, принятие решений и автоматизацию.;Etl-пайплайны нужно только программистам, обычным компаниям оно бесполезно.;2
Какие навыки необходимы специалисту для работы с модели прогнозирования?;Модели прогнозирования применяется в маркетинге, финансах, медицине, логистике, телекоммуникациях и промышленности. Примеры: прогнозирование, анализ поведения пользователей, автоматизация решений, выявление закономерностей.;Модели прогнозирования нужно только программистам.;2
Что такое Graph Neural Networks и для каких задач они превосходят традиционные подходы?;Нейросети для графовых данных, учитывающие связи между объектами. Превосходят в задачах с relational структурами: рекомендательные системы, drug discovery, social network analysis.;Нейросети для работы со связанными данными.;2
Что такое data governance в Big Data?;Управление доступностью, usability, integrity и security данных в организации;Контроль над данными в компании;3
Какие риски связаны с использованием рекомендательные системы в критически важных системах?;Рекомендательные системы используется для решения задач анализа данных, автоматизации процессов, построения прогностических моделей и оптимизации бизнеса. Применяется в e-commerce, банках, производстве и науке.;Рекомендательные системы нужно только программистам.;2
Что такое статистическая гипотеза? Какие виды гипотез вы знаете?;Статистическая гипотеза — это предположение о параметрах генеральной совокупности. Различают нулевую гипотезу H0 и альтернативную H1. Пример: H0: ?1 = ?2, H1: ?1 ? ?2.;Гипотеза — предположение, нулевая и альтернативная различаются по сути проверки.;4
Примеры использования гистограммы;Гистограммы применяются для анализа распределения яркости в обработке изображений, контроля качества в производстве через анализ распределения параметров продукции;Для анализа яркости изображений и контроля параметров продукции;4
